{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Full_Pipeline",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s26NMHDouSh"
      },
      "source": [
        "\n",
        "\n",
        "Code adapted from \"Custom Object Detection Using Tensorflow in Google Colab\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DirnTh9B4NEP"
      },
      "source": [
        "Installing tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iJiy4kJBJMe",
        "outputId": "872cfc45-25e8-4aea-e5a0-e8dc20019833"
      },
      "source": [
        "%tensorflow_version 1.x # Select module of the tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x # Select module of the tensorflow`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp3LZ7CMDo6B",
        "outputId": "4aa8b703-e4d1-45c3-ce80-011434895dc9"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-02 19:16:33--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 3.231.73.243, 54.174.143.90, 3.88.118.105, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|3.231.73.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  13.9MB/s    in 1.0s    \n",
            "\n",
            "2021-08-02 19:16:34 (13.9 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g83aRU0cDp3b",
        "outputId": "ccae52b5-769a-4f2a-f52b-6b4166bda801"
      },
      "source": [
        "#the logs that are created while training \n",
        "LOG_DIR = \"/root/models/trained\"\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "#The link to tensorboard.\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "IndexError: list index out of range\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvVBzPmLxiou",
        "outputId": "92257554-d186-474d-af72-13fda2a53aa2"
      },
      "source": [
        "!python -c 'import matplotlib as tf; print(tf.__version__)' # Check the version of the tensorflow\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYeFiM-WrJ25",
        "outputId": "5b02665f-2928-4b16-a6b3-1f67ee53ba81"
      },
      "source": [
        "%cd /root"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5HQjw8n4bA6"
      },
      "source": [
        "Cloning Object Detection Models from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUGwDKR62WpS",
        "outputId": "fcfa2f88-b4c5-4e3a-ced2-2417f0c2df86"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git # Import required files from the website\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 59568, done.\u001b[K\n",
            "remote: Counting objects: 100% (1048/1048), done.\u001b[K\n",
            "remote: Compressing objects: 100% (398/398), done.\u001b[K\n",
            "remote: Total 59568 (delta 709), reused 943 (delta 632), pack-reused 58520\u001b[K\n",
            "Receiving objects: 100% (59568/59568), 573.73 MiB | 25.41 MiB/s, done.\n",
            "Resolving deltas: 100% (41335/41335), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DiK5vm_4o1b"
      },
      "source": [
        "Testing a File in Cloned Object Detection File "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i7fbZ8XzuoC",
        "outputId": "a3bf9da0-96e4-4d06-d776-e9f01fa018f0"
      },
      "source": [
        "%cd /root/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!python setup.py build"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n",
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJtmMRYr8iPr"
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thMo1S6qAp1d",
        "outputId": "89f9302f-d0d9-4d07-efba-a03901ac7590"
      },
      "source": [
        "!pip install tf_slim"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 30.0 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 35.3 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 37.9 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 352 kB 15.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNNJ917V_hoe"
      },
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5YwT9Lf3mly",
        "outputId": "2ec5740f-9ad2-4738-a23c-67b59cd0b729"
      },
      "source": [
        "#!python3 --version\n",
        "\n",
        "!python -c 'import tensorflow as tf; print(tf.__version__)'"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVUIxcOP5R9o"
      },
      "source": [
        "Import Labelled Images from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI_9ceNWVYro",
        "outputId": "4dbc857c-23c4-4b9b-ec3e-4411b3f0904a"
      },
      "source": [
        "%cd /root/models/\n",
        "!git clone https://github.com/emurphy7/Odometer_project  "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models\n",
            "Cloning into 'Odometer_project'...\n",
            "remote: Enumerating objects: 119, done.\u001b[K\n",
            "remote: Counting objects: 100% (119/119), done.\u001b[K\n",
            "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
            "remote: Total 119 (delta 35), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (119/119), 72.35 MiB | 14.79 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QfWd_Lyi2etP",
        "outputId": "56c7adc9-e2f9-485e-f3db-21ad53030b95"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib\n",
        "import tarfile\n",
        "from requests import get\n",
        "source = '/root/models/Odometer_project/odometer'\n",
        "destination = '/root/models/'\n",
        "shutil.move('/root/models/Odometer_project/odometer',  '/root/models/') "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/models/odometer'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qpYUFw1cYoUP",
        "outputId": "9b81113c-1f80-4162-9543-49252eec9f5e"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/models'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuZwmzDaO1yR"
      },
      "source": [
        "# full Dataset\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JQykw5ea1Zt"
      },
      "source": [
        "#!cp -r /content/drive/MyDrive/ODOMETER_FILTERED /root/models/"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMLO-18or5Eo"
      },
      "source": [
        "#create train / test datasets ( Full dataset will just be uploaded from laptop)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(\"/root/models/Odometer_project/small_data/Odo_small_dataset.csv\")\n",
        "#df['split'] = np.random.randn(df.shape[0], 1)\n",
        "msk = np.random.rand(len(df)) <= 0.75\n",
        "\n",
        "train = df[msk]\n",
        "test = df[~msk]\n",
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uFOrl8zsCJ5"
      },
      "source": [
        "compression_opts = dict(method='zip',\n",
        "                        archive_name='train.csv') \n",
        "train.to_csv('train.zip', index=False,\n",
        "          compression=compression_opts) \n",
        "compression_opts = dict(method='zip',\n",
        "                        archive_name='test.csv') \n",
        "test.to_csv('test.zip', index=False,\n",
        "             compression=compression_opts) "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-57YiGosQGA",
        "outputId": "1a090fe5-b12f-4f40-ea8c-1efbc665aa56"
      },
      "source": [
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test.zip\n",
            "  inflating: test.csv                \n",
            "\n",
            "Archive:  train.zip\n",
            "  inflating: train.csv               \n",
            "\n",
            "2 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g72rx_l_sY7a"
      },
      "source": [
        "!cp -r /root/models/test.csv /root/models/odometer/data/test_labels.csv"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdKBfkn7sdNQ"
      },
      "source": [
        "!cp -r /root/models/train.csv /root/models/odometer/data/train_labels.csv"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqdD9Jfm2zki"
      },
      "source": [
        "Upload test and train csv files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTIjPgvvM3O4",
        "outputId": "db19df1e-75ba-495a-ec52-a1c8242bbc04"
      },
      "source": [
        "%cd /root/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "#!export PYTHONPATH=$PYTHONPATH: /usr/local/lib/python3.6/dist-packages/tensorflow/models/research/:/usr/local/lib/python3.6/dist-packages/tensorflow/models/research/slim\n",
        "#!pwd\n",
        "#!python /usr/local/lib/python3.6/dist-packages/tensorflow/models/research/object_detection/builders/model_builder_test.py\n",
        "#!python setup.py build\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n",
        "\"\"\"\n",
        "Usage:\n",
        "  # From tensorflow/models/\n",
        "  # Create train data:\n",
        "  python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record\n",
        "\n",
        "  # Create test data:\n",
        "  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record\n",
        "\"\"\"\n",
        "%cd /root/models/odometer/tfrecord\n",
        "# change path for full dataset\n",
        "!python generate_tfrecord.py --csv_input=/root/models/odometer/data/train_labels.csv  --output_path=train.record --image_dir=/root/models/Odometer_project/small_data/small_odometer_dataset\n",
        "!python generate_tfrecord.py --csv_input=/root/models/odometer/data/test_labels.csv  --output_path=test.record --image_dir=/root/models/Odometer_project/small_data/small_odometer_dataset\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n",
            "/root/models/odometer/tfrecord\n",
            "WARNING:tensorflow:From generate_tfrecord.py:101: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:87: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0802 19:17:27.421816 140424017340288 module_wrapper.py:139] From generate_tfrecord.py:87: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:46: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0802 19:17:27.430088 140424017340288 module_wrapper.py:139] From generate_tfrecord.py:46: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /root/models/odometer/tfrecord/train.record\n",
            "WARNING:tensorflow:From generate_tfrecord.py:101: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:87: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0802 19:17:29.618862 140460738996096 module_wrapper.py:139] From generate_tfrecord.py:87: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:46: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0802 19:17:29.629823 140460738996096 module_wrapper.py:139] From generate_tfrecord.py:46: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /root/models/odometer/tfrecord/test.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFXjiGuX57R-"
      },
      "source": [
        "Downloading Pre-trained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0D6p_3cg_Ex",
        "outputId": "52529c36-1161-487e-861e-0b8a62ec1342"
      },
      "source": [
        "#'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "#        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "#\n",
        "%cd ~/models\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib\n",
        "import tarfile\n",
        "from requests import get\n",
        "\n",
        "MODEL = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "  with open(MODEL_FILE, \"wb\") as file:\n",
        "    # get request\n",
        "    response = get(DOWNLOAD_BASE + MODEL_FILE)\n",
        "    # write to file\n",
        "    file.write(response.content)\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "i-duQErZ-0dk",
        "outputId": "7eb83ed5-6b87-4b9a-fccc-4535181d3724"
      },
      "source": [
        "# Move Config file to directory \"models\"\n",
        "shutil.move(\"/root/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\", \"/root/models\") "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/models/ssd_mobilenet_v2_coco.config'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywZpLKkd7HvC"
      },
      "source": [
        "Modifying the Config File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtag9ql0-eRs",
        "outputId": "a2af30ae-82fe-47a3-cee6-19c5e735cf71"
      },
      "source": [
        "%cd /root/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "#!export PYTHONPATH=$PYTHONPATH: /usr/local/lib/python3.6/dist-packages/tensorflow/models/research/:/usr/local/lib/python3.6/dist-packages/tensorflow/models/research/slim\n",
        "#!pwd\n",
        "#!python /usr/local/lib/python3.6/dist-packages/tensorflow/models/research/object_detection/builders/model_builder_test.py\n",
        "#!python setup.py build\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n",
        "\n",
        "# Edit Pipeline \n",
        "import tensorflow as tf\n",
        "from google.protobuf import text_format\n",
        "from object_detection.protos import pipeline_pb2\n",
        "\n",
        "pipeline = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
        "config_path = '/root/models/ssd_mobilenet_v2_coco.config'\n",
        "with tf.gfile.GFile( config_path, \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline)\n",
        "\n",
        "pipeline.train_input_reader.tf_record_input_reader.input_path[:] = ['/root/models/odometer/tfrecord/train.record'] \n",
        "pipeline.train_input_reader.label_map_path = '/root/models/odometer/data/object-detection.pbtxt'\n",
        "pipeline.eval_input_reader[0].tf_record_input_reader.input_path[:] = ['/root/models/odometer/tfrecord/test.record'] \n",
        "pipeline.eval_input_reader[0].label_map_path = '/root/models/odometer/data/object-detection.pbtxt'\n",
        "pipeline.train_config.fine_tune_checkpoint = '/root/models/pretrained_model/model.ckpt'\n",
        "pipeline.train_config.num_steps = 10000\n",
        "pipeline.model.ssd.num_classes = 1\n",
        "pipeline.eval_config.num_examples = len(test)\n",
        "\n",
        "config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        \n",
        "with tf.gfile.Open( config_path, \"wb\") as f:                                                                                                                                                                                                                       \n",
        "    f.write(config_text)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNn9BkBU7zGl"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFQY476vHsiZ",
        "outputId": "15d8040f-0b4b-4a96-8de9-d69e73dc822b"
      },
      "source": [
        "# Change into the models directory\n",
        "%cd /root/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n",
        "\n",
        "# Begin training\n",
        "!python /root/models/research/object_detection/legacy/train.py \\\n",
        "    --logtostderr \\\n",
        "    --train_dir=/root/models/trained \\\n",
        "    --pipeline_config_path=/root/models/ssd_mobilenet_v2_coco.config\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:tensorflow:global step 7513: loss = 0.7215 (0.231 sec/step)\n",
            "I0802 19:49:09.640462 140624834570112 learning.py:512] global step 7513: loss = 0.7215 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7514: loss = 0.7164 (0.236 sec/step)\n",
            "I0802 19:49:09.877508 140624834570112 learning.py:512] global step 7514: loss = 0.7164 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7515: loss = 0.5133 (0.243 sec/step)\n",
            "I0802 19:49:10.122313 140624834570112 learning.py:512] global step 7515: loss = 0.5133 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7516: loss = 0.6188 (0.248 sec/step)\n",
            "I0802 19:49:10.371601 140624834570112 learning.py:512] global step 7516: loss = 0.6188 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7517: loss = 0.6144 (0.235 sec/step)\n",
            "I0802 19:49:10.607661 140624834570112 learning.py:512] global step 7517: loss = 0.6144 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7518: loss = 0.9960 (0.233 sec/step)\n",
            "I0802 19:49:10.842018 140624834570112 learning.py:512] global step 7518: loss = 0.9960 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7519: loss = 0.5805 (0.251 sec/step)\n",
            "I0802 19:49:11.094030 140624834570112 learning.py:512] global step 7519: loss = 0.5805 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7520: loss = 0.5105 (0.246 sec/step)\n",
            "I0802 19:49:11.342052 140624834570112 learning.py:512] global step 7520: loss = 0.5105 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7521: loss = 0.6373 (0.262 sec/step)\n",
            "I0802 19:49:11.605780 140624834570112 learning.py:512] global step 7521: loss = 0.6373 (0.262 sec/step)\n",
            "INFO:tensorflow:global step 7522: loss = 0.7467 (0.247 sec/step)\n",
            "I0802 19:49:11.854214 140624834570112 learning.py:512] global step 7522: loss = 0.7467 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7523: loss = 0.7529 (0.253 sec/step)\n",
            "I0802 19:49:12.108888 140624834570112 learning.py:512] global step 7523: loss = 0.7529 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 7524: loss = 0.8808 (0.241 sec/step)\n",
            "I0802 19:49:12.351903 140624834570112 learning.py:512] global step 7524: loss = 0.8808 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7525: loss = 0.6700 (0.245 sec/step)\n",
            "I0802 19:49:12.598451 140624834570112 learning.py:512] global step 7525: loss = 0.6700 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7526: loss = 0.6324 (0.257 sec/step)\n",
            "I0802 19:49:12.856558 140624834570112 learning.py:512] global step 7526: loss = 0.6324 (0.257 sec/step)\n",
            "INFO:tensorflow:global step 7527: loss = 0.6676 (0.226 sec/step)\n",
            "I0802 19:49:13.084572 140624834570112 learning.py:512] global step 7527: loss = 0.6676 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 7528: loss = 0.5409 (0.244 sec/step)\n",
            "I0802 19:49:13.330482 140624834570112 learning.py:512] global step 7528: loss = 0.5409 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7529: loss = 0.7768 (0.234 sec/step)\n",
            "I0802 19:49:13.565753 140624834570112 learning.py:512] global step 7529: loss = 0.7768 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7530: loss = 0.6202 (0.244 sec/step)\n",
            "I0802 19:49:13.810830 140624834570112 learning.py:512] global step 7530: loss = 0.6202 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7531: loss = 0.6779 (0.241 sec/step)\n",
            "I0802 19:49:14.053613 140624834570112 learning.py:512] global step 7531: loss = 0.6779 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7532: loss = 0.8757 (0.249 sec/step)\n",
            "I0802 19:49:14.303700 140624834570112 learning.py:512] global step 7532: loss = 0.8757 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7533: loss = 0.9435 (0.250 sec/step)\n",
            "I0802 19:49:14.554955 140624834570112 learning.py:512] global step 7533: loss = 0.9435 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7534: loss = 0.8075 (0.242 sec/step)\n",
            "I0802 19:49:14.798508 140624834570112 learning.py:512] global step 7534: loss = 0.8075 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7535: loss = 0.9767 (0.251 sec/step)\n",
            "I0802 19:49:15.050843 140624834570112 learning.py:512] global step 7535: loss = 0.9767 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7536: loss = 0.8246 (0.243 sec/step)\n",
            "I0802 19:49:15.295561 140624834570112 learning.py:512] global step 7536: loss = 0.8246 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7537: loss = 0.8728 (0.249 sec/step)\n",
            "I0802 19:49:15.545851 140624834570112 learning.py:512] global step 7537: loss = 0.8728 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7538: loss = 0.6975 (0.250 sec/step)\n",
            "I0802 19:49:15.797708 140624834570112 learning.py:512] global step 7538: loss = 0.6975 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7539: loss = 0.7623 (0.250 sec/step)\n",
            "I0802 19:49:16.049416 140624834570112 learning.py:512] global step 7539: loss = 0.7623 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7540: loss = 0.7448 (0.245 sec/step)\n",
            "I0802 19:49:16.295516 140624834570112 learning.py:512] global step 7540: loss = 0.7448 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7541: loss = 0.7141 (0.247 sec/step)\n",
            "I0802 19:49:16.544491 140624834570112 learning.py:512] global step 7541: loss = 0.7141 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7542: loss = 0.7083 (0.242 sec/step)\n",
            "I0802 19:49:16.788197 140624834570112 learning.py:512] global step 7542: loss = 0.7083 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7543: loss = 0.5985 (0.241 sec/step)\n",
            "I0802 19:49:17.030253 140624834570112 learning.py:512] global step 7543: loss = 0.5985 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7544: loss = 0.6662 (0.253 sec/step)\n",
            "I0802 19:49:17.284676 140624834570112 learning.py:512] global step 7544: loss = 0.6662 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 7545: loss = 0.7971 (0.233 sec/step)\n",
            "I0802 19:49:17.518959 140624834570112 learning.py:512] global step 7545: loss = 0.7971 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7546: loss = 0.6941 (0.239 sec/step)\n",
            "I0802 19:49:17.758815 140624834570112 learning.py:512] global step 7546: loss = 0.6941 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7547: loss = 0.6784 (0.228 sec/step)\n",
            "I0802 19:49:17.987661 140624834570112 learning.py:512] global step 7547: loss = 0.6784 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7548: loss = 0.6353 (0.253 sec/step)\n",
            "I0802 19:49:18.242210 140624834570112 learning.py:512] global step 7548: loss = 0.6353 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 7549: loss = 0.7613 (0.249 sec/step)\n",
            "I0802 19:49:18.492466 140624834570112 learning.py:512] global step 7549: loss = 0.7613 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7550: loss = 0.8382 (0.240 sec/step)\n",
            "I0802 19:49:18.734226 140624834570112 learning.py:512] global step 7550: loss = 0.8382 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7551: loss = 0.5484 (0.247 sec/step)\n",
            "I0802 19:49:18.983054 140624834570112 learning.py:512] global step 7551: loss = 0.5484 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7552: loss = 0.6104 (0.243 sec/step)\n",
            "I0802 19:49:19.227812 140624834570112 learning.py:512] global step 7552: loss = 0.6104 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7553: loss = 0.6660 (0.257 sec/step)\n",
            "I0802 19:49:19.486485 140624834570112 learning.py:512] global step 7553: loss = 0.6660 (0.257 sec/step)\n",
            "INFO:tensorflow:global step 7554: loss = 0.8539 (0.241 sec/step)\n",
            "I0802 19:49:19.729266 140624834570112 learning.py:512] global step 7554: loss = 0.8539 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7555: loss = 0.7009 (0.249 sec/step)\n",
            "I0802 19:49:19.979616 140624834570112 learning.py:512] global step 7555: loss = 0.7009 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7556: loss = 0.6181 (0.248 sec/step)\n",
            "I0802 19:49:20.228789 140624834570112 learning.py:512] global step 7556: loss = 0.6181 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7557: loss = 0.8035 (0.242 sec/step)\n",
            "I0802 19:49:20.473021 140624834570112 learning.py:512] global step 7557: loss = 0.8035 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7558: loss = 0.6342 (0.251 sec/step)\n",
            "I0802 19:49:20.725690 140624834570112 learning.py:512] global step 7558: loss = 0.6342 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7559: loss = 0.6935 (0.247 sec/step)\n",
            "I0802 19:49:20.974570 140624834570112 learning.py:512] global step 7559: loss = 0.6935 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7560: loss = 0.6423 (0.232 sec/step)\n",
            "I0802 19:49:21.208234 140624834570112 learning.py:512] global step 7560: loss = 0.6423 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7561: loss = 0.6400 (0.235 sec/step)\n",
            "I0802 19:49:21.444636 140624834570112 learning.py:512] global step 7561: loss = 0.6400 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7562: loss = 0.5787 (0.245 sec/step)\n",
            "I0802 19:49:21.691202 140624834570112 learning.py:512] global step 7562: loss = 0.5787 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7563: loss = 0.8346 (0.234 sec/step)\n",
            "I0802 19:49:21.926893 140624834570112 learning.py:512] global step 7563: loss = 0.8346 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7564: loss = 0.6717 (0.235 sec/step)\n",
            "I0802 19:49:22.163811 140624834570112 learning.py:512] global step 7564: loss = 0.6717 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7565: loss = 1.1034 (0.244 sec/step)\n",
            "I0802 19:49:22.409400 140624834570112 learning.py:512] global step 7565: loss = 1.1034 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7566: loss = 0.7801 (0.230 sec/step)\n",
            "I0802 19:49:22.640689 140624834570112 learning.py:512] global step 7566: loss = 0.7801 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7567: loss = 0.7286 (0.247 sec/step)\n",
            "I0802 19:49:22.889585 140624834570112 learning.py:512] global step 7567: loss = 0.7286 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7568: loss = 0.7278 (0.242 sec/step)\n",
            "I0802 19:49:23.132896 140624834570112 learning.py:512] global step 7568: loss = 0.7278 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7569: loss = 0.5622 (0.245 sec/step)\n",
            "I0802 19:49:23.378991 140624834570112 learning.py:512] global step 7569: loss = 0.5622 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7570: loss = 0.7188 (0.244 sec/step)\n",
            "I0802 19:49:23.623870 140624834570112 learning.py:512] global step 7570: loss = 0.7188 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7571: loss = 0.6423 (0.248 sec/step)\n",
            "I0802 19:49:23.873104 140624834570112 learning.py:512] global step 7571: loss = 0.6423 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7572: loss = 0.6111 (0.250 sec/step)\n",
            "I0802 19:49:24.125138 140624834570112 learning.py:512] global step 7572: loss = 0.6111 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7573: loss = 0.7897 (0.246 sec/step)\n",
            "I0802 19:49:24.372764 140624834570112 learning.py:512] global step 7573: loss = 0.7897 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7574: loss = 0.6751 (0.233 sec/step)\n",
            "I0802 19:49:24.607098 140624834570112 learning.py:512] global step 7574: loss = 0.6751 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7575: loss = 0.7429 (0.243 sec/step)\n",
            "I0802 19:49:24.851180 140624834570112 learning.py:512] global step 7575: loss = 0.7429 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7576: loss = 0.9114 (0.248 sec/step)\n",
            "I0802 19:49:25.100418 140624834570112 learning.py:512] global step 7576: loss = 0.9114 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7577: loss = 0.9003 (0.229 sec/step)\n",
            "I0802 19:49:25.331240 140624834570112 learning.py:512] global step 7577: loss = 0.9003 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7578: loss = 0.8301 (0.249 sec/step)\n",
            "I0802 19:49:25.581912 140624834570112 learning.py:512] global step 7578: loss = 0.8301 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7579: loss = 0.5567 (0.234 sec/step)\n",
            "I0802 19:49:25.817485 140624834570112 learning.py:512] global step 7579: loss = 0.5567 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7580: loss = 0.7985 (0.234 sec/step)\n",
            "I0802 19:49:26.052847 140624834570112 learning.py:512] global step 7580: loss = 0.7985 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7581: loss = 1.1152 (0.245 sec/step)\n",
            "I0802 19:49:26.299516 140624834570112 learning.py:512] global step 7581: loss = 1.1152 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7582: loss = 0.8591 (0.247 sec/step)\n",
            "I0802 19:49:26.547791 140624834570112 learning.py:512] global step 7582: loss = 0.8591 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7583: loss = 0.5338 (0.245 sec/step)\n",
            "I0802 19:49:26.794133 140624834570112 learning.py:512] global step 7583: loss = 0.5338 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7584: loss = 0.5778 (0.250 sec/step)\n",
            "I0802 19:49:27.045582 140624834570112 learning.py:512] global step 7584: loss = 0.5778 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7585: loss = 0.7576 (0.244 sec/step)\n",
            "I0802 19:49:27.291056 140624834570112 learning.py:512] global step 7585: loss = 0.7576 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7586: loss = 0.7219 (0.251 sec/step)\n",
            "I0802 19:49:27.543981 140624834570112 learning.py:512] global step 7586: loss = 0.7219 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7587: loss = 0.6777 (0.248 sec/step)\n",
            "I0802 19:49:27.793105 140624834570112 learning.py:512] global step 7587: loss = 0.6777 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7588: loss = 0.9045 (0.243 sec/step)\n",
            "I0802 19:49:28.037607 140624834570112 learning.py:512] global step 7588: loss = 0.9045 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7589: loss = 0.7974 (0.242 sec/step)\n",
            "I0802 19:49:28.280673 140624834570112 learning.py:512] global step 7589: loss = 0.7974 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7590: loss = 1.0884 (0.232 sec/step)\n",
            "I0802 19:49:28.513905 140624834570112 learning.py:512] global step 7590: loss = 1.0884 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7591: loss = 0.7079 (0.247 sec/step)\n",
            "I0802 19:49:28.762064 140624834570112 learning.py:512] global step 7591: loss = 0.7079 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7592: loss = 0.6331 (0.249 sec/step)\n",
            "I0802 19:49:29.013091 140624834570112 learning.py:512] global step 7592: loss = 0.6331 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7593: loss = 0.8489 (0.240 sec/step)\n",
            "I0802 19:49:29.254631 140624834570112 learning.py:512] global step 7593: loss = 0.8489 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7594: loss = 0.6521 (0.240 sec/step)\n",
            "I0802 19:49:29.495794 140624834570112 learning.py:512] global step 7594: loss = 0.6521 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7595: loss = 1.0168 (0.235 sec/step)\n",
            "I0802 19:49:29.731954 140624834570112 learning.py:512] global step 7595: loss = 1.0168 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7596: loss = 0.7070 (0.239 sec/step)\n",
            "I0802 19:49:29.971914 140624834570112 learning.py:512] global step 7596: loss = 0.7070 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7597: loss = 0.8675 (0.246 sec/step)\n",
            "I0802 19:49:30.219201 140624834570112 learning.py:512] global step 7597: loss = 0.8675 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7598: loss = 0.6202 (0.235 sec/step)\n",
            "I0802 19:49:30.455376 140624834570112 learning.py:512] global step 7598: loss = 0.6202 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7599: loss = 1.1397 (0.237 sec/step)\n",
            "I0802 19:49:30.693786 140624834570112 learning.py:512] global step 7599: loss = 1.1397 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7600: loss = 0.7067 (0.240 sec/step)\n",
            "I0802 19:49:30.935099 140624834570112 learning.py:512] global step 7600: loss = 0.7067 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7601: loss = 0.7152 (0.230 sec/step)\n",
            "I0802 19:49:31.166033 140624834570112 learning.py:512] global step 7601: loss = 0.7152 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7602: loss = 0.7597 (0.242 sec/step)\n",
            "I0802 19:49:31.409605 140624834570112 learning.py:512] global step 7602: loss = 0.7597 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7603: loss = 0.8348 (0.246 sec/step)\n",
            "I0802 19:49:31.657282 140624834570112 learning.py:512] global step 7603: loss = 0.8348 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7604: loss = 0.7590 (0.224 sec/step)\n",
            "I0802 19:49:31.883161 140624834570112 learning.py:512] global step 7604: loss = 0.7590 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7605: loss = 0.6114 (0.232 sec/step)\n",
            "I0802 19:49:32.116818 140624834570112 learning.py:512] global step 7605: loss = 0.6114 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7606: loss = 0.9433 (0.244 sec/step)\n",
            "I0802 19:49:32.362473 140624834570112 learning.py:512] global step 7606: loss = 0.9433 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7607: loss = 1.1631 (0.234 sec/step)\n",
            "I0802 19:49:32.597821 140624834570112 learning.py:512] global step 7607: loss = 1.1631 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7608: loss = 0.8891 (0.236 sec/step)\n",
            "I0802 19:49:32.835372 140624834570112 learning.py:512] global step 7608: loss = 0.8891 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7609: loss = 0.8456 (0.238 sec/step)\n",
            "I0802 19:49:33.074601 140624834570112 learning.py:512] global step 7609: loss = 0.8456 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7610: loss = 0.7241 (0.243 sec/step)\n",
            "I0802 19:49:33.318747 140624834570112 learning.py:512] global step 7610: loss = 0.7241 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7611: loss = 0.7503 (0.243 sec/step)\n",
            "I0802 19:49:33.563309 140624834570112 learning.py:512] global step 7611: loss = 0.7503 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7612: loss = 0.6757 (0.238 sec/step)\n",
            "I0802 19:49:33.802374 140624834570112 learning.py:512] global step 7612: loss = 0.6757 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7613: loss = 0.6231 (0.238 sec/step)\n",
            "I0802 19:49:34.042191 140624834570112 learning.py:512] global step 7613: loss = 0.6231 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7614: loss = 0.6953 (0.234 sec/step)\n",
            "I0802 19:49:34.277201 140624834570112 learning.py:512] global step 7614: loss = 0.6953 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7615: loss = 0.6720 (0.227 sec/step)\n",
            "I0802 19:49:34.506058 140624834570112 learning.py:512] global step 7615: loss = 0.6720 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7616: loss = 0.7083 (0.241 sec/step)\n",
            "I0802 19:49:34.748872 140624834570112 learning.py:512] global step 7616: loss = 0.7083 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7617: loss = 0.6612 (0.239 sec/step)\n",
            "I0802 19:49:34.989487 140624834570112 learning.py:512] global step 7617: loss = 0.6612 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7618: loss = 0.8521 (0.237 sec/step)\n",
            "I0802 19:49:35.228144 140624834570112 learning.py:512] global step 7618: loss = 0.8521 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7619: loss = 0.7229 (0.252 sec/step)\n",
            "I0802 19:49:35.481611 140624834570112 learning.py:512] global step 7619: loss = 0.7229 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 7620: loss = 0.7834 (0.231 sec/step)\n",
            "I0802 19:49:35.714351 140624834570112 learning.py:512] global step 7620: loss = 0.7834 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7621: loss = 0.6581 (0.240 sec/step)\n",
            "I0802 19:49:35.955437 140624834570112 learning.py:512] global step 7621: loss = 0.6581 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7622: loss = 0.6429 (0.235 sec/step)\n",
            "I0802 19:49:36.191329 140624834570112 learning.py:512] global step 7622: loss = 0.6429 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7623: loss = 0.7739 (0.244 sec/step)\n",
            "I0802 19:49:36.437067 140624834570112 learning.py:512] global step 7623: loss = 0.7739 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7624: loss = 0.6313 (0.252 sec/step)\n",
            "I0802 19:49:36.690167 140624834570112 learning.py:512] global step 7624: loss = 0.6313 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 7625: loss = 0.6577 (0.241 sec/step)\n",
            "I0802 19:49:36.932295 140624834570112 learning.py:512] global step 7625: loss = 0.6577 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7626: loss = 0.7654 (0.243 sec/step)\n",
            "I0802 19:49:37.176721 140624834570112 learning.py:512] global step 7626: loss = 0.7654 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7627: loss = 0.6982 (0.244 sec/step)\n",
            "I0802 19:49:37.422399 140624834570112 learning.py:512] global step 7627: loss = 0.6982 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7628: loss = 0.7479 (0.242 sec/step)\n",
            "I0802 19:49:37.665459 140624834570112 learning.py:512] global step 7628: loss = 0.7479 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7629: loss = 0.7105 (0.240 sec/step)\n",
            "I0802 19:49:37.907114 140624834570112 learning.py:512] global step 7629: loss = 0.7105 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7630: loss = 0.6834 (0.227 sec/step)\n",
            "I0802 19:49:38.135411 140624834570112 learning.py:512] global step 7630: loss = 0.6834 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7631: loss = 0.6504 (0.242 sec/step)\n",
            "I0802 19:49:38.379234 140624834570112 learning.py:512] global step 7631: loss = 0.6504 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7632: loss = 0.8634 (0.242 sec/step)\n",
            "I0802 19:49:38.623081 140624834570112 learning.py:512] global step 7632: loss = 0.8634 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7633: loss = 0.7919 (0.225 sec/step)\n",
            "I0802 19:49:38.849152 140624834570112 learning.py:512] global step 7633: loss = 0.7919 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7634: loss = 0.7026 (0.238 sec/step)\n",
            "I0802 19:49:39.088812 140624834570112 learning.py:512] global step 7634: loss = 0.7026 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7635: loss = 0.8829 (0.243 sec/step)\n",
            "I0802 19:49:39.332865 140624834570112 learning.py:512] global step 7635: loss = 0.8829 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7636: loss = 0.6675 (0.241 sec/step)\n",
            "I0802 19:49:39.575684 140624834570112 learning.py:512] global step 7636: loss = 0.6675 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7637: loss = 0.5189 (0.251 sec/step)\n",
            "I0802 19:49:39.828559 140624834570112 learning.py:512] global step 7637: loss = 0.5189 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7638: loss = 0.6997 (0.228 sec/step)\n",
            "I0802 19:49:40.057521 140624834570112 learning.py:512] global step 7638: loss = 0.6997 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7639: loss = 0.7768 (0.248 sec/step)\n",
            "I0802 19:49:40.309216 140624834570112 learning.py:512] global step 7639: loss = 0.7768 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7640: loss = 0.6512 (0.247 sec/step)\n",
            "I0802 19:49:40.557863 140624834570112 learning.py:512] global step 7640: loss = 0.6512 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7641: loss = 0.6903 (0.236 sec/step)\n",
            "I0802 19:49:40.795753 140624834570112 learning.py:512] global step 7641: loss = 0.6903 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7642: loss = 0.7963 (0.247 sec/step)\n",
            "I0802 19:49:41.044882 140624834570112 learning.py:512] global step 7642: loss = 0.7963 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7643: loss = 0.9381 (0.233 sec/step)\n",
            "I0802 19:49:41.280018 140624834570112 learning.py:512] global step 7643: loss = 0.9381 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7644: loss = 0.6603 (0.231 sec/step)\n",
            "I0802 19:49:41.512315 140624834570112 learning.py:512] global step 7644: loss = 0.6603 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7645: loss = 0.8159 (0.242 sec/step)\n",
            "I0802 19:49:41.755535 140624834570112 learning.py:512] global step 7645: loss = 0.8159 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7646: loss = 0.5911 (0.237 sec/step)\n",
            "I0802 19:49:41.994404 140624834570112 learning.py:512] global step 7646: loss = 0.5911 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7647: loss = 0.7465 (0.233 sec/step)\n",
            "I0802 19:49:42.228727 140624834570112 learning.py:512] global step 7647: loss = 0.7465 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7648: loss = 0.8741 (0.233 sec/step)\n",
            "I0802 19:49:42.463215 140624834570112 learning.py:512] global step 7648: loss = 0.8741 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7649: loss = 0.6388 (0.241 sec/step)\n",
            "I0802 19:49:42.705321 140624834570112 learning.py:512] global step 7649: loss = 0.6388 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7650: loss = 0.5798 (0.243 sec/step)\n",
            "I0802 19:49:42.950309 140624834570112 learning.py:512] global step 7650: loss = 0.5798 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7651: loss = 0.4806 (0.248 sec/step)\n",
            "I0802 19:49:43.199820 140624834570112 learning.py:512] global step 7651: loss = 0.4806 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7652: loss = 0.6914 (0.238 sec/step)\n",
            "I0802 19:49:43.439194 140624834570112 learning.py:512] global step 7652: loss = 0.6914 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7653: loss = 0.6114 (0.223 sec/step)\n",
            "I0802 19:49:43.663463 140624834570112 learning.py:512] global step 7653: loss = 0.6114 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 7654: loss = 0.6124 (0.227 sec/step)\n",
            "I0802 19:49:43.892364 140624834570112 learning.py:512] global step 7654: loss = 0.6124 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7655: loss = 0.7735 (0.232 sec/step)\n",
            "I0802 19:49:44.125890 140624834570112 learning.py:512] global step 7655: loss = 0.7735 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7656: loss = 0.8317 (0.235 sec/step)\n",
            "I0802 19:49:44.361938 140624834570112 learning.py:512] global step 7656: loss = 0.8317 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7657: loss = 0.7540 (0.240 sec/step)\n",
            "I0802 19:49:44.603103 140624834570112 learning.py:512] global step 7657: loss = 0.7540 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7658: loss = 0.5658 (0.233 sec/step)\n",
            "I0802 19:49:44.837680 140624834570112 learning.py:512] global step 7658: loss = 0.5658 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7659: loss = 0.8766 (0.231 sec/step)\n",
            "I0802 19:49:45.069536 140624834570112 learning.py:512] global step 7659: loss = 0.8766 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7660: loss = 0.8234 (0.238 sec/step)\n",
            "I0802 19:49:45.308861 140624834570112 learning.py:512] global step 7660: loss = 0.8234 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7661: loss = 0.9239 (0.244 sec/step)\n",
            "I0802 19:49:45.554743 140624834570112 learning.py:512] global step 7661: loss = 0.9239 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7662: loss = 0.9391 (0.227 sec/step)\n",
            "I0802 19:49:45.782904 140624834570112 learning.py:512] global step 7662: loss = 0.9391 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7663: loss = 0.5681 (0.252 sec/step)\n",
            "I0802 19:49:46.036334 140624834570112 learning.py:512] global step 7663: loss = 0.5681 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 7664: loss = 0.5791 (0.247 sec/step)\n",
            "I0802 19:49:46.284657 140624834570112 learning.py:512] global step 7664: loss = 0.5791 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7665: loss = 0.5556 (0.238 sec/step)\n",
            "I0802 19:49:46.524474 140624834570112 learning.py:512] global step 7665: loss = 0.5556 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7666: loss = 0.7210 (0.237 sec/step)\n",
            "I0802 19:49:46.762413 140624834570112 learning.py:512] global step 7666: loss = 0.7210 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7667: loss = 0.8953 (0.242 sec/step)\n",
            "I0802 19:49:47.005585 140624834570112 learning.py:512] global step 7667: loss = 0.8953 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7668: loss = 0.7240 (0.257 sec/step)\n",
            "I0802 19:49:47.263856 140624834570112 learning.py:512] global step 7668: loss = 0.7240 (0.257 sec/step)\n",
            "INFO:tensorflow:global step 7669: loss = 0.6163 (0.239 sec/step)\n",
            "I0802 19:49:47.504336 140624834570112 learning.py:512] global step 7669: loss = 0.6163 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7670: loss = 0.7230 (0.229 sec/step)\n",
            "I0802 19:49:47.734578 140624834570112 learning.py:512] global step 7670: loss = 0.7230 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7671: loss = 0.6542 (0.238 sec/step)\n",
            "I0802 19:49:47.974438 140624834570112 learning.py:512] global step 7671: loss = 0.6542 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7672: loss = 0.5741 (0.244 sec/step)\n",
            "I0802 19:49:48.220169 140624834570112 learning.py:512] global step 7672: loss = 0.5741 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7673: loss = 0.8613 (0.229 sec/step)\n",
            "I0802 19:49:48.450382 140624834570112 learning.py:512] global step 7673: loss = 0.8613 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7674: loss = 0.5778 (0.240 sec/step)\n",
            "I0802 19:49:48.691970 140624834570112 learning.py:512] global step 7674: loss = 0.5778 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7675: loss = 0.8923 (0.242 sec/step)\n",
            "I0802 19:49:48.935688 140624834570112 learning.py:512] global step 7675: loss = 0.8923 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7676: loss = 0.6525 (0.244 sec/step)\n",
            "I0802 19:49:49.181299 140624834570112 learning.py:512] global step 7676: loss = 0.6525 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7677: loss = 0.7259 (0.236 sec/step)\n",
            "I0802 19:49:49.419211 140624834570112 learning.py:512] global step 7677: loss = 0.7259 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7678: loss = 0.6385 (0.239 sec/step)\n",
            "I0802 19:49:49.659559 140624834570112 learning.py:512] global step 7678: loss = 0.6385 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7679: loss = 0.9357 (0.243 sec/step)\n",
            "I0802 19:49:49.903727 140624834570112 learning.py:512] global step 7679: loss = 0.9357 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7680: loss = 0.7588 (0.243 sec/step)\n",
            "I0802 19:49:50.148690 140624834570112 learning.py:512] global step 7680: loss = 0.7588 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7681: loss = 0.8749 (0.242 sec/step)\n",
            "I0802 19:49:50.392593 140624834570112 learning.py:512] global step 7681: loss = 0.8749 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7682: loss = 0.8021 (0.227 sec/step)\n",
            "I0802 19:49:50.620899 140624834570112 learning.py:512] global step 7682: loss = 0.8021 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7683: loss = 0.6364 (0.232 sec/step)\n",
            "I0802 19:49:50.854533 140624834570112 learning.py:512] global step 7683: loss = 0.6364 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7684: loss = 1.0479 (0.238 sec/step)\n",
            "I0802 19:49:51.094169 140624834570112 learning.py:512] global step 7684: loss = 1.0479 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7685: loss = 0.8172 (0.235 sec/step)\n",
            "I0802 19:49:51.330758 140624834570112 learning.py:512] global step 7685: loss = 0.8172 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7686: loss = 0.7069 (0.243 sec/step)\n",
            "I0802 19:49:51.575355 140624834570112 learning.py:512] global step 7686: loss = 0.7069 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7687: loss = 0.5834 (0.230 sec/step)\n",
            "I0802 19:49:51.807255 140624834570112 learning.py:512] global step 7687: loss = 0.5834 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7688: loss = 0.8717 (0.227 sec/step)\n",
            "I0802 19:49:52.036150 140624834570112 learning.py:512] global step 7688: loss = 0.8717 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7689: loss = 0.6745 (0.251 sec/step)\n",
            "I0802 19:49:52.288794 140624834570112 learning.py:512] global step 7689: loss = 0.6745 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7690: loss = 0.7914 (0.248 sec/step)\n",
            "I0802 19:49:52.538790 140624834570112 learning.py:512] global step 7690: loss = 0.7914 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7691: loss = 0.6839 (0.245 sec/step)\n",
            "I0802 19:49:52.784783 140624834570112 learning.py:512] global step 7691: loss = 0.6839 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7692: loss = 0.7591 (0.247 sec/step)\n",
            "I0802 19:49:53.033020 140624834570112 learning.py:512] global step 7692: loss = 0.7591 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7693: loss = 0.7075 (0.243 sec/step)\n",
            "I0802 19:49:53.278058 140624834570112 learning.py:512] global step 7693: loss = 0.7075 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7694: loss = 0.7396 (0.246 sec/step)\n",
            "I0802 19:49:53.525714 140624834570112 learning.py:512] global step 7694: loss = 0.7396 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7695: loss = 0.7674 (0.240 sec/step)\n",
            "I0802 19:49:53.767176 140624834570112 learning.py:512] global step 7695: loss = 0.7674 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7696: loss = 0.6026 (0.250 sec/step)\n",
            "I0802 19:49:54.018329 140624834570112 learning.py:512] global step 7696: loss = 0.6026 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7697: loss = 0.4947 (0.228 sec/step)\n",
            "I0802 19:49:54.247780 140624834570112 learning.py:512] global step 7697: loss = 0.4947 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7698: loss = 0.6816 (0.238 sec/step)\n",
            "I0802 19:49:54.487199 140624834570112 learning.py:512] global step 7698: loss = 0.6816 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7699: loss = 0.6542 (0.229 sec/step)\n",
            "I0802 19:49:54.717851 140624834570112 learning.py:512] global step 7699: loss = 0.6542 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7700: loss = 0.7231 (0.232 sec/step)\n",
            "I0802 19:49:54.951524 140624834570112 learning.py:512] global step 7700: loss = 0.7231 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7701: loss = 0.9819 (0.247 sec/step)\n",
            "I0802 19:49:55.200156 140624834570112 learning.py:512] global step 7701: loss = 0.9819 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7702: loss = 0.6466 (0.242 sec/step)\n",
            "I0802 19:49:55.443454 140624834570112 learning.py:512] global step 7702: loss = 0.6466 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7703: loss = 0.6522 (0.226 sec/step)\n",
            "I0802 19:49:55.670580 140624834570112 learning.py:512] global step 7703: loss = 0.6522 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 7704: loss = 0.5979 (0.249 sec/step)\n",
            "I0802 19:49:55.921056 140624834570112 learning.py:512] global step 7704: loss = 0.5979 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7705: loss = 0.9433 (0.245 sec/step)\n",
            "I0802 19:49:56.167623 140624834570112 learning.py:512] global step 7705: loss = 0.9433 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7706: loss = 0.7528 (0.241 sec/step)\n",
            "I0802 19:49:56.410062 140624834570112 learning.py:512] global step 7706: loss = 0.7528 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7707: loss = 0.8975 (0.237 sec/step)\n",
            "I0802 19:49:56.648199 140624834570112 learning.py:512] global step 7707: loss = 0.8975 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7708: loss = 0.8281 (0.243 sec/step)\n",
            "I0802 19:49:56.892515 140624834570112 learning.py:512] global step 7708: loss = 0.8281 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7709: loss = 0.6775 (0.242 sec/step)\n",
            "I0802 19:49:57.135584 140624834570112 learning.py:512] global step 7709: loss = 0.6775 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7710: loss = 0.7657 (0.238 sec/step)\n",
            "I0802 19:49:57.375237 140624834570112 learning.py:512] global step 7710: loss = 0.7657 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7711: loss = 0.8247 (0.232 sec/step)\n",
            "I0802 19:49:57.608878 140624834570112 learning.py:512] global step 7711: loss = 0.8247 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7712: loss = 0.6716 (0.242 sec/step)\n",
            "I0802 19:49:57.852125 140624834570112 learning.py:512] global step 7712: loss = 0.6716 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7713: loss = 0.7074 (0.242 sec/step)\n",
            "I0802 19:49:58.095959 140624834570112 learning.py:512] global step 7713: loss = 0.7074 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7714: loss = 0.6428 (0.247 sec/step)\n",
            "I0802 19:49:58.344123 140624834570112 learning.py:512] global step 7714: loss = 0.6428 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7715: loss = 0.8690 (0.227 sec/step)\n",
            "I0802 19:49:58.572787 140624834570112 learning.py:512] global step 7715: loss = 0.8690 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7716: loss = 0.7134 (0.242 sec/step)\n",
            "I0802 19:49:58.816506 140624834570112 learning.py:512] global step 7716: loss = 0.7134 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7717: loss = 0.6961 (0.245 sec/step)\n",
            "I0802 19:49:59.063888 140624834570112 learning.py:512] global step 7717: loss = 0.6961 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7718: loss = 0.6560 (0.239 sec/step)\n",
            "I0802 19:49:59.304447 140624834570112 learning.py:512] global step 7718: loss = 0.6560 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7719: loss = 0.7304 (0.250 sec/step)\n",
            "I0802 19:49:59.555332 140624834570112 learning.py:512] global step 7719: loss = 0.7304 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7720: loss = 0.8401 (0.239 sec/step)\n",
            "I0802 19:49:59.795681 140624834570112 learning.py:512] global step 7720: loss = 0.8401 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7721: loss = 0.7696 (0.233 sec/step)\n",
            "I0802 19:50:00.029809 140624834570112 learning.py:512] global step 7721: loss = 0.7696 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7722: loss = 1.0454 (0.230 sec/step)\n",
            "I0802 19:50:00.261521 140624834570112 learning.py:512] global step 7722: loss = 1.0454 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7723: loss = 0.6963 (0.235 sec/step)\n",
            "I0802 19:50:00.497642 140624834570112 learning.py:512] global step 7723: loss = 0.6963 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7724: loss = 0.7797 (0.229 sec/step)\n",
            "I0802 19:50:00.728291 140624834570112 learning.py:512] global step 7724: loss = 0.7797 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7725: loss = 0.7339 (0.231 sec/step)\n",
            "I0802 19:50:00.960813 140624834570112 learning.py:512] global step 7725: loss = 0.7339 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7726: loss = 0.8601 (0.241 sec/step)\n",
            "I0802 19:50:01.203112 140624834570112 learning.py:512] global step 7726: loss = 0.8601 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7727: loss = 0.6774 (0.246 sec/step)\n",
            "I0802 19:50:01.451004 140624834570112 learning.py:512] global step 7727: loss = 0.6774 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7728: loss = 0.7078 (0.239 sec/step)\n",
            "I0802 19:50:01.691148 140624834570112 learning.py:512] global step 7728: loss = 0.7078 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7729: loss = 0.9323 (0.242 sec/step)\n",
            "I0802 19:50:01.934834 140624834570112 learning.py:512] global step 7729: loss = 0.9323 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7730: loss = 0.7343 (0.233 sec/step)\n",
            "I0802 19:50:02.168974 140624834570112 learning.py:512] global step 7730: loss = 0.7343 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7731: loss = 0.6346 (0.243 sec/step)\n",
            "I0802 19:50:02.413326 140624834570112 learning.py:512] global step 7731: loss = 0.6346 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7732: loss = 0.5708 (0.241 sec/step)\n",
            "I0802 19:50:02.655632 140624834570112 learning.py:512] global step 7732: loss = 0.5708 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7733: loss = 0.6284 (0.242 sec/step)\n",
            "I0802 19:50:02.898567 140624834570112 learning.py:512] global step 7733: loss = 0.6284 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7734: loss = 0.9045 (0.230 sec/step)\n",
            "I0802 19:50:03.130357 140624834570112 learning.py:512] global step 7734: loss = 0.9045 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7735: loss = 0.7788 (0.242 sec/step)\n",
            "I0802 19:50:03.373469 140624834570112 learning.py:512] global step 7735: loss = 0.7788 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7736: loss = 0.8271 (0.237 sec/step)\n",
            "I0802 19:50:03.612259 140624834570112 learning.py:512] global step 7736: loss = 0.8271 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7737: loss = 0.7774 (0.247 sec/step)\n",
            "I0802 19:50:03.861318 140624834570112 learning.py:512] global step 7737: loss = 0.7774 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7738: loss = 0.8309 (0.241 sec/step)\n",
            "I0802 19:50:04.103655 140624834570112 learning.py:512] global step 7738: loss = 0.8309 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7739: loss = 0.5570 (0.245 sec/step)\n",
            "I0802 19:50:04.349812 140624834570112 learning.py:512] global step 7739: loss = 0.5570 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7740: loss = 0.7623 (0.243 sec/step)\n",
            "I0802 19:50:04.594570 140624834570112 learning.py:512] global step 7740: loss = 0.7623 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7741: loss = 0.7440 (0.237 sec/step)\n",
            "I0802 19:50:04.832827 140624834570112 learning.py:512] global step 7741: loss = 0.7440 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7742: loss = 0.6053 (0.252 sec/step)\n",
            "I0802 19:50:05.086464 140624834570112 learning.py:512] global step 7742: loss = 0.6053 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 7743: loss = 0.6485 (0.241 sec/step)\n",
            "I0802 19:50:05.329179 140624834570112 learning.py:512] global step 7743: loss = 0.6485 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7744: loss = 0.7824 (0.235 sec/step)\n",
            "I0802 19:50:05.565212 140624834570112 learning.py:512] global step 7744: loss = 0.7824 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7745: loss = 0.7438 (0.246 sec/step)\n",
            "I0802 19:50:05.812282 140624834570112 learning.py:512] global step 7745: loss = 0.7438 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7746: loss = 0.7706 (0.232 sec/step)\n",
            "I0802 19:50:06.046172 140624834570112 learning.py:512] global step 7746: loss = 0.7706 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7747: loss = 0.7130 (0.231 sec/step)\n",
            "I0802 19:50:06.278708 140624834570112 learning.py:512] global step 7747: loss = 0.7130 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7748: loss = 0.6871 (0.240 sec/step)\n",
            "I0802 19:50:06.520246 140624834570112 learning.py:512] global step 7748: loss = 0.6871 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7749: loss = 0.6476 (0.243 sec/step)\n",
            "I0802 19:50:06.764850 140624834570112 learning.py:512] global step 7749: loss = 0.6476 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7750: loss = 0.5686 (0.236 sec/step)\n",
            "I0802 19:50:07.002176 140624834570112 learning.py:512] global step 7750: loss = 0.5686 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7751: loss = 0.8620 (0.229 sec/step)\n",
            "I0802 19:50:07.232448 140624834570112 learning.py:512] global step 7751: loss = 0.8620 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7752: loss = 0.7206 (0.235 sec/step)\n",
            "I0802 19:50:07.468459 140624834570112 learning.py:512] global step 7752: loss = 0.7206 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7753: loss = 0.6053 (0.250 sec/step)\n",
            "I0802 19:50:07.719542 140624834570112 learning.py:512] global step 7753: loss = 0.6053 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7754: loss = 0.7230 (0.247 sec/step)\n",
            "I0802 19:50:07.967973 140624834570112 learning.py:512] global step 7754: loss = 0.7230 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7755: loss = 0.7464 (0.240 sec/step)\n",
            "I0802 19:50:08.209682 140624834570112 learning.py:512] global step 7755: loss = 0.7464 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7756: loss = 0.7085 (0.244 sec/step)\n",
            "I0802 19:50:08.455470 140624834570112 learning.py:512] global step 7756: loss = 0.7085 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7757: loss = 0.8347 (0.243 sec/step)\n",
            "I0802 19:50:08.699420 140624834570112 learning.py:512] global step 7757: loss = 0.8347 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7758: loss = 0.6715 (0.242 sec/step)\n",
            "I0802 19:50:08.943211 140624834570112 learning.py:512] global step 7758: loss = 0.6715 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7759: loss = 0.5736 (0.240 sec/step)\n",
            "I0802 19:50:09.185012 140624834570112 learning.py:512] global step 7759: loss = 0.5736 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7760: loss = 0.8682 (0.246 sec/step)\n",
            "I0802 19:50:09.432458 140624834570112 learning.py:512] global step 7760: loss = 0.8682 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7761: loss = 0.7488 (0.240 sec/step)\n",
            "I0802 19:50:09.673878 140624834570112 learning.py:512] global step 7761: loss = 0.7488 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7762: loss = 0.8142 (0.248 sec/step)\n",
            "I0802 19:50:09.923486 140624834570112 learning.py:512] global step 7762: loss = 0.8142 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7763: loss = 0.8914 (0.227 sec/step)\n",
            "I0802 19:50:10.151326 140624834570112 learning.py:512] global step 7763: loss = 0.8914 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7764: loss = 0.5712 (0.242 sec/step)\n",
            "I0802 19:50:10.394369 140624834570112 learning.py:512] global step 7764: loss = 0.5712 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7765: loss = 0.7673 (0.245 sec/step)\n",
            "I0802 19:50:10.640566 140624834570112 learning.py:512] global step 7765: loss = 0.7673 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7766: loss = 0.7818 (0.234 sec/step)\n",
            "I0802 19:50:10.875740 140624834570112 learning.py:512] global step 7766: loss = 0.7818 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7767: loss = 0.8776 (0.238 sec/step)\n",
            "I0802 19:50:11.115464 140624834570112 learning.py:512] global step 7767: loss = 0.8776 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7768: loss = 0.6646 (0.229 sec/step)\n",
            "I0802 19:50:11.345952 140624834570112 learning.py:512] global step 7768: loss = 0.6646 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7769: loss = 0.9117 (0.230 sec/step)\n",
            "I0802 19:50:11.577961 140624834570112 learning.py:512] global step 7769: loss = 0.9117 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7770: loss = 0.7331 (0.251 sec/step)\n",
            "I0802 19:50:11.830191 140624834570112 learning.py:512] global step 7770: loss = 0.7331 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7771: loss = 0.7923 (0.243 sec/step)\n",
            "I0802 19:50:12.074370 140624834570112 learning.py:512] global step 7771: loss = 0.7923 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7772: loss = 0.5868 (0.243 sec/step)\n",
            "I0802 19:50:12.319071 140624834570112 learning.py:512] global step 7772: loss = 0.5868 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7773: loss = 0.5658 (0.258 sec/step)\n",
            "I0802 19:50:12.580364 140624834570112 learning.py:512] global step 7773: loss = 0.5658 (0.258 sec/step)\n",
            "INFO:tensorflow:global step 7774: loss = 0.6609 (0.253 sec/step)\n",
            "I0802 19:50:12.834839 140624834570112 learning.py:512] global step 7774: loss = 0.6609 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 7775: loss = 0.6265 (0.243 sec/step)\n",
            "I0802 19:50:13.079824 140624834570112 learning.py:512] global step 7775: loss = 0.6265 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7776: loss = 0.7569 (0.246 sec/step)\n",
            "I0802 19:50:13.327240 140624834570112 learning.py:512] global step 7776: loss = 0.7569 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7777: loss = 0.5684 (0.255 sec/step)\n",
            "I0802 19:50:13.584337 140624834570112 learning.py:512] global step 7777: loss = 0.5684 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 7778: loss = 0.9664 (0.247 sec/step)\n",
            "I0802 19:50:13.832976 140624834570112 learning.py:512] global step 7778: loss = 0.9664 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7779: loss = 0.7498 (0.244 sec/step)\n",
            "I0802 19:50:14.079560 140624834570112 learning.py:512] global step 7779: loss = 0.7498 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7780: loss = 0.5994 (0.235 sec/step)\n",
            "I0802 19:50:14.316027 140624834570112 learning.py:512] global step 7780: loss = 0.5994 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7781: loss = 0.7336 (0.240 sec/step)\n",
            "I0802 19:50:14.558033 140624834570112 learning.py:512] global step 7781: loss = 0.7336 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7782: loss = 0.6985 (0.242 sec/step)\n",
            "I0802 19:50:14.802285 140624834570112 learning.py:512] global step 7782: loss = 0.6985 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7783: loss = 0.6245 (0.300 sec/step)\n",
            "I0802 19:50:15.106388 140624834570112 learning.py:512] global step 7783: loss = 0.6245 (0.300 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 7783.\n",
            "I0802 19:50:15.263290 140620445013760 supervisor.py:1050] Recording summary at step 7783.\n",
            "INFO:tensorflow:global step 7784: loss = 0.5509 (0.278 sec/step)\n",
            "I0802 19:50:15.386165 140624834570112 learning.py:512] global step 7784: loss = 0.5509 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 7785: loss = 0.7361 (0.249 sec/step)\n",
            "I0802 19:50:15.636274 140624834570112 learning.py:512] global step 7785: loss = 0.7361 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7786: loss = 0.6107 (0.251 sec/step)\n",
            "I0802 19:50:15.888789 140624834570112 learning.py:512] global step 7786: loss = 0.6107 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7787: loss = 0.6478 (0.231 sec/step)\n",
            "I0802 19:50:16.121375 140624834570112 learning.py:512] global step 7787: loss = 0.6478 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7788: loss = 0.7636 (0.245 sec/step)\n",
            "I0802 19:50:16.367821 140624834570112 learning.py:512] global step 7788: loss = 0.7636 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7789: loss = 0.7561 (0.244 sec/step)\n",
            "I0802 19:50:16.613200 140624834570112 learning.py:512] global step 7789: loss = 0.7561 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7790: loss = 0.6796 (0.251 sec/step)\n",
            "I0802 19:50:16.865772 140624834570112 learning.py:512] global step 7790: loss = 0.6796 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7791: loss = 0.6807 (0.248 sec/step)\n",
            "I0802 19:50:17.115247 140624834570112 learning.py:512] global step 7791: loss = 0.6807 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7792: loss = 0.8529 (0.251 sec/step)\n",
            "I0802 19:50:17.367524 140624834570112 learning.py:512] global step 7792: loss = 0.8529 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7793: loss = 0.5801 (0.249 sec/step)\n",
            "I0802 19:50:17.617530 140624834570112 learning.py:512] global step 7793: loss = 0.5801 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7794: loss = 0.7426 (0.247 sec/step)\n",
            "I0802 19:50:17.865683 140624834570112 learning.py:512] global step 7794: loss = 0.7426 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7795: loss = 0.9295 (0.241 sec/step)\n",
            "I0802 19:50:18.108254 140624834570112 learning.py:512] global step 7795: loss = 0.9295 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7796: loss = 0.5969 (0.234 sec/step)\n",
            "I0802 19:50:18.343964 140624834570112 learning.py:512] global step 7796: loss = 0.5969 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7797: loss = 0.6786 (0.247 sec/step)\n",
            "I0802 19:50:18.592705 140624834570112 learning.py:512] global step 7797: loss = 0.6786 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7798: loss = 0.7143 (0.241 sec/step)\n",
            "I0802 19:50:18.835223 140624834570112 learning.py:512] global step 7798: loss = 0.7143 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7799: loss = 0.9548 (0.245 sec/step)\n",
            "I0802 19:50:19.081585 140624834570112 learning.py:512] global step 7799: loss = 0.9548 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7800: loss = 0.6717 (0.232 sec/step)\n",
            "I0802 19:50:19.315233 140624834570112 learning.py:512] global step 7800: loss = 0.6717 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7801: loss = 0.9492 (0.240 sec/step)\n",
            "I0802 19:50:19.556390 140624834570112 learning.py:512] global step 7801: loss = 0.9492 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7802: loss = 0.7043 (0.241 sec/step)\n",
            "I0802 19:50:19.798525 140624834570112 learning.py:512] global step 7802: loss = 0.7043 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7803: loss = 0.8151 (0.243 sec/step)\n",
            "I0802 19:50:20.042982 140624834570112 learning.py:512] global step 7803: loss = 0.8151 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7804: loss = 0.6673 (0.244 sec/step)\n",
            "I0802 19:50:20.288537 140624834570112 learning.py:512] global step 7804: loss = 0.6673 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7805: loss = 0.9180 (0.247 sec/step)\n",
            "I0802 19:50:20.536743 140624834570112 learning.py:512] global step 7805: loss = 0.9180 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7806: loss = 0.8280 (0.230 sec/step)\n",
            "I0802 19:50:20.768548 140624834570112 learning.py:512] global step 7806: loss = 0.8280 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7807: loss = 0.8312 (0.245 sec/step)\n",
            "I0802 19:50:21.015291 140624834570112 learning.py:512] global step 7807: loss = 0.8312 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7808: loss = 0.7432 (0.233 sec/step)\n",
            "I0802 19:50:21.249581 140624834570112 learning.py:512] global step 7808: loss = 0.7432 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7809: loss = 0.7678 (0.247 sec/step)\n",
            "I0802 19:50:21.498220 140624834570112 learning.py:512] global step 7809: loss = 0.7678 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7810: loss = 0.7801 (0.240 sec/step)\n",
            "I0802 19:50:21.739496 140624834570112 learning.py:512] global step 7810: loss = 0.7801 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7811: loss = 0.6337 (0.238 sec/step)\n",
            "I0802 19:50:21.978430 140624834570112 learning.py:512] global step 7811: loss = 0.6337 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7812: loss = 0.8815 (0.245 sec/step)\n",
            "I0802 19:50:22.224744 140624834570112 learning.py:512] global step 7812: loss = 0.8815 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7813: loss = 0.7324 (0.248 sec/step)\n",
            "I0802 19:50:22.474287 140624834570112 learning.py:512] global step 7813: loss = 0.7324 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7814: loss = 0.6884 (0.254 sec/step)\n",
            "I0802 19:50:22.729741 140624834570112 learning.py:512] global step 7814: loss = 0.6884 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 7815: loss = 0.9021 (0.239 sec/step)\n",
            "I0802 19:50:22.970234 140624834570112 learning.py:512] global step 7815: loss = 0.9021 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7816: loss = 0.8013 (0.251 sec/step)\n",
            "I0802 19:50:23.222752 140624834570112 learning.py:512] global step 7816: loss = 0.8013 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7817: loss = 0.6975 (0.246 sec/step)\n",
            "I0802 19:50:23.470511 140624834570112 learning.py:512] global step 7817: loss = 0.6975 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7818: loss = 0.5935 (0.243 sec/step)\n",
            "I0802 19:50:23.715320 140624834570112 learning.py:512] global step 7818: loss = 0.5935 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7819: loss = 0.7908 (0.231 sec/step)\n",
            "I0802 19:50:23.947628 140624834570112 learning.py:512] global step 7819: loss = 0.7908 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7820: loss = 0.7978 (0.255 sec/step)\n",
            "I0802 19:50:24.204545 140624834570112 learning.py:512] global step 7820: loss = 0.7978 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 7821: loss = 0.8642 (0.248 sec/step)\n",
            "I0802 19:50:24.456286 140624834570112 learning.py:512] global step 7821: loss = 0.8642 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7822: loss = 0.7193 (0.251 sec/step)\n",
            "I0802 19:50:24.708673 140624834570112 learning.py:512] global step 7822: loss = 0.7193 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7823: loss = 0.8598 (0.251 sec/step)\n",
            "I0802 19:50:24.961103 140624834570112 learning.py:512] global step 7823: loss = 0.8598 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7824: loss = 0.9366 (0.240 sec/step)\n",
            "I0802 19:50:25.202264 140624834570112 learning.py:512] global step 7824: loss = 0.9366 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7825: loss = 0.8521 (0.243 sec/step)\n",
            "I0802 19:50:25.446578 140624834570112 learning.py:512] global step 7825: loss = 0.8521 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7826: loss = 0.7334 (0.253 sec/step)\n",
            "I0802 19:50:25.701132 140624834570112 learning.py:512] global step 7826: loss = 0.7334 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 7827: loss = 0.6922 (0.256 sec/step)\n",
            "I0802 19:50:25.958301 140624834570112 learning.py:512] global step 7827: loss = 0.6922 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 7828: loss = 0.8834 (0.245 sec/step)\n",
            "I0802 19:50:26.204184 140624834570112 learning.py:512] global step 7828: loss = 0.8834 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7829: loss = 0.7755 (0.235 sec/step)\n",
            "I0802 19:50:26.440402 140624834570112 learning.py:512] global step 7829: loss = 0.7755 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7830: loss = 0.7740 (0.234 sec/step)\n",
            "I0802 19:50:26.675443 140624834570112 learning.py:512] global step 7830: loss = 0.7740 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7831: loss = 0.7872 (0.242 sec/step)\n",
            "I0802 19:50:26.918914 140624834570112 learning.py:512] global step 7831: loss = 0.7872 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7832: loss = 0.9107 (0.241 sec/step)\n",
            "I0802 19:50:27.161343 140624834570112 learning.py:512] global step 7832: loss = 0.9107 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7833: loss = 0.6427 (0.252 sec/step)\n",
            "I0802 19:50:27.415014 140624834570112 learning.py:512] global step 7833: loss = 0.6427 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 7834: loss = 0.7187 (0.253 sec/step)\n",
            "I0802 19:50:27.669116 140624834570112 learning.py:512] global step 7834: loss = 0.7187 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 7835: loss = 0.8130 (0.227 sec/step)\n",
            "I0802 19:50:27.897557 140624834570112 learning.py:512] global step 7835: loss = 0.8130 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7836: loss = 0.9266 (0.241 sec/step)\n",
            "I0802 19:50:28.140790 140624834570112 learning.py:512] global step 7836: loss = 0.9266 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7837: loss = 0.6875 (0.250 sec/step)\n",
            "I0802 19:50:28.392946 140624834570112 learning.py:512] global step 7837: loss = 0.6875 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7838: loss = 0.7065 (0.250 sec/step)\n",
            "I0802 19:50:28.644914 140624834570112 learning.py:512] global step 7838: loss = 0.7065 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7839: loss = 0.5436 (0.233 sec/step)\n",
            "I0802 19:50:28.879479 140624834570112 learning.py:512] global step 7839: loss = 0.5436 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7840: loss = 0.7380 (0.251 sec/step)\n",
            "I0802 19:50:29.131710 140624834570112 learning.py:512] global step 7840: loss = 0.7380 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7841: loss = 0.7989 (0.230 sec/step)\n",
            "I0802 19:50:29.363685 140624834570112 learning.py:512] global step 7841: loss = 0.7989 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7842: loss = 0.5813 (0.235 sec/step)\n",
            "I0802 19:50:29.600242 140624834570112 learning.py:512] global step 7842: loss = 0.5813 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7843: loss = 0.5938 (0.248 sec/step)\n",
            "I0802 19:50:29.849468 140624834570112 learning.py:512] global step 7843: loss = 0.5938 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7844: loss = 0.6637 (0.249 sec/step)\n",
            "I0802 19:50:30.099832 140624834570112 learning.py:512] global step 7844: loss = 0.6637 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7845: loss = 0.6668 (0.244 sec/step)\n",
            "I0802 19:50:30.345466 140624834570112 learning.py:512] global step 7845: loss = 0.6668 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7846: loss = 0.6600 (0.253 sec/step)\n",
            "I0802 19:50:30.599762 140624834570112 learning.py:512] global step 7846: loss = 0.6600 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 7847: loss = 0.6743 (0.248 sec/step)\n",
            "I0802 19:50:30.849589 140624834570112 learning.py:512] global step 7847: loss = 0.6743 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7848: loss = 0.6402 (0.251 sec/step)\n",
            "I0802 19:50:31.102337 140624834570112 learning.py:512] global step 7848: loss = 0.6402 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7849: loss = 0.6416 (0.238 sec/step)\n",
            "I0802 19:50:31.342160 140624834570112 learning.py:512] global step 7849: loss = 0.6416 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7850: loss = 0.5954 (0.247 sec/step)\n",
            "I0802 19:50:31.591221 140624834570112 learning.py:512] global step 7850: loss = 0.5954 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7851: loss = 0.9821 (0.239 sec/step)\n",
            "I0802 19:50:31.831305 140624834570112 learning.py:512] global step 7851: loss = 0.9821 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7852: loss = 0.6758 (0.243 sec/step)\n",
            "I0802 19:50:32.079307 140624834570112 learning.py:512] global step 7852: loss = 0.6758 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7853: loss = 0.6221 (0.231 sec/step)\n",
            "I0802 19:50:32.313732 140624834570112 learning.py:512] global step 7853: loss = 0.6221 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7854: loss = 0.7866 (0.246 sec/step)\n",
            "I0802 19:50:32.561634 140624834570112 learning.py:512] global step 7854: loss = 0.7866 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7855: loss = 0.9887 (0.242 sec/step)\n",
            "I0802 19:50:32.804602 140624834570112 learning.py:512] global step 7855: loss = 0.9887 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7856: loss = 0.9746 (0.248 sec/step)\n",
            "I0802 19:50:33.054313 140624834570112 learning.py:512] global step 7856: loss = 0.9746 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7857: loss = 0.8265 (0.249 sec/step)\n",
            "I0802 19:50:33.304771 140624834570112 learning.py:512] global step 7857: loss = 0.8265 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7858: loss = 0.5631 (0.245 sec/step)\n",
            "I0802 19:50:33.550838 140624834570112 learning.py:512] global step 7858: loss = 0.5631 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7859: loss = 0.6598 (0.246 sec/step)\n",
            "I0802 19:50:33.798431 140624834570112 learning.py:512] global step 7859: loss = 0.6598 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7860: loss = 0.7838 (0.242 sec/step)\n",
            "I0802 19:50:34.042509 140624834570112 learning.py:512] global step 7860: loss = 0.7838 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7861: loss = 0.7614 (0.244 sec/step)\n",
            "I0802 19:50:34.288538 140624834570112 learning.py:512] global step 7861: loss = 0.7614 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7862: loss = 0.9509 (0.228 sec/step)\n",
            "I0802 19:50:34.518155 140624834570112 learning.py:512] global step 7862: loss = 0.9509 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7863: loss = 0.7232 (0.250 sec/step)\n",
            "I0802 19:50:34.769189 140624834570112 learning.py:512] global step 7863: loss = 0.7232 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7864: loss = 0.7474 (0.238 sec/step)\n",
            "I0802 19:50:35.008846 140624834570112 learning.py:512] global step 7864: loss = 0.7474 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7865: loss = 0.7562 (0.230 sec/step)\n",
            "I0802 19:50:35.240234 140624834570112 learning.py:512] global step 7865: loss = 0.7562 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7866: loss = 0.8876 (0.247 sec/step)\n",
            "I0802 19:50:35.488488 140624834570112 learning.py:512] global step 7866: loss = 0.8876 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7867: loss = 0.6318 (0.246 sec/step)\n",
            "I0802 19:50:35.736139 140624834570112 learning.py:512] global step 7867: loss = 0.6318 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7868: loss = 0.8197 (0.240 sec/step)\n",
            "I0802 19:50:35.977402 140624834570112 learning.py:512] global step 7868: loss = 0.8197 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7869: loss = 0.6817 (0.234 sec/step)\n",
            "I0802 19:50:36.213477 140624834570112 learning.py:512] global step 7869: loss = 0.6817 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7870: loss = 0.6216 (0.245 sec/step)\n",
            "I0802 19:50:36.459844 140624834570112 learning.py:512] global step 7870: loss = 0.6216 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7871: loss = 0.7044 (0.247 sec/step)\n",
            "I0802 19:50:36.708439 140624834570112 learning.py:512] global step 7871: loss = 0.7044 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7872: loss = 0.8263 (0.243 sec/step)\n",
            "I0802 19:50:36.952620 140624834570112 learning.py:512] global step 7872: loss = 0.8263 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7873: loss = 0.6951 (0.252 sec/step)\n",
            "I0802 19:50:37.205790 140624834570112 learning.py:512] global step 7873: loss = 0.6951 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 7874: loss = 0.6773 (0.248 sec/step)\n",
            "I0802 19:50:37.455813 140624834570112 learning.py:512] global step 7874: loss = 0.6773 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7875: loss = 0.7663 (0.247 sec/step)\n",
            "I0802 19:50:37.704365 140624834570112 learning.py:512] global step 7875: loss = 0.7663 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7876: loss = 0.5570 (0.243 sec/step)\n",
            "I0802 19:50:37.948835 140624834570112 learning.py:512] global step 7876: loss = 0.5570 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7877: loss = 0.6614 (0.234 sec/step)\n",
            "I0802 19:50:38.184750 140624834570112 learning.py:512] global step 7877: loss = 0.6614 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7878: loss = 0.7028 (0.236 sec/step)\n",
            "I0802 19:50:38.422851 140624834570112 learning.py:512] global step 7878: loss = 0.7028 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7879: loss = 0.8252 (0.242 sec/step)\n",
            "I0802 19:50:38.666135 140624834570112 learning.py:512] global step 7879: loss = 0.8252 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7880: loss = 0.5124 (0.241 sec/step)\n",
            "I0802 19:50:38.908724 140624834570112 learning.py:512] global step 7880: loss = 0.5124 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7881: loss = 0.6205 (0.243 sec/step)\n",
            "I0802 19:50:39.153219 140624834570112 learning.py:512] global step 7881: loss = 0.6205 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7882: loss = 0.6568 (0.239 sec/step)\n",
            "I0802 19:50:39.393513 140624834570112 learning.py:512] global step 7882: loss = 0.6568 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7883: loss = 0.6808 (0.240 sec/step)\n",
            "I0802 19:50:39.635388 140624834570112 learning.py:512] global step 7883: loss = 0.6808 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7884: loss = 0.8437 (0.227 sec/step)\n",
            "I0802 19:50:39.863445 140624834570112 learning.py:512] global step 7884: loss = 0.8437 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7885: loss = 0.5732 (0.224 sec/step)\n",
            "I0802 19:50:40.088608 140624834570112 learning.py:512] global step 7885: loss = 0.5732 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7886: loss = 0.7218 (0.240 sec/step)\n",
            "I0802 19:50:40.329864 140624834570112 learning.py:512] global step 7886: loss = 0.7218 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7887: loss = 0.6602 (0.245 sec/step)\n",
            "I0802 19:50:40.577703 140624834570112 learning.py:512] global step 7887: loss = 0.6602 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7888: loss = 0.6689 (0.246 sec/step)\n",
            "I0802 19:50:40.825139 140624834570112 learning.py:512] global step 7888: loss = 0.6689 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7889: loss = 0.8276 (0.228 sec/step)\n",
            "I0802 19:50:41.054439 140624834570112 learning.py:512] global step 7889: loss = 0.8276 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7890: loss = 0.7255 (0.225 sec/step)\n",
            "I0802 19:50:41.280690 140624834570112 learning.py:512] global step 7890: loss = 0.7255 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7891: loss = 0.7001 (0.245 sec/step)\n",
            "I0802 19:50:41.526847 140624834570112 learning.py:512] global step 7891: loss = 0.7001 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7892: loss = 0.8869 (0.247 sec/step)\n",
            "I0802 19:50:41.775344 140624834570112 learning.py:512] global step 7892: loss = 0.8869 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7893: loss = 0.7622 (0.240 sec/step)\n",
            "I0802 19:50:42.016625 140624834570112 learning.py:512] global step 7893: loss = 0.7622 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7894: loss = 0.8385 (0.246 sec/step)\n",
            "I0802 19:50:42.263908 140624834570112 learning.py:512] global step 7894: loss = 0.8385 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7895: loss = 0.6176 (0.231 sec/step)\n",
            "I0802 19:50:42.496419 140624834570112 learning.py:512] global step 7895: loss = 0.6176 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7896: loss = 0.8483 (0.233 sec/step)\n",
            "I0802 19:50:42.731092 140624834570112 learning.py:512] global step 7896: loss = 0.8483 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7897: loss = 0.8263 (0.238 sec/step)\n",
            "I0802 19:50:42.970407 140624834570112 learning.py:512] global step 7897: loss = 0.8263 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7898: loss = 0.7106 (0.246 sec/step)\n",
            "I0802 19:50:43.217741 140624834570112 learning.py:512] global step 7898: loss = 0.7106 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7899: loss = 0.9010 (0.249 sec/step)\n",
            "I0802 19:50:43.468096 140624834570112 learning.py:512] global step 7899: loss = 0.9010 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7900: loss = 0.9595 (0.228 sec/step)\n",
            "I0802 19:50:43.697556 140624834570112 learning.py:512] global step 7900: loss = 0.9595 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7901: loss = 0.5929 (0.233 sec/step)\n",
            "I0802 19:50:43.932345 140624834570112 learning.py:512] global step 7901: loss = 0.5929 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7902: loss = 1.0523 (0.244 sec/step)\n",
            "I0802 19:50:44.178210 140624834570112 learning.py:512] global step 7902: loss = 1.0523 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7903: loss = 0.9634 (0.232 sec/step)\n",
            "I0802 19:50:44.411784 140624834570112 learning.py:512] global step 7903: loss = 0.9634 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7904: loss = 0.7145 (0.246 sec/step)\n",
            "I0802 19:50:44.659676 140624834570112 learning.py:512] global step 7904: loss = 0.7145 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7905: loss = 0.8311 (0.225 sec/step)\n",
            "I0802 19:50:44.886824 140624834570112 learning.py:512] global step 7905: loss = 0.8311 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7906: loss = 0.6320 (0.229 sec/step)\n",
            "I0802 19:50:45.117283 140624834570112 learning.py:512] global step 7906: loss = 0.6320 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7907: loss = 1.0583 (0.246 sec/step)\n",
            "I0802 19:50:45.367261 140624834570112 learning.py:512] global step 7907: loss = 1.0583 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7908: loss = 0.8572 (0.251 sec/step)\n",
            "I0802 19:50:45.620681 140624834570112 learning.py:512] global step 7908: loss = 0.8572 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7909: loss = 0.7146 (0.246 sec/step)\n",
            "I0802 19:50:45.867768 140624834570112 learning.py:512] global step 7909: loss = 0.7146 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7910: loss = 0.8128 (0.241 sec/step)\n",
            "I0802 19:50:46.109938 140624834570112 learning.py:512] global step 7910: loss = 0.8128 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7911: loss = 0.7692 (0.250 sec/step)\n",
            "I0802 19:50:46.361633 140624834570112 learning.py:512] global step 7911: loss = 0.7692 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7912: loss = 0.7922 (0.243 sec/step)\n",
            "I0802 19:50:46.606147 140624834570112 learning.py:512] global step 7912: loss = 0.7922 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7913: loss = 0.6430 (0.246 sec/step)\n",
            "I0802 19:50:46.853598 140624834570112 learning.py:512] global step 7913: loss = 0.6430 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7914: loss = 0.9841 (0.243 sec/step)\n",
            "I0802 19:50:47.097669 140624834570112 learning.py:512] global step 7914: loss = 0.9841 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7915: loss = 0.5700 (0.246 sec/step)\n",
            "I0802 19:50:47.345427 140624834570112 learning.py:512] global step 7915: loss = 0.5700 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7916: loss = 0.7342 (0.249 sec/step)\n",
            "I0802 19:50:47.596163 140624834570112 learning.py:512] global step 7916: loss = 0.7342 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7917: loss = 0.7990 (0.246 sec/step)\n",
            "I0802 19:50:47.843471 140624834570112 learning.py:512] global step 7917: loss = 0.7990 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7918: loss = 0.9773 (0.238 sec/step)\n",
            "I0802 19:50:48.083321 140624834570112 learning.py:512] global step 7918: loss = 0.9773 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7919: loss = 0.7033 (0.245 sec/step)\n",
            "I0802 19:50:48.329663 140624834570112 learning.py:512] global step 7919: loss = 0.7033 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7920: loss = 0.6870 (0.248 sec/step)\n",
            "I0802 19:50:48.578805 140624834570112 learning.py:512] global step 7920: loss = 0.6870 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7921: loss = 1.0483 (0.231 sec/step)\n",
            "I0802 19:50:48.811519 140624834570112 learning.py:512] global step 7921: loss = 1.0483 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7922: loss = 0.9641 (0.250 sec/step)\n",
            "I0802 19:50:49.063509 140624834570112 learning.py:512] global step 7922: loss = 0.9641 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7923: loss = 0.7073 (0.244 sec/step)\n",
            "I0802 19:50:49.308797 140624834570112 learning.py:512] global step 7923: loss = 0.7073 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7924: loss = 0.5413 (0.242 sec/step)\n",
            "I0802 19:50:49.552277 140624834570112 learning.py:512] global step 7924: loss = 0.5413 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7925: loss = 1.0207 (0.249 sec/step)\n",
            "I0802 19:50:49.802323 140624834570112 learning.py:512] global step 7925: loss = 1.0207 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7926: loss = 0.6674 (0.248 sec/step)\n",
            "I0802 19:50:50.052039 140624834570112 learning.py:512] global step 7926: loss = 0.6674 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7927: loss = 0.9393 (0.248 sec/step)\n",
            "I0802 19:50:50.301638 140624834570112 learning.py:512] global step 7927: loss = 0.9393 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7928: loss = 0.8184 (0.244 sec/step)\n",
            "I0802 19:50:50.546850 140624834570112 learning.py:512] global step 7928: loss = 0.8184 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7929: loss = 0.7094 (0.243 sec/step)\n",
            "I0802 19:50:50.791931 140624834570112 learning.py:512] global step 7929: loss = 0.7094 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7930: loss = 0.7216 (0.245 sec/step)\n",
            "I0802 19:50:51.038098 140624834570112 learning.py:512] global step 7930: loss = 0.7216 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7931: loss = 0.6640 (0.242 sec/step)\n",
            "I0802 19:50:51.281345 140624834570112 learning.py:512] global step 7931: loss = 0.6640 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7932: loss = 0.7509 (0.243 sec/step)\n",
            "I0802 19:50:51.525643 140624834570112 learning.py:512] global step 7932: loss = 0.7509 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7933: loss = 0.5230 (0.245 sec/step)\n",
            "I0802 19:50:51.772328 140624834570112 learning.py:512] global step 7933: loss = 0.5230 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7934: loss = 0.8702 (0.249 sec/step)\n",
            "I0802 19:50:52.022781 140624834570112 learning.py:512] global step 7934: loss = 0.8702 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7935: loss = 0.8645 (0.235 sec/step)\n",
            "I0802 19:50:52.259104 140624834570112 learning.py:512] global step 7935: loss = 0.8645 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7936: loss = 0.5495 (0.249 sec/step)\n",
            "I0802 19:50:52.509542 140624834570112 learning.py:512] global step 7936: loss = 0.5495 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7937: loss = 0.7705 (0.242 sec/step)\n",
            "I0802 19:50:52.753727 140624834570112 learning.py:512] global step 7937: loss = 0.7705 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7938: loss = 0.9165 (0.247 sec/step)\n",
            "I0802 19:50:53.002573 140624834570112 learning.py:512] global step 7938: loss = 0.9165 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7939: loss = 0.7165 (0.239 sec/step)\n",
            "I0802 19:50:53.243425 140624834570112 learning.py:512] global step 7939: loss = 0.7165 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7940: loss = 0.7896 (0.242 sec/step)\n",
            "I0802 19:50:53.487077 140624834570112 learning.py:512] global step 7940: loss = 0.7896 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7941: loss = 0.7878 (0.260 sec/step)\n",
            "I0802 19:50:53.748260 140624834570112 learning.py:512] global step 7941: loss = 0.7878 (0.260 sec/step)\n",
            "INFO:tensorflow:global step 7942: loss = 0.6762 (0.250 sec/step)\n",
            "I0802 19:50:53.999848 140624834570112 learning.py:512] global step 7942: loss = 0.6762 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7943: loss = 0.7491 (0.231 sec/step)\n",
            "I0802 19:50:54.232225 140624834570112 learning.py:512] global step 7943: loss = 0.7491 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7944: loss = 0.5103 (0.243 sec/step)\n",
            "I0802 19:50:54.476886 140624834570112 learning.py:512] global step 7944: loss = 0.5103 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7945: loss = 1.0037 (0.241 sec/step)\n",
            "I0802 19:50:54.719942 140624834570112 learning.py:512] global step 7945: loss = 1.0037 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7946: loss = 0.7251 (0.245 sec/step)\n",
            "I0802 19:50:54.966838 140624834570112 learning.py:512] global step 7946: loss = 0.7251 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7947: loss = 0.7758 (0.248 sec/step)\n",
            "I0802 19:50:55.216445 140624834570112 learning.py:512] global step 7947: loss = 0.7758 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7948: loss = 0.6976 (0.236 sec/step)\n",
            "I0802 19:50:55.454334 140624834570112 learning.py:512] global step 7948: loss = 0.6976 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7949: loss = 0.8134 (0.251 sec/step)\n",
            "I0802 19:50:55.706950 140624834570112 learning.py:512] global step 7949: loss = 0.8134 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7950: loss = 0.9036 (0.246 sec/step)\n",
            "I0802 19:50:55.954084 140624834570112 learning.py:512] global step 7950: loss = 0.9036 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7951: loss = 0.8632 (0.228 sec/step)\n",
            "I0802 19:50:56.183442 140624834570112 learning.py:512] global step 7951: loss = 0.8632 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7952: loss = 0.7011 (0.233 sec/step)\n",
            "I0802 19:50:56.418156 140624834570112 learning.py:512] global step 7952: loss = 0.7011 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7953: loss = 0.6651 (0.247 sec/step)\n",
            "I0802 19:50:56.666706 140624834570112 learning.py:512] global step 7953: loss = 0.6651 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7954: loss = 0.7080 (0.240 sec/step)\n",
            "I0802 19:50:56.908031 140624834570112 learning.py:512] global step 7954: loss = 0.7080 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7955: loss = 0.7381 (0.249 sec/step)\n",
            "I0802 19:50:57.157943 140624834570112 learning.py:512] global step 7955: loss = 0.7381 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7956: loss = 0.5823 (0.245 sec/step)\n",
            "I0802 19:50:57.404650 140624834570112 learning.py:512] global step 7956: loss = 0.5823 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7957: loss = 0.5350 (0.231 sec/step)\n",
            "I0802 19:50:57.636876 140624834570112 learning.py:512] global step 7957: loss = 0.5350 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7958: loss = 0.8254 (0.240 sec/step)\n",
            "I0802 19:50:57.878057 140624834570112 learning.py:512] global step 7958: loss = 0.8254 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7959: loss = 0.6814 (0.228 sec/step)\n",
            "I0802 19:50:58.107180 140624834570112 learning.py:512] global step 7959: loss = 0.6814 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7960: loss = 0.7834 (0.233 sec/step)\n",
            "I0802 19:50:58.341588 140624834570112 learning.py:512] global step 7960: loss = 0.7834 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7961: loss = 0.8179 (0.249 sec/step)\n",
            "I0802 19:50:58.591945 140624834570112 learning.py:512] global step 7961: loss = 0.8179 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7962: loss = 0.7974 (0.244 sec/step)\n",
            "I0802 19:50:58.837263 140624834570112 learning.py:512] global step 7962: loss = 0.7974 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7963: loss = 0.7372 (0.249 sec/step)\n",
            "I0802 19:50:59.087721 140624834570112 learning.py:512] global step 7963: loss = 0.7372 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7964: loss = 1.0103 (0.248 sec/step)\n",
            "I0802 19:50:59.337680 140624834570112 learning.py:512] global step 7964: loss = 1.0103 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7965: loss = 0.7510 (0.247 sec/step)\n",
            "I0802 19:50:59.586295 140624834570112 learning.py:512] global step 7965: loss = 0.7510 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7966: loss = 0.5855 (0.249 sec/step)\n",
            "I0802 19:50:59.836916 140624834570112 learning.py:512] global step 7966: loss = 0.5855 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7967: loss = 0.7362 (0.240 sec/step)\n",
            "I0802 19:51:00.078078 140624834570112 learning.py:512] global step 7967: loss = 0.7362 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7968: loss = 0.8262 (0.246 sec/step)\n",
            "I0802 19:51:00.325291 140624834570112 learning.py:512] global step 7968: loss = 0.8262 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7969: loss = 0.6222 (0.248 sec/step)\n",
            "I0802 19:51:00.575042 140624834570112 learning.py:512] global step 7969: loss = 0.6222 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7970: loss = 0.6238 (0.247 sec/step)\n",
            "I0802 19:51:00.823244 140624834570112 learning.py:512] global step 7970: loss = 0.6238 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7971: loss = 0.5402 (0.237 sec/step)\n",
            "I0802 19:51:01.062155 140624834570112 learning.py:512] global step 7971: loss = 0.5402 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7972: loss = 0.7713 (0.248 sec/step)\n",
            "I0802 19:51:01.311625 140624834570112 learning.py:512] global step 7972: loss = 0.7713 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7973: loss = 0.6160 (0.244 sec/step)\n",
            "I0802 19:51:01.557427 140624834570112 learning.py:512] global step 7973: loss = 0.6160 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7974: loss = 0.6787 (0.257 sec/step)\n",
            "I0802 19:51:01.815833 140624834570112 learning.py:512] global step 7974: loss = 0.6787 (0.257 sec/step)\n",
            "INFO:tensorflow:global step 7975: loss = 0.7424 (0.237 sec/step)\n",
            "I0802 19:51:02.054261 140624834570112 learning.py:512] global step 7975: loss = 0.7424 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7976: loss = 0.7134 (0.249 sec/step)\n",
            "I0802 19:51:02.304942 140624834570112 learning.py:512] global step 7976: loss = 0.7134 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7977: loss = 0.7375 (0.245 sec/step)\n",
            "I0802 19:51:02.551205 140624834570112 learning.py:512] global step 7977: loss = 0.7375 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7978: loss = 0.8572 (0.228 sec/step)\n",
            "I0802 19:51:02.781052 140624834570112 learning.py:512] global step 7978: loss = 0.8572 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7979: loss = 0.7388 (0.227 sec/step)\n",
            "I0802 19:51:03.009647 140624834570112 learning.py:512] global step 7979: loss = 0.7388 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7980: loss = 1.5617 (0.246 sec/step)\n",
            "I0802 19:51:03.257574 140624834570112 learning.py:512] global step 7980: loss = 1.5617 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7981: loss = 0.6765 (0.252 sec/step)\n",
            "I0802 19:51:03.511133 140624834570112 learning.py:512] global step 7981: loss = 0.6765 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 7982: loss = 0.5823 (0.226 sec/step)\n",
            "I0802 19:51:03.738735 140624834570112 learning.py:512] global step 7982: loss = 0.5823 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 7983: loss = 0.6114 (0.233 sec/step)\n",
            "I0802 19:51:03.972851 140624834570112 learning.py:512] global step 7983: loss = 0.6114 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7984: loss = 0.6062 (0.239 sec/step)\n",
            "I0802 19:51:04.213160 140624834570112 learning.py:512] global step 7984: loss = 0.6062 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7985: loss = 0.6255 (0.255 sec/step)\n",
            "I0802 19:51:04.469724 140624834570112 learning.py:512] global step 7985: loss = 0.6255 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 7986: loss = 0.6562 (0.247 sec/step)\n",
            "I0802 19:51:04.718541 140624834570112 learning.py:512] global step 7986: loss = 0.6562 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7987: loss = 0.6926 (0.255 sec/step)\n",
            "I0802 19:51:04.975355 140624834570112 learning.py:512] global step 7987: loss = 0.6926 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 7988: loss = 0.6139 (0.249 sec/step)\n",
            "I0802 19:51:05.225695 140624834570112 learning.py:512] global step 7988: loss = 0.6139 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7989: loss = 0.5894 (0.239 sec/step)\n",
            "I0802 19:51:05.465893 140624834570112 learning.py:512] global step 7989: loss = 0.5894 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7990: loss = 0.8040 (0.248 sec/step)\n",
            "I0802 19:51:05.715678 140624834570112 learning.py:512] global step 7990: loss = 0.8040 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7991: loss = 0.7479 (0.238 sec/step)\n",
            "I0802 19:51:05.955085 140624834570112 learning.py:512] global step 7991: loss = 0.7479 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7992: loss = 0.8622 (0.249 sec/step)\n",
            "I0802 19:51:06.206294 140624834570112 learning.py:512] global step 7992: loss = 0.8622 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7993: loss = 0.8932 (0.246 sec/step)\n",
            "I0802 19:51:06.453671 140624834570112 learning.py:512] global step 7993: loss = 0.8932 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7994: loss = 0.8197 (0.247 sec/step)\n",
            "I0802 19:51:06.705177 140624834570112 learning.py:512] global step 7994: loss = 0.8197 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7995: loss = 0.9180 (0.232 sec/step)\n",
            "I0802 19:51:06.939727 140624834570112 learning.py:512] global step 7995: loss = 0.9180 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7996: loss = 0.7579 (0.230 sec/step)\n",
            "I0802 19:51:07.171439 140624834570112 learning.py:512] global step 7996: loss = 0.7579 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7997: loss = 0.5990 (0.240 sec/step)\n",
            "I0802 19:51:07.412938 140624834570112 learning.py:512] global step 7997: loss = 0.5990 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7998: loss = 0.7276 (0.235 sec/step)\n",
            "I0802 19:51:07.650891 140624834570112 learning.py:512] global step 7998: loss = 0.7276 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7999: loss = 0.6496 (0.244 sec/step)\n",
            "I0802 19:51:07.896033 140624834570112 learning.py:512] global step 7999: loss = 0.6496 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8000: loss = 0.7168 (0.243 sec/step)\n",
            "I0802 19:51:08.140521 140624834570112 learning.py:512] global step 8000: loss = 0.7168 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8001: loss = 0.7101 (0.229 sec/step)\n",
            "I0802 19:51:08.370791 140624834570112 learning.py:512] global step 8001: loss = 0.7101 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8002: loss = 0.7525 (0.246 sec/step)\n",
            "I0802 19:51:08.618259 140624834570112 learning.py:512] global step 8002: loss = 0.7525 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8003: loss = 0.6723 (0.239 sec/step)\n",
            "I0802 19:51:08.858958 140624834570112 learning.py:512] global step 8003: loss = 0.6723 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8004: loss = 0.6313 (0.229 sec/step)\n",
            "I0802 19:51:09.089680 140624834570112 learning.py:512] global step 8004: loss = 0.6313 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8005: loss = 0.6562 (0.231 sec/step)\n",
            "I0802 19:51:09.322233 140624834570112 learning.py:512] global step 8005: loss = 0.6562 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8006: loss = 0.6589 (0.243 sec/step)\n",
            "I0802 19:51:09.567169 140624834570112 learning.py:512] global step 8006: loss = 0.6589 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8007: loss = 0.6173 (0.249 sec/step)\n",
            "I0802 19:51:09.817176 140624834570112 learning.py:512] global step 8007: loss = 0.6173 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8008: loss = 0.6955 (0.239 sec/step)\n",
            "I0802 19:51:10.058012 140624834570112 learning.py:512] global step 8008: loss = 0.6955 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8009: loss = 0.6624 (0.236 sec/step)\n",
            "I0802 19:51:10.295132 140624834570112 learning.py:512] global step 8009: loss = 0.6624 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8010: loss = 0.7750 (0.240 sec/step)\n",
            "I0802 19:51:10.536526 140624834570112 learning.py:512] global step 8010: loss = 0.7750 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8011: loss = 0.8504 (0.236 sec/step)\n",
            "I0802 19:51:10.774305 140624834570112 learning.py:512] global step 8011: loss = 0.8504 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8012: loss = 0.8021 (0.243 sec/step)\n",
            "I0802 19:51:11.018997 140624834570112 learning.py:512] global step 8012: loss = 0.8021 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8013: loss = 0.8045 (0.252 sec/step)\n",
            "I0802 19:51:11.272162 140624834570112 learning.py:512] global step 8013: loss = 0.8045 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8014: loss = 0.6479 (0.228 sec/step)\n",
            "I0802 19:51:11.501142 140624834570112 learning.py:512] global step 8014: loss = 0.6479 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8015: loss = 0.7174 (0.246 sec/step)\n",
            "I0802 19:51:11.748046 140624834570112 learning.py:512] global step 8015: loss = 0.7174 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8016: loss = 0.7094 (0.235 sec/step)\n",
            "I0802 19:51:11.984214 140624834570112 learning.py:512] global step 8016: loss = 0.7094 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8017: loss = 0.7004 (0.244 sec/step)\n",
            "I0802 19:51:12.229541 140624834570112 learning.py:512] global step 8017: loss = 0.7004 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8018: loss = 0.7095 (0.236 sec/step)\n",
            "I0802 19:51:12.466873 140624834570112 learning.py:512] global step 8018: loss = 0.7095 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8019: loss = 0.5269 (0.235 sec/step)\n",
            "I0802 19:51:12.702879 140624834570112 learning.py:512] global step 8019: loss = 0.5269 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8020: loss = 0.9276 (0.239 sec/step)\n",
            "I0802 19:51:12.943565 140624834570112 learning.py:512] global step 8020: loss = 0.9276 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8021: loss = 0.8009 (0.245 sec/step)\n",
            "I0802 19:51:13.189429 140624834570112 learning.py:512] global step 8021: loss = 0.8009 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8022: loss = 0.7817 (0.240 sec/step)\n",
            "I0802 19:51:13.430512 140624834570112 learning.py:512] global step 8022: loss = 0.7817 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8023: loss = 0.7580 (0.244 sec/step)\n",
            "I0802 19:51:13.675994 140624834570112 learning.py:512] global step 8023: loss = 0.7580 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8024: loss = 0.7210 (0.237 sec/step)\n",
            "I0802 19:51:13.914249 140624834570112 learning.py:512] global step 8024: loss = 0.7210 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8025: loss = 0.4377 (0.239 sec/step)\n",
            "I0802 19:51:14.155049 140624834570112 learning.py:512] global step 8025: loss = 0.4377 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8026: loss = 0.7536 (0.238 sec/step)\n",
            "I0802 19:51:14.394062 140624834570112 learning.py:512] global step 8026: loss = 0.7536 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8027: loss = 0.7722 (0.243 sec/step)\n",
            "I0802 19:51:14.638584 140624834570112 learning.py:512] global step 8027: loss = 0.7722 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8028: loss = 0.7663 (0.237 sec/step)\n",
            "I0802 19:51:14.877521 140624834570112 learning.py:512] global step 8028: loss = 0.7663 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8029: loss = 0.7310 (0.236 sec/step)\n",
            "I0802 19:51:15.114815 140624834570112 learning.py:512] global step 8029: loss = 0.7310 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8030: loss = 0.7927 (0.238 sec/step)\n",
            "I0802 19:51:15.354607 140624834570112 learning.py:512] global step 8030: loss = 0.7927 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8031: loss = 0.9055 (0.248 sec/step)\n",
            "I0802 19:51:15.604256 140624834570112 learning.py:512] global step 8031: loss = 0.9055 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8032: loss = 0.7298 (0.239 sec/step)\n",
            "I0802 19:51:15.844708 140624834570112 learning.py:512] global step 8032: loss = 0.7298 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8033: loss = 0.7011 (0.242 sec/step)\n",
            "I0802 19:51:16.087975 140624834570112 learning.py:512] global step 8033: loss = 0.7011 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8034: loss = 0.5329 (0.245 sec/step)\n",
            "I0802 19:51:16.334119 140624834570112 learning.py:512] global step 8034: loss = 0.5329 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8035: loss = 0.7655 (0.254 sec/step)\n",
            "I0802 19:51:16.589476 140624834570112 learning.py:512] global step 8035: loss = 0.7655 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8036: loss = 0.7561 (0.237 sec/step)\n",
            "I0802 19:51:16.827836 140624834570112 learning.py:512] global step 8036: loss = 0.7561 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8037: loss = 0.6947 (0.247 sec/step)\n",
            "I0802 19:51:17.076098 140624834570112 learning.py:512] global step 8037: loss = 0.6947 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8038: loss = 0.7024 (0.236 sec/step)\n",
            "I0802 19:51:17.313508 140624834570112 learning.py:512] global step 8038: loss = 0.7024 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8039: loss = 0.4756 (0.244 sec/step)\n",
            "I0802 19:51:17.559331 140624834570112 learning.py:512] global step 8039: loss = 0.4756 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8040: loss = 0.7596 (0.243 sec/step)\n",
            "I0802 19:51:17.803560 140624834570112 learning.py:512] global step 8040: loss = 0.7596 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8041: loss = 0.7978 (0.248 sec/step)\n",
            "I0802 19:51:18.053113 140624834570112 learning.py:512] global step 8041: loss = 0.7978 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8042: loss = 0.7032 (0.249 sec/step)\n",
            "I0802 19:51:18.303623 140624834570112 learning.py:512] global step 8042: loss = 0.7032 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8043: loss = 0.6153 (0.232 sec/step)\n",
            "I0802 19:51:18.536911 140624834570112 learning.py:512] global step 8043: loss = 0.6153 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8044: loss = 0.7675 (0.241 sec/step)\n",
            "I0802 19:51:18.778777 140624834570112 learning.py:512] global step 8044: loss = 0.7675 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8045: loss = 1.0427 (0.241 sec/step)\n",
            "I0802 19:51:19.021315 140624834570112 learning.py:512] global step 8045: loss = 1.0427 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8046: loss = 0.8330 (0.234 sec/step)\n",
            "I0802 19:51:19.257176 140624834570112 learning.py:512] global step 8046: loss = 0.8330 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8047: loss = 0.6092 (0.243 sec/step)\n",
            "I0802 19:51:19.501833 140624834570112 learning.py:512] global step 8047: loss = 0.6092 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8048: loss = 0.7405 (0.233 sec/step)\n",
            "I0802 19:51:19.736588 140624834570112 learning.py:512] global step 8048: loss = 0.7405 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8049: loss = 0.7416 (0.243 sec/step)\n",
            "I0802 19:51:19.981021 140624834570112 learning.py:512] global step 8049: loss = 0.7416 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8050: loss = 0.5579 (0.236 sec/step)\n",
            "I0802 19:51:20.218598 140624834570112 learning.py:512] global step 8050: loss = 0.5579 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8051: loss = 0.8325 (0.237 sec/step)\n",
            "I0802 19:51:20.457075 140624834570112 learning.py:512] global step 8051: loss = 0.8325 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8052: loss = 0.7847 (0.252 sec/step)\n",
            "I0802 19:51:20.710357 140624834570112 learning.py:512] global step 8052: loss = 0.7847 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8053: loss = 0.5170 (0.248 sec/step)\n",
            "I0802 19:51:20.959378 140624834570112 learning.py:512] global step 8053: loss = 0.5170 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8054: loss = 0.6651 (0.232 sec/step)\n",
            "I0802 19:51:21.193387 140624834570112 learning.py:512] global step 8054: loss = 0.6651 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8055: loss = 0.5689 (0.243 sec/step)\n",
            "I0802 19:51:21.437678 140624834570112 learning.py:512] global step 8055: loss = 0.5689 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8056: loss = 0.6736 (0.239 sec/step)\n",
            "I0802 19:51:21.677669 140624834570112 learning.py:512] global step 8056: loss = 0.6736 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8057: loss = 0.6090 (0.238 sec/step)\n",
            "I0802 19:51:21.917039 140624834570112 learning.py:512] global step 8057: loss = 0.6090 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8058: loss = 0.7287 (0.229 sec/step)\n",
            "I0802 19:51:22.147727 140624834570112 learning.py:512] global step 8058: loss = 0.7287 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8059: loss = 0.8105 (0.244 sec/step)\n",
            "I0802 19:51:22.392812 140624834570112 learning.py:512] global step 8059: loss = 0.8105 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8060: loss = 0.7787 (0.232 sec/step)\n",
            "I0802 19:51:22.626303 140624834570112 learning.py:512] global step 8060: loss = 0.7787 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8061: loss = 0.7010 (0.232 sec/step)\n",
            "I0802 19:51:22.859322 140624834570112 learning.py:512] global step 8061: loss = 0.7010 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8062: loss = 0.8025 (0.255 sec/step)\n",
            "I0802 19:51:23.115784 140624834570112 learning.py:512] global step 8062: loss = 0.8025 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8063: loss = 0.7332 (0.237 sec/step)\n",
            "I0802 19:51:23.354481 140624834570112 learning.py:512] global step 8063: loss = 0.7332 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8064: loss = 0.7453 (0.239 sec/step)\n",
            "I0802 19:51:23.594365 140624834570112 learning.py:512] global step 8064: loss = 0.7453 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8065: loss = 0.6876 (0.249 sec/step)\n",
            "I0802 19:51:23.844855 140624834570112 learning.py:512] global step 8065: loss = 0.6876 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8066: loss = 0.8422 (0.243 sec/step)\n",
            "I0802 19:51:24.089237 140624834570112 learning.py:512] global step 8066: loss = 0.8422 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8067: loss = 0.7745 (0.242 sec/step)\n",
            "I0802 19:51:24.332631 140624834570112 learning.py:512] global step 8067: loss = 0.7745 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8068: loss = 0.6962 (0.223 sec/step)\n",
            "I0802 19:51:24.556542 140624834570112 learning.py:512] global step 8068: loss = 0.6962 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8069: loss = 0.9138 (0.231 sec/step)\n",
            "I0802 19:51:24.789068 140624834570112 learning.py:512] global step 8069: loss = 0.9138 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8070: loss = 0.7501 (0.250 sec/step)\n",
            "I0802 19:51:25.040903 140624834570112 learning.py:512] global step 8070: loss = 0.7501 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8071: loss = 0.9371 (0.246 sec/step)\n",
            "I0802 19:51:25.288726 140624834570112 learning.py:512] global step 8071: loss = 0.9371 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8072: loss = 0.5883 (0.237 sec/step)\n",
            "I0802 19:51:25.527526 140624834570112 learning.py:512] global step 8072: loss = 0.5883 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8073: loss = 0.8626 (0.235 sec/step)\n",
            "I0802 19:51:25.764178 140624834570112 learning.py:512] global step 8073: loss = 0.8626 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8074: loss = 0.7229 (0.243 sec/step)\n",
            "I0802 19:51:26.008582 140624834570112 learning.py:512] global step 8074: loss = 0.7229 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8075: loss = 0.7287 (0.239 sec/step)\n",
            "I0802 19:51:26.248795 140624834570112 learning.py:512] global step 8075: loss = 0.7287 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8076: loss = 0.6942 (0.237 sec/step)\n",
            "I0802 19:51:26.487494 140624834570112 learning.py:512] global step 8076: loss = 0.6942 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8077: loss = 1.0290 (0.229 sec/step)\n",
            "I0802 19:51:26.718301 140624834570112 learning.py:512] global step 8077: loss = 1.0290 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8078: loss = 0.4862 (0.229 sec/step)\n",
            "I0802 19:51:26.948894 140624834570112 learning.py:512] global step 8078: loss = 0.4862 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8079: loss = 0.8261 (0.242 sec/step)\n",
            "I0802 19:51:27.192506 140624834570112 learning.py:512] global step 8079: loss = 0.8261 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8080: loss = 0.7766 (0.242 sec/step)\n",
            "I0802 19:51:27.436143 140624834570112 learning.py:512] global step 8080: loss = 0.7766 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8081: loss = 0.6895 (0.243 sec/step)\n",
            "I0802 19:51:27.680299 140624834570112 learning.py:512] global step 8081: loss = 0.6895 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8082: loss = 0.7792 (0.226 sec/step)\n",
            "I0802 19:51:27.907877 140624834570112 learning.py:512] global step 8082: loss = 0.7792 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8083: loss = 0.7435 (0.243 sec/step)\n",
            "I0802 19:51:28.152081 140624834570112 learning.py:512] global step 8083: loss = 0.7435 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8084: loss = 0.8460 (0.234 sec/step)\n",
            "I0802 19:51:28.387596 140624834570112 learning.py:512] global step 8084: loss = 0.8460 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8085: loss = 0.5831 (0.237 sec/step)\n",
            "I0802 19:51:28.626227 140624834570112 learning.py:512] global step 8085: loss = 0.5831 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8086: loss = 0.8696 (0.241 sec/step)\n",
            "I0802 19:51:28.868854 140624834570112 learning.py:512] global step 8086: loss = 0.8696 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8087: loss = 0.7459 (0.239 sec/step)\n",
            "I0802 19:51:29.109555 140624834570112 learning.py:512] global step 8087: loss = 0.7459 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8088: loss = 0.6237 (0.253 sec/step)\n",
            "I0802 19:51:29.364473 140624834570112 learning.py:512] global step 8088: loss = 0.6237 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8089: loss = 0.7040 (0.234 sec/step)\n",
            "I0802 19:51:29.599556 140624834570112 learning.py:512] global step 8089: loss = 0.7040 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8090: loss = 0.5814 (0.259 sec/step)\n",
            "I0802 19:51:29.859912 140624834570112 learning.py:512] global step 8090: loss = 0.5814 (0.259 sec/step)\n",
            "INFO:tensorflow:global step 8091: loss = 0.6879 (0.245 sec/step)\n",
            "I0802 19:51:30.108577 140624834570112 learning.py:512] global step 8091: loss = 0.6879 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8092: loss = 0.8333 (0.228 sec/step)\n",
            "I0802 19:51:30.338127 140624834570112 learning.py:512] global step 8092: loss = 0.8333 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8093: loss = 0.8477 (0.243 sec/step)\n",
            "I0802 19:51:30.583010 140624834570112 learning.py:512] global step 8093: loss = 0.8477 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8094: loss = 0.9593 (0.243 sec/step)\n",
            "I0802 19:51:30.828080 140624834570112 learning.py:512] global step 8094: loss = 0.9593 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8095: loss = 0.6767 (0.248 sec/step)\n",
            "I0802 19:51:31.078352 140624834570112 learning.py:512] global step 8095: loss = 0.6767 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8096: loss = 0.9320 (0.235 sec/step)\n",
            "I0802 19:51:31.314757 140624834570112 learning.py:512] global step 8096: loss = 0.9320 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8097: loss = 0.7677 (0.241 sec/step)\n",
            "I0802 19:51:31.557301 140624834570112 learning.py:512] global step 8097: loss = 0.7677 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8098: loss = 0.6179 (0.231 sec/step)\n",
            "I0802 19:51:31.789567 140624834570112 learning.py:512] global step 8098: loss = 0.6179 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8099: loss = 0.6593 (0.227 sec/step)\n",
            "I0802 19:51:32.018429 140624834570112 learning.py:512] global step 8099: loss = 0.6593 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8100: loss = 0.5607 (0.251 sec/step)\n",
            "I0802 19:51:32.271342 140624834570112 learning.py:512] global step 8100: loss = 0.5607 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8101: loss = 0.7477 (0.244 sec/step)\n",
            "I0802 19:51:32.516851 140624834570112 learning.py:512] global step 8101: loss = 0.7477 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8102: loss = 0.7450 (0.232 sec/step)\n",
            "I0802 19:51:32.750263 140624834570112 learning.py:512] global step 8102: loss = 0.7450 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8103: loss = 1.5868 (0.246 sec/step)\n",
            "I0802 19:51:32.998020 140624834570112 learning.py:512] global step 8103: loss = 1.5868 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8104: loss = 0.8623 (0.242 sec/step)\n",
            "I0802 19:51:33.241064 140624834570112 learning.py:512] global step 8104: loss = 0.8623 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8105: loss = 0.8480 (0.239 sec/step)\n",
            "I0802 19:51:33.481835 140624834570112 learning.py:512] global step 8105: loss = 0.8480 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8106: loss = 0.6496 (0.244 sec/step)\n",
            "I0802 19:51:33.727581 140624834570112 learning.py:512] global step 8106: loss = 0.6496 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8107: loss = 0.6704 (0.247 sec/step)\n",
            "I0802 19:51:33.976293 140624834570112 learning.py:512] global step 8107: loss = 0.6704 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8108: loss = 0.9908 (0.225 sec/step)\n",
            "I0802 19:51:34.202490 140624834570112 learning.py:512] global step 8108: loss = 0.9908 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8109: loss = 0.7862 (0.232 sec/step)\n",
            "I0802 19:51:34.435482 140624834570112 learning.py:512] global step 8109: loss = 0.7862 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8110: loss = 0.7003 (0.250 sec/step)\n",
            "I0802 19:51:34.686940 140624834570112 learning.py:512] global step 8110: loss = 0.7003 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8111: loss = 0.6763 (0.243 sec/step)\n",
            "I0802 19:51:34.930952 140624834570112 learning.py:512] global step 8111: loss = 0.6763 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8112: loss = 0.7031 (0.242 sec/step)\n",
            "I0802 19:51:35.174220 140624834570112 learning.py:512] global step 8112: loss = 0.7031 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8113: loss = 0.7928 (0.243 sec/step)\n",
            "I0802 19:51:35.418227 140624834570112 learning.py:512] global step 8113: loss = 0.7928 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8114: loss = 0.8169 (0.240 sec/step)\n",
            "I0802 19:51:35.659307 140624834570112 learning.py:512] global step 8114: loss = 0.8169 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8115: loss = 0.6891 (0.226 sec/step)\n",
            "I0802 19:51:35.887046 140624834570112 learning.py:512] global step 8115: loss = 0.6891 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8116: loss = 0.7987 (0.241 sec/step)\n",
            "I0802 19:51:36.129188 140624834570112 learning.py:512] global step 8116: loss = 0.7987 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8117: loss = 0.6465 (0.239 sec/step)\n",
            "I0802 19:51:36.369938 140624834570112 learning.py:512] global step 8117: loss = 0.6465 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8118: loss = 0.6615 (0.246 sec/step)\n",
            "I0802 19:51:36.616976 140624834570112 learning.py:512] global step 8118: loss = 0.6615 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8119: loss = 0.5660 (0.255 sec/step)\n",
            "I0802 19:51:36.873161 140624834570112 learning.py:512] global step 8119: loss = 0.5660 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8120: loss = 0.5724 (0.244 sec/step)\n",
            "I0802 19:51:37.119024 140624834570112 learning.py:512] global step 8120: loss = 0.5724 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8121: loss = 0.5935 (0.227 sec/step)\n",
            "I0802 19:51:37.347357 140624834570112 learning.py:512] global step 8121: loss = 0.5935 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8122: loss = 0.6837 (0.234 sec/step)\n",
            "I0802 19:51:37.583075 140624834570112 learning.py:512] global step 8122: loss = 0.6837 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8123: loss = 1.0966 (0.232 sec/step)\n",
            "I0802 19:51:37.816786 140624834570112 learning.py:512] global step 8123: loss = 1.0966 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8124: loss = 0.6890 (0.223 sec/step)\n",
            "I0802 19:51:38.041791 140624834570112 learning.py:512] global step 8124: loss = 0.6890 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8125: loss = 0.6193 (0.239 sec/step)\n",
            "I0802 19:51:38.282314 140624834570112 learning.py:512] global step 8125: loss = 0.6193 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8126: loss = 1.0840 (0.245 sec/step)\n",
            "I0802 19:51:38.529045 140624834570112 learning.py:512] global step 8126: loss = 1.0840 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8127: loss = 0.8197 (0.246 sec/step)\n",
            "I0802 19:51:38.777216 140624834570112 learning.py:512] global step 8127: loss = 0.8197 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8128: loss = 0.6995 (0.227 sec/step)\n",
            "I0802 19:51:39.005542 140624834570112 learning.py:512] global step 8128: loss = 0.6995 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8129: loss = 0.5185 (0.247 sec/step)\n",
            "I0802 19:51:39.253509 140624834570112 learning.py:512] global step 8129: loss = 0.5185 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8130: loss = 0.6306 (0.230 sec/step)\n",
            "I0802 19:51:39.484842 140624834570112 learning.py:512] global step 8130: loss = 0.6306 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8131: loss = 0.9012 (0.252 sec/step)\n",
            "I0802 19:51:39.738775 140624834570112 learning.py:512] global step 8131: loss = 0.9012 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8132: loss = 0.6606 (0.247 sec/step)\n",
            "I0802 19:51:39.987179 140624834570112 learning.py:512] global step 8132: loss = 0.6606 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8133: loss = 0.5973 (0.235 sec/step)\n",
            "I0802 19:51:40.223783 140624834570112 learning.py:512] global step 8133: loss = 0.5973 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8134: loss = 0.6579 (0.246 sec/step)\n",
            "I0802 19:51:40.471755 140624834570112 learning.py:512] global step 8134: loss = 0.6579 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8135: loss = 0.8502 (0.249 sec/step)\n",
            "I0802 19:51:40.722242 140624834570112 learning.py:512] global step 8135: loss = 0.8502 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8136: loss = 0.7366 (0.238 sec/step)\n",
            "I0802 19:51:40.961384 140624834570112 learning.py:512] global step 8136: loss = 0.7366 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8137: loss = 0.8432 (0.247 sec/step)\n",
            "I0802 19:51:41.209730 140624834570112 learning.py:512] global step 8137: loss = 0.8432 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8138: loss = 0.7666 (0.243 sec/step)\n",
            "I0802 19:51:41.454660 140624834570112 learning.py:512] global step 8138: loss = 0.7666 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8139: loss = 0.9225 (0.245 sec/step)\n",
            "I0802 19:51:41.700931 140624834570112 learning.py:512] global step 8139: loss = 0.9225 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8140: loss = 0.5612 (0.243 sec/step)\n",
            "I0802 19:51:41.945567 140624834570112 learning.py:512] global step 8140: loss = 0.5612 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8141: loss = 0.7834 (0.245 sec/step)\n",
            "I0802 19:51:42.192517 140624834570112 learning.py:512] global step 8141: loss = 0.7834 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8142: loss = 0.7594 (0.245 sec/step)\n",
            "I0802 19:51:42.438796 140624834570112 learning.py:512] global step 8142: loss = 0.7594 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8143: loss = 0.7523 (0.242 sec/step)\n",
            "I0802 19:51:42.682100 140624834570112 learning.py:512] global step 8143: loss = 0.7523 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8144: loss = 0.8474 (0.248 sec/step)\n",
            "I0802 19:51:42.931902 140624834570112 learning.py:512] global step 8144: loss = 0.8474 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8145: loss = 0.6232 (0.251 sec/step)\n",
            "I0802 19:51:43.184714 140624834570112 learning.py:512] global step 8145: loss = 0.6232 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8146: loss = 0.7379 (0.245 sec/step)\n",
            "I0802 19:51:43.431483 140624834570112 learning.py:512] global step 8146: loss = 0.7379 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8147: loss = 0.8476 (0.245 sec/step)\n",
            "I0802 19:51:43.678333 140624834570112 learning.py:512] global step 8147: loss = 0.8476 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8148: loss = 0.7050 (0.240 sec/step)\n",
            "I0802 19:51:43.919721 140624834570112 learning.py:512] global step 8148: loss = 0.7050 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8149: loss = 0.6560 (0.249 sec/step)\n",
            "I0802 19:51:44.170458 140624834570112 learning.py:512] global step 8149: loss = 0.6560 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8150: loss = 0.6521 (0.241 sec/step)\n",
            "I0802 19:51:44.415077 140624834570112 learning.py:512] global step 8150: loss = 0.6521 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8151: loss = 0.7828 (0.229 sec/step)\n",
            "I0802 19:51:44.646146 140624834570112 learning.py:512] global step 8151: loss = 0.7828 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8152: loss = 0.7656 (0.249 sec/step)\n",
            "I0802 19:51:44.896786 140624834570112 learning.py:512] global step 8152: loss = 0.7656 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8153: loss = 0.6620 (0.238 sec/step)\n",
            "I0802 19:51:45.136548 140624834570112 learning.py:512] global step 8153: loss = 0.6620 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8154: loss = 0.6643 (0.234 sec/step)\n",
            "I0802 19:51:45.372132 140624834570112 learning.py:512] global step 8154: loss = 0.6643 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8155: loss = 0.4747 (0.250 sec/step)\n",
            "I0802 19:51:45.623847 140624834570112 learning.py:512] global step 8155: loss = 0.4747 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8156: loss = 0.8545 (0.255 sec/step)\n",
            "I0802 19:51:45.880451 140624834570112 learning.py:512] global step 8156: loss = 0.8545 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8157: loss = 0.8605 (0.240 sec/step)\n",
            "I0802 19:51:46.122354 140624834570112 learning.py:512] global step 8157: loss = 0.8605 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8158: loss = 0.7064 (0.232 sec/step)\n",
            "I0802 19:51:46.355679 140624834570112 learning.py:512] global step 8158: loss = 0.7064 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8159: loss = 0.8403 (0.241 sec/step)\n",
            "I0802 19:51:46.598587 140624834570112 learning.py:512] global step 8159: loss = 0.8403 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8160: loss = 0.6599 (0.241 sec/step)\n",
            "I0802 19:51:46.840979 140624834570112 learning.py:512] global step 8160: loss = 0.6599 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8161: loss = 0.8103 (0.244 sec/step)\n",
            "I0802 19:51:47.087031 140624834570112 learning.py:512] global step 8161: loss = 0.8103 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8162: loss = 0.6352 (0.235 sec/step)\n",
            "I0802 19:51:47.323439 140624834570112 learning.py:512] global step 8162: loss = 0.6352 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8163: loss = 0.7409 (0.248 sec/step)\n",
            "I0802 19:51:47.572781 140624834570112 learning.py:512] global step 8163: loss = 0.7409 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8164: loss = 0.7567 (0.230 sec/step)\n",
            "I0802 19:51:47.804256 140624834570112 learning.py:512] global step 8164: loss = 0.7567 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8165: loss = 1.0740 (0.226 sec/step)\n",
            "I0802 19:51:48.031994 140624834570112 learning.py:512] global step 8165: loss = 1.0740 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8166: loss = 0.7382 (0.240 sec/step)\n",
            "I0802 19:51:48.273584 140624834570112 learning.py:512] global step 8166: loss = 0.7382 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8167: loss = 0.7406 (0.248 sec/step)\n",
            "I0802 19:51:48.522691 140624834570112 learning.py:512] global step 8167: loss = 0.7406 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8168: loss = 0.8872 (0.245 sec/step)\n",
            "I0802 19:51:48.769473 140624834570112 learning.py:512] global step 8168: loss = 0.8872 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8169: loss = 0.7035 (0.243 sec/step)\n",
            "I0802 19:51:49.013581 140624834570112 learning.py:512] global step 8169: loss = 0.7035 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8170: loss = 0.6519 (0.238 sec/step)\n",
            "I0802 19:51:49.253269 140624834570112 learning.py:512] global step 8170: loss = 0.6519 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8171: loss = 0.6983 (0.242 sec/step)\n",
            "I0802 19:51:49.496820 140624834570112 learning.py:512] global step 8171: loss = 0.6983 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8172: loss = 0.7599 (0.235 sec/step)\n",
            "I0802 19:51:49.732860 140624834570112 learning.py:512] global step 8172: loss = 0.7599 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8173: loss = 0.7442 (0.232 sec/step)\n",
            "I0802 19:51:49.966248 140624834570112 learning.py:512] global step 8173: loss = 0.7442 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8174: loss = 0.7311 (0.242 sec/step)\n",
            "I0802 19:51:50.210114 140624834570112 learning.py:512] global step 8174: loss = 0.7311 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8175: loss = 0.6093 (0.238 sec/step)\n",
            "I0802 19:51:50.449547 140624834570112 learning.py:512] global step 8175: loss = 0.6093 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8176: loss = 0.7025 (0.244 sec/step)\n",
            "I0802 19:51:50.695298 140624834570112 learning.py:512] global step 8176: loss = 0.7025 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8177: loss = 0.6449 (0.233 sec/step)\n",
            "I0802 19:51:50.929468 140624834570112 learning.py:512] global step 8177: loss = 0.6449 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8178: loss = 0.8111 (0.223 sec/step)\n",
            "I0802 19:51:51.154149 140624834570112 learning.py:512] global step 8178: loss = 0.8111 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8179: loss = 0.6681 (0.235 sec/step)\n",
            "I0802 19:51:51.389988 140624834570112 learning.py:512] global step 8179: loss = 0.6681 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8180: loss = 0.7665 (0.243 sec/step)\n",
            "I0802 19:51:51.634110 140624834570112 learning.py:512] global step 8180: loss = 0.7665 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8181: loss = 0.6828 (0.244 sec/step)\n",
            "I0802 19:51:51.879833 140624834570112 learning.py:512] global step 8181: loss = 0.6828 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8182: loss = 0.6465 (0.251 sec/step)\n",
            "I0802 19:51:52.132588 140624834570112 learning.py:512] global step 8182: loss = 0.6465 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8183: loss = 1.0933 (0.240 sec/step)\n",
            "I0802 19:51:52.374117 140624834570112 learning.py:512] global step 8183: loss = 1.0933 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8184: loss = 0.5291 (0.260 sec/step)\n",
            "I0802 19:51:52.635974 140624834570112 learning.py:512] global step 8184: loss = 0.5291 (0.260 sec/step)\n",
            "INFO:tensorflow:global step 8185: loss = 0.7153 (0.233 sec/step)\n",
            "I0802 19:51:52.870854 140624834570112 learning.py:512] global step 8185: loss = 0.7153 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8186: loss = 0.9650 (0.233 sec/step)\n",
            "I0802 19:51:53.106003 140624834570112 learning.py:512] global step 8186: loss = 0.9650 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8187: loss = 0.7420 (0.245 sec/step)\n",
            "I0802 19:51:53.352080 140624834570112 learning.py:512] global step 8187: loss = 0.7420 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8188: loss = 0.6958 (0.242 sec/step)\n",
            "I0802 19:51:53.595251 140624834570112 learning.py:512] global step 8188: loss = 0.6958 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8189: loss = 0.6483 (0.246 sec/step)\n",
            "I0802 19:51:53.842801 140624834570112 learning.py:512] global step 8189: loss = 0.6483 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8190: loss = 0.6732 (0.236 sec/step)\n",
            "I0802 19:51:54.080430 140624834570112 learning.py:512] global step 8190: loss = 0.6732 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8191: loss = 0.7485 (0.241 sec/step)\n",
            "I0802 19:51:54.323290 140624834570112 learning.py:512] global step 8191: loss = 0.7485 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8192: loss = 0.6913 (0.240 sec/step)\n",
            "I0802 19:51:54.564681 140624834570112 learning.py:512] global step 8192: loss = 0.6913 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8193: loss = 0.6517 (0.249 sec/step)\n",
            "I0802 19:51:54.815653 140624834570112 learning.py:512] global step 8193: loss = 0.6517 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8194: loss = 0.5883 (0.249 sec/step)\n",
            "I0802 19:51:55.066059 140624834570112 learning.py:512] global step 8194: loss = 0.5883 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8195: loss = 0.6687 (0.246 sec/step)\n",
            "I0802 19:51:55.313568 140624834570112 learning.py:512] global step 8195: loss = 0.6687 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8196: loss = 1.0861 (0.252 sec/step)\n",
            "I0802 19:51:55.567381 140624834570112 learning.py:512] global step 8196: loss = 1.0861 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8197: loss = 0.6010 (0.243 sec/step)\n",
            "I0802 19:51:55.811794 140624834570112 learning.py:512] global step 8197: loss = 0.6010 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8198: loss = 0.9704 (0.246 sec/step)\n",
            "I0802 19:51:56.058782 140624834570112 learning.py:512] global step 8198: loss = 0.9704 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8199: loss = 0.6824 (0.233 sec/step)\n",
            "I0802 19:51:56.293337 140624834570112 learning.py:512] global step 8199: loss = 0.6824 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8200: loss = 0.8926 (0.262 sec/step)\n",
            "I0802 19:51:56.557153 140624834570112 learning.py:512] global step 8200: loss = 0.8926 (0.262 sec/step)\n",
            "INFO:tensorflow:global step 8201: loss = 0.8036 (0.242 sec/step)\n",
            "I0802 19:51:56.800269 140624834570112 learning.py:512] global step 8201: loss = 0.8036 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8202: loss = 0.7260 (0.235 sec/step)\n",
            "I0802 19:51:57.036575 140624834570112 learning.py:512] global step 8202: loss = 0.7260 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8203: loss = 0.9710 (0.245 sec/step)\n",
            "I0802 19:51:57.283489 140624834570112 learning.py:512] global step 8203: loss = 0.9710 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8204: loss = 0.5999 (0.247 sec/step)\n",
            "I0802 19:51:57.531762 140624834570112 learning.py:512] global step 8204: loss = 0.5999 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8205: loss = 0.6077 (0.242 sec/step)\n",
            "I0802 19:51:57.775230 140624834570112 learning.py:512] global step 8205: loss = 0.6077 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8206: loss = 0.5905 (0.252 sec/step)\n",
            "I0802 19:51:58.029161 140624834570112 learning.py:512] global step 8206: loss = 0.5905 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8207: loss = 0.7269 (0.247 sec/step)\n",
            "I0802 19:51:58.277891 140624834570112 learning.py:512] global step 8207: loss = 0.7269 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8208: loss = 0.7120 (0.241 sec/step)\n",
            "I0802 19:51:58.520428 140624834570112 learning.py:512] global step 8208: loss = 0.7120 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8209: loss = 0.8235 (0.246 sec/step)\n",
            "I0802 19:51:58.767904 140624834570112 learning.py:512] global step 8209: loss = 0.8235 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8210: loss = 0.5875 (0.243 sec/step)\n",
            "I0802 19:51:59.012728 140624834570112 learning.py:512] global step 8210: loss = 0.5875 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8211: loss = 0.8674 (0.250 sec/step)\n",
            "I0802 19:51:59.264653 140624834570112 learning.py:512] global step 8211: loss = 0.8674 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8212: loss = 0.4918 (0.231 sec/step)\n",
            "I0802 19:51:59.497003 140624834570112 learning.py:512] global step 8212: loss = 0.4918 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8213: loss = 0.6453 (0.245 sec/step)\n",
            "I0802 19:51:59.743556 140624834570112 learning.py:512] global step 8213: loss = 0.6453 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8214: loss = 0.7017 (0.235 sec/step)\n",
            "I0802 19:51:59.980653 140624834570112 learning.py:512] global step 8214: loss = 0.7017 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8215: loss = 0.7945 (0.244 sec/step)\n",
            "I0802 19:52:00.226557 140624834570112 learning.py:512] global step 8215: loss = 0.7945 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8216: loss = 0.6512 (0.247 sec/step)\n",
            "I0802 19:52:00.474748 140624834570112 learning.py:512] global step 8216: loss = 0.6512 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8217: loss = 0.7768 (0.242 sec/step)\n",
            "I0802 19:52:00.717737 140624834570112 learning.py:512] global step 8217: loss = 0.7768 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8218: loss = 0.9074 (0.256 sec/step)\n",
            "I0802 19:52:00.975005 140624834570112 learning.py:512] global step 8218: loss = 0.9074 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 8219: loss = 0.6733 (0.254 sec/step)\n",
            "I0802 19:52:01.230406 140624834570112 learning.py:512] global step 8219: loss = 0.6733 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8220: loss = 0.6129 (0.242 sec/step)\n",
            "I0802 19:52:01.473976 140624834570112 learning.py:512] global step 8220: loss = 0.6129 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8221: loss = 0.6775 (0.232 sec/step)\n",
            "I0802 19:52:01.707705 140624834570112 learning.py:512] global step 8221: loss = 0.6775 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8222: loss = 0.7718 (0.247 sec/step)\n",
            "I0802 19:52:01.956263 140624834570112 learning.py:512] global step 8222: loss = 0.7718 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8223: loss = 0.6362 (0.239 sec/step)\n",
            "I0802 19:52:02.197057 140624834570112 learning.py:512] global step 8223: loss = 0.6362 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8224: loss = 0.7293 (0.229 sec/step)\n",
            "I0802 19:52:02.427328 140624834570112 learning.py:512] global step 8224: loss = 0.7293 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8225: loss = 0.9367 (0.233 sec/step)\n",
            "I0802 19:52:02.661764 140624834570112 learning.py:512] global step 8225: loss = 0.9367 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8226: loss = 0.5843 (0.255 sec/step)\n",
            "I0802 19:52:02.919198 140624834570112 learning.py:512] global step 8226: loss = 0.5843 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8227: loss = 0.5467 (0.234 sec/step)\n",
            "I0802 19:52:03.154617 140624834570112 learning.py:512] global step 8227: loss = 0.5467 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8228: loss = 0.6698 (0.241 sec/step)\n",
            "I0802 19:52:03.397193 140624834570112 learning.py:512] global step 8228: loss = 0.6698 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8229: loss = 0.6177 (0.243 sec/step)\n",
            "I0802 19:52:03.641955 140624834570112 learning.py:512] global step 8229: loss = 0.6177 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8230: loss = 0.5601 (0.249 sec/step)\n",
            "I0802 19:52:03.895287 140624834570112 learning.py:512] global step 8230: loss = 0.5601 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8231: loss = 0.6964 (0.234 sec/step)\n",
            "I0802 19:52:04.131349 140624834570112 learning.py:512] global step 8231: loss = 0.6964 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8232: loss = 0.5485 (0.246 sec/step)\n",
            "I0802 19:52:04.378849 140624834570112 learning.py:512] global step 8232: loss = 0.5485 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8233: loss = 0.7068 (0.254 sec/step)\n",
            "I0802 19:52:04.633869 140624834570112 learning.py:512] global step 8233: loss = 0.7068 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8234: loss = 0.6851 (0.244 sec/step)\n",
            "I0802 19:52:04.879532 140624834570112 learning.py:512] global step 8234: loss = 0.6851 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8235: loss = 0.9114 (0.244 sec/step)\n",
            "I0802 19:52:05.125524 140624834570112 learning.py:512] global step 8235: loss = 0.9114 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8236: loss = 0.8655 (0.243 sec/step)\n",
            "I0802 19:52:05.370527 140624834570112 learning.py:512] global step 8236: loss = 0.8655 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8237: loss = 0.7634 (0.243 sec/step)\n",
            "I0802 19:52:05.614857 140624834570112 learning.py:512] global step 8237: loss = 0.7634 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8238: loss = 0.5531 (0.250 sec/step)\n",
            "I0802 19:52:05.866477 140624834570112 learning.py:512] global step 8238: loss = 0.5531 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8239: loss = 0.4947 (0.243 sec/step)\n",
            "I0802 19:52:06.111022 140624834570112 learning.py:512] global step 8239: loss = 0.4947 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8240: loss = 0.8283 (0.247 sec/step)\n",
            "I0802 19:52:06.359542 140624834570112 learning.py:512] global step 8240: loss = 0.8283 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8241: loss = 0.6100 (0.252 sec/step)\n",
            "I0802 19:52:06.613134 140624834570112 learning.py:512] global step 8241: loss = 0.6100 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8242: loss = 0.7625 (0.243 sec/step)\n",
            "I0802 19:52:06.857760 140624834570112 learning.py:512] global step 8242: loss = 0.7625 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8243: loss = 0.8200 (0.240 sec/step)\n",
            "I0802 19:52:07.099379 140624834570112 learning.py:512] global step 8243: loss = 0.8200 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8244: loss = 0.7115 (0.233 sec/step)\n",
            "I0802 19:52:07.334433 140624834570112 learning.py:512] global step 8244: loss = 0.7115 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8245: loss = 0.7008 (0.244 sec/step)\n",
            "I0802 19:52:07.580291 140624834570112 learning.py:512] global step 8245: loss = 0.7008 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8246: loss = 0.7276 (0.235 sec/step)\n",
            "I0802 19:52:07.817126 140624834570112 learning.py:512] global step 8246: loss = 0.7276 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8247: loss = 0.6248 (0.245 sec/step)\n",
            "I0802 19:52:08.063080 140624834570112 learning.py:512] global step 8247: loss = 0.6248 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8248: loss = 0.7495 (0.246 sec/step)\n",
            "I0802 19:52:08.310625 140624834570112 learning.py:512] global step 8248: loss = 0.7495 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8249: loss = 0.6965 (0.232 sec/step)\n",
            "I0802 19:52:08.544512 140624834570112 learning.py:512] global step 8249: loss = 0.6965 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8250: loss = 0.6417 (0.253 sec/step)\n",
            "I0802 19:52:08.799060 140624834570112 learning.py:512] global step 8250: loss = 0.6417 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8251: loss = 0.8753 (0.235 sec/step)\n",
            "I0802 19:52:09.035775 140624834570112 learning.py:512] global step 8251: loss = 0.8753 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8252: loss = 0.7053 (0.242 sec/step)\n",
            "I0802 19:52:09.279251 140624834570112 learning.py:512] global step 8252: loss = 0.7053 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8253: loss = 0.7999 (0.263 sec/step)\n",
            "I0802 19:52:09.544184 140624834570112 learning.py:512] global step 8253: loss = 0.7999 (0.263 sec/step)\n",
            "INFO:tensorflow:global step 8254: loss = 0.8123 (0.243 sec/step)\n",
            "I0802 19:52:09.788467 140624834570112 learning.py:512] global step 8254: loss = 0.8123 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8255: loss = 0.6906 (0.243 sec/step)\n",
            "I0802 19:52:10.032892 140624834570112 learning.py:512] global step 8255: loss = 0.6906 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8256: loss = 0.9116 (0.246 sec/step)\n",
            "I0802 19:52:10.280779 140624834570112 learning.py:512] global step 8256: loss = 0.9116 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8257: loss = 0.6072 (0.248 sec/step)\n",
            "I0802 19:52:10.529889 140624834570112 learning.py:512] global step 8257: loss = 0.6072 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8258: loss = 0.5805 (0.228 sec/step)\n",
            "I0802 19:52:10.759591 140624834570112 learning.py:512] global step 8258: loss = 0.5805 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8259: loss = 0.8479 (0.243 sec/step)\n",
            "I0802 19:52:11.003723 140624834570112 learning.py:512] global step 8259: loss = 0.8479 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8260: loss = 0.8179 (0.250 sec/step)\n",
            "I0802 19:52:11.255287 140624834570112 learning.py:512] global step 8260: loss = 0.8179 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8261: loss = 0.5902 (0.256 sec/step)\n",
            "I0802 19:52:11.512497 140624834570112 learning.py:512] global step 8261: loss = 0.5902 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 8262: loss = 0.8711 (0.238 sec/step)\n",
            "I0802 19:52:11.752012 140624834570112 learning.py:512] global step 8262: loss = 0.8711 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8263: loss = 0.7204 (0.248 sec/step)\n",
            "I0802 19:52:12.001763 140624834570112 learning.py:512] global step 8263: loss = 0.7204 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8264: loss = 0.6215 (0.256 sec/step)\n",
            "I0802 19:52:12.259550 140624834570112 learning.py:512] global step 8264: loss = 0.6215 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 8265: loss = 0.6317 (0.245 sec/step)\n",
            "I0802 19:52:12.505942 140624834570112 learning.py:512] global step 8265: loss = 0.6317 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8266: loss = 0.5327 (0.250 sec/step)\n",
            "I0802 19:52:12.757027 140624834570112 learning.py:512] global step 8266: loss = 0.5327 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8267: loss = 0.7347 (0.252 sec/step)\n",
            "I0802 19:52:13.011000 140624834570112 learning.py:512] global step 8267: loss = 0.7347 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8268: loss = 0.6286 (0.249 sec/step)\n",
            "I0802 19:52:13.261439 140624834570112 learning.py:512] global step 8268: loss = 0.6286 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8269: loss = 0.7147 (0.246 sec/step)\n",
            "I0802 19:52:13.508730 140624834570112 learning.py:512] global step 8269: loss = 0.7147 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8270: loss = 0.6248 (0.246 sec/step)\n",
            "I0802 19:52:13.757086 140624834570112 learning.py:512] global step 8270: loss = 0.6248 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8271: loss = 0.8431 (0.245 sec/step)\n",
            "I0802 19:52:14.004290 140624834570112 learning.py:512] global step 8271: loss = 0.8431 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8272: loss = 0.6739 (0.254 sec/step)\n",
            "I0802 19:52:14.259702 140624834570112 learning.py:512] global step 8272: loss = 0.6739 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8273: loss = 0.6581 (0.247 sec/step)\n",
            "I0802 19:52:14.507905 140624834570112 learning.py:512] global step 8273: loss = 0.6581 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8274: loss = 0.6955 (0.243 sec/step)\n",
            "I0802 19:52:14.752162 140624834570112 learning.py:512] global step 8274: loss = 0.6955 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8275: loss = 0.6620 (0.260 sec/step)\n",
            "I0802 19:52:15.016602 140624834570112 learning.py:512] global step 8275: loss = 0.6620 (0.260 sec/step)\n",
            "INFO:tensorflow:global step 8276: loss = 0.6814 (0.307 sec/step)\n",
            "I0802 19:52:15.326992 140624834570112 learning.py:512] global step 8276: loss = 0.6814 (0.307 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 8276.\n",
            "I0802 19:52:15.348095 140620445013760 supervisor.py:1050] Recording summary at step 8276.\n",
            "INFO:tensorflow:global step 8277: loss = 0.8251 (0.252 sec/step)\n",
            "I0802 19:52:15.585577 140624834570112 learning.py:512] global step 8277: loss = 0.8251 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8278: loss = 0.7134 (0.241 sec/step)\n",
            "I0802 19:52:15.827708 140624834570112 learning.py:512] global step 8278: loss = 0.7134 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8279: loss = 0.8535 (0.234 sec/step)\n",
            "I0802 19:52:16.063095 140624834570112 learning.py:512] global step 8279: loss = 0.8535 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8280: loss = 0.6221 (0.245 sec/step)\n",
            "I0802 19:52:16.309576 140624834570112 learning.py:512] global step 8280: loss = 0.6221 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8281: loss = 0.7569 (0.237 sec/step)\n",
            "I0802 19:52:16.547616 140624834570112 learning.py:512] global step 8281: loss = 0.7569 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8282: loss = 0.5915 (0.243 sec/step)\n",
            "I0802 19:52:16.792089 140624834570112 learning.py:512] global step 8282: loss = 0.5915 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8283: loss = 0.5697 (0.238 sec/step)\n",
            "I0802 19:52:17.032207 140624834570112 learning.py:512] global step 8283: loss = 0.5697 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8284: loss = 0.9178 (0.241 sec/step)\n",
            "I0802 19:52:17.275070 140624834570112 learning.py:512] global step 8284: loss = 0.9178 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8285: loss = 0.7572 (0.236 sec/step)\n",
            "I0802 19:52:17.511979 140624834570112 learning.py:512] global step 8285: loss = 0.7572 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8286: loss = 0.7962 (0.231 sec/step)\n",
            "I0802 19:52:17.744385 140624834570112 learning.py:512] global step 8286: loss = 0.7962 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8287: loss = 0.6620 (0.247 sec/step)\n",
            "I0802 19:52:17.993401 140624834570112 learning.py:512] global step 8287: loss = 0.6620 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8288: loss = 0.6814 (0.245 sec/step)\n",
            "I0802 19:52:18.239968 140624834570112 learning.py:512] global step 8288: loss = 0.6814 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8289: loss = 0.8850 (0.237 sec/step)\n",
            "I0802 19:52:18.478386 140624834570112 learning.py:512] global step 8289: loss = 0.8850 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8290: loss = 0.5702 (0.236 sec/step)\n",
            "I0802 19:52:18.716199 140624834570112 learning.py:512] global step 8290: loss = 0.5702 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8291: loss = 0.6734 (0.242 sec/step)\n",
            "I0802 19:52:18.959852 140624834570112 learning.py:512] global step 8291: loss = 0.6734 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8292: loss = 0.6208 (0.241 sec/step)\n",
            "I0802 19:52:19.201826 140624834570112 learning.py:512] global step 8292: loss = 0.6208 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8293: loss = 0.8112 (0.235 sec/step)\n",
            "I0802 19:52:19.438356 140624834570112 learning.py:512] global step 8293: loss = 0.8112 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8294: loss = 0.5622 (0.244 sec/step)\n",
            "I0802 19:52:19.683945 140624834570112 learning.py:512] global step 8294: loss = 0.5622 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8295: loss = 0.7516 (0.243 sec/step)\n",
            "I0802 19:52:19.928074 140624834570112 learning.py:512] global step 8295: loss = 0.7516 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8296: loss = 0.4826 (0.233 sec/step)\n",
            "I0802 19:52:20.162401 140624834570112 learning.py:512] global step 8296: loss = 0.4826 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8297: loss = 0.6649 (0.244 sec/step)\n",
            "I0802 19:52:20.408246 140624834570112 learning.py:512] global step 8297: loss = 0.6649 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8298: loss = 0.7461 (0.246 sec/step)\n",
            "I0802 19:52:20.655558 140624834570112 learning.py:512] global step 8298: loss = 0.7461 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8299: loss = 0.7748 (0.246 sec/step)\n",
            "I0802 19:52:20.905089 140624834570112 learning.py:512] global step 8299: loss = 0.7748 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8300: loss = 1.2094 (0.247 sec/step)\n",
            "I0802 19:52:21.153779 140624834570112 learning.py:512] global step 8300: loss = 1.2094 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8301: loss = 0.6311 (0.241 sec/step)\n",
            "I0802 19:52:21.396281 140624834570112 learning.py:512] global step 8301: loss = 0.6311 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8302: loss = 0.6139 (0.244 sec/step)\n",
            "I0802 19:52:21.641782 140624834570112 learning.py:512] global step 8302: loss = 0.6139 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8303: loss = 0.7801 (0.242 sec/step)\n",
            "I0802 19:52:21.885465 140624834570112 learning.py:512] global step 8303: loss = 0.7801 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8304: loss = 0.8457 (0.245 sec/step)\n",
            "I0802 19:52:22.132218 140624834570112 learning.py:512] global step 8304: loss = 0.8457 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8305: loss = 0.8862 (0.235 sec/step)\n",
            "I0802 19:52:22.368767 140624834570112 learning.py:512] global step 8305: loss = 0.8862 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8306: loss = 0.6391 (0.251 sec/step)\n",
            "I0802 19:52:22.621529 140624834570112 learning.py:512] global step 8306: loss = 0.6391 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8307: loss = 0.5449 (0.254 sec/step)\n",
            "I0802 19:52:22.877576 140624834570112 learning.py:512] global step 8307: loss = 0.5449 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8308: loss = 0.6230 (0.242 sec/step)\n",
            "I0802 19:52:23.120651 140624834570112 learning.py:512] global step 8308: loss = 0.6230 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8309: loss = 0.8488 (0.244 sec/step)\n",
            "I0802 19:52:23.366176 140624834570112 learning.py:512] global step 8309: loss = 0.8488 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8310: loss = 1.0251 (0.248 sec/step)\n",
            "I0802 19:52:23.615672 140624834570112 learning.py:512] global step 8310: loss = 1.0251 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8311: loss = 0.9892 (0.228 sec/step)\n",
            "I0802 19:52:23.845151 140624834570112 learning.py:512] global step 8311: loss = 0.9892 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8312: loss = 0.6709 (0.239 sec/step)\n",
            "I0802 19:52:24.085496 140624834570112 learning.py:512] global step 8312: loss = 0.6709 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8313: loss = 1.1374 (0.251 sec/step)\n",
            "I0802 19:52:24.337687 140624834570112 learning.py:512] global step 8313: loss = 1.1374 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8314: loss = 0.8249 (0.242 sec/step)\n",
            "I0802 19:52:24.580959 140624834570112 learning.py:512] global step 8314: loss = 0.8249 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8315: loss = 0.5619 (0.237 sec/step)\n",
            "I0802 19:52:24.819900 140624834570112 learning.py:512] global step 8315: loss = 0.5619 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8316: loss = 0.8137 (0.240 sec/step)\n",
            "I0802 19:52:25.060873 140624834570112 learning.py:512] global step 8316: loss = 0.8137 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8317: loss = 0.8232 (0.232 sec/step)\n",
            "I0802 19:52:25.294053 140624834570112 learning.py:512] global step 8317: loss = 0.8232 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8318: loss = 0.6087 (0.249 sec/step)\n",
            "I0802 19:52:25.543987 140624834570112 learning.py:512] global step 8318: loss = 0.6087 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8319: loss = 0.7139 (0.230 sec/step)\n",
            "I0802 19:52:25.775830 140624834570112 learning.py:512] global step 8319: loss = 0.7139 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8320: loss = 0.6873 (0.247 sec/step)\n",
            "I0802 19:52:26.023847 140624834570112 learning.py:512] global step 8320: loss = 0.6873 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8321: loss = 0.5824 (0.239 sec/step)\n",
            "I0802 19:52:26.264583 140624834570112 learning.py:512] global step 8321: loss = 0.5824 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8322: loss = 0.6854 (0.239 sec/step)\n",
            "I0802 19:52:26.505600 140624834570112 learning.py:512] global step 8322: loss = 0.6854 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8323: loss = 0.6725 (0.247 sec/step)\n",
            "I0802 19:52:26.753830 140624834570112 learning.py:512] global step 8323: loss = 0.6725 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8324: loss = 0.5231 (0.226 sec/step)\n",
            "I0802 19:52:26.981173 140624834570112 learning.py:512] global step 8324: loss = 0.5231 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8325: loss = 0.8268 (0.235 sec/step)\n",
            "I0802 19:52:27.218009 140624834570112 learning.py:512] global step 8325: loss = 0.8268 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8326: loss = 0.7277 (0.244 sec/step)\n",
            "I0802 19:52:27.463683 140624834570112 learning.py:512] global step 8326: loss = 0.7277 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8327: loss = 0.6586 (0.237 sec/step)\n",
            "I0802 19:52:27.701840 140624834570112 learning.py:512] global step 8327: loss = 0.6586 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8328: loss = 0.7353 (0.245 sec/step)\n",
            "I0802 19:52:27.948503 140624834570112 learning.py:512] global step 8328: loss = 0.7353 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8329: loss = 0.6359 (0.229 sec/step)\n",
            "I0802 19:52:28.178908 140624834570112 learning.py:512] global step 8329: loss = 0.6359 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8330: loss = 0.6905 (0.241 sec/step)\n",
            "I0802 19:52:28.421949 140624834570112 learning.py:512] global step 8330: loss = 0.6905 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8331: loss = 0.8118 (0.240 sec/step)\n",
            "I0802 19:52:28.664898 140624834570112 learning.py:512] global step 8331: loss = 0.8118 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8332: loss = 0.6805 (0.244 sec/step)\n",
            "I0802 19:52:28.911558 140624834570112 learning.py:512] global step 8332: loss = 0.6805 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8333: loss = 0.6727 (0.245 sec/step)\n",
            "I0802 19:52:29.157848 140624834570112 learning.py:512] global step 8333: loss = 0.6727 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8334: loss = 0.8008 (0.246 sec/step)\n",
            "I0802 19:52:29.406047 140624834570112 learning.py:512] global step 8334: loss = 0.8008 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8335: loss = 1.0199 (0.243 sec/step)\n",
            "I0802 19:52:29.650102 140624834570112 learning.py:512] global step 8335: loss = 1.0199 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8336: loss = 0.9841 (0.253 sec/step)\n",
            "I0802 19:52:29.904034 140624834570112 learning.py:512] global step 8336: loss = 0.9841 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8337: loss = 0.8606 (0.233 sec/step)\n",
            "I0802 19:52:30.138544 140624834570112 learning.py:512] global step 8337: loss = 0.8606 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8338: loss = 0.9699 (0.249 sec/step)\n",
            "I0802 19:52:30.389328 140624834570112 learning.py:512] global step 8338: loss = 0.9699 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8339: loss = 1.0103 (0.237 sec/step)\n",
            "I0802 19:52:30.627251 140624834570112 learning.py:512] global step 8339: loss = 1.0103 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8340: loss = 0.6054 (0.245 sec/step)\n",
            "I0802 19:52:30.873884 140624834570112 learning.py:512] global step 8340: loss = 0.6054 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8341: loss = 0.8739 (0.233 sec/step)\n",
            "I0802 19:52:31.108072 140624834570112 learning.py:512] global step 8341: loss = 0.8739 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8342: loss = 0.6611 (0.244 sec/step)\n",
            "I0802 19:52:31.353854 140624834570112 learning.py:512] global step 8342: loss = 0.6611 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8343: loss = 0.7828 (0.238 sec/step)\n",
            "I0802 19:52:31.593315 140624834570112 learning.py:512] global step 8343: loss = 0.7828 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8344: loss = 0.9476 (0.245 sec/step)\n",
            "I0802 19:52:31.839393 140624834570112 learning.py:512] global step 8344: loss = 0.9476 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8345: loss = 0.5611 (0.244 sec/step)\n",
            "I0802 19:52:32.085509 140624834570112 learning.py:512] global step 8345: loss = 0.5611 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8346: loss = 0.7056 (0.240 sec/step)\n",
            "I0802 19:52:32.326747 140624834570112 learning.py:512] global step 8346: loss = 0.7056 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8347: loss = 0.8619 (0.243 sec/step)\n",
            "I0802 19:52:32.571497 140624834570112 learning.py:512] global step 8347: loss = 0.8619 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8348: loss = 0.7922 (0.246 sec/step)\n",
            "I0802 19:52:32.819102 140624834570112 learning.py:512] global step 8348: loss = 0.7922 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8349: loss = 0.7314 (0.242 sec/step)\n",
            "I0802 19:52:33.062739 140624834570112 learning.py:512] global step 8349: loss = 0.7314 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8350: loss = 0.7997 (0.238 sec/step)\n",
            "I0802 19:52:33.302263 140624834570112 learning.py:512] global step 8350: loss = 0.7997 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8351: loss = 0.7856 (0.242 sec/step)\n",
            "I0802 19:52:33.545682 140624834570112 learning.py:512] global step 8351: loss = 0.7856 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8352: loss = 0.7243 (0.253 sec/step)\n",
            "I0802 19:52:33.800000 140624834570112 learning.py:512] global step 8352: loss = 0.7243 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8353: loss = 0.5703 (0.238 sec/step)\n",
            "I0802 19:52:34.039619 140624834570112 learning.py:512] global step 8353: loss = 0.5703 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8354: loss = 0.7436 (0.241 sec/step)\n",
            "I0802 19:52:34.281820 140624834570112 learning.py:512] global step 8354: loss = 0.7436 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8355: loss = 0.7896 (0.233 sec/step)\n",
            "I0802 19:52:34.516502 140624834570112 learning.py:512] global step 8355: loss = 0.7896 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8356: loss = 0.5789 (0.238 sec/step)\n",
            "I0802 19:52:34.755463 140624834570112 learning.py:512] global step 8356: loss = 0.5789 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8357: loss = 0.7550 (0.233 sec/step)\n",
            "I0802 19:52:34.990105 140624834570112 learning.py:512] global step 8357: loss = 0.7550 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8358: loss = 0.7261 (0.233 sec/step)\n",
            "I0802 19:52:35.223989 140624834570112 learning.py:512] global step 8358: loss = 0.7261 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8359: loss = 0.9257 (0.241 sec/step)\n",
            "I0802 19:52:35.466550 140624834570112 learning.py:512] global step 8359: loss = 0.9257 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8360: loss = 1.0264 (0.244 sec/step)\n",
            "I0802 19:52:35.711598 140624834570112 learning.py:512] global step 8360: loss = 1.0264 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8361: loss = 0.7913 (0.251 sec/step)\n",
            "I0802 19:52:35.963884 140624834570112 learning.py:512] global step 8361: loss = 0.7913 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8362: loss = 0.7532 (0.230 sec/step)\n",
            "I0802 19:52:36.195375 140624834570112 learning.py:512] global step 8362: loss = 0.7532 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8363: loss = 0.6183 (0.242 sec/step)\n",
            "I0802 19:52:36.439126 140624834570112 learning.py:512] global step 8363: loss = 0.6183 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8364: loss = 0.6681 (0.238 sec/step)\n",
            "I0802 19:52:36.678536 140624834570112 learning.py:512] global step 8364: loss = 0.6681 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8365: loss = 0.6495 (0.230 sec/step)\n",
            "I0802 19:52:36.910455 140624834570112 learning.py:512] global step 8365: loss = 0.6495 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8366: loss = 0.8119 (0.242 sec/step)\n",
            "I0802 19:52:37.154319 140624834570112 learning.py:512] global step 8366: loss = 0.8119 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8367: loss = 0.6003 (0.240 sec/step)\n",
            "I0802 19:52:37.395215 140624834570112 learning.py:512] global step 8367: loss = 0.6003 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8368: loss = 0.7239 (0.227 sec/step)\n",
            "I0802 19:52:37.623444 140624834570112 learning.py:512] global step 8368: loss = 0.7239 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8369: loss = 0.8235 (0.246 sec/step)\n",
            "I0802 19:52:37.870844 140624834570112 learning.py:512] global step 8369: loss = 0.8235 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8370: loss = 0.7779 (0.233 sec/step)\n",
            "I0802 19:52:38.105855 140624834570112 learning.py:512] global step 8370: loss = 0.7779 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8371: loss = 0.7948 (0.239 sec/step)\n",
            "I0802 19:52:38.346723 140624834570112 learning.py:512] global step 8371: loss = 0.7948 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8372: loss = 0.7788 (0.239 sec/step)\n",
            "I0802 19:52:38.587187 140624834570112 learning.py:512] global step 8372: loss = 0.7788 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8373: loss = 0.7277 (0.246 sec/step)\n",
            "I0802 19:52:38.835122 140624834570112 learning.py:512] global step 8373: loss = 0.7277 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8374: loss = 0.7502 (0.229 sec/step)\n",
            "I0802 19:52:39.065807 140624834570112 learning.py:512] global step 8374: loss = 0.7502 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8375: loss = 0.8281 (0.237 sec/step)\n",
            "I0802 19:52:39.304658 140624834570112 learning.py:512] global step 8375: loss = 0.8281 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8376: loss = 0.6158 (0.251 sec/step)\n",
            "I0802 19:52:39.557283 140624834570112 learning.py:512] global step 8376: loss = 0.6158 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8377: loss = 0.6244 (0.242 sec/step)\n",
            "I0802 19:52:39.800652 140624834570112 learning.py:512] global step 8377: loss = 0.6244 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8378: loss = 0.5690 (0.239 sec/step)\n",
            "I0802 19:52:40.040992 140624834570112 learning.py:512] global step 8378: loss = 0.5690 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8379: loss = 0.7460 (0.238 sec/step)\n",
            "I0802 19:52:40.280656 140624834570112 learning.py:512] global step 8379: loss = 0.7460 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8380: loss = 0.9341 (0.249 sec/step)\n",
            "I0802 19:52:40.531004 140624834570112 learning.py:512] global step 8380: loss = 0.9341 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8381: loss = 0.9477 (0.248 sec/step)\n",
            "I0802 19:52:40.780506 140624834570112 learning.py:512] global step 8381: loss = 0.9477 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8382: loss = 0.6533 (0.249 sec/step)\n",
            "I0802 19:52:41.031187 140624834570112 learning.py:512] global step 8382: loss = 0.6533 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8383: loss = 0.6163 (0.228 sec/step)\n",
            "I0802 19:52:41.260315 140624834570112 learning.py:512] global step 8383: loss = 0.6163 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8384: loss = 0.5829 (0.246 sec/step)\n",
            "I0802 19:52:41.508182 140624834570112 learning.py:512] global step 8384: loss = 0.5829 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8385: loss = 0.9301 (0.235 sec/step)\n",
            "I0802 19:52:41.745230 140624834570112 learning.py:512] global step 8385: loss = 0.9301 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8386: loss = 0.5830 (0.245 sec/step)\n",
            "I0802 19:52:41.991361 140624834570112 learning.py:512] global step 8386: loss = 0.5830 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8387: loss = 0.6012 (0.243 sec/step)\n",
            "I0802 19:52:42.236776 140624834570112 learning.py:512] global step 8387: loss = 0.6012 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8388: loss = 0.6384 (0.245 sec/step)\n",
            "I0802 19:52:42.485109 140624834570112 learning.py:512] global step 8388: loss = 0.6384 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8389: loss = 0.8032 (0.249 sec/step)\n",
            "I0802 19:52:42.736050 140624834570112 learning.py:512] global step 8389: loss = 0.8032 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8390: loss = 0.7553 (0.244 sec/step)\n",
            "I0802 19:52:42.982068 140624834570112 learning.py:512] global step 8390: loss = 0.7553 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8391: loss = 0.7700 (0.237 sec/step)\n",
            "I0802 19:52:43.220247 140624834570112 learning.py:512] global step 8391: loss = 0.7700 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8392: loss = 0.7779 (0.235 sec/step)\n",
            "I0802 19:52:43.457154 140624834570112 learning.py:512] global step 8392: loss = 0.7779 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8393: loss = 0.7984 (0.234 sec/step)\n",
            "I0802 19:52:43.692647 140624834570112 learning.py:512] global step 8393: loss = 0.7984 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8394: loss = 0.7773 (0.247 sec/step)\n",
            "I0802 19:52:43.940886 140624834570112 learning.py:512] global step 8394: loss = 0.7773 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8395: loss = 0.8490 (0.230 sec/step)\n",
            "I0802 19:52:44.172544 140624834570112 learning.py:512] global step 8395: loss = 0.8490 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8396: loss = 0.9053 (0.236 sec/step)\n",
            "I0802 19:52:44.410096 140624834570112 learning.py:512] global step 8396: loss = 0.9053 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8397: loss = 0.8005 (0.242 sec/step)\n",
            "I0802 19:52:44.653910 140624834570112 learning.py:512] global step 8397: loss = 0.8005 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8398: loss = 0.6757 (0.245 sec/step)\n",
            "I0802 19:52:44.900137 140624834570112 learning.py:512] global step 8398: loss = 0.6757 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8399: loss = 0.6663 (0.243 sec/step)\n",
            "I0802 19:52:45.144482 140624834570112 learning.py:512] global step 8399: loss = 0.6663 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8400: loss = 0.8023 (0.243 sec/step)\n",
            "I0802 19:52:45.388835 140624834570112 learning.py:512] global step 8400: loss = 0.8023 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8401: loss = 0.7266 (0.233 sec/step)\n",
            "I0802 19:52:45.623183 140624834570112 learning.py:512] global step 8401: loss = 0.7266 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8402: loss = 0.7126 (0.244 sec/step)\n",
            "I0802 19:52:45.868700 140624834570112 learning.py:512] global step 8402: loss = 0.7126 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8403: loss = 0.7549 (0.228 sec/step)\n",
            "I0802 19:52:46.098601 140624834570112 learning.py:512] global step 8403: loss = 0.7549 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8404: loss = 0.8241 (0.236 sec/step)\n",
            "I0802 19:52:46.335618 140624834570112 learning.py:512] global step 8404: loss = 0.8241 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8405: loss = 0.7106 (0.249 sec/step)\n",
            "I0802 19:52:46.586072 140624834570112 learning.py:512] global step 8405: loss = 0.7106 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8406: loss = 0.8693 (0.229 sec/step)\n",
            "I0802 19:52:46.816741 140624834570112 learning.py:512] global step 8406: loss = 0.8693 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8407: loss = 0.8160 (0.247 sec/step)\n",
            "I0802 19:52:47.065490 140624834570112 learning.py:512] global step 8407: loss = 0.8160 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8408: loss = 0.7661 (0.242 sec/step)\n",
            "I0802 19:52:47.308823 140624834570112 learning.py:512] global step 8408: loss = 0.7661 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8409: loss = 0.7861 (0.248 sec/step)\n",
            "I0802 19:52:47.558273 140624834570112 learning.py:512] global step 8409: loss = 0.7861 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8410: loss = 0.9144 (0.244 sec/step)\n",
            "I0802 19:52:47.803820 140624834570112 learning.py:512] global step 8410: loss = 0.9144 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8411: loss = 0.7107 (0.241 sec/step)\n",
            "I0802 19:52:48.045861 140624834570112 learning.py:512] global step 8411: loss = 0.7107 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8412: loss = 0.6809 (0.243 sec/step)\n",
            "I0802 19:52:48.290477 140624834570112 learning.py:512] global step 8412: loss = 0.6809 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8413: loss = 0.7673 (0.243 sec/step)\n",
            "I0802 19:52:48.534664 140624834570112 learning.py:512] global step 8413: loss = 0.7673 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8414: loss = 0.7906 (0.227 sec/step)\n",
            "I0802 19:52:48.763195 140624834570112 learning.py:512] global step 8414: loss = 0.7906 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8415: loss = 0.7365 (0.232 sec/step)\n",
            "I0802 19:52:48.996769 140624834570112 learning.py:512] global step 8415: loss = 0.7365 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8416: loss = 0.7805 (0.239 sec/step)\n",
            "I0802 19:52:49.236700 140624834570112 learning.py:512] global step 8416: loss = 0.7805 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8417: loss = 0.6330 (0.255 sec/step)\n",
            "I0802 19:52:49.494166 140624834570112 learning.py:512] global step 8417: loss = 0.6330 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8418: loss = 0.6268 (0.223 sec/step)\n",
            "I0802 19:52:49.718892 140624834570112 learning.py:512] global step 8418: loss = 0.6268 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8419: loss = 0.6154 (0.240 sec/step)\n",
            "I0802 19:52:49.960448 140624834570112 learning.py:512] global step 8419: loss = 0.6154 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8420: loss = 0.7632 (0.242 sec/step)\n",
            "I0802 19:52:50.204096 140624834570112 learning.py:512] global step 8420: loss = 0.7632 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8421: loss = 0.6415 (0.247 sec/step)\n",
            "I0802 19:52:50.452879 140624834570112 learning.py:512] global step 8421: loss = 0.6415 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8422: loss = 1.3080 (0.246 sec/step)\n",
            "I0802 19:52:50.701035 140624834570112 learning.py:512] global step 8422: loss = 1.3080 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8423: loss = 0.7402 (0.251 sec/step)\n",
            "I0802 19:52:50.953788 140624834570112 learning.py:512] global step 8423: loss = 0.7402 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8424: loss = 0.6805 (0.250 sec/step)\n",
            "I0802 19:52:51.205062 140624834570112 learning.py:512] global step 8424: loss = 0.6805 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8425: loss = 0.7755 (0.223 sec/step)\n",
            "I0802 19:52:51.429819 140624834570112 learning.py:512] global step 8425: loss = 0.7755 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8426: loss = 0.8078 (0.236 sec/step)\n",
            "I0802 19:52:51.666844 140624834570112 learning.py:512] global step 8426: loss = 0.8078 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8427: loss = 0.7439 (0.222 sec/step)\n",
            "I0802 19:52:51.890568 140624834570112 learning.py:512] global step 8427: loss = 0.7439 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8428: loss = 0.7506 (0.241 sec/step)\n",
            "I0802 19:52:52.133497 140624834570112 learning.py:512] global step 8428: loss = 0.7506 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8429: loss = 0.9052 (0.238 sec/step)\n",
            "I0802 19:52:52.372781 140624834570112 learning.py:512] global step 8429: loss = 0.9052 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8430: loss = 0.7362 (0.237 sec/step)\n",
            "I0802 19:52:52.611363 140624834570112 learning.py:512] global step 8430: loss = 0.7362 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8431: loss = 0.7236 (0.243 sec/step)\n",
            "I0802 19:52:52.856060 140624834570112 learning.py:512] global step 8431: loss = 0.7236 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8432: loss = 0.7600 (0.247 sec/step)\n",
            "I0802 19:52:53.104403 140624834570112 learning.py:512] global step 8432: loss = 0.7600 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8433: loss = 0.7937 (0.240 sec/step)\n",
            "I0802 19:52:53.345625 140624834570112 learning.py:512] global step 8433: loss = 0.7937 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8434: loss = 1.1864 (0.240 sec/step)\n",
            "I0802 19:52:53.587627 140624834570112 learning.py:512] global step 8434: loss = 1.1864 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8435: loss = 0.6420 (0.245 sec/step)\n",
            "I0802 19:52:53.834023 140624834570112 learning.py:512] global step 8435: loss = 0.6420 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8436: loss = 0.6033 (0.236 sec/step)\n",
            "I0802 19:52:54.071270 140624834570112 learning.py:512] global step 8436: loss = 0.6033 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8437: loss = 0.6993 (0.247 sec/step)\n",
            "I0802 19:52:54.319576 140624834570112 learning.py:512] global step 8437: loss = 0.6993 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8438: loss = 0.6895 (0.240 sec/step)\n",
            "I0802 19:52:54.561322 140624834570112 learning.py:512] global step 8438: loss = 0.6895 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8439: loss = 0.9508 (0.239 sec/step)\n",
            "I0802 19:52:54.801928 140624834570112 learning.py:512] global step 8439: loss = 0.9508 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8440: loss = 0.6781 (0.246 sec/step)\n",
            "I0802 19:52:55.049759 140624834570112 learning.py:512] global step 8440: loss = 0.6781 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8441: loss = 1.0927 (0.244 sec/step)\n",
            "I0802 19:52:55.294859 140624834570112 learning.py:512] global step 8441: loss = 1.0927 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8442: loss = 0.7215 (0.241 sec/step)\n",
            "I0802 19:52:55.537308 140624834570112 learning.py:512] global step 8442: loss = 0.7215 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8443: loss = 0.9347 (0.239 sec/step)\n",
            "I0802 19:52:55.778224 140624834570112 learning.py:512] global step 8443: loss = 0.9347 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8444: loss = 0.7534 (0.228 sec/step)\n",
            "I0802 19:52:56.007835 140624834570112 learning.py:512] global step 8444: loss = 0.7534 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8445: loss = 0.7458 (0.243 sec/step)\n",
            "I0802 19:52:56.252469 140624834570112 learning.py:512] global step 8445: loss = 0.7458 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8446: loss = 0.7157 (0.236 sec/step)\n",
            "I0802 19:52:56.489858 140624834570112 learning.py:512] global step 8446: loss = 0.7157 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8447: loss = 0.8056 (0.243 sec/step)\n",
            "I0802 19:52:56.734612 140624834570112 learning.py:512] global step 8447: loss = 0.8056 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8448: loss = 0.6937 (0.237 sec/step)\n",
            "I0802 19:52:56.973152 140624834570112 learning.py:512] global step 8448: loss = 0.6937 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8449: loss = 0.6204 (0.240 sec/step)\n",
            "I0802 19:52:57.214119 140624834570112 learning.py:512] global step 8449: loss = 0.6204 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8450: loss = 0.6721 (0.242 sec/step)\n",
            "I0802 19:52:57.457798 140624834570112 learning.py:512] global step 8450: loss = 0.6721 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8451: loss = 0.7445 (0.235 sec/step)\n",
            "I0802 19:52:57.694088 140624834570112 learning.py:512] global step 8451: loss = 0.7445 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8452: loss = 0.7240 (0.237 sec/step)\n",
            "I0802 19:52:57.932888 140624834570112 learning.py:512] global step 8452: loss = 0.7240 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8453: loss = 0.6728 (0.244 sec/step)\n",
            "I0802 19:52:58.178725 140624834570112 learning.py:512] global step 8453: loss = 0.6728 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8454: loss = 0.8757 (0.244 sec/step)\n",
            "I0802 19:52:58.424571 140624834570112 learning.py:512] global step 8454: loss = 0.8757 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8455: loss = 0.7450 (0.237 sec/step)\n",
            "I0802 19:52:58.662749 140624834570112 learning.py:512] global step 8455: loss = 0.7450 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8456: loss = 0.7240 (0.232 sec/step)\n",
            "I0802 19:52:58.895940 140624834570112 learning.py:512] global step 8456: loss = 0.7240 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8457: loss = 0.8814 (0.253 sec/step)\n",
            "I0802 19:52:59.150964 140624834570112 learning.py:512] global step 8457: loss = 0.8814 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8458: loss = 0.6377 (0.243 sec/step)\n",
            "I0802 19:52:59.395901 140624834570112 learning.py:512] global step 8458: loss = 0.6377 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8459: loss = 0.6182 (0.254 sec/step)\n",
            "I0802 19:52:59.651309 140624834570112 learning.py:512] global step 8459: loss = 0.6182 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8460: loss = 0.7131 (0.247 sec/step)\n",
            "I0802 19:52:59.899894 140624834570112 learning.py:512] global step 8460: loss = 0.7131 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8461: loss = 0.9369 (0.245 sec/step)\n",
            "I0802 19:53:00.146679 140624834570112 learning.py:512] global step 8461: loss = 0.9369 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8462: loss = 0.7336 (0.235 sec/step)\n",
            "I0802 19:53:00.383167 140624834570112 learning.py:512] global step 8462: loss = 0.7336 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8463: loss = 0.8247 (0.246 sec/step)\n",
            "I0802 19:53:00.630698 140624834570112 learning.py:512] global step 8463: loss = 0.8247 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8464: loss = 0.5846 (0.250 sec/step)\n",
            "I0802 19:53:00.882446 140624834570112 learning.py:512] global step 8464: loss = 0.5846 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8465: loss = 0.7864 (0.245 sec/step)\n",
            "I0802 19:53:01.129159 140624834570112 learning.py:512] global step 8465: loss = 0.7864 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8466: loss = 0.9493 (0.251 sec/step)\n",
            "I0802 19:53:01.382682 140624834570112 learning.py:512] global step 8466: loss = 0.9493 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8467: loss = 0.8223 (0.250 sec/step)\n",
            "I0802 19:53:01.634121 140624834570112 learning.py:512] global step 8467: loss = 0.8223 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8468: loss = 0.5956 (0.244 sec/step)\n",
            "I0802 19:53:01.879747 140624834570112 learning.py:512] global step 8468: loss = 0.5956 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8469: loss = 0.7504 (0.244 sec/step)\n",
            "I0802 19:53:02.125500 140624834570112 learning.py:512] global step 8469: loss = 0.7504 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8470: loss = 0.6485 (0.250 sec/step)\n",
            "I0802 19:53:02.377110 140624834570112 learning.py:512] global step 8470: loss = 0.6485 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8471: loss = 0.7647 (0.244 sec/step)\n",
            "I0802 19:53:02.623119 140624834570112 learning.py:512] global step 8471: loss = 0.7647 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8472: loss = 0.8260 (0.239 sec/step)\n",
            "I0802 19:53:02.864484 140624834570112 learning.py:512] global step 8472: loss = 0.8260 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8473: loss = 0.6423 (0.250 sec/step)\n",
            "I0802 19:53:03.116027 140624834570112 learning.py:512] global step 8473: loss = 0.6423 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8474: loss = 0.6053 (0.247 sec/step)\n",
            "I0802 19:53:03.364309 140624834570112 learning.py:512] global step 8474: loss = 0.6053 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8475: loss = 0.5889 (0.246 sec/step)\n",
            "I0802 19:53:03.611740 140624834570112 learning.py:512] global step 8475: loss = 0.5889 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8476: loss = 0.8365 (0.246 sec/step)\n",
            "I0802 19:53:03.859005 140624834570112 learning.py:512] global step 8476: loss = 0.8365 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8477: loss = 0.7899 (0.250 sec/step)\n",
            "I0802 19:53:04.110886 140624834570112 learning.py:512] global step 8477: loss = 0.7899 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8478: loss = 0.8592 (0.228 sec/step)\n",
            "I0802 19:53:04.340722 140624834570112 learning.py:512] global step 8478: loss = 0.8592 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8479: loss = 0.7395 (0.242 sec/step)\n",
            "I0802 19:53:04.583812 140624834570112 learning.py:512] global step 8479: loss = 0.7395 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8480: loss = 0.6227 (0.234 sec/step)\n",
            "I0802 19:53:04.819339 140624834570112 learning.py:512] global step 8480: loss = 0.6227 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8481: loss = 0.7000 (0.246 sec/step)\n",
            "I0802 19:53:05.066941 140624834570112 learning.py:512] global step 8481: loss = 0.7000 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8482: loss = 0.6551 (0.242 sec/step)\n",
            "I0802 19:53:05.310273 140624834570112 learning.py:512] global step 8482: loss = 0.6551 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8483: loss = 0.7701 (0.242 sec/step)\n",
            "I0802 19:53:05.553786 140624834570112 learning.py:512] global step 8483: loss = 0.7701 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8484: loss = 0.7538 (0.237 sec/step)\n",
            "I0802 19:53:05.792049 140624834570112 learning.py:512] global step 8484: loss = 0.7538 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8485: loss = 0.7184 (0.248 sec/step)\n",
            "I0802 19:53:06.041183 140624834570112 learning.py:512] global step 8485: loss = 0.7184 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8486: loss = 0.8286 (0.247 sec/step)\n",
            "I0802 19:53:06.289786 140624834570112 learning.py:512] global step 8486: loss = 0.8286 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8487: loss = 1.0413 (0.243 sec/step)\n",
            "I0802 19:53:06.534861 140624834570112 learning.py:512] global step 8487: loss = 1.0413 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8488: loss = 0.7137 (0.229 sec/step)\n",
            "I0802 19:53:06.764860 140624834570112 learning.py:512] global step 8488: loss = 0.7137 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8489: loss = 0.6359 (0.238 sec/step)\n",
            "I0802 19:53:07.004842 140624834570112 learning.py:512] global step 8489: loss = 0.6359 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8490: loss = 0.7182 (0.244 sec/step)\n",
            "I0802 19:53:07.250029 140624834570112 learning.py:512] global step 8490: loss = 0.7182 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8491: loss = 0.9324 (0.228 sec/step)\n",
            "I0802 19:53:07.479206 140624834570112 learning.py:512] global step 8491: loss = 0.9324 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8492: loss = 0.8326 (0.246 sec/step)\n",
            "I0802 19:53:07.727154 140624834570112 learning.py:512] global step 8492: loss = 0.8326 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8493: loss = 0.6133 (0.248 sec/step)\n",
            "I0802 19:53:07.976820 140624834570112 learning.py:512] global step 8493: loss = 0.6133 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8494: loss = 0.6045 (0.244 sec/step)\n",
            "I0802 19:53:08.222792 140624834570112 learning.py:512] global step 8494: loss = 0.6045 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8495: loss = 0.6411 (0.244 sec/step)\n",
            "I0802 19:53:08.468277 140624834570112 learning.py:512] global step 8495: loss = 0.6411 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8496: loss = 0.7667 (0.234 sec/step)\n",
            "I0802 19:53:08.703492 140624834570112 learning.py:512] global step 8496: loss = 0.7667 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8497: loss = 0.7102 (0.245 sec/step)\n",
            "I0802 19:53:08.950277 140624834570112 learning.py:512] global step 8497: loss = 0.7102 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8498: loss = 0.5997 (0.242 sec/step)\n",
            "I0802 19:53:09.193556 140624834570112 learning.py:512] global step 8498: loss = 0.5997 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8499: loss = 0.7836 (0.246 sec/step)\n",
            "I0802 19:53:09.441075 140624834570112 learning.py:512] global step 8499: loss = 0.7836 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8500: loss = 0.6684 (0.244 sec/step)\n",
            "I0802 19:53:09.686881 140624834570112 learning.py:512] global step 8500: loss = 0.6684 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8501: loss = 1.1660 (0.255 sec/step)\n",
            "I0802 19:53:09.943863 140624834570112 learning.py:512] global step 8501: loss = 1.1660 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8502: loss = 0.6645 (0.234 sec/step)\n",
            "I0802 19:53:10.179161 140624834570112 learning.py:512] global step 8502: loss = 0.6645 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8503: loss = 0.8421 (0.233 sec/step)\n",
            "I0802 19:53:10.413089 140624834570112 learning.py:512] global step 8503: loss = 0.8421 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8504: loss = 0.8292 (0.242 sec/step)\n",
            "I0802 19:53:10.656129 140624834570112 learning.py:512] global step 8504: loss = 0.8292 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8505: loss = 0.6844 (0.251 sec/step)\n",
            "I0802 19:53:10.908258 140624834570112 learning.py:512] global step 8505: loss = 0.6844 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8506: loss = 0.8009 (0.234 sec/step)\n",
            "I0802 19:53:11.143500 140624834570112 learning.py:512] global step 8506: loss = 0.8009 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8507: loss = 0.6931 (0.227 sec/step)\n",
            "I0802 19:53:11.371889 140624834570112 learning.py:512] global step 8507: loss = 0.6931 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8508: loss = 0.7824 (0.255 sec/step)\n",
            "I0802 19:53:11.628622 140624834570112 learning.py:512] global step 8508: loss = 0.7824 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8509: loss = 0.5946 (0.252 sec/step)\n",
            "I0802 19:53:11.882364 140624834570112 learning.py:512] global step 8509: loss = 0.5946 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8510: loss = 0.8394 (0.247 sec/step)\n",
            "I0802 19:53:12.130821 140624834570112 learning.py:512] global step 8510: loss = 0.8394 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8511: loss = 0.5337 (0.233 sec/step)\n",
            "I0802 19:53:12.364885 140624834570112 learning.py:512] global step 8511: loss = 0.5337 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8512: loss = 0.6963 (0.246 sec/step)\n",
            "I0802 19:53:12.612123 140624834570112 learning.py:512] global step 8512: loss = 0.6963 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8513: loss = 1.0080 (0.243 sec/step)\n",
            "I0802 19:53:12.856256 140624834570112 learning.py:512] global step 8513: loss = 1.0080 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8514: loss = 0.8186 (0.245 sec/step)\n",
            "I0802 19:53:13.102719 140624834570112 learning.py:512] global step 8514: loss = 0.8186 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8515: loss = 1.4659 (0.244 sec/step)\n",
            "I0802 19:53:13.348385 140624834570112 learning.py:512] global step 8515: loss = 1.4659 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8516: loss = 0.6780 (0.239 sec/step)\n",
            "I0802 19:53:13.588513 140624834570112 learning.py:512] global step 8516: loss = 0.6780 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8517: loss = 0.5521 (0.234 sec/step)\n",
            "I0802 19:53:13.824100 140624834570112 learning.py:512] global step 8517: loss = 0.5521 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8518: loss = 0.6356 (0.237 sec/step)\n",
            "I0802 19:53:14.062281 140624834570112 learning.py:512] global step 8518: loss = 0.6356 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8519: loss = 0.4976 (0.245 sec/step)\n",
            "I0802 19:53:14.308688 140624834570112 learning.py:512] global step 8519: loss = 0.4976 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8520: loss = 0.5251 (0.252 sec/step)\n",
            "I0802 19:53:14.563163 140624834570112 learning.py:512] global step 8520: loss = 0.5251 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8521: loss = 0.8374 (0.238 sec/step)\n",
            "I0802 19:53:14.803061 140624834570112 learning.py:512] global step 8521: loss = 0.8374 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8522: loss = 0.8678 (0.248 sec/step)\n",
            "I0802 19:53:15.052376 140624834570112 learning.py:512] global step 8522: loss = 0.8678 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8523: loss = 0.6786 (0.244 sec/step)\n",
            "I0802 19:53:15.298105 140624834570112 learning.py:512] global step 8523: loss = 0.6786 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8524: loss = 1.0085 (0.246 sec/step)\n",
            "I0802 19:53:15.545436 140624834570112 learning.py:512] global step 8524: loss = 1.0085 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8525: loss = 0.6917 (0.245 sec/step)\n",
            "I0802 19:53:15.792376 140624834570112 learning.py:512] global step 8525: loss = 0.6917 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8526: loss = 0.9072 (0.239 sec/step)\n",
            "I0802 19:53:16.033260 140624834570112 learning.py:512] global step 8526: loss = 0.9072 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8527: loss = 0.6801 (0.250 sec/step)\n",
            "I0802 19:53:16.285118 140624834570112 learning.py:512] global step 8527: loss = 0.6801 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8528: loss = 0.7263 (0.242 sec/step)\n",
            "I0802 19:53:16.528755 140624834570112 learning.py:512] global step 8528: loss = 0.7263 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8529: loss = 0.9474 (0.249 sec/step)\n",
            "I0802 19:53:16.779590 140624834570112 learning.py:512] global step 8529: loss = 0.9474 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8530: loss = 0.7992 (0.246 sec/step)\n",
            "I0802 19:53:17.026745 140624834570112 learning.py:512] global step 8530: loss = 0.7992 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8531: loss = 0.5460 (0.251 sec/step)\n",
            "I0802 19:53:17.279569 140624834570112 learning.py:512] global step 8531: loss = 0.5460 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8532: loss = 0.7754 (0.243 sec/step)\n",
            "I0802 19:53:17.523860 140624834570112 learning.py:512] global step 8532: loss = 0.7754 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8533: loss = 0.7070 (0.242 sec/step)\n",
            "I0802 19:53:17.767258 140624834570112 learning.py:512] global step 8533: loss = 0.7070 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8534: loss = 0.7886 (0.246 sec/step)\n",
            "I0802 19:53:18.014775 140624834570112 learning.py:512] global step 8534: loss = 0.7886 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8535: loss = 0.7551 (0.239 sec/step)\n",
            "I0802 19:53:18.255050 140624834570112 learning.py:512] global step 8535: loss = 0.7551 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8536: loss = 0.7807 (0.233 sec/step)\n",
            "I0802 19:53:18.489747 140624834570112 learning.py:512] global step 8536: loss = 0.7807 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8537: loss = 0.8712 (0.239 sec/step)\n",
            "I0802 19:53:18.730292 140624834570112 learning.py:512] global step 8537: loss = 0.8712 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8538: loss = 0.7709 (0.239 sec/step)\n",
            "I0802 19:53:18.971211 140624834570112 learning.py:512] global step 8538: loss = 0.7709 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8539: loss = 0.8455 (0.238 sec/step)\n",
            "I0802 19:53:19.210835 140624834570112 learning.py:512] global step 8539: loss = 0.8455 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8540: loss = 0.6812 (0.228 sec/step)\n",
            "I0802 19:53:19.440801 140624834570112 learning.py:512] global step 8540: loss = 0.6812 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8541: loss = 0.8839 (0.242 sec/step)\n",
            "I0802 19:53:19.684005 140624834570112 learning.py:512] global step 8541: loss = 0.8839 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8542: loss = 0.6660 (0.237 sec/step)\n",
            "I0802 19:53:19.922056 140624834570112 learning.py:512] global step 8542: loss = 0.6660 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8543: loss = 0.6937 (0.243 sec/step)\n",
            "I0802 19:53:20.166026 140624834570112 learning.py:512] global step 8543: loss = 0.6937 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8544: loss = 0.6424 (0.247 sec/step)\n",
            "I0802 19:53:20.414286 140624834570112 learning.py:512] global step 8544: loss = 0.6424 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8545: loss = 1.3120 (0.244 sec/step)\n",
            "I0802 19:53:20.659502 140624834570112 learning.py:512] global step 8545: loss = 1.3120 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8546: loss = 0.6611 (0.251 sec/step)\n",
            "I0802 19:53:20.912388 140624834570112 learning.py:512] global step 8546: loss = 0.6611 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8547: loss = 0.6948 (0.229 sec/step)\n",
            "I0802 19:53:21.143271 140624834570112 learning.py:512] global step 8547: loss = 0.6948 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8548: loss = 0.8001 (0.242 sec/step)\n",
            "I0802 19:53:21.386810 140624834570112 learning.py:512] global step 8548: loss = 0.8001 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8549: loss = 0.6751 (0.245 sec/step)\n",
            "I0802 19:53:21.633020 140624834570112 learning.py:512] global step 8549: loss = 0.6751 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8550: loss = 0.7317 (0.242 sec/step)\n",
            "I0802 19:53:21.877042 140624834570112 learning.py:512] global step 8550: loss = 0.7317 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8551: loss = 0.9845 (0.231 sec/step)\n",
            "I0802 19:53:22.109565 140624834570112 learning.py:512] global step 8551: loss = 0.9845 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8552: loss = 0.7979 (0.233 sec/step)\n",
            "I0802 19:53:22.345139 140624834570112 learning.py:512] global step 8552: loss = 0.7979 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8553: loss = 1.0461 (0.253 sec/step)\n",
            "I0802 19:53:22.599294 140624834570112 learning.py:512] global step 8553: loss = 1.0461 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8554: loss = 0.6454 (0.260 sec/step)\n",
            "I0802 19:53:22.860954 140624834570112 learning.py:512] global step 8554: loss = 0.6454 (0.260 sec/step)\n",
            "INFO:tensorflow:global step 8555: loss = 0.6875 (0.243 sec/step)\n",
            "I0802 19:53:23.105324 140624834570112 learning.py:512] global step 8555: loss = 0.6875 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8556: loss = 0.5803 (0.232 sec/step)\n",
            "I0802 19:53:23.338658 140624834570112 learning.py:512] global step 8556: loss = 0.5803 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8557: loss = 0.8575 (0.245 sec/step)\n",
            "I0802 19:53:23.585610 140624834570112 learning.py:512] global step 8557: loss = 0.8575 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8558: loss = 0.6791 (0.230 sec/step)\n",
            "I0802 19:53:23.816911 140624834570112 learning.py:512] global step 8558: loss = 0.6791 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8559: loss = 0.8512 (0.229 sec/step)\n",
            "I0802 19:53:24.047176 140624834570112 learning.py:512] global step 8559: loss = 0.8512 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8560: loss = 0.8333 (0.233 sec/step)\n",
            "I0802 19:53:24.281970 140624834570112 learning.py:512] global step 8560: loss = 0.8333 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8561: loss = 0.7446 (0.240 sec/step)\n",
            "I0802 19:53:24.523551 140624834570112 learning.py:512] global step 8561: loss = 0.7446 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8562: loss = 0.7247 (0.235 sec/step)\n",
            "I0802 19:53:24.760194 140624834570112 learning.py:512] global step 8562: loss = 0.7247 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8563: loss = 0.7932 (0.243 sec/step)\n",
            "I0802 19:53:25.004729 140624834570112 learning.py:512] global step 8563: loss = 0.7932 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8564: loss = 0.7323 (0.241 sec/step)\n",
            "I0802 19:53:25.247148 140624834570112 learning.py:512] global step 8564: loss = 0.7323 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8565: loss = 1.1115 (0.241 sec/step)\n",
            "I0802 19:53:25.490037 140624834570112 learning.py:512] global step 8565: loss = 1.1115 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8566: loss = 0.7004 (0.252 sec/step)\n",
            "I0802 19:53:25.743724 140624834570112 learning.py:512] global step 8566: loss = 0.7004 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8567: loss = 0.6059 (0.237 sec/step)\n",
            "I0802 19:53:25.982438 140624834570112 learning.py:512] global step 8567: loss = 0.6059 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8568: loss = 0.9466 (0.248 sec/step)\n",
            "I0802 19:53:26.231904 140624834570112 learning.py:512] global step 8568: loss = 0.9466 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8569: loss = 0.7293 (0.240 sec/step)\n",
            "I0802 19:53:26.473542 140624834570112 learning.py:512] global step 8569: loss = 0.7293 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8570: loss = 0.9566 (0.232 sec/step)\n",
            "I0802 19:53:26.707116 140624834570112 learning.py:512] global step 8570: loss = 0.9566 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8571: loss = 0.6520 (0.243 sec/step)\n",
            "I0802 19:53:26.951242 140624834570112 learning.py:512] global step 8571: loss = 0.6520 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8572: loss = 0.7824 (0.233 sec/step)\n",
            "I0802 19:53:27.185422 140624834570112 learning.py:512] global step 8572: loss = 0.7824 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8573: loss = 0.7828 (0.236 sec/step)\n",
            "I0802 19:53:27.423154 140624834570112 learning.py:512] global step 8573: loss = 0.7828 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8574: loss = 0.7178 (0.237 sec/step)\n",
            "I0802 19:53:27.661544 140624834570112 learning.py:512] global step 8574: loss = 0.7178 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8575: loss = 0.7866 (0.221 sec/step)\n",
            "I0802 19:53:27.884008 140624834570112 learning.py:512] global step 8575: loss = 0.7866 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 8576: loss = 1.1992 (0.229 sec/step)\n",
            "I0802 19:53:28.114069 140624834570112 learning.py:512] global step 8576: loss = 1.1992 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8577: loss = 0.6675 (0.225 sec/step)\n",
            "I0802 19:53:28.340650 140624834570112 learning.py:512] global step 8577: loss = 0.6675 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8578: loss = 0.5767 (0.236 sec/step)\n",
            "I0802 19:53:28.577894 140624834570112 learning.py:512] global step 8578: loss = 0.5767 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8579: loss = 0.5207 (0.229 sec/step)\n",
            "I0802 19:53:28.808424 140624834570112 learning.py:512] global step 8579: loss = 0.5207 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8580: loss = 0.5697 (0.235 sec/step)\n",
            "I0802 19:53:29.044987 140624834570112 learning.py:512] global step 8580: loss = 0.5697 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8581: loss = 1.0407 (0.247 sec/step)\n",
            "I0802 19:53:29.293414 140624834570112 learning.py:512] global step 8581: loss = 1.0407 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8582: loss = 0.7432 (0.237 sec/step)\n",
            "I0802 19:53:29.531886 140624834570112 learning.py:512] global step 8582: loss = 0.7432 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8583: loss = 0.8243 (0.242 sec/step)\n",
            "I0802 19:53:29.775858 140624834570112 learning.py:512] global step 8583: loss = 0.8243 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8584: loss = 0.7240 (0.248 sec/step)\n",
            "I0802 19:53:30.025610 140624834570112 learning.py:512] global step 8584: loss = 0.7240 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8585: loss = 0.5625 (0.248 sec/step)\n",
            "I0802 19:53:30.275350 140624834570112 learning.py:512] global step 8585: loss = 0.5625 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8586: loss = 0.7368 (0.251 sec/step)\n",
            "I0802 19:53:30.527970 140624834570112 learning.py:512] global step 8586: loss = 0.7368 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8587: loss = 0.8332 (0.245 sec/step)\n",
            "I0802 19:53:30.774363 140624834570112 learning.py:512] global step 8587: loss = 0.8332 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8588: loss = 0.6566 (0.230 sec/step)\n",
            "I0802 19:53:31.005678 140624834570112 learning.py:512] global step 8588: loss = 0.6566 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8589: loss = 0.8479 (0.244 sec/step)\n",
            "I0802 19:53:31.250802 140624834570112 learning.py:512] global step 8589: loss = 0.8479 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8590: loss = 0.6583 (0.244 sec/step)\n",
            "I0802 19:53:31.496301 140624834570112 learning.py:512] global step 8590: loss = 0.6583 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8591: loss = 0.5955 (0.235 sec/step)\n",
            "I0802 19:53:31.732830 140624834570112 learning.py:512] global step 8591: loss = 0.5955 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8592: loss = 0.7229 (0.242 sec/step)\n",
            "I0802 19:53:31.976450 140624834570112 learning.py:512] global step 8592: loss = 0.7229 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8593: loss = 0.6895 (0.235 sec/step)\n",
            "I0802 19:53:32.213162 140624834570112 learning.py:512] global step 8593: loss = 0.6895 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8594: loss = 0.7152 (0.230 sec/step)\n",
            "I0802 19:53:32.444683 140624834570112 learning.py:512] global step 8594: loss = 0.7152 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8595: loss = 0.6752 (0.238 sec/step)\n",
            "I0802 19:53:32.684598 140624834570112 learning.py:512] global step 8595: loss = 0.6752 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8596: loss = 0.8405 (0.236 sec/step)\n",
            "I0802 19:53:32.922244 140624834570112 learning.py:512] global step 8596: loss = 0.8405 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8597: loss = 0.7348 (0.240 sec/step)\n",
            "I0802 19:53:33.163462 140624834570112 learning.py:512] global step 8597: loss = 0.7348 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8598: loss = 0.5946 (0.244 sec/step)\n",
            "I0802 19:53:33.408357 140624834570112 learning.py:512] global step 8598: loss = 0.5946 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8599: loss = 0.7405 (0.229 sec/step)\n",
            "I0802 19:53:33.638641 140624834570112 learning.py:512] global step 8599: loss = 0.7405 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8600: loss = 0.5198 (0.233 sec/step)\n",
            "I0802 19:53:33.873647 140624834570112 learning.py:512] global step 8600: loss = 0.5198 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8601: loss = 0.6070 (0.229 sec/step)\n",
            "I0802 19:53:34.103713 140624834570112 learning.py:512] global step 8601: loss = 0.6070 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8602: loss = 0.6398 (0.224 sec/step)\n",
            "I0802 19:53:34.329329 140624834570112 learning.py:512] global step 8602: loss = 0.6398 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8603: loss = 0.6375 (0.234 sec/step)\n",
            "I0802 19:53:34.564559 140624834570112 learning.py:512] global step 8603: loss = 0.6375 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8604: loss = 0.6451 (0.245 sec/step)\n",
            "I0802 19:53:34.811002 140624834570112 learning.py:512] global step 8604: loss = 0.6451 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8605: loss = 0.7057 (0.241 sec/step)\n",
            "I0802 19:53:35.053427 140624834570112 learning.py:512] global step 8605: loss = 0.7057 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8606: loss = 0.7877 (0.243 sec/step)\n",
            "I0802 19:53:35.297342 140624834570112 learning.py:512] global step 8606: loss = 0.7877 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8607: loss = 0.6708 (0.233 sec/step)\n",
            "I0802 19:53:35.531362 140624834570112 learning.py:512] global step 8607: loss = 0.6708 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8608: loss = 0.7028 (0.247 sec/step)\n",
            "I0802 19:53:35.779587 140624834570112 learning.py:512] global step 8608: loss = 0.7028 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8609: loss = 0.8177 (0.235 sec/step)\n",
            "I0802 19:53:36.016340 140624834570112 learning.py:512] global step 8609: loss = 0.8177 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8610: loss = 0.6834 (0.237 sec/step)\n",
            "I0802 19:53:36.254381 140624834570112 learning.py:512] global step 8610: loss = 0.6834 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8611: loss = 0.9616 (0.234 sec/step)\n",
            "I0802 19:53:36.489271 140624834570112 learning.py:512] global step 8611: loss = 0.9616 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8612: loss = 0.6306 (0.236 sec/step)\n",
            "I0802 19:53:36.726859 140624834570112 learning.py:512] global step 8612: loss = 0.6306 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8613: loss = 0.7892 (0.248 sec/step)\n",
            "I0802 19:53:36.976095 140624834570112 learning.py:512] global step 8613: loss = 0.7892 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8614: loss = 0.7814 (0.231 sec/step)\n",
            "I0802 19:53:37.208159 140624834570112 learning.py:512] global step 8614: loss = 0.7814 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8615: loss = 0.6361 (0.226 sec/step)\n",
            "I0802 19:53:37.436028 140624834570112 learning.py:512] global step 8615: loss = 0.6361 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8616: loss = 0.7892 (0.246 sec/step)\n",
            "I0802 19:53:37.683767 140624834570112 learning.py:512] global step 8616: loss = 0.7892 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8617: loss = 0.8631 (0.237 sec/step)\n",
            "I0802 19:53:37.922517 140624834570112 learning.py:512] global step 8617: loss = 0.8631 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8618: loss = 0.7539 (0.238 sec/step)\n",
            "I0802 19:53:38.161770 140624834570112 learning.py:512] global step 8618: loss = 0.7539 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8619: loss = 0.7517 (0.242 sec/step)\n",
            "I0802 19:53:38.405292 140624834570112 learning.py:512] global step 8619: loss = 0.7517 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8620: loss = 0.7208 (0.232 sec/step)\n",
            "I0802 19:53:38.639162 140624834570112 learning.py:512] global step 8620: loss = 0.7208 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8621: loss = 0.6447 (0.247 sec/step)\n",
            "I0802 19:53:38.887710 140624834570112 learning.py:512] global step 8621: loss = 0.6447 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8622: loss = 0.6961 (0.231 sec/step)\n",
            "I0802 19:53:39.120018 140624834570112 learning.py:512] global step 8622: loss = 0.6961 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8623: loss = 0.9592 (0.235 sec/step)\n",
            "I0802 19:53:39.356330 140624834570112 learning.py:512] global step 8623: loss = 0.9592 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8624: loss = 0.9527 (0.243 sec/step)\n",
            "I0802 19:53:39.600536 140624834570112 learning.py:512] global step 8624: loss = 0.9527 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8625: loss = 0.6504 (0.247 sec/step)\n",
            "I0802 19:53:39.848615 140624834570112 learning.py:512] global step 8625: loss = 0.6504 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8626: loss = 0.7271 (0.222 sec/step)\n",
            "I0802 19:53:40.072373 140624834570112 learning.py:512] global step 8626: loss = 0.7271 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8627: loss = 0.8383 (0.242 sec/step)\n",
            "I0802 19:53:40.315214 140624834570112 learning.py:512] global step 8627: loss = 0.8383 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8628: loss = 0.5925 (0.241 sec/step)\n",
            "I0802 19:53:40.557070 140624834570112 learning.py:512] global step 8628: loss = 0.5925 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8629: loss = 0.6373 (0.244 sec/step)\n",
            "I0802 19:53:40.802783 140624834570112 learning.py:512] global step 8629: loss = 0.6373 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8630: loss = 0.7599 (0.246 sec/step)\n",
            "I0802 19:53:41.050011 140624834570112 learning.py:512] global step 8630: loss = 0.7599 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8631: loss = 0.7853 (0.240 sec/step)\n",
            "I0802 19:53:41.291153 140624834570112 learning.py:512] global step 8631: loss = 0.7853 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8632: loss = 0.5378 (0.252 sec/step)\n",
            "I0802 19:53:41.545355 140624834570112 learning.py:512] global step 8632: loss = 0.5378 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8633: loss = 0.6887 (0.244 sec/step)\n",
            "I0802 19:53:41.791358 140624834570112 learning.py:512] global step 8633: loss = 0.6887 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8634: loss = 0.6569 (0.254 sec/step)\n",
            "I0802 19:53:42.047257 140624834570112 learning.py:512] global step 8634: loss = 0.6569 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8635: loss = 0.7281 (0.243 sec/step)\n",
            "I0802 19:53:42.291580 140624834570112 learning.py:512] global step 8635: loss = 0.7281 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8636: loss = 0.8127 (0.244 sec/step)\n",
            "I0802 19:53:42.536864 140624834570112 learning.py:512] global step 8636: loss = 0.8127 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8637: loss = 0.5948 (0.229 sec/step)\n",
            "I0802 19:53:42.767142 140624834570112 learning.py:512] global step 8637: loss = 0.5948 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8638: loss = 1.0597 (0.235 sec/step)\n",
            "I0802 19:53:43.004052 140624834570112 learning.py:512] global step 8638: loss = 1.0597 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8639: loss = 0.7419 (0.231 sec/step)\n",
            "I0802 19:53:43.236529 140624834570112 learning.py:512] global step 8639: loss = 0.7419 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8640: loss = 0.5314 (0.236 sec/step)\n",
            "I0802 19:53:43.474186 140624834570112 learning.py:512] global step 8640: loss = 0.5314 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8641: loss = 0.6746 (0.245 sec/step)\n",
            "I0802 19:53:43.720758 140624834570112 learning.py:512] global step 8641: loss = 0.6746 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8642: loss = 0.6196 (0.231 sec/step)\n",
            "I0802 19:53:43.952801 140624834570112 learning.py:512] global step 8642: loss = 0.6196 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8643: loss = 0.8453 (0.228 sec/step)\n",
            "I0802 19:53:44.182624 140624834570112 learning.py:512] global step 8643: loss = 0.8453 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8644: loss = 0.8422 (0.235 sec/step)\n",
            "I0802 19:53:44.419551 140624834570112 learning.py:512] global step 8644: loss = 0.8422 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8645: loss = 0.6908 (0.242 sec/step)\n",
            "I0802 19:53:44.662718 140624834570112 learning.py:512] global step 8645: loss = 0.6908 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8646: loss = 0.7712 (0.234 sec/step)\n",
            "I0802 19:53:44.898462 140624834570112 learning.py:512] global step 8646: loss = 0.7712 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8647: loss = 0.6551 (0.240 sec/step)\n",
            "I0802 19:53:45.139434 140624834570112 learning.py:512] global step 8647: loss = 0.6551 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8648: loss = 0.6415 (0.235 sec/step)\n",
            "I0802 19:53:45.376237 140624834570112 learning.py:512] global step 8648: loss = 0.6415 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8649: loss = 0.8456 (0.244 sec/step)\n",
            "I0802 19:53:45.621299 140624834570112 learning.py:512] global step 8649: loss = 0.8456 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8650: loss = 0.5923 (0.251 sec/step)\n",
            "I0802 19:53:45.874271 140624834570112 learning.py:512] global step 8650: loss = 0.5923 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8651: loss = 0.8220 (0.239 sec/step)\n",
            "I0802 19:53:46.114326 140624834570112 learning.py:512] global step 8651: loss = 0.8220 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8652: loss = 0.7402 (0.240 sec/step)\n",
            "I0802 19:53:46.358408 140624834570112 learning.py:512] global step 8652: loss = 0.7402 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8653: loss = 0.6106 (0.228 sec/step)\n",
            "I0802 19:53:46.589649 140624834570112 learning.py:512] global step 8653: loss = 0.6106 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8654: loss = 0.6282 (0.243 sec/step)\n",
            "I0802 19:53:46.833944 140624834570112 learning.py:512] global step 8654: loss = 0.6282 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8655: loss = 0.7451 (0.234 sec/step)\n",
            "I0802 19:53:47.069107 140624834570112 learning.py:512] global step 8655: loss = 0.7451 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8656: loss = 0.9047 (0.223 sec/step)\n",
            "I0802 19:53:47.293780 140624834570112 learning.py:512] global step 8656: loss = 0.9047 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8657: loss = 0.6921 (0.230 sec/step)\n",
            "I0802 19:53:47.524810 140624834570112 learning.py:512] global step 8657: loss = 0.6921 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8658: loss = 1.5130 (0.244 sec/step)\n",
            "I0802 19:53:47.770207 140624834570112 learning.py:512] global step 8658: loss = 1.5130 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8659: loss = 0.7094 (0.235 sec/step)\n",
            "I0802 19:53:48.006653 140624834570112 learning.py:512] global step 8659: loss = 0.7094 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8660: loss = 0.6647 (0.234 sec/step)\n",
            "I0802 19:53:48.242393 140624834570112 learning.py:512] global step 8660: loss = 0.6647 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8661: loss = 0.6035 (0.230 sec/step)\n",
            "I0802 19:53:48.473978 140624834570112 learning.py:512] global step 8661: loss = 0.6035 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8662: loss = 0.8035 (0.233 sec/step)\n",
            "I0802 19:53:48.708841 140624834570112 learning.py:512] global step 8662: loss = 0.8035 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8663: loss = 0.7452 (0.246 sec/step)\n",
            "I0802 19:53:48.956243 140624834570112 learning.py:512] global step 8663: loss = 0.7452 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8664: loss = 0.6225 (0.238 sec/step)\n",
            "I0802 19:53:49.195173 140624834570112 learning.py:512] global step 8664: loss = 0.6225 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8665: loss = 0.5725 (0.238 sec/step)\n",
            "I0802 19:53:49.434900 140624834570112 learning.py:512] global step 8665: loss = 0.5725 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8666: loss = 0.6375 (0.247 sec/step)\n",
            "I0802 19:53:49.683560 140624834570112 learning.py:512] global step 8666: loss = 0.6375 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8667: loss = 0.7631 (0.230 sec/step)\n",
            "I0802 19:53:49.914898 140624834570112 learning.py:512] global step 8667: loss = 0.7631 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8668: loss = 0.7738 (0.227 sec/step)\n",
            "I0802 19:53:50.143749 140624834570112 learning.py:512] global step 8668: loss = 0.7738 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8669: loss = 0.7518 (0.229 sec/step)\n",
            "I0802 19:53:50.374195 140624834570112 learning.py:512] global step 8669: loss = 0.7518 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8670: loss = 0.6714 (0.226 sec/step)\n",
            "I0802 19:53:50.601222 140624834570112 learning.py:512] global step 8670: loss = 0.6714 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8671: loss = 0.6851 (0.242 sec/step)\n",
            "I0802 19:53:50.844540 140624834570112 learning.py:512] global step 8671: loss = 0.6851 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8672: loss = 0.5926 (0.245 sec/step)\n",
            "I0802 19:53:51.091545 140624834570112 learning.py:512] global step 8672: loss = 0.5926 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8673: loss = 0.6198 (0.236 sec/step)\n",
            "I0802 19:53:51.329337 140624834570112 learning.py:512] global step 8673: loss = 0.6198 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8674: loss = 0.8642 (0.240 sec/step)\n",
            "I0802 19:53:51.570279 140624834570112 learning.py:512] global step 8674: loss = 0.8642 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8675: loss = 0.9370 (0.237 sec/step)\n",
            "I0802 19:53:51.808305 140624834570112 learning.py:512] global step 8675: loss = 0.9370 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8676: loss = 0.6402 (0.237 sec/step)\n",
            "I0802 19:53:52.046885 140624834570112 learning.py:512] global step 8676: loss = 0.6402 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8677: loss = 0.5571 (0.240 sec/step)\n",
            "I0802 19:53:52.288545 140624834570112 learning.py:512] global step 8677: loss = 0.5571 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8678: loss = 0.7071 (0.250 sec/step)\n",
            "I0802 19:53:52.539478 140624834570112 learning.py:512] global step 8678: loss = 0.7071 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8679: loss = 0.6201 (0.228 sec/step)\n",
            "I0802 19:53:52.769255 140624834570112 learning.py:512] global step 8679: loss = 0.6201 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8680: loss = 0.8018 (0.249 sec/step)\n",
            "I0802 19:53:53.019762 140624834570112 learning.py:512] global step 8680: loss = 0.8018 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8681: loss = 0.6615 (0.230 sec/step)\n",
            "I0802 19:53:53.251243 140624834570112 learning.py:512] global step 8681: loss = 0.6615 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8682: loss = 0.7210 (0.230 sec/step)\n",
            "I0802 19:53:53.482947 140624834570112 learning.py:512] global step 8682: loss = 0.7210 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8683: loss = 0.7195 (0.247 sec/step)\n",
            "I0802 19:53:53.731195 140624834570112 learning.py:512] global step 8683: loss = 0.7195 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8684: loss = 0.5892 (0.260 sec/step)\n",
            "I0802 19:53:53.993019 140624834570112 learning.py:512] global step 8684: loss = 0.5892 (0.260 sec/step)\n",
            "INFO:tensorflow:global step 8685: loss = 0.8872 (0.243 sec/step)\n",
            "I0802 19:53:54.237582 140624834570112 learning.py:512] global step 8685: loss = 0.8872 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8686: loss = 0.6993 (0.221 sec/step)\n",
            "I0802 19:53:54.460611 140624834570112 learning.py:512] global step 8686: loss = 0.6993 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 8687: loss = 0.7004 (0.241 sec/step)\n",
            "I0802 19:53:54.703138 140624834570112 learning.py:512] global step 8687: loss = 0.7004 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8688: loss = 0.6677 (0.232 sec/step)\n",
            "I0802 19:53:54.936734 140624834570112 learning.py:512] global step 8688: loss = 0.6677 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8689: loss = 0.7369 (0.239 sec/step)\n",
            "I0802 19:53:55.177395 140624834570112 learning.py:512] global step 8689: loss = 0.7369 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8690: loss = 0.6797 (0.235 sec/step)\n",
            "I0802 19:53:55.413656 140624834570112 learning.py:512] global step 8690: loss = 0.6797 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8691: loss = 0.8395 (0.239 sec/step)\n",
            "I0802 19:53:55.654347 140624834570112 learning.py:512] global step 8691: loss = 0.8395 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8692: loss = 0.7304 (0.232 sec/step)\n",
            "I0802 19:53:55.887668 140624834570112 learning.py:512] global step 8692: loss = 0.7304 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8693: loss = 0.6500 (0.239 sec/step)\n",
            "I0802 19:53:56.127845 140624834570112 learning.py:512] global step 8693: loss = 0.6500 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8694: loss = 0.7608 (0.243 sec/step)\n",
            "I0802 19:53:56.372378 140624834570112 learning.py:512] global step 8694: loss = 0.7608 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8695: loss = 0.7031 (0.246 sec/step)\n",
            "I0802 19:53:56.620378 140624834570112 learning.py:512] global step 8695: loss = 0.7031 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8696: loss = 0.6020 (0.231 sec/step)\n",
            "I0802 19:53:56.852491 140624834570112 learning.py:512] global step 8696: loss = 0.6020 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8697: loss = 1.0121 (0.239 sec/step)\n",
            "I0802 19:53:57.093011 140624834570112 learning.py:512] global step 8697: loss = 1.0121 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8698: loss = 0.6588 (0.247 sec/step)\n",
            "I0802 19:53:57.341377 140624834570112 learning.py:512] global step 8698: loss = 0.6588 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8699: loss = 0.7428 (0.237 sec/step)\n",
            "I0802 19:53:57.579700 140624834570112 learning.py:512] global step 8699: loss = 0.7428 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8700: loss = 0.6011 (0.245 sec/step)\n",
            "I0802 19:53:57.826345 140624834570112 learning.py:512] global step 8700: loss = 0.6011 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8701: loss = 0.8256 (0.229 sec/step)\n",
            "I0802 19:53:58.056854 140624834570112 learning.py:512] global step 8701: loss = 0.8256 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8702: loss = 0.7098 (0.238 sec/step)\n",
            "I0802 19:53:58.295988 140624834570112 learning.py:512] global step 8702: loss = 0.7098 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8703: loss = 0.7571 (0.229 sec/step)\n",
            "I0802 19:53:58.526381 140624834570112 learning.py:512] global step 8703: loss = 0.7571 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8704: loss = 0.6609 (0.238 sec/step)\n",
            "I0802 19:53:58.766137 140624834570112 learning.py:512] global step 8704: loss = 0.6609 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8705: loss = 0.6737 (0.233 sec/step)\n",
            "I0802 19:53:59.000540 140624834570112 learning.py:512] global step 8705: loss = 0.6737 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8706: loss = 0.6753 (0.250 sec/step)\n",
            "I0802 19:53:59.252032 140624834570112 learning.py:512] global step 8706: loss = 0.6753 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8707: loss = 0.5878 (0.237 sec/step)\n",
            "I0802 19:53:59.490316 140624834570112 learning.py:512] global step 8707: loss = 0.5878 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8708: loss = 0.6333 (0.253 sec/step)\n",
            "I0802 19:53:59.744633 140624834570112 learning.py:512] global step 8708: loss = 0.6333 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8709: loss = 0.5108 (0.243 sec/step)\n",
            "I0802 19:53:59.989588 140624834570112 learning.py:512] global step 8709: loss = 0.5108 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8710: loss = 0.7664 (0.246 sec/step)\n",
            "I0802 19:54:00.236779 140624834570112 learning.py:512] global step 8710: loss = 0.7664 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8711: loss = 0.8124 (0.227 sec/step)\n",
            "I0802 19:54:00.465642 140624834570112 learning.py:512] global step 8711: loss = 0.8124 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8712: loss = 0.5632 (0.231 sec/step)\n",
            "I0802 19:54:00.697668 140624834570112 learning.py:512] global step 8712: loss = 0.5632 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8713: loss = 0.7200 (0.234 sec/step)\n",
            "I0802 19:54:00.932754 140624834570112 learning.py:512] global step 8713: loss = 0.7200 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8714: loss = 0.7906 (0.253 sec/step)\n",
            "I0802 19:54:01.187233 140624834570112 learning.py:512] global step 8714: loss = 0.7906 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8715: loss = 0.6746 (0.239 sec/step)\n",
            "I0802 19:54:01.428410 140624834570112 learning.py:512] global step 8715: loss = 0.6746 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8716: loss = 0.8258 (0.231 sec/step)\n",
            "I0802 19:54:01.660499 140624834570112 learning.py:512] global step 8716: loss = 0.8258 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8717: loss = 0.6552 (0.247 sec/step)\n",
            "I0802 19:54:01.908492 140624834570112 learning.py:512] global step 8717: loss = 0.6552 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8718: loss = 0.7393 (0.243 sec/step)\n",
            "I0802 19:54:02.152511 140624834570112 learning.py:512] global step 8718: loss = 0.7393 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8719: loss = 0.6525 (0.243 sec/step)\n",
            "I0802 19:54:02.396345 140624834570112 learning.py:512] global step 8719: loss = 0.6525 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8720: loss = 0.7597 (0.244 sec/step)\n",
            "I0802 19:54:02.642020 140624834570112 learning.py:512] global step 8720: loss = 0.7597 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8721: loss = 0.6844 (0.258 sec/step)\n",
            "I0802 19:54:02.901244 140624834570112 learning.py:512] global step 8721: loss = 0.6844 (0.258 sec/step)\n",
            "INFO:tensorflow:global step 8722: loss = 0.6794 (0.245 sec/step)\n",
            "I0802 19:54:03.148049 140624834570112 learning.py:512] global step 8722: loss = 0.6794 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8723: loss = 0.5999 (0.245 sec/step)\n",
            "I0802 19:54:03.394806 140624834570112 learning.py:512] global step 8723: loss = 0.5999 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8724: loss = 0.7431 (0.246 sec/step)\n",
            "I0802 19:54:03.642690 140624834570112 learning.py:512] global step 8724: loss = 0.7431 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8725: loss = 0.6011 (0.238 sec/step)\n",
            "I0802 19:54:03.882052 140624834570112 learning.py:512] global step 8725: loss = 0.6011 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8726: loss = 0.6084 (0.249 sec/step)\n",
            "I0802 19:54:04.132331 140624834570112 learning.py:512] global step 8726: loss = 0.6084 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8727: loss = 0.8070 (0.255 sec/step)\n",
            "I0802 19:54:04.388318 140624834570112 learning.py:512] global step 8727: loss = 0.8070 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8728: loss = 0.8106 (0.241 sec/step)\n",
            "I0802 19:54:04.630568 140624834570112 learning.py:512] global step 8728: loss = 0.8106 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8729: loss = 0.6265 (0.240 sec/step)\n",
            "I0802 19:54:04.872011 140624834570112 learning.py:512] global step 8729: loss = 0.6265 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8730: loss = 0.6793 (0.253 sec/step)\n",
            "I0802 19:54:05.126175 140624834570112 learning.py:512] global step 8730: loss = 0.6793 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8731: loss = 0.8267 (0.249 sec/step)\n",
            "I0802 19:54:05.376787 140624834570112 learning.py:512] global step 8731: loss = 0.8267 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8732: loss = 0.6395 (0.243 sec/step)\n",
            "I0802 19:54:05.621748 140624834570112 learning.py:512] global step 8732: loss = 0.6395 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8733: loss = 0.8519 (0.255 sec/step)\n",
            "I0802 19:54:05.878241 140624834570112 learning.py:512] global step 8733: loss = 0.8519 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8734: loss = 0.8385 (0.248 sec/step)\n",
            "I0802 19:54:06.127793 140624834570112 learning.py:512] global step 8734: loss = 0.8385 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8735: loss = 0.7053 (0.251 sec/step)\n",
            "I0802 19:54:06.380707 140624834570112 learning.py:512] global step 8735: loss = 0.7053 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8736: loss = 0.8578 (0.244 sec/step)\n",
            "I0802 19:54:06.626655 140624834570112 learning.py:512] global step 8736: loss = 0.8578 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8737: loss = 0.7814 (0.232 sec/step)\n",
            "I0802 19:54:06.860113 140624834570112 learning.py:512] global step 8737: loss = 0.7814 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8738: loss = 0.8620 (0.253 sec/step)\n",
            "I0802 19:54:07.114093 140624834570112 learning.py:512] global step 8738: loss = 0.8620 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8739: loss = 0.7148 (0.259 sec/step)\n",
            "I0802 19:54:07.374263 140624834570112 learning.py:512] global step 8739: loss = 0.7148 (0.259 sec/step)\n",
            "INFO:tensorflow:global step 8740: loss = 0.6142 (0.234 sec/step)\n",
            "I0802 19:54:07.609445 140624834570112 learning.py:512] global step 8740: loss = 0.6142 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8741: loss = 1.2104 (0.250 sec/step)\n",
            "I0802 19:54:07.860704 140624834570112 learning.py:512] global step 8741: loss = 1.2104 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8742: loss = 0.6817 (0.245 sec/step)\n",
            "I0802 19:54:08.107450 140624834570112 learning.py:512] global step 8742: loss = 0.6817 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8743: loss = 0.9143 (0.246 sec/step)\n",
            "I0802 19:54:08.355286 140624834570112 learning.py:512] global step 8743: loss = 0.9143 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8744: loss = 0.8551 (0.244 sec/step)\n",
            "I0802 19:54:08.602136 140624834570112 learning.py:512] global step 8744: loss = 0.8551 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8745: loss = 0.8035 (0.255 sec/step)\n",
            "I0802 19:54:08.858883 140624834570112 learning.py:512] global step 8745: loss = 0.8035 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8746: loss = 0.7663 (0.252 sec/step)\n",
            "I0802 19:54:09.112240 140624834570112 learning.py:512] global step 8746: loss = 0.7663 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8747: loss = 0.7564 (0.241 sec/step)\n",
            "I0802 19:54:09.354224 140624834570112 learning.py:512] global step 8747: loss = 0.7564 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8748: loss = 0.9439 (0.231 sec/step)\n",
            "I0802 19:54:09.587058 140624834570112 learning.py:512] global step 8748: loss = 0.9439 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8749: loss = 0.6235 (0.253 sec/step)\n",
            "I0802 19:54:09.841991 140624834570112 learning.py:512] global step 8749: loss = 0.6235 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8750: loss = 0.7201 (0.241 sec/step)\n",
            "I0802 19:54:10.084600 140624834570112 learning.py:512] global step 8750: loss = 0.7201 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8751: loss = 0.6880 (0.249 sec/step)\n",
            "I0802 19:54:10.335130 140624834570112 learning.py:512] global step 8751: loss = 0.6880 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8752: loss = 0.6255 (0.246 sec/step)\n",
            "I0802 19:54:10.582619 140624834570112 learning.py:512] global step 8752: loss = 0.6255 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8753: loss = 0.9334 (0.243 sec/step)\n",
            "I0802 19:54:10.827464 140624834570112 learning.py:512] global step 8753: loss = 0.9334 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8754: loss = 0.6720 (0.245 sec/step)\n",
            "I0802 19:54:11.073929 140624834570112 learning.py:512] global step 8754: loss = 0.6720 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8755: loss = 0.6769 (0.246 sec/step)\n",
            "I0802 19:54:11.320859 140624834570112 learning.py:512] global step 8755: loss = 0.6769 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8756: loss = 0.5353 (0.241 sec/step)\n",
            "I0802 19:54:11.563456 140624834570112 learning.py:512] global step 8756: loss = 0.5353 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8757: loss = 0.8478 (0.252 sec/step)\n",
            "I0802 19:54:11.816580 140624834570112 learning.py:512] global step 8757: loss = 0.8478 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8758: loss = 0.6355 (0.246 sec/step)\n",
            "I0802 19:54:12.063827 140624834570112 learning.py:512] global step 8758: loss = 0.6355 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8759: loss = 0.6171 (0.244 sec/step)\n",
            "I0802 19:54:12.309091 140624834570112 learning.py:512] global step 8759: loss = 0.6171 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8760: loss = 0.6403 (0.244 sec/step)\n",
            "I0802 19:54:12.555000 140624834570112 learning.py:512] global step 8760: loss = 0.6403 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8761: loss = 0.7248 (0.242 sec/step)\n",
            "I0802 19:54:12.798616 140624834570112 learning.py:512] global step 8761: loss = 0.7248 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8762: loss = 1.0293 (0.252 sec/step)\n",
            "I0802 19:54:13.051965 140624834570112 learning.py:512] global step 8762: loss = 1.0293 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8763: loss = 0.7775 (0.233 sec/step)\n",
            "I0802 19:54:13.286668 140624834570112 learning.py:512] global step 8763: loss = 0.7775 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8764: loss = 0.9476 (0.254 sec/step)\n",
            "I0802 19:54:13.541948 140624834570112 learning.py:512] global step 8764: loss = 0.9476 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8765: loss = 0.5030 (0.244 sec/step)\n",
            "I0802 19:54:13.787956 140624834570112 learning.py:512] global step 8765: loss = 0.5030 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8766: loss = 0.6752 (0.241 sec/step)\n",
            "I0802 19:54:14.030170 140624834570112 learning.py:512] global step 8766: loss = 0.6752 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8767: loss = 0.7590 (0.247 sec/step)\n",
            "I0802 19:54:14.278641 140624834570112 learning.py:512] global step 8767: loss = 0.7590 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8768: loss = 0.5999 (0.229 sec/step)\n",
            "I0802 19:54:14.509310 140624834570112 learning.py:512] global step 8768: loss = 0.5999 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8769: loss = 0.7375 (0.255 sec/step)\n",
            "I0802 19:54:14.765442 140624834570112 learning.py:512] global step 8769: loss = 0.7375 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8770: loss = 0.8743 (0.258 sec/step)\n",
            "I0802 19:54:15.030261 140624834570112 learning.py:512] global step 8770: loss = 0.8743 (0.258 sec/step)\n",
            "INFO:tensorflow:global step 8771: loss = 0.7566 (0.309 sec/step)\n",
            "I0802 19:54:15.347114 140624834570112 learning.py:512] global step 8771: loss = 0.7566 (0.309 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 8771.\n",
            "I0802 19:54:15.428513 140620445013760 supervisor.py:1050] Recording summary at step 8771.\n",
            "INFO:tensorflow:global step 8772: loss = 0.7294 (0.256 sec/step)\n",
            "I0802 19:54:15.605481 140624834570112 learning.py:512] global step 8772: loss = 0.7294 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 8773: loss = 0.6673 (0.244 sec/step)\n",
            "I0802 19:54:15.850478 140624834570112 learning.py:512] global step 8773: loss = 0.6673 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8774: loss = 0.6552 (0.247 sec/step)\n",
            "I0802 19:54:16.098693 140624834570112 learning.py:512] global step 8774: loss = 0.6552 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8775: loss = 0.5820 (0.227 sec/step)\n",
            "I0802 19:54:16.327562 140624834570112 learning.py:512] global step 8775: loss = 0.5820 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8776: loss = 0.6853 (0.236 sec/step)\n",
            "I0802 19:54:16.565192 140624834570112 learning.py:512] global step 8776: loss = 0.6853 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8777: loss = 0.7816 (0.242 sec/step)\n",
            "I0802 19:54:16.808422 140624834570112 learning.py:512] global step 8777: loss = 0.7816 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8778: loss = 0.6496 (0.236 sec/step)\n",
            "I0802 19:54:17.046373 140624834570112 learning.py:512] global step 8778: loss = 0.6496 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8779: loss = 0.5758 (0.246 sec/step)\n",
            "I0802 19:54:17.293951 140624834570112 learning.py:512] global step 8779: loss = 0.5758 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8780: loss = 0.7047 (0.236 sec/step)\n",
            "I0802 19:54:17.531837 140624834570112 learning.py:512] global step 8780: loss = 0.7047 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8781: loss = 0.7388 (0.251 sec/step)\n",
            "I0802 19:54:17.783891 140624834570112 learning.py:512] global step 8781: loss = 0.7388 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8782: loss = 0.6841 (0.233 sec/step)\n",
            "I0802 19:54:18.018728 140624834570112 learning.py:512] global step 8782: loss = 0.6841 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8783: loss = 0.7847 (0.245 sec/step)\n",
            "I0802 19:54:18.265786 140624834570112 learning.py:512] global step 8783: loss = 0.7847 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8784: loss = 1.0062 (0.238 sec/step)\n",
            "I0802 19:54:18.504878 140624834570112 learning.py:512] global step 8784: loss = 1.0062 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8785: loss = 0.7588 (0.250 sec/step)\n",
            "I0802 19:54:18.756289 140624834570112 learning.py:512] global step 8785: loss = 0.7588 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8786: loss = 0.7344 (0.247 sec/step)\n",
            "I0802 19:54:19.004809 140624834570112 learning.py:512] global step 8786: loss = 0.7344 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8787: loss = 0.5930 (0.243 sec/step)\n",
            "I0802 19:54:19.249691 140624834570112 learning.py:512] global step 8787: loss = 0.5930 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8788: loss = 0.6098 (0.248 sec/step)\n",
            "I0802 19:54:19.499586 140624834570112 learning.py:512] global step 8788: loss = 0.6098 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8789: loss = 0.7287 (0.244 sec/step)\n",
            "I0802 19:54:19.745048 140624834570112 learning.py:512] global step 8789: loss = 0.7287 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8790: loss = 0.6544 (0.243 sec/step)\n",
            "I0802 19:54:19.989254 140624834570112 learning.py:512] global step 8790: loss = 0.6544 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8791: loss = 0.7402 (0.246 sec/step)\n",
            "I0802 19:54:20.236403 140624834570112 learning.py:512] global step 8791: loss = 0.7402 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8792: loss = 0.7800 (0.237 sec/step)\n",
            "I0802 19:54:20.474697 140624834570112 learning.py:512] global step 8792: loss = 0.7800 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8793: loss = 0.7572 (0.234 sec/step)\n",
            "I0802 19:54:20.710165 140624834570112 learning.py:512] global step 8793: loss = 0.7572 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8794: loss = 0.6969 (0.228 sec/step)\n",
            "I0802 19:54:20.939629 140624834570112 learning.py:512] global step 8794: loss = 0.6969 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8795: loss = 0.7209 (0.243 sec/step)\n",
            "I0802 19:54:21.184132 140624834570112 learning.py:512] global step 8795: loss = 0.7209 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8796: loss = 0.5488 (0.243 sec/step)\n",
            "I0802 19:54:21.428256 140624834570112 learning.py:512] global step 8796: loss = 0.5488 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8797: loss = 0.8198 (0.246 sec/step)\n",
            "I0802 19:54:21.676101 140624834570112 learning.py:512] global step 8797: loss = 0.8198 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8798: loss = 0.5612 (0.257 sec/step)\n",
            "I0802 19:54:21.934726 140624834570112 learning.py:512] global step 8798: loss = 0.5612 (0.257 sec/step)\n",
            "INFO:tensorflow:global step 8799: loss = 0.6775 (0.247 sec/step)\n",
            "I0802 19:54:22.182892 140624834570112 learning.py:512] global step 8799: loss = 0.6775 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8800: loss = 0.9132 (0.251 sec/step)\n",
            "I0802 19:54:22.435331 140624834570112 learning.py:512] global step 8800: loss = 0.9132 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8801: loss = 0.8040 (0.232 sec/step)\n",
            "I0802 19:54:22.669263 140624834570112 learning.py:512] global step 8801: loss = 0.8040 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8802: loss = 0.8302 (0.232 sec/step)\n",
            "I0802 19:54:22.902404 140624834570112 learning.py:512] global step 8802: loss = 0.8302 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8803: loss = 0.7096 (0.243 sec/step)\n",
            "I0802 19:54:23.147275 140624834570112 learning.py:512] global step 8803: loss = 0.7096 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8804: loss = 0.6352 (0.255 sec/step)\n",
            "I0802 19:54:23.403437 140624834570112 learning.py:512] global step 8804: loss = 0.6352 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 8805: loss = 0.7200 (0.246 sec/step)\n",
            "I0802 19:54:23.651045 140624834570112 learning.py:512] global step 8805: loss = 0.7200 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8806: loss = 0.5921 (0.232 sec/step)\n",
            "I0802 19:54:23.885147 140624834570112 learning.py:512] global step 8806: loss = 0.5921 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8807: loss = 0.7496 (0.251 sec/step)\n",
            "I0802 19:54:24.138644 140624834570112 learning.py:512] global step 8807: loss = 0.7496 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8808: loss = 1.0399 (0.244 sec/step)\n",
            "I0802 19:54:24.383872 140624834570112 learning.py:512] global step 8808: loss = 1.0399 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8809: loss = 0.5824 (0.253 sec/step)\n",
            "I0802 19:54:24.638945 140624834570112 learning.py:512] global step 8809: loss = 0.5824 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8810: loss = 0.6162 (0.250 sec/step)\n",
            "I0802 19:54:24.890474 140624834570112 learning.py:512] global step 8810: loss = 0.6162 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8811: loss = 0.7658 (0.241 sec/step)\n",
            "I0802 19:54:25.133286 140624834570112 learning.py:512] global step 8811: loss = 0.7658 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8812: loss = 0.7432 (0.233 sec/step)\n",
            "I0802 19:54:25.367744 140624834570112 learning.py:512] global step 8812: loss = 0.7432 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8813: loss = 0.6465 (0.231 sec/step)\n",
            "I0802 19:54:25.600572 140624834570112 learning.py:512] global step 8813: loss = 0.6465 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8814: loss = 0.6955 (0.228 sec/step)\n",
            "I0802 19:54:25.830759 140624834570112 learning.py:512] global step 8814: loss = 0.6955 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8815: loss = 0.8348 (0.251 sec/step)\n",
            "I0802 19:54:26.083224 140624834570112 learning.py:512] global step 8815: loss = 0.8348 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8816: loss = 0.7841 (0.251 sec/step)\n",
            "I0802 19:54:26.335256 140624834570112 learning.py:512] global step 8816: loss = 0.7841 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8817: loss = 0.5352 (0.245 sec/step)\n",
            "I0802 19:54:26.583931 140624834570112 learning.py:512] global step 8817: loss = 0.5352 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8818: loss = 0.5967 (0.256 sec/step)\n",
            "I0802 19:54:26.841392 140624834570112 learning.py:512] global step 8818: loss = 0.5967 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 8819: loss = 0.5780 (0.249 sec/step)\n",
            "I0802 19:54:27.091856 140624834570112 learning.py:512] global step 8819: loss = 0.5780 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8820: loss = 0.9980 (0.228 sec/step)\n",
            "I0802 19:54:27.321140 140624834570112 learning.py:512] global step 8820: loss = 0.9980 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8821: loss = 0.7156 (0.246 sec/step)\n",
            "I0802 19:54:27.568125 140624834570112 learning.py:512] global step 8821: loss = 0.7156 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8822: loss = 0.5851 (0.250 sec/step)\n",
            "I0802 19:54:27.819703 140624834570112 learning.py:512] global step 8822: loss = 0.5851 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8823: loss = 0.7816 (0.242 sec/step)\n",
            "I0802 19:54:28.063076 140624834570112 learning.py:512] global step 8823: loss = 0.7816 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8824: loss = 0.7273 (0.238 sec/step)\n",
            "I0802 19:54:28.302708 140624834570112 learning.py:512] global step 8824: loss = 0.7273 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8825: loss = 0.6455 (0.244 sec/step)\n",
            "I0802 19:54:28.547672 140624834570112 learning.py:512] global step 8825: loss = 0.6455 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8826: loss = 0.6144 (0.241 sec/step)\n",
            "I0802 19:54:28.790591 140624834570112 learning.py:512] global step 8826: loss = 0.6144 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8827: loss = 0.7218 (0.245 sec/step)\n",
            "I0802 19:54:29.037055 140624834570112 learning.py:512] global step 8827: loss = 0.7218 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8828: loss = 0.7766 (0.237 sec/step)\n",
            "I0802 19:54:29.275878 140624834570112 learning.py:512] global step 8828: loss = 0.7766 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8829: loss = 0.7598 (0.245 sec/step)\n",
            "I0802 19:54:29.521836 140624834570112 learning.py:512] global step 8829: loss = 0.7598 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8830: loss = 0.6943 (0.244 sec/step)\n",
            "I0802 19:54:29.767103 140624834570112 learning.py:512] global step 8830: loss = 0.6943 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8831: loss = 0.7165 (0.235 sec/step)\n",
            "I0802 19:54:30.003558 140624834570112 learning.py:512] global step 8831: loss = 0.7165 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8832: loss = 0.6297 (0.243 sec/step)\n",
            "I0802 19:54:30.248308 140624834570112 learning.py:512] global step 8832: loss = 0.6297 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8833: loss = 0.6312 (0.248 sec/step)\n",
            "I0802 19:54:30.497255 140624834570112 learning.py:512] global step 8833: loss = 0.6312 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8834: loss = 0.7994 (0.245 sec/step)\n",
            "I0802 19:54:30.743769 140624834570112 learning.py:512] global step 8834: loss = 0.7994 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8835: loss = 0.7176 (0.231 sec/step)\n",
            "I0802 19:54:30.975956 140624834570112 learning.py:512] global step 8835: loss = 0.7176 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8836: loss = 0.6006 (0.243 sec/step)\n",
            "I0802 19:54:31.220629 140624834570112 learning.py:512] global step 8836: loss = 0.6006 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8837: loss = 0.6014 (0.249 sec/step)\n",
            "I0802 19:54:31.471577 140624834570112 learning.py:512] global step 8837: loss = 0.6014 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8838: loss = 0.6949 (0.248 sec/step)\n",
            "I0802 19:54:31.721250 140624834570112 learning.py:512] global step 8838: loss = 0.6949 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8839: loss = 0.6886 (0.226 sec/step)\n",
            "I0802 19:54:31.949091 140624834570112 learning.py:512] global step 8839: loss = 0.6886 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8840: loss = 0.9179 (0.246 sec/step)\n",
            "I0802 19:54:32.196262 140624834570112 learning.py:512] global step 8840: loss = 0.9179 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8841: loss = 0.7596 (0.248 sec/step)\n",
            "I0802 19:54:32.445636 140624834570112 learning.py:512] global step 8841: loss = 0.7596 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8842: loss = 0.6633 (0.240 sec/step)\n",
            "I0802 19:54:32.686805 140624834570112 learning.py:512] global step 8842: loss = 0.6633 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8843: loss = 0.6760 (0.239 sec/step)\n",
            "I0802 19:54:32.927478 140624834570112 learning.py:512] global step 8843: loss = 0.6760 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8844: loss = 0.6163 (0.247 sec/step)\n",
            "I0802 19:54:33.175349 140624834570112 learning.py:512] global step 8844: loss = 0.6163 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8845: loss = 0.6080 (0.249 sec/step)\n",
            "I0802 19:54:33.426151 140624834570112 learning.py:512] global step 8845: loss = 0.6080 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8846: loss = 0.9927 (0.234 sec/step)\n",
            "I0802 19:54:33.661946 140624834570112 learning.py:512] global step 8846: loss = 0.9927 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8847: loss = 0.9586 (0.243 sec/step)\n",
            "I0802 19:54:33.906151 140624834570112 learning.py:512] global step 8847: loss = 0.9586 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8848: loss = 0.5386 (0.228 sec/step)\n",
            "I0802 19:54:34.135627 140624834570112 learning.py:512] global step 8848: loss = 0.5386 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8849: loss = 0.8365 (0.257 sec/step)\n",
            "I0802 19:54:34.393891 140624834570112 learning.py:512] global step 8849: loss = 0.8365 (0.257 sec/step)\n",
            "INFO:tensorflow:global step 8850: loss = 0.7706 (0.244 sec/step)\n",
            "I0802 19:54:34.639013 140624834570112 learning.py:512] global step 8850: loss = 0.7706 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8851: loss = 0.8941 (0.229 sec/step)\n",
            "I0802 19:54:34.869398 140624834570112 learning.py:512] global step 8851: loss = 0.8941 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8852: loss = 0.7453 (0.244 sec/step)\n",
            "I0802 19:54:35.115242 140624834570112 learning.py:512] global step 8852: loss = 0.7453 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8853: loss = 0.6309 (0.228 sec/step)\n",
            "I0802 19:54:35.344866 140624834570112 learning.py:512] global step 8853: loss = 0.6309 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8854: loss = 0.9240 (0.242 sec/step)\n",
            "I0802 19:54:35.587909 140624834570112 learning.py:512] global step 8854: loss = 0.9240 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8855: loss = 0.6335 (0.241 sec/step)\n",
            "I0802 19:54:35.830010 140624834570112 learning.py:512] global step 8855: loss = 0.6335 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8856: loss = 0.7809 (0.244 sec/step)\n",
            "I0802 19:54:36.075588 140624834570112 learning.py:512] global step 8856: loss = 0.7809 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8857: loss = 0.7812 (0.244 sec/step)\n",
            "I0802 19:54:36.320701 140624834570112 learning.py:512] global step 8857: loss = 0.7812 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8858: loss = 0.7102 (0.239 sec/step)\n",
            "I0802 19:54:36.561109 140624834570112 learning.py:512] global step 8858: loss = 0.7102 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8859: loss = 0.5706 (0.247 sec/step)\n",
            "I0802 19:54:36.809594 140624834570112 learning.py:512] global step 8859: loss = 0.5706 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8860: loss = 0.7793 (0.244 sec/step)\n",
            "I0802 19:54:37.055831 140624834570112 learning.py:512] global step 8860: loss = 0.7793 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8861: loss = 0.5911 (0.237 sec/step)\n",
            "I0802 19:54:37.294249 140624834570112 learning.py:512] global step 8861: loss = 0.5911 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8862: loss = 0.6461 (0.238 sec/step)\n",
            "I0802 19:54:37.533879 140624834570112 learning.py:512] global step 8862: loss = 0.6461 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8863: loss = 0.6396 (0.249 sec/step)\n",
            "I0802 19:54:37.784219 140624834570112 learning.py:512] global step 8863: loss = 0.6396 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8864: loss = 0.7276 (0.244 sec/step)\n",
            "I0802 19:54:38.029620 140624834570112 learning.py:512] global step 8864: loss = 0.7276 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8865: loss = 0.7763 (0.237 sec/step)\n",
            "I0802 19:54:38.267949 140624834570112 learning.py:512] global step 8865: loss = 0.7763 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8866: loss = 0.8820 (0.233 sec/step)\n",
            "I0802 19:54:38.502146 140624834570112 learning.py:512] global step 8866: loss = 0.8820 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8867: loss = 0.6939 (0.248 sec/step)\n",
            "I0802 19:54:38.751462 140624834570112 learning.py:512] global step 8867: loss = 0.6939 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8868: loss = 0.5242 (0.250 sec/step)\n",
            "I0802 19:54:39.003314 140624834570112 learning.py:512] global step 8868: loss = 0.5242 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8869: loss = 0.7360 (0.241 sec/step)\n",
            "I0802 19:54:39.245897 140624834570112 learning.py:512] global step 8869: loss = 0.7360 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8870: loss = 0.6306 (0.239 sec/step)\n",
            "I0802 19:54:39.486091 140624834570112 learning.py:512] global step 8870: loss = 0.6306 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8871: loss = 0.7645 (0.247 sec/step)\n",
            "I0802 19:54:39.734633 140624834570112 learning.py:512] global step 8871: loss = 0.7645 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8872: loss = 0.6721 (0.237 sec/step)\n",
            "I0802 19:54:39.973380 140624834570112 learning.py:512] global step 8872: loss = 0.6721 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8873: loss = 0.6690 (0.241 sec/step)\n",
            "I0802 19:54:40.215696 140624834570112 learning.py:512] global step 8873: loss = 0.6690 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8874: loss = 0.6648 (0.246 sec/step)\n",
            "I0802 19:54:40.463484 140624834570112 learning.py:512] global step 8874: loss = 0.6648 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8875: loss = 0.6956 (0.234 sec/step)\n",
            "I0802 19:54:40.698636 140624834570112 learning.py:512] global step 8875: loss = 0.6956 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8876: loss = 0.7791 (0.229 sec/step)\n",
            "I0802 19:54:40.929702 140624834570112 learning.py:512] global step 8876: loss = 0.7791 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8877: loss = 0.6162 (0.223 sec/step)\n",
            "I0802 19:54:41.154095 140624834570112 learning.py:512] global step 8877: loss = 0.6162 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8878: loss = 0.8121 (0.248 sec/step)\n",
            "I0802 19:54:41.404179 140624834570112 learning.py:512] global step 8878: loss = 0.8121 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8879: loss = 0.8765 (0.245 sec/step)\n",
            "I0802 19:54:41.650554 140624834570112 learning.py:512] global step 8879: loss = 0.8765 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8880: loss = 0.5746 (0.242 sec/step)\n",
            "I0802 19:54:41.893792 140624834570112 learning.py:512] global step 8880: loss = 0.5746 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8881: loss = 0.8972 (0.225 sec/step)\n",
            "I0802 19:54:42.120090 140624834570112 learning.py:512] global step 8881: loss = 0.8972 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8882: loss = 0.6396 (0.253 sec/step)\n",
            "I0802 19:54:42.374691 140624834570112 learning.py:512] global step 8882: loss = 0.6396 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8883: loss = 0.7386 (0.244 sec/step)\n",
            "I0802 19:54:42.620641 140624834570112 learning.py:512] global step 8883: loss = 0.7386 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8884: loss = 0.7136 (0.231 sec/step)\n",
            "I0802 19:54:42.853932 140624834570112 learning.py:512] global step 8884: loss = 0.7136 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8885: loss = 0.5581 (0.236 sec/step)\n",
            "I0802 19:54:43.091801 140624834570112 learning.py:512] global step 8885: loss = 0.5581 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8886: loss = 0.6100 (0.242 sec/step)\n",
            "I0802 19:54:43.335182 140624834570112 learning.py:512] global step 8886: loss = 0.6100 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8887: loss = 0.5667 (0.248 sec/step)\n",
            "I0802 19:54:43.584766 140624834570112 learning.py:512] global step 8887: loss = 0.5667 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8888: loss = 0.5038 (0.238 sec/step)\n",
            "I0802 19:54:43.824156 140624834570112 learning.py:512] global step 8888: loss = 0.5038 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8889: loss = 0.5224 (0.243 sec/step)\n",
            "I0802 19:54:44.068061 140624834570112 learning.py:512] global step 8889: loss = 0.5224 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8890: loss = 0.7247 (0.244 sec/step)\n",
            "I0802 19:54:44.314043 140624834570112 learning.py:512] global step 8890: loss = 0.7247 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8891: loss = 0.6451 (0.245 sec/step)\n",
            "I0802 19:54:44.561623 140624834570112 learning.py:512] global step 8891: loss = 0.6451 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8892: loss = 0.7793 (0.232 sec/step)\n",
            "I0802 19:54:44.795291 140624834570112 learning.py:512] global step 8892: loss = 0.7793 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8893: loss = 0.6139 (0.242 sec/step)\n",
            "I0802 19:54:45.038962 140624834570112 learning.py:512] global step 8893: loss = 0.6139 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8894: loss = 0.5526 (0.245 sec/step)\n",
            "I0802 19:54:45.285283 140624834570112 learning.py:512] global step 8894: loss = 0.5526 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8895: loss = 0.5554 (0.245 sec/step)\n",
            "I0802 19:54:45.531678 140624834570112 learning.py:512] global step 8895: loss = 0.5554 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8896: loss = 0.8739 (0.240 sec/step)\n",
            "I0802 19:54:45.773168 140624834570112 learning.py:512] global step 8896: loss = 0.8739 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8897: loss = 0.6387 (0.240 sec/step)\n",
            "I0802 19:54:46.014901 140624834570112 learning.py:512] global step 8897: loss = 0.6387 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8898: loss = 0.8145 (0.246 sec/step)\n",
            "I0802 19:54:46.261897 140624834570112 learning.py:512] global step 8898: loss = 0.8145 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8899: loss = 0.8950 (0.247 sec/step)\n",
            "I0802 19:54:46.510266 140624834570112 learning.py:512] global step 8899: loss = 0.8950 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8900: loss = 0.6111 (0.234 sec/step)\n",
            "I0802 19:54:46.745383 140624834570112 learning.py:512] global step 8900: loss = 0.6111 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8901: loss = 0.6159 (0.232 sec/step)\n",
            "I0802 19:54:46.978590 140624834570112 learning.py:512] global step 8901: loss = 0.6159 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8902: loss = 0.7750 (0.241 sec/step)\n",
            "I0802 19:54:47.221372 140624834570112 learning.py:512] global step 8902: loss = 0.7750 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8903: loss = 0.5901 (0.227 sec/step)\n",
            "I0802 19:54:47.450061 140624834570112 learning.py:512] global step 8903: loss = 0.5901 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8904: loss = 0.7521 (0.245 sec/step)\n",
            "I0802 19:54:47.696116 140624834570112 learning.py:512] global step 8904: loss = 0.7521 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8905: loss = 0.5674 (0.238 sec/step)\n",
            "I0802 19:54:47.936017 140624834570112 learning.py:512] global step 8905: loss = 0.5674 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8906: loss = 0.5373 (0.248 sec/step)\n",
            "I0802 19:54:48.185995 140624834570112 learning.py:512] global step 8906: loss = 0.5373 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8907: loss = 0.7654 (0.232 sec/step)\n",
            "I0802 19:54:48.419248 140624834570112 learning.py:512] global step 8907: loss = 0.7654 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8908: loss = 0.7197 (0.242 sec/step)\n",
            "I0802 19:54:48.662860 140624834570112 learning.py:512] global step 8908: loss = 0.7197 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8909: loss = 0.6444 (0.251 sec/step)\n",
            "I0802 19:54:48.914860 140624834570112 learning.py:512] global step 8909: loss = 0.6444 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8910: loss = 0.7237 (0.223 sec/step)\n",
            "I0802 19:54:49.139692 140624834570112 learning.py:512] global step 8910: loss = 0.7237 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8911: loss = 0.7217 (0.239 sec/step)\n",
            "I0802 19:54:49.379982 140624834570112 learning.py:512] global step 8911: loss = 0.7217 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8912: loss = 0.7624 (0.240 sec/step)\n",
            "I0802 19:54:49.621487 140624834570112 learning.py:512] global step 8912: loss = 0.7624 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8913: loss = 0.5140 (0.244 sec/step)\n",
            "I0802 19:54:49.866738 140624834570112 learning.py:512] global step 8913: loss = 0.5140 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8914: loss = 0.6606 (0.232 sec/step)\n",
            "I0802 19:54:50.100043 140624834570112 learning.py:512] global step 8914: loss = 0.6606 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8915: loss = 0.9498 (0.228 sec/step)\n",
            "I0802 19:54:50.329244 140624834570112 learning.py:512] global step 8915: loss = 0.9498 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8916: loss = 0.6213 (0.238 sec/step)\n",
            "I0802 19:54:50.568176 140624834570112 learning.py:512] global step 8916: loss = 0.6213 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8917: loss = 0.7433 (0.227 sec/step)\n",
            "I0802 19:54:50.796609 140624834570112 learning.py:512] global step 8917: loss = 0.7433 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8918: loss = 0.6194 (0.254 sec/step)\n",
            "I0802 19:54:51.052653 140624834570112 learning.py:512] global step 8918: loss = 0.6194 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8919: loss = 0.6901 (0.246 sec/step)\n",
            "I0802 19:54:51.300262 140624834570112 learning.py:512] global step 8919: loss = 0.6901 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8920: loss = 0.7492 (0.221 sec/step)\n",
            "I0802 19:54:51.522171 140624834570112 learning.py:512] global step 8920: loss = 0.7492 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 8921: loss = 0.5990 (0.228 sec/step)\n",
            "I0802 19:54:51.751877 140624834570112 learning.py:512] global step 8921: loss = 0.5990 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8922: loss = 0.6680 (0.243 sec/step)\n",
            "I0802 19:54:51.996329 140624834570112 learning.py:512] global step 8922: loss = 0.6680 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8923: loss = 0.9023 (0.229 sec/step)\n",
            "I0802 19:54:52.227296 140624834570112 learning.py:512] global step 8923: loss = 0.9023 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8924: loss = 0.8312 (0.236 sec/step)\n",
            "I0802 19:54:52.465406 140624834570112 learning.py:512] global step 8924: loss = 0.8312 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8925: loss = 0.6276 (0.250 sec/step)\n",
            "I0802 19:54:52.717109 140624834570112 learning.py:512] global step 8925: loss = 0.6276 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8926: loss = 0.6367 (0.243 sec/step)\n",
            "I0802 19:54:52.961513 140624834570112 learning.py:512] global step 8926: loss = 0.6367 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8927: loss = 0.6083 (0.241 sec/step)\n",
            "I0802 19:54:53.203670 140624834570112 learning.py:512] global step 8927: loss = 0.6083 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8928: loss = 0.7293 (0.226 sec/step)\n",
            "I0802 19:54:53.430798 140624834570112 learning.py:512] global step 8928: loss = 0.7293 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8929: loss = 0.7128 (0.243 sec/step)\n",
            "I0802 19:54:53.675431 140624834570112 learning.py:512] global step 8929: loss = 0.7128 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8930: loss = 0.7448 (0.233 sec/step)\n",
            "I0802 19:54:53.910446 140624834570112 learning.py:512] global step 8930: loss = 0.7448 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8931: loss = 0.6085 (0.242 sec/step)\n",
            "I0802 19:54:54.154164 140624834570112 learning.py:512] global step 8931: loss = 0.6085 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8932: loss = 0.6635 (0.228 sec/step)\n",
            "I0802 19:54:54.383170 140624834570112 learning.py:512] global step 8932: loss = 0.6635 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8933: loss = 0.5513 (0.238 sec/step)\n",
            "I0802 19:54:54.623127 140624834570112 learning.py:512] global step 8933: loss = 0.5513 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8934: loss = 0.5887 (0.242 sec/step)\n",
            "I0802 19:54:54.866355 140624834570112 learning.py:512] global step 8934: loss = 0.5887 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8935: loss = 0.6606 (0.244 sec/step)\n",
            "I0802 19:54:55.112257 140624834570112 learning.py:512] global step 8935: loss = 0.6606 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8936: loss = 0.6454 (0.231 sec/step)\n",
            "I0802 19:54:55.344269 140624834570112 learning.py:512] global step 8936: loss = 0.6454 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8937: loss = 0.6422 (0.231 sec/step)\n",
            "I0802 19:54:55.576739 140624834570112 learning.py:512] global step 8937: loss = 0.6422 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8938: loss = 0.7336 (0.240 sec/step)\n",
            "I0802 19:54:55.818022 140624834570112 learning.py:512] global step 8938: loss = 0.7336 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8939: loss = 0.7660 (0.239 sec/step)\n",
            "I0802 19:54:56.058628 140624834570112 learning.py:512] global step 8939: loss = 0.7660 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8940: loss = 0.6487 (0.231 sec/step)\n",
            "I0802 19:54:56.291469 140624834570112 learning.py:512] global step 8940: loss = 0.6487 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8941: loss = 0.6679 (0.231 sec/step)\n",
            "I0802 19:54:56.523418 140624834570112 learning.py:512] global step 8941: loss = 0.6679 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8942: loss = 0.8735 (0.233 sec/step)\n",
            "I0802 19:54:56.758094 140624834570112 learning.py:512] global step 8942: loss = 0.8735 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8943: loss = 0.7302 (0.231 sec/step)\n",
            "I0802 19:54:56.990240 140624834570112 learning.py:512] global step 8943: loss = 0.7302 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8944: loss = 0.7306 (0.247 sec/step)\n",
            "I0802 19:54:57.240146 140624834570112 learning.py:512] global step 8944: loss = 0.7306 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8945: loss = 0.4793 (0.254 sec/step)\n",
            "I0802 19:54:57.495735 140624834570112 learning.py:512] global step 8945: loss = 0.4793 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8946: loss = 0.6741 (0.251 sec/step)\n",
            "I0802 19:54:57.748258 140624834570112 learning.py:512] global step 8946: loss = 0.6741 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8947: loss = 0.4836 (0.239 sec/step)\n",
            "I0802 19:54:57.988990 140624834570112 learning.py:512] global step 8947: loss = 0.4836 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8948: loss = 0.6992 (0.224 sec/step)\n",
            "I0802 19:54:58.214349 140624834570112 learning.py:512] global step 8948: loss = 0.6992 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8949: loss = 0.7344 (0.224 sec/step)\n",
            "I0802 19:54:58.440191 140624834570112 learning.py:512] global step 8949: loss = 0.7344 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8950: loss = 0.6686 (0.241 sec/step)\n",
            "I0802 19:54:58.682160 140624834570112 learning.py:512] global step 8950: loss = 0.6686 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8951: loss = 0.5430 (0.246 sec/step)\n",
            "I0802 19:54:58.929229 140624834570112 learning.py:512] global step 8951: loss = 0.5430 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8952: loss = 0.7633 (0.242 sec/step)\n",
            "I0802 19:54:59.172623 140624834570112 learning.py:512] global step 8952: loss = 0.7633 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8953: loss = 0.6622 (0.237 sec/step)\n",
            "I0802 19:54:59.410661 140624834570112 learning.py:512] global step 8953: loss = 0.6622 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8954: loss = 1.1648 (0.245 sec/step)\n",
            "I0802 19:54:59.656810 140624834570112 learning.py:512] global step 8954: loss = 1.1648 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8955: loss = 0.6016 (0.228 sec/step)\n",
            "I0802 19:54:59.886103 140624834570112 learning.py:512] global step 8955: loss = 0.6016 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8956: loss = 0.8052 (0.242 sec/step)\n",
            "I0802 19:55:00.129999 140624834570112 learning.py:512] global step 8956: loss = 0.8052 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8957: loss = 0.8440 (0.243 sec/step)\n",
            "I0802 19:55:00.374334 140624834570112 learning.py:512] global step 8957: loss = 0.8440 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8958: loss = 0.6033 (0.246 sec/step)\n",
            "I0802 19:55:00.622428 140624834570112 learning.py:512] global step 8958: loss = 0.6033 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8959: loss = 0.7483 (0.243 sec/step)\n",
            "I0802 19:55:00.868144 140624834570112 learning.py:512] global step 8959: loss = 0.7483 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8960: loss = 0.7809 (0.245 sec/step)\n",
            "I0802 19:55:01.114272 140624834570112 learning.py:512] global step 8960: loss = 0.7809 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8961: loss = 0.8125 (0.226 sec/step)\n",
            "I0802 19:55:01.341521 140624834570112 learning.py:512] global step 8961: loss = 0.8125 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8962: loss = 0.9787 (0.238 sec/step)\n",
            "I0802 19:55:01.581218 140624834570112 learning.py:512] global step 8962: loss = 0.9787 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8963: loss = 0.6484 (0.246 sec/step)\n",
            "I0802 19:55:01.829041 140624834570112 learning.py:512] global step 8963: loss = 0.6484 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8964: loss = 0.6861 (0.251 sec/step)\n",
            "I0802 19:55:02.081603 140624834570112 learning.py:512] global step 8964: loss = 0.6861 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8965: loss = 0.7084 (0.238 sec/step)\n",
            "I0802 19:55:02.321199 140624834570112 learning.py:512] global step 8965: loss = 0.7084 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8966: loss = 0.5893 (0.238 sec/step)\n",
            "I0802 19:55:02.560946 140624834570112 learning.py:512] global step 8966: loss = 0.5893 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8967: loss = 0.5316 (0.251 sec/step)\n",
            "I0802 19:55:02.813440 140624834570112 learning.py:512] global step 8967: loss = 0.5316 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8968: loss = 0.7246 (0.240 sec/step)\n",
            "I0802 19:55:03.055334 140624834570112 learning.py:512] global step 8968: loss = 0.7246 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8969: loss = 1.2338 (0.226 sec/step)\n",
            "I0802 19:55:03.282482 140624834570112 learning.py:512] global step 8969: loss = 1.2338 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8970: loss = 0.8216 (0.240 sec/step)\n",
            "I0802 19:55:03.524161 140624834570112 learning.py:512] global step 8970: loss = 0.8216 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8971: loss = 0.8054 (0.247 sec/step)\n",
            "I0802 19:55:03.772871 140624834570112 learning.py:512] global step 8971: loss = 0.8054 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8972: loss = 0.6355 (0.246 sec/step)\n",
            "I0802 19:55:04.020265 140624834570112 learning.py:512] global step 8972: loss = 0.6355 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8973: loss = 0.5833 (0.238 sec/step)\n",
            "I0802 19:55:04.260085 140624834570112 learning.py:512] global step 8973: loss = 0.5833 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8974: loss = 0.5357 (0.240 sec/step)\n",
            "I0802 19:55:04.501389 140624834570112 learning.py:512] global step 8974: loss = 0.5357 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8975: loss = 0.6765 (0.230 sec/step)\n",
            "I0802 19:55:04.732789 140624834570112 learning.py:512] global step 8975: loss = 0.6765 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8976: loss = 0.7888 (0.240 sec/step)\n",
            "I0802 19:55:04.973863 140624834570112 learning.py:512] global step 8976: loss = 0.7888 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8977: loss = 0.9205 (0.246 sec/step)\n",
            "I0802 19:55:05.221378 140624834570112 learning.py:512] global step 8977: loss = 0.9205 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8978: loss = 0.7903 (0.246 sec/step)\n",
            "I0802 19:55:05.468499 140624834570112 learning.py:512] global step 8978: loss = 0.7903 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8979: loss = 0.6991 (0.252 sec/step)\n",
            "I0802 19:55:05.721685 140624834570112 learning.py:512] global step 8979: loss = 0.6991 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8980: loss = 0.7302 (0.238 sec/step)\n",
            "I0802 19:55:05.960948 140624834570112 learning.py:512] global step 8980: loss = 0.7302 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8981: loss = 0.8260 (0.241 sec/step)\n",
            "I0802 19:55:06.203528 140624834570112 learning.py:512] global step 8981: loss = 0.8260 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8982: loss = 0.9185 (0.243 sec/step)\n",
            "I0802 19:55:06.447758 140624834570112 learning.py:512] global step 8982: loss = 0.9185 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8983: loss = 0.7856 (0.240 sec/step)\n",
            "I0802 19:55:06.688834 140624834570112 learning.py:512] global step 8983: loss = 0.7856 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8984: loss = 0.5579 (0.230 sec/step)\n",
            "I0802 19:55:06.920308 140624834570112 learning.py:512] global step 8984: loss = 0.5579 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8985: loss = 1.0001 (0.223 sec/step)\n",
            "I0802 19:55:07.145250 140624834570112 learning.py:512] global step 8985: loss = 1.0001 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8986: loss = 0.6488 (0.247 sec/step)\n",
            "I0802 19:55:07.393489 140624834570112 learning.py:512] global step 8986: loss = 0.6488 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8987: loss = 0.7265 (0.245 sec/step)\n",
            "I0802 19:55:07.639993 140624834570112 learning.py:512] global step 8987: loss = 0.7265 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8988: loss = 0.6078 (0.245 sec/step)\n",
            "I0802 19:55:07.886186 140624834570112 learning.py:512] global step 8988: loss = 0.6078 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8989: loss = 0.6490 (0.241 sec/step)\n",
            "I0802 19:55:08.128545 140624834570112 learning.py:512] global step 8989: loss = 0.6490 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8990: loss = 0.6951 (0.240 sec/step)\n",
            "I0802 19:55:08.370079 140624834570112 learning.py:512] global step 8990: loss = 0.6951 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8991: loss = 0.6580 (0.246 sec/step)\n",
            "I0802 19:55:08.617289 140624834570112 learning.py:512] global step 8991: loss = 0.6580 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8992: loss = 0.7560 (0.240 sec/step)\n",
            "I0802 19:55:08.858499 140624834570112 learning.py:512] global step 8992: loss = 0.7560 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8993: loss = 0.8359 (0.229 sec/step)\n",
            "I0802 19:55:09.088981 140624834570112 learning.py:512] global step 8993: loss = 0.8359 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8994: loss = 0.8960 (0.248 sec/step)\n",
            "I0802 19:55:09.338372 140624834570112 learning.py:512] global step 8994: loss = 0.8960 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8995: loss = 0.6349 (0.249 sec/step)\n",
            "I0802 19:55:09.588850 140624834570112 learning.py:512] global step 8995: loss = 0.6349 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8996: loss = 0.6308 (0.244 sec/step)\n",
            "I0802 19:55:09.834535 140624834570112 learning.py:512] global step 8996: loss = 0.6308 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8997: loss = 0.6123 (0.230 sec/step)\n",
            "I0802 19:55:10.066116 140624834570112 learning.py:512] global step 8997: loss = 0.6123 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8998: loss = 0.7456 (0.247 sec/step)\n",
            "I0802 19:55:10.314574 140624834570112 learning.py:512] global step 8998: loss = 0.7456 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8999: loss = 0.6733 (0.242 sec/step)\n",
            "I0802 19:55:10.558536 140624834570112 learning.py:512] global step 8999: loss = 0.6733 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9000: loss = 0.7941 (0.231 sec/step)\n",
            "I0802 19:55:10.790534 140624834570112 learning.py:512] global step 9000: loss = 0.7941 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9001: loss = 0.8100 (0.248 sec/step)\n",
            "I0802 19:55:11.040052 140624834570112 learning.py:512] global step 9001: loss = 0.8100 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9002: loss = 0.8518 (0.245 sec/step)\n",
            "I0802 19:55:11.286234 140624834570112 learning.py:512] global step 9002: loss = 0.8518 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9003: loss = 0.7168 (0.240 sec/step)\n",
            "I0802 19:55:11.527758 140624834570112 learning.py:512] global step 9003: loss = 0.7168 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9004: loss = 0.6290 (0.240 sec/step)\n",
            "I0802 19:55:11.769091 140624834570112 learning.py:512] global step 9004: loss = 0.6290 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9005: loss = 0.7358 (0.255 sec/step)\n",
            "I0802 19:55:12.025670 140624834570112 learning.py:512] global step 9005: loss = 0.7358 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 9006: loss = 0.6556 (0.245 sec/step)\n",
            "I0802 19:55:12.271910 140624834570112 learning.py:512] global step 9006: loss = 0.6556 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9007: loss = 0.9370 (0.247 sec/step)\n",
            "I0802 19:55:12.520246 140624834570112 learning.py:512] global step 9007: loss = 0.9370 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9008: loss = 0.7517 (0.233 sec/step)\n",
            "I0802 19:55:12.754618 140624834570112 learning.py:512] global step 9008: loss = 0.7517 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9009: loss = 0.6904 (0.250 sec/step)\n",
            "I0802 19:55:13.005986 140624834570112 learning.py:512] global step 9009: loss = 0.6904 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9010: loss = 0.6835 (0.243 sec/step)\n",
            "I0802 19:55:13.250484 140624834570112 learning.py:512] global step 9010: loss = 0.6835 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9011: loss = 0.7961 (0.228 sec/step)\n",
            "I0802 19:55:13.479830 140624834570112 learning.py:512] global step 9011: loss = 0.7961 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9012: loss = 0.5724 (0.247 sec/step)\n",
            "I0802 19:55:13.728606 140624834570112 learning.py:512] global step 9012: loss = 0.5724 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9013: loss = 0.6646 (0.245 sec/step)\n",
            "I0802 19:55:13.975239 140624834570112 learning.py:512] global step 9013: loss = 0.6646 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9014: loss = 0.7943 (0.240 sec/step)\n",
            "I0802 19:55:14.216979 140624834570112 learning.py:512] global step 9014: loss = 0.7943 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9015: loss = 0.7477 (0.256 sec/step)\n",
            "I0802 19:55:14.474095 140624834570112 learning.py:512] global step 9015: loss = 0.7477 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 9016: loss = 0.6570 (0.237 sec/step)\n",
            "I0802 19:55:14.713056 140624834570112 learning.py:512] global step 9016: loss = 0.6570 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9017: loss = 0.8032 (0.247 sec/step)\n",
            "I0802 19:55:14.961755 140624834570112 learning.py:512] global step 9017: loss = 0.8032 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9018: loss = 0.6138 (0.245 sec/step)\n",
            "I0802 19:55:15.208015 140624834570112 learning.py:512] global step 9018: loss = 0.6138 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9019: loss = 0.5519 (0.231 sec/step)\n",
            "I0802 19:55:15.440639 140624834570112 learning.py:512] global step 9019: loss = 0.5519 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9020: loss = 0.7503 (0.250 sec/step)\n",
            "I0802 19:55:15.692430 140624834570112 learning.py:512] global step 9020: loss = 0.7503 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9021: loss = 0.5555 (0.236 sec/step)\n",
            "I0802 19:55:15.930012 140624834570112 learning.py:512] global step 9021: loss = 0.5555 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9022: loss = 0.8773 (0.243 sec/step)\n",
            "I0802 19:55:16.174348 140624834570112 learning.py:512] global step 9022: loss = 0.8773 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9023: loss = 0.6160 (0.228 sec/step)\n",
            "I0802 19:55:16.404157 140624834570112 learning.py:512] global step 9023: loss = 0.6160 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9024: loss = 0.7040 (0.252 sec/step)\n",
            "I0802 19:55:16.657854 140624834570112 learning.py:512] global step 9024: loss = 0.7040 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9025: loss = 0.7724 (0.232 sec/step)\n",
            "I0802 19:55:16.891431 140624834570112 learning.py:512] global step 9025: loss = 0.7724 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9026: loss = 0.6294 (0.229 sec/step)\n",
            "I0802 19:55:17.121574 140624834570112 learning.py:512] global step 9026: loss = 0.6294 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9027: loss = 0.7828 (0.236 sec/step)\n",
            "I0802 19:55:17.359482 140624834570112 learning.py:512] global step 9027: loss = 0.7828 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9028: loss = 0.8314 (0.246 sec/step)\n",
            "I0802 19:55:17.607868 140624834570112 learning.py:512] global step 9028: loss = 0.8314 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9029: loss = 0.6668 (0.242 sec/step)\n",
            "I0802 19:55:17.851060 140624834570112 learning.py:512] global step 9029: loss = 0.6668 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9030: loss = 0.5964 (0.249 sec/step)\n",
            "I0802 19:55:18.101855 140624834570112 learning.py:512] global step 9030: loss = 0.5964 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9031: loss = 0.7100 (0.249 sec/step)\n",
            "I0802 19:55:18.352201 140624834570112 learning.py:512] global step 9031: loss = 0.7100 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9032: loss = 0.5511 (0.237 sec/step)\n",
            "I0802 19:55:18.590966 140624834570112 learning.py:512] global step 9032: loss = 0.5511 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9033: loss = 0.6455 (0.247 sec/step)\n",
            "I0802 19:55:18.839597 140624834570112 learning.py:512] global step 9033: loss = 0.6455 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9034: loss = 0.6191 (0.251 sec/step)\n",
            "I0802 19:55:19.091595 140624834570112 learning.py:512] global step 9034: loss = 0.6191 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9035: loss = 0.5878 (0.245 sec/step)\n",
            "I0802 19:55:19.337465 140624834570112 learning.py:512] global step 9035: loss = 0.5878 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9036: loss = 0.6227 (0.245 sec/step)\n",
            "I0802 19:55:19.583384 140624834570112 learning.py:512] global step 9036: loss = 0.6227 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9037: loss = 0.6721 (0.233 sec/step)\n",
            "I0802 19:55:19.817847 140624834570112 learning.py:512] global step 9037: loss = 0.6721 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9038: loss = 0.6267 (0.245 sec/step)\n",
            "I0802 19:55:20.064273 140624834570112 learning.py:512] global step 9038: loss = 0.6267 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9039: loss = 0.6869 (0.249 sec/step)\n",
            "I0802 19:55:20.314542 140624834570112 learning.py:512] global step 9039: loss = 0.6869 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9040: loss = 0.6889 (0.246 sec/step)\n",
            "I0802 19:55:20.561746 140624834570112 learning.py:512] global step 9040: loss = 0.6889 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9041: loss = 0.6539 (0.228 sec/step)\n",
            "I0802 19:55:20.791857 140624834570112 learning.py:512] global step 9041: loss = 0.6539 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9042: loss = 0.4562 (0.231 sec/step)\n",
            "I0802 19:55:21.024461 140624834570112 learning.py:512] global step 9042: loss = 0.4562 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9043: loss = 0.6210 (0.245 sec/step)\n",
            "I0802 19:55:21.271255 140624834570112 learning.py:512] global step 9043: loss = 0.6210 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9044: loss = 0.7716 (0.252 sec/step)\n",
            "I0802 19:55:21.524751 140624834570112 learning.py:512] global step 9044: loss = 0.7716 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9045: loss = 0.6557 (0.250 sec/step)\n",
            "I0802 19:55:21.776713 140624834570112 learning.py:512] global step 9045: loss = 0.6557 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9046: loss = 0.5784 (0.231 sec/step)\n",
            "I0802 19:55:22.008673 140624834570112 learning.py:512] global step 9046: loss = 0.5784 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9047: loss = 0.7233 (0.239 sec/step)\n",
            "I0802 19:55:22.249428 140624834570112 learning.py:512] global step 9047: loss = 0.7233 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9048: loss = 0.6441 (0.239 sec/step)\n",
            "I0802 19:55:22.489728 140624834570112 learning.py:512] global step 9048: loss = 0.6441 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9049: loss = 0.6315 (0.244 sec/step)\n",
            "I0802 19:55:22.735334 140624834570112 learning.py:512] global step 9049: loss = 0.6315 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9050: loss = 0.6175 (0.238 sec/step)\n",
            "I0802 19:55:22.974543 140624834570112 learning.py:512] global step 9050: loss = 0.6175 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9051: loss = 0.7392 (0.237 sec/step)\n",
            "I0802 19:55:23.213474 140624834570112 learning.py:512] global step 9051: loss = 0.7392 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9052: loss = 0.7935 (0.238 sec/step)\n",
            "I0802 19:55:23.453140 140624834570112 learning.py:512] global step 9052: loss = 0.7935 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9053: loss = 0.7553 (0.236 sec/step)\n",
            "I0802 19:55:23.691044 140624834570112 learning.py:512] global step 9053: loss = 0.7553 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9054: loss = 0.5789 (0.227 sec/step)\n",
            "I0802 19:55:23.920075 140624834570112 learning.py:512] global step 9054: loss = 0.5789 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9055: loss = 0.7978 (0.250 sec/step)\n",
            "I0802 19:55:24.171644 140624834570112 learning.py:512] global step 9055: loss = 0.7978 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9056: loss = 0.5331 (0.236 sec/step)\n",
            "I0802 19:55:24.408821 140624834570112 learning.py:512] global step 9056: loss = 0.5331 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9057: loss = 0.9093 (0.233 sec/step)\n",
            "I0802 19:55:24.643419 140624834570112 learning.py:512] global step 9057: loss = 0.9093 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9058: loss = 0.5481 (0.243 sec/step)\n",
            "I0802 19:55:24.888186 140624834570112 learning.py:512] global step 9058: loss = 0.5481 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9059: loss = 0.7774 (0.244 sec/step)\n",
            "I0802 19:55:25.133859 140624834570112 learning.py:512] global step 9059: loss = 0.7774 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9060: loss = 1.0102 (0.234 sec/step)\n",
            "I0802 19:55:25.369704 140624834570112 learning.py:512] global step 9060: loss = 1.0102 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9061: loss = 0.7017 (0.244 sec/step)\n",
            "I0802 19:55:25.615602 140624834570112 learning.py:512] global step 9061: loss = 0.7017 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9062: loss = 0.7627 (0.250 sec/step)\n",
            "I0802 19:55:25.867430 140624834570112 learning.py:512] global step 9062: loss = 0.7627 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9063: loss = 0.7100 (0.232 sec/step)\n",
            "I0802 19:55:26.101316 140624834570112 learning.py:512] global step 9063: loss = 0.7100 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9064: loss = 0.7090 (0.245 sec/step)\n",
            "I0802 19:55:26.348201 140624834570112 learning.py:512] global step 9064: loss = 0.7090 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9065: loss = 0.7378 (0.242 sec/step)\n",
            "I0802 19:55:26.592037 140624834570112 learning.py:512] global step 9065: loss = 0.7378 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9066: loss = 0.7686 (0.238 sec/step)\n",
            "I0802 19:55:26.831164 140624834570112 learning.py:512] global step 9066: loss = 0.7686 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9067: loss = 0.5190 (0.242 sec/step)\n",
            "I0802 19:55:27.074162 140624834570112 learning.py:512] global step 9067: loss = 0.5190 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9068: loss = 0.6432 (0.231 sec/step)\n",
            "I0802 19:55:27.307224 140624834570112 learning.py:512] global step 9068: loss = 0.6432 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9069: loss = 0.7258 (0.244 sec/step)\n",
            "I0802 19:55:27.552420 140624834570112 learning.py:512] global step 9069: loss = 0.7258 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9070: loss = 0.8253 (0.244 sec/step)\n",
            "I0802 19:55:27.800466 140624834570112 learning.py:512] global step 9070: loss = 0.8253 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9071: loss = 0.6849 (0.254 sec/step)\n",
            "I0802 19:55:28.055487 140624834570112 learning.py:512] global step 9071: loss = 0.6849 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 9072: loss = 0.6649 (0.229 sec/step)\n",
            "I0802 19:55:28.286025 140624834570112 learning.py:512] global step 9072: loss = 0.6649 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9073: loss = 1.3006 (0.244 sec/step)\n",
            "I0802 19:55:28.531804 140624834570112 learning.py:512] global step 9073: loss = 1.3006 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9074: loss = 0.9590 (0.249 sec/step)\n",
            "I0802 19:55:28.781810 140624834570112 learning.py:512] global step 9074: loss = 0.9590 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9075: loss = 0.7389 (0.241 sec/step)\n",
            "I0802 19:55:29.024190 140624834570112 learning.py:512] global step 9075: loss = 0.7389 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9076: loss = 0.5911 (0.249 sec/step)\n",
            "I0802 19:55:29.276163 140624834570112 learning.py:512] global step 9076: loss = 0.5911 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9077: loss = 0.6612 (0.238 sec/step)\n",
            "I0802 19:55:29.515292 140624834570112 learning.py:512] global step 9077: loss = 0.6612 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9078: loss = 0.7434 (0.235 sec/step)\n",
            "I0802 19:55:29.751464 140624834570112 learning.py:512] global step 9078: loss = 0.7434 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9079: loss = 0.5739 (0.248 sec/step)\n",
            "I0802 19:55:30.001032 140624834570112 learning.py:512] global step 9079: loss = 0.5739 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9080: loss = 0.7198 (0.244 sec/step)\n",
            "I0802 19:55:30.246828 140624834570112 learning.py:512] global step 9080: loss = 0.7198 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9081: loss = 0.7623 (0.244 sec/step)\n",
            "I0802 19:55:30.492184 140624834570112 learning.py:512] global step 9081: loss = 0.7623 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9082: loss = 1.0605 (0.232 sec/step)\n",
            "I0802 19:55:30.725641 140624834570112 learning.py:512] global step 9082: loss = 1.0605 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9083: loss = 0.5607 (0.247 sec/step)\n",
            "I0802 19:55:30.973887 140624834570112 learning.py:512] global step 9083: loss = 0.5607 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9084: loss = 0.6563 (0.247 sec/step)\n",
            "I0802 19:55:31.222595 140624834570112 learning.py:512] global step 9084: loss = 0.6563 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9085: loss = 0.7405 (0.242 sec/step)\n",
            "I0802 19:55:31.466092 140624834570112 learning.py:512] global step 9085: loss = 0.7405 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9086: loss = 0.6837 (0.232 sec/step)\n",
            "I0802 19:55:31.699450 140624834570112 learning.py:512] global step 9086: loss = 0.6837 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9087: loss = 0.6654 (0.236 sec/step)\n",
            "I0802 19:55:31.937344 140624834570112 learning.py:512] global step 9087: loss = 0.6654 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9088: loss = 0.7225 (0.246 sec/step)\n",
            "I0802 19:55:32.185056 140624834570112 learning.py:512] global step 9088: loss = 0.7225 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9089: loss = 0.7657 (0.238 sec/step)\n",
            "I0802 19:55:32.424177 140624834570112 learning.py:512] global step 9089: loss = 0.7657 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9090: loss = 0.6771 (0.248 sec/step)\n",
            "I0802 19:55:32.673795 140624834570112 learning.py:512] global step 9090: loss = 0.6771 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9091: loss = 0.6633 (0.233 sec/step)\n",
            "I0802 19:55:32.908518 140624834570112 learning.py:512] global step 9091: loss = 0.6633 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9092: loss = 0.8359 (0.244 sec/step)\n",
            "I0802 19:55:33.154131 140624834570112 learning.py:512] global step 9092: loss = 0.8359 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9093: loss = 0.6844 (0.241 sec/step)\n",
            "I0802 19:55:33.396688 140624834570112 learning.py:512] global step 9093: loss = 0.6844 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9094: loss = 0.8948 (0.242 sec/step)\n",
            "I0802 19:55:33.640505 140624834570112 learning.py:512] global step 9094: loss = 0.8948 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9095: loss = 0.7280 (0.234 sec/step)\n",
            "I0802 19:55:33.875656 140624834570112 learning.py:512] global step 9095: loss = 0.7280 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9096: loss = 0.8141 (0.241 sec/step)\n",
            "I0802 19:55:34.118500 140624834570112 learning.py:512] global step 9096: loss = 0.8141 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9097: loss = 0.6956 (0.247 sec/step)\n",
            "I0802 19:55:34.367123 140624834570112 learning.py:512] global step 9097: loss = 0.6956 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9098: loss = 0.5274 (0.240 sec/step)\n",
            "I0802 19:55:34.608204 140624834570112 learning.py:512] global step 9098: loss = 0.5274 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9099: loss = 0.6803 (0.244 sec/step)\n",
            "I0802 19:55:34.853834 140624834570112 learning.py:512] global step 9099: loss = 0.6803 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9100: loss = 0.5459 (0.247 sec/step)\n",
            "I0802 19:55:35.102729 140624834570112 learning.py:512] global step 9100: loss = 0.5459 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9101: loss = 0.6135 (0.242 sec/step)\n",
            "I0802 19:55:35.346151 140624834570112 learning.py:512] global step 9101: loss = 0.6135 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9102: loss = 0.9412 (0.253 sec/step)\n",
            "I0802 19:55:35.600778 140624834570112 learning.py:512] global step 9102: loss = 0.9412 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9103: loss = 0.5222 (0.242 sec/step)\n",
            "I0802 19:55:35.844161 140624834570112 learning.py:512] global step 9103: loss = 0.5222 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9104: loss = 0.6822 (0.239 sec/step)\n",
            "I0802 19:55:36.085138 140624834570112 learning.py:512] global step 9104: loss = 0.6822 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9105: loss = 0.9460 (0.244 sec/step)\n",
            "I0802 19:55:36.330843 140624834570112 learning.py:512] global step 9105: loss = 0.9460 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9106: loss = 0.7647 (0.235 sec/step)\n",
            "I0802 19:55:36.567699 140624834570112 learning.py:512] global step 9106: loss = 0.7647 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9107: loss = 0.6100 (0.238 sec/step)\n",
            "I0802 19:55:36.807105 140624834570112 learning.py:512] global step 9107: loss = 0.6100 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9108: loss = 0.8748 (0.225 sec/step)\n",
            "I0802 19:55:37.033241 140624834570112 learning.py:512] global step 9108: loss = 0.8748 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9109: loss = 0.6435 (0.229 sec/step)\n",
            "I0802 19:55:37.263910 140624834570112 learning.py:512] global step 9109: loss = 0.6435 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9110: loss = 0.6588 (0.247 sec/step)\n",
            "I0802 19:55:37.512531 140624834570112 learning.py:512] global step 9110: loss = 0.6588 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9111: loss = 0.9962 (0.244 sec/step)\n",
            "I0802 19:55:37.758007 140624834570112 learning.py:512] global step 9111: loss = 0.9962 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9112: loss = 0.6544 (0.236 sec/step)\n",
            "I0802 19:55:37.995249 140624834570112 learning.py:512] global step 9112: loss = 0.6544 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9113: loss = 1.1087 (0.235 sec/step)\n",
            "I0802 19:55:38.231889 140624834570112 learning.py:512] global step 9113: loss = 1.1087 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9114: loss = 0.7625 (0.226 sec/step)\n",
            "I0802 19:55:38.459403 140624834570112 learning.py:512] global step 9114: loss = 0.7625 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9115: loss = 0.8251 (0.240 sec/step)\n",
            "I0802 19:55:38.700789 140624834570112 learning.py:512] global step 9115: loss = 0.8251 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9116: loss = 0.6014 (0.242 sec/step)\n",
            "I0802 19:55:38.944402 140624834570112 learning.py:512] global step 9116: loss = 0.6014 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9117: loss = 0.8405 (0.238 sec/step)\n",
            "I0802 19:55:39.183378 140624834570112 learning.py:512] global step 9117: loss = 0.8405 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9118: loss = 0.8266 (0.245 sec/step)\n",
            "I0802 19:55:39.429499 140624834570112 learning.py:512] global step 9118: loss = 0.8266 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9119: loss = 0.6113 (0.245 sec/step)\n",
            "I0802 19:55:39.675834 140624834570112 learning.py:512] global step 9119: loss = 0.6113 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9120: loss = 0.6462 (0.245 sec/step)\n",
            "I0802 19:55:39.922595 140624834570112 learning.py:512] global step 9120: loss = 0.6462 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9121: loss = 0.6780 (0.227 sec/step)\n",
            "I0802 19:55:40.151353 140624834570112 learning.py:512] global step 9121: loss = 0.6780 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9122: loss = 0.8065 (0.248 sec/step)\n",
            "I0802 19:55:40.400580 140624834570112 learning.py:512] global step 9122: loss = 0.8065 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9123: loss = 0.7207 (0.239 sec/step)\n",
            "I0802 19:55:40.641050 140624834570112 learning.py:512] global step 9123: loss = 0.7207 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9124: loss = 0.5257 (0.235 sec/step)\n",
            "I0802 19:55:40.877957 140624834570112 learning.py:512] global step 9124: loss = 0.5257 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9125: loss = 0.7604 (0.240 sec/step)\n",
            "I0802 19:55:41.119644 140624834570112 learning.py:512] global step 9125: loss = 0.7604 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9126: loss = 0.5750 (0.242 sec/step)\n",
            "I0802 19:55:41.363006 140624834570112 learning.py:512] global step 9126: loss = 0.5750 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9127: loss = 0.5757 (0.246 sec/step)\n",
            "I0802 19:55:41.610778 140624834570112 learning.py:512] global step 9127: loss = 0.5757 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9128: loss = 0.6196 (0.250 sec/step)\n",
            "I0802 19:55:41.862509 140624834570112 learning.py:512] global step 9128: loss = 0.6196 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9129: loss = 0.6125 (0.239 sec/step)\n",
            "I0802 19:55:42.102564 140624834570112 learning.py:512] global step 9129: loss = 0.6125 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9130: loss = 0.8218 (0.247 sec/step)\n",
            "I0802 19:55:42.350952 140624834570112 learning.py:512] global step 9130: loss = 0.8218 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9131: loss = 0.9903 (0.247 sec/step)\n",
            "I0802 19:55:42.599215 140624834570112 learning.py:512] global step 9131: loss = 0.9903 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9132: loss = 1.0054 (0.240 sec/step)\n",
            "I0802 19:55:42.840725 140624834570112 learning.py:512] global step 9132: loss = 1.0054 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9133: loss = 1.1203 (0.247 sec/step)\n",
            "I0802 19:55:43.089468 140624834570112 learning.py:512] global step 9133: loss = 1.1203 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9134: loss = 0.5928 (0.248 sec/step)\n",
            "I0802 19:55:43.338518 140624834570112 learning.py:512] global step 9134: loss = 0.5928 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9135: loss = 0.6877 (0.249 sec/step)\n",
            "I0802 19:55:43.589188 140624834570112 learning.py:512] global step 9135: loss = 0.6877 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9136: loss = 0.6088 (0.243 sec/step)\n",
            "I0802 19:55:43.833744 140624834570112 learning.py:512] global step 9136: loss = 0.6088 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9137: loss = 0.6640 (0.246 sec/step)\n",
            "I0802 19:55:44.081198 140624834570112 learning.py:512] global step 9137: loss = 0.6640 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9138: loss = 0.6780 (0.240 sec/step)\n",
            "I0802 19:55:44.322772 140624834570112 learning.py:512] global step 9138: loss = 0.6780 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9139: loss = 0.7520 (0.240 sec/step)\n",
            "I0802 19:55:44.564280 140624834570112 learning.py:512] global step 9139: loss = 0.7520 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9140: loss = 0.7616 (0.227 sec/step)\n",
            "I0802 19:55:44.792357 140624834570112 learning.py:512] global step 9140: loss = 0.7616 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9141: loss = 0.9851 (0.243 sec/step)\n",
            "I0802 19:55:45.037243 140624834570112 learning.py:512] global step 9141: loss = 0.9851 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9142: loss = 0.6244 (0.235 sec/step)\n",
            "I0802 19:55:45.274187 140624834570112 learning.py:512] global step 9142: loss = 0.6244 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9143: loss = 0.7292 (0.241 sec/step)\n",
            "I0802 19:55:45.516670 140624834570112 learning.py:512] global step 9143: loss = 0.7292 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9144: loss = 0.9549 (0.242 sec/step)\n",
            "I0802 19:55:45.760509 140624834570112 learning.py:512] global step 9144: loss = 0.9549 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9145: loss = 0.6525 (0.245 sec/step)\n",
            "I0802 19:55:46.007253 140624834570112 learning.py:512] global step 9145: loss = 0.6525 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9146: loss = 0.9077 (0.249 sec/step)\n",
            "I0802 19:55:46.257564 140624834570112 learning.py:512] global step 9146: loss = 0.9077 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9147: loss = 0.7952 (0.237 sec/step)\n",
            "I0802 19:55:46.496639 140624834570112 learning.py:512] global step 9147: loss = 0.7952 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9148: loss = 0.6858 (0.244 sec/step)\n",
            "I0802 19:55:46.742381 140624834570112 learning.py:512] global step 9148: loss = 0.6858 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9149: loss = 0.9437 (0.248 sec/step)\n",
            "I0802 19:55:46.992136 140624834570112 learning.py:512] global step 9149: loss = 0.9437 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9150: loss = 0.8830 (0.251 sec/step)\n",
            "I0802 19:55:47.244234 140624834570112 learning.py:512] global step 9150: loss = 0.8830 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9151: loss = 1.0527 (0.231 sec/step)\n",
            "I0802 19:55:47.476848 140624834570112 learning.py:512] global step 9151: loss = 1.0527 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9152: loss = 0.8623 (0.238 sec/step)\n",
            "I0802 19:55:47.716352 140624834570112 learning.py:512] global step 9152: loss = 0.8623 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9153: loss = 0.8569 (0.238 sec/step)\n",
            "I0802 19:55:47.956102 140624834570112 learning.py:512] global step 9153: loss = 0.8569 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9154: loss = 0.6749 (0.250 sec/step)\n",
            "I0802 19:55:48.207068 140624834570112 learning.py:512] global step 9154: loss = 0.6749 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9155: loss = 0.8373 (0.242 sec/step)\n",
            "I0802 19:55:48.450178 140624834570112 learning.py:512] global step 9155: loss = 0.8373 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9156: loss = 0.5197 (0.244 sec/step)\n",
            "I0802 19:55:48.695099 140624834570112 learning.py:512] global step 9156: loss = 0.5197 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9157: loss = 0.7357 (0.244 sec/step)\n",
            "I0802 19:55:48.940655 140624834570112 learning.py:512] global step 9157: loss = 0.7357 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9158: loss = 1.1389 (0.239 sec/step)\n",
            "I0802 19:55:49.180721 140624834570112 learning.py:512] global step 9158: loss = 1.1389 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9159: loss = 0.8585 (0.252 sec/step)\n",
            "I0802 19:55:49.434295 140624834570112 learning.py:512] global step 9159: loss = 0.8585 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9160: loss = 0.7893 (0.249 sec/step)\n",
            "I0802 19:55:49.684240 140624834570112 learning.py:512] global step 9160: loss = 0.7893 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9161: loss = 0.9943 (0.242 sec/step)\n",
            "I0802 19:55:49.927283 140624834570112 learning.py:512] global step 9161: loss = 0.9943 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9162: loss = 0.7192 (0.235 sec/step)\n",
            "I0802 19:55:50.164042 140624834570112 learning.py:512] global step 9162: loss = 0.7192 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9163: loss = 0.7770 (0.242 sec/step)\n",
            "I0802 19:55:50.407428 140624834570112 learning.py:512] global step 9163: loss = 0.7770 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9164: loss = 0.7355 (0.236 sec/step)\n",
            "I0802 19:55:50.644437 140624834570112 learning.py:512] global step 9164: loss = 0.7355 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9165: loss = 0.9872 (0.244 sec/step)\n",
            "I0802 19:55:50.889816 140624834570112 learning.py:512] global step 9165: loss = 0.9872 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9166: loss = 0.7914 (0.237 sec/step)\n",
            "I0802 19:55:51.128738 140624834570112 learning.py:512] global step 9166: loss = 0.7914 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9167: loss = 0.7749 (0.241 sec/step)\n",
            "I0802 19:55:51.371467 140624834570112 learning.py:512] global step 9167: loss = 0.7749 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9168: loss = 0.6075 (0.245 sec/step)\n",
            "I0802 19:55:51.617857 140624834570112 learning.py:512] global step 9168: loss = 0.6075 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9169: loss = 0.6977 (0.228 sec/step)\n",
            "I0802 19:55:51.847550 140624834570112 learning.py:512] global step 9169: loss = 0.6977 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9170: loss = 0.5439 (0.230 sec/step)\n",
            "I0802 19:55:52.079105 140624834570112 learning.py:512] global step 9170: loss = 0.5439 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9171: loss = 0.7737 (0.231 sec/step)\n",
            "I0802 19:55:52.311978 140624834570112 learning.py:512] global step 9171: loss = 0.7737 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9172: loss = 0.6139 (0.243 sec/step)\n",
            "I0802 19:55:52.556397 140624834570112 learning.py:512] global step 9172: loss = 0.6139 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9173: loss = 0.7161 (0.247 sec/step)\n",
            "I0802 19:55:52.805185 140624834570112 learning.py:512] global step 9173: loss = 0.7161 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9174: loss = 0.7637 (0.222 sec/step)\n",
            "I0802 19:55:53.028841 140624834570112 learning.py:512] global step 9174: loss = 0.7637 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9175: loss = 0.8831 (0.233 sec/step)\n",
            "I0802 19:55:53.263370 140624834570112 learning.py:512] global step 9175: loss = 0.8831 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9176: loss = 0.6769 (0.248 sec/step)\n",
            "I0802 19:55:53.513680 140624834570112 learning.py:512] global step 9176: loss = 0.6769 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9177: loss = 0.8037 (0.236 sec/step)\n",
            "I0802 19:55:53.751624 140624834570112 learning.py:512] global step 9177: loss = 0.8037 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9178: loss = 0.7804 (0.231 sec/step)\n",
            "I0802 19:55:53.984039 140624834570112 learning.py:512] global step 9178: loss = 0.7804 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9179: loss = 0.7420 (0.242 sec/step)\n",
            "I0802 19:55:54.227311 140624834570112 learning.py:512] global step 9179: loss = 0.7420 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9180: loss = 0.5306 (0.247 sec/step)\n",
            "I0802 19:55:54.475650 140624834570112 learning.py:512] global step 9180: loss = 0.5306 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9181: loss = 0.5675 (0.235 sec/step)\n",
            "I0802 19:55:54.712825 140624834570112 learning.py:512] global step 9181: loss = 0.5675 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9182: loss = 0.8226 (0.242 sec/step)\n",
            "I0802 19:55:54.957433 140624834570112 learning.py:512] global step 9182: loss = 0.8226 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9183: loss = 0.7472 (0.225 sec/step)\n",
            "I0802 19:55:55.183839 140624834570112 learning.py:512] global step 9183: loss = 0.7472 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9184: loss = 0.5605 (0.240 sec/step)\n",
            "I0802 19:55:55.425844 140624834570112 learning.py:512] global step 9184: loss = 0.5605 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9185: loss = 0.6626 (0.251 sec/step)\n",
            "I0802 19:55:55.679209 140624834570112 learning.py:512] global step 9185: loss = 0.6626 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9186: loss = 0.6569 (0.254 sec/step)\n",
            "I0802 19:55:55.935722 140624834570112 learning.py:512] global step 9186: loss = 0.6569 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 9187: loss = 0.7223 (0.246 sec/step)\n",
            "I0802 19:55:56.183282 140624834570112 learning.py:512] global step 9187: loss = 0.7223 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9188: loss = 0.6803 (0.236 sec/step)\n",
            "I0802 19:55:56.420978 140624834570112 learning.py:512] global step 9188: loss = 0.6803 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9189: loss = 0.5832 (0.232 sec/step)\n",
            "I0802 19:55:56.655139 140624834570112 learning.py:512] global step 9189: loss = 0.5832 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9190: loss = 0.6190 (0.229 sec/step)\n",
            "I0802 19:55:56.885822 140624834570112 learning.py:512] global step 9190: loss = 0.6190 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9191: loss = 0.7096 (0.225 sec/step)\n",
            "I0802 19:55:57.112411 140624834570112 learning.py:512] global step 9191: loss = 0.7096 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9192: loss = 0.6569 (0.242 sec/step)\n",
            "I0802 19:55:57.355501 140624834570112 learning.py:512] global step 9192: loss = 0.6569 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9193: loss = 0.7641 (0.246 sec/step)\n",
            "I0802 19:55:57.602766 140624834570112 learning.py:512] global step 9193: loss = 0.7641 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9194: loss = 0.7025 (0.242 sec/step)\n",
            "I0802 19:55:57.846550 140624834570112 learning.py:512] global step 9194: loss = 0.7025 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9195: loss = 0.7473 (0.241 sec/step)\n",
            "I0802 19:55:58.088849 140624834570112 learning.py:512] global step 9195: loss = 0.7473 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9196: loss = 0.8937 (0.242 sec/step)\n",
            "I0802 19:55:58.332051 140624834570112 learning.py:512] global step 9196: loss = 0.8937 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9197: loss = 0.6656 (0.233 sec/step)\n",
            "I0802 19:55:58.570506 140624834570112 learning.py:512] global step 9197: loss = 0.6656 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9198: loss = 0.6993 (0.241 sec/step)\n",
            "I0802 19:55:58.813115 140624834570112 learning.py:512] global step 9198: loss = 0.6993 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9199: loss = 0.7112 (0.241 sec/step)\n",
            "I0802 19:55:59.056812 140624834570112 learning.py:512] global step 9199: loss = 0.7112 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9200: loss = 0.6015 (0.240 sec/step)\n",
            "I0802 19:55:59.298664 140624834570112 learning.py:512] global step 9200: loss = 0.6015 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9201: loss = 0.6213 (0.252 sec/step)\n",
            "I0802 19:55:59.551957 140624834570112 learning.py:512] global step 9201: loss = 0.6213 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9202: loss = 0.6415 (0.242 sec/step)\n",
            "I0802 19:55:59.795018 140624834570112 learning.py:512] global step 9202: loss = 0.6415 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9203: loss = 0.6588 (0.243 sec/step)\n",
            "I0802 19:56:00.039217 140624834570112 learning.py:512] global step 9203: loss = 0.6588 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9204: loss = 0.5986 (0.231 sec/step)\n",
            "I0802 19:56:00.271295 140624834570112 learning.py:512] global step 9204: loss = 0.5986 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9205: loss = 0.7413 (0.247 sec/step)\n",
            "I0802 19:56:00.519639 140624834570112 learning.py:512] global step 9205: loss = 0.7413 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9206: loss = 0.9625 (0.239 sec/step)\n",
            "I0802 19:56:00.760125 140624834570112 learning.py:512] global step 9206: loss = 0.9625 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9207: loss = 0.7194 (0.235 sec/step)\n",
            "I0802 19:56:00.996448 140624834570112 learning.py:512] global step 9207: loss = 0.7194 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9208: loss = 0.8732 (0.232 sec/step)\n",
            "I0802 19:56:01.229599 140624834570112 learning.py:512] global step 9208: loss = 0.8732 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9209: loss = 0.6787 (0.246 sec/step)\n",
            "I0802 19:56:01.477188 140624834570112 learning.py:512] global step 9209: loss = 0.6787 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9210: loss = 1.0049 (0.229 sec/step)\n",
            "I0802 19:56:01.707743 140624834570112 learning.py:512] global step 9210: loss = 1.0049 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9211: loss = 0.5728 (0.243 sec/step)\n",
            "I0802 19:56:01.952212 140624834570112 learning.py:512] global step 9211: loss = 0.5728 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9212: loss = 0.6179 (0.245 sec/step)\n",
            "I0802 19:56:02.198504 140624834570112 learning.py:512] global step 9212: loss = 0.6179 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9213: loss = 0.5703 (0.228 sec/step)\n",
            "I0802 19:56:02.427748 140624834570112 learning.py:512] global step 9213: loss = 0.5703 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9214: loss = 0.8367 (0.254 sec/step)\n",
            "I0802 19:56:02.683263 140624834570112 learning.py:512] global step 9214: loss = 0.8367 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 9215: loss = 0.7492 (0.243 sec/step)\n",
            "I0802 19:56:02.928084 140624834570112 learning.py:512] global step 9215: loss = 0.7492 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9216: loss = 0.7054 (0.231 sec/step)\n",
            "I0802 19:56:03.160186 140624834570112 learning.py:512] global step 9216: loss = 0.7054 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9217: loss = 0.5896 (0.241 sec/step)\n",
            "I0802 19:56:03.402668 140624834570112 learning.py:512] global step 9217: loss = 0.5896 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9218: loss = 0.7278 (0.242 sec/step)\n",
            "I0802 19:56:03.646190 140624834570112 learning.py:512] global step 9218: loss = 0.7278 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9219: loss = 0.7245 (0.236 sec/step)\n",
            "I0802 19:56:03.884109 140624834570112 learning.py:512] global step 9219: loss = 0.7245 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9220: loss = 0.6059 (0.246 sec/step)\n",
            "I0802 19:56:04.131606 140624834570112 learning.py:512] global step 9220: loss = 0.6059 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9221: loss = 0.6938 (0.246 sec/step)\n",
            "I0802 19:56:04.378881 140624834570112 learning.py:512] global step 9221: loss = 0.6938 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9222: loss = 0.6701 (0.246 sec/step)\n",
            "I0802 19:56:04.626575 140624834570112 learning.py:512] global step 9222: loss = 0.6701 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9223: loss = 0.5895 (0.242 sec/step)\n",
            "I0802 19:56:04.870222 140624834570112 learning.py:512] global step 9223: loss = 0.5895 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9224: loss = 0.7225 (0.242 sec/step)\n",
            "I0802 19:56:05.113484 140624834570112 learning.py:512] global step 9224: loss = 0.7225 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9225: loss = 0.5862 (0.250 sec/step)\n",
            "I0802 19:56:05.365191 140624834570112 learning.py:512] global step 9225: loss = 0.5862 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9226: loss = 0.6994 (0.231 sec/step)\n",
            "I0802 19:56:05.597634 140624834570112 learning.py:512] global step 9226: loss = 0.6994 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9227: loss = 0.8453 (0.228 sec/step)\n",
            "I0802 19:56:05.827244 140624834570112 learning.py:512] global step 9227: loss = 0.8453 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9228: loss = 0.8902 (0.230 sec/step)\n",
            "I0802 19:56:06.058445 140624834570112 learning.py:512] global step 9228: loss = 0.8902 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9229: loss = 0.5700 (0.243 sec/step)\n",
            "I0802 19:56:06.303552 140624834570112 learning.py:512] global step 9229: loss = 0.5700 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9230: loss = 0.6309 (0.231 sec/step)\n",
            "I0802 19:56:06.536482 140624834570112 learning.py:512] global step 9230: loss = 0.6309 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9231: loss = 0.5462 (0.249 sec/step)\n",
            "I0802 19:56:06.786494 140624834570112 learning.py:512] global step 9231: loss = 0.5462 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9232: loss = 0.5518 (0.242 sec/step)\n",
            "I0802 19:56:07.030143 140624834570112 learning.py:512] global step 9232: loss = 0.5518 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9233: loss = 0.5074 (0.244 sec/step)\n",
            "I0802 19:56:07.275594 140624834570112 learning.py:512] global step 9233: loss = 0.5074 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9234: loss = 0.7429 (0.250 sec/step)\n",
            "I0802 19:56:07.526736 140624834570112 learning.py:512] global step 9234: loss = 0.7429 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9235: loss = 0.9467 (0.231 sec/step)\n",
            "I0802 19:56:07.759567 140624834570112 learning.py:512] global step 9235: loss = 0.9467 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9236: loss = 1.2939 (0.243 sec/step)\n",
            "I0802 19:56:08.004299 140624834570112 learning.py:512] global step 9236: loss = 1.2939 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9237: loss = 0.9106 (0.239 sec/step)\n",
            "I0802 19:56:08.244827 140624834570112 learning.py:512] global step 9237: loss = 0.9106 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9238: loss = 0.6551 (0.243 sec/step)\n",
            "I0802 19:56:08.489211 140624834570112 learning.py:512] global step 9238: loss = 0.6551 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9239: loss = 0.7099 (0.248 sec/step)\n",
            "I0802 19:56:08.738575 140624834570112 learning.py:512] global step 9239: loss = 0.7099 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9240: loss = 0.6459 (0.234 sec/step)\n",
            "I0802 19:56:08.973716 140624834570112 learning.py:512] global step 9240: loss = 0.6459 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9241: loss = 1.0109 (0.235 sec/step)\n",
            "I0802 19:56:09.210305 140624834570112 learning.py:512] global step 9241: loss = 1.0109 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9242: loss = 0.6332 (0.239 sec/step)\n",
            "I0802 19:56:09.450554 140624834570112 learning.py:512] global step 9242: loss = 0.6332 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9243: loss = 0.8677 (0.243 sec/step)\n",
            "I0802 19:56:09.694821 140624834570112 learning.py:512] global step 9243: loss = 0.8677 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9244: loss = 0.7549 (0.237 sec/step)\n",
            "I0802 19:56:09.933293 140624834570112 learning.py:512] global step 9244: loss = 0.7549 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9245: loss = 0.7021 (0.243 sec/step)\n",
            "I0802 19:56:10.177877 140624834570112 learning.py:512] global step 9245: loss = 0.7021 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9246: loss = 0.5704 (0.252 sec/step)\n",
            "I0802 19:56:10.430813 140624834570112 learning.py:512] global step 9246: loss = 0.5704 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9247: loss = 0.6644 (0.242 sec/step)\n",
            "I0802 19:56:10.674471 140624834570112 learning.py:512] global step 9247: loss = 0.6644 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9248: loss = 0.5926 (0.238 sec/step)\n",
            "I0802 19:56:10.913352 140624834570112 learning.py:512] global step 9248: loss = 0.5926 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9249: loss = 0.6005 (0.241 sec/step)\n",
            "I0802 19:56:11.155793 140624834570112 learning.py:512] global step 9249: loss = 0.6005 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9250: loss = 0.8338 (0.234 sec/step)\n",
            "I0802 19:56:11.391357 140624834570112 learning.py:512] global step 9250: loss = 0.8338 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9251: loss = 0.5634 (0.246 sec/step)\n",
            "I0802 19:56:11.638767 140624834570112 learning.py:512] global step 9251: loss = 0.5634 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9252: loss = 0.7662 (0.223 sec/step)\n",
            "I0802 19:56:11.863248 140624834570112 learning.py:512] global step 9252: loss = 0.7662 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9253: loss = 0.6730 (0.239 sec/step)\n",
            "I0802 19:56:12.103600 140624834570112 learning.py:512] global step 9253: loss = 0.6730 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9254: loss = 0.6906 (0.247 sec/step)\n",
            "I0802 19:56:12.352128 140624834570112 learning.py:512] global step 9254: loss = 0.6906 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9255: loss = 0.4983 (0.240 sec/step)\n",
            "I0802 19:56:12.593486 140624834570112 learning.py:512] global step 9255: loss = 0.4983 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9256: loss = 0.5722 (0.238 sec/step)\n",
            "I0802 19:56:12.833017 140624834570112 learning.py:512] global step 9256: loss = 0.5722 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9257: loss = 0.8900 (0.239 sec/step)\n",
            "I0802 19:56:13.073390 140624834570112 learning.py:512] global step 9257: loss = 0.8900 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9258: loss = 0.9989 (0.244 sec/step)\n",
            "I0802 19:56:13.318948 140624834570112 learning.py:512] global step 9258: loss = 0.9989 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9259: loss = 0.7660 (0.241 sec/step)\n",
            "I0802 19:56:13.561739 140624834570112 learning.py:512] global step 9259: loss = 0.7660 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9260: loss = 0.7598 (0.248 sec/step)\n",
            "I0802 19:56:13.811240 140624834570112 learning.py:512] global step 9260: loss = 0.7598 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9261: loss = 0.7648 (0.243 sec/step)\n",
            "I0802 19:56:14.055845 140624834570112 learning.py:512] global step 9261: loss = 0.7648 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9262: loss = 0.6257 (0.243 sec/step)\n",
            "I0802 19:56:14.300183 140624834570112 learning.py:512] global step 9262: loss = 0.6257 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9263: loss = 0.6666 (0.245 sec/step)\n",
            "I0802 19:56:14.547028 140624834570112 learning.py:512] global step 9263: loss = 0.6666 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9264: loss = 0.5831 (0.229 sec/step)\n",
            "I0802 19:56:14.777055 140624834570112 learning.py:512] global step 9264: loss = 0.5831 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9265: loss = 0.7576 (0.287 sec/step)\n",
            "I0802 19:56:15.067748 140624834570112 learning.py:512] global step 9265: loss = 0.7576 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 9266: loss = 0.9358 (0.303 sec/step)\n",
            "I0802 19:56:15.375114 140624834570112 learning.py:512] global step 9266: loss = 0.9358 (0.303 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 9266.\n",
            "I0802 19:56:15.407694 140620445013760 supervisor.py:1050] Recording summary at step 9266.\n",
            "INFO:tensorflow:global step 9267: loss = 0.6878 (0.251 sec/step)\n",
            "I0802 19:56:15.628048 140624834570112 learning.py:512] global step 9267: loss = 0.6878 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9268: loss = 0.6600 (0.242 sec/step)\n",
            "I0802 19:56:15.871326 140624834570112 learning.py:512] global step 9268: loss = 0.6600 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9269: loss = 0.7352 (0.244 sec/step)\n",
            "I0802 19:56:16.116998 140624834570112 learning.py:512] global step 9269: loss = 0.7352 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9270: loss = 0.6920 (0.248 sec/step)\n",
            "I0802 19:56:16.366537 140624834570112 learning.py:512] global step 9270: loss = 0.6920 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9271: loss = 0.5935 (0.232 sec/step)\n",
            "I0802 19:56:16.599780 140624834570112 learning.py:512] global step 9271: loss = 0.5935 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9272: loss = 0.5859 (0.252 sec/step)\n",
            "I0802 19:56:16.852914 140624834570112 learning.py:512] global step 9272: loss = 0.5859 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9273: loss = 0.6690 (0.238 sec/step)\n",
            "I0802 19:56:17.092283 140624834570112 learning.py:512] global step 9273: loss = 0.6690 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9274: loss = 0.7792 (0.231 sec/step)\n",
            "I0802 19:56:17.324839 140624834570112 learning.py:512] global step 9274: loss = 0.7792 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9275: loss = 0.6506 (0.253 sec/step)\n",
            "I0802 19:56:17.579735 140624834570112 learning.py:512] global step 9275: loss = 0.6506 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9276: loss = 0.5308 (0.246 sec/step)\n",
            "I0802 19:56:17.827509 140624834570112 learning.py:512] global step 9276: loss = 0.5308 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9277: loss = 0.7332 (0.248 sec/step)\n",
            "I0802 19:56:18.077582 140624834570112 learning.py:512] global step 9277: loss = 0.7332 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9278: loss = 0.6269 (0.242 sec/step)\n",
            "I0802 19:56:18.321334 140624834570112 learning.py:512] global step 9278: loss = 0.6269 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9279: loss = 0.6071 (0.239 sec/step)\n",
            "I0802 19:56:18.561430 140624834570112 learning.py:512] global step 9279: loss = 0.6071 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9280: loss = 0.6686 (0.250 sec/step)\n",
            "I0802 19:56:18.813001 140624834570112 learning.py:512] global step 9280: loss = 0.6686 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9281: loss = 0.7270 (0.240 sec/step)\n",
            "I0802 19:56:19.054882 140624834570112 learning.py:512] global step 9281: loss = 0.7270 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9282: loss = 0.6359 (0.233 sec/step)\n",
            "I0802 19:56:19.290620 140624834570112 learning.py:512] global step 9282: loss = 0.6359 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9283: loss = 0.8359 (0.250 sec/step)\n",
            "I0802 19:56:19.542251 140624834570112 learning.py:512] global step 9283: loss = 0.8359 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9284: loss = 0.5542 (0.244 sec/step)\n",
            "I0802 19:56:19.787724 140624834570112 learning.py:512] global step 9284: loss = 0.5542 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9285: loss = 0.8961 (0.232 sec/step)\n",
            "I0802 19:56:20.021009 140624834570112 learning.py:512] global step 9285: loss = 0.8961 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9286: loss = 0.6197 (0.233 sec/step)\n",
            "I0802 19:56:20.255619 140624834570112 learning.py:512] global step 9286: loss = 0.6197 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9287: loss = 0.9713 (0.243 sec/step)\n",
            "I0802 19:56:20.500108 140624834570112 learning.py:512] global step 9287: loss = 0.9713 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9288: loss = 0.5730 (0.241 sec/step)\n",
            "I0802 19:56:20.742680 140624834570112 learning.py:512] global step 9288: loss = 0.5730 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9289: loss = 0.9107 (0.243 sec/step)\n",
            "I0802 19:56:20.987109 140624834570112 learning.py:512] global step 9289: loss = 0.9107 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9290: loss = 0.6597 (0.232 sec/step)\n",
            "I0802 19:56:21.220659 140624834570112 learning.py:512] global step 9290: loss = 0.6597 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9291: loss = 0.5931 (0.253 sec/step)\n",
            "I0802 19:56:21.475469 140624834570112 learning.py:512] global step 9291: loss = 0.5931 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9292: loss = 0.6044 (0.237 sec/step)\n",
            "I0802 19:56:21.714432 140624834570112 learning.py:512] global step 9292: loss = 0.6044 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9293: loss = 1.4364 (0.226 sec/step)\n",
            "I0802 19:56:21.941852 140624834570112 learning.py:512] global step 9293: loss = 1.4364 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9294: loss = 0.6621 (0.246 sec/step)\n",
            "I0802 19:56:22.189350 140624834570112 learning.py:512] global step 9294: loss = 0.6621 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9295: loss = 0.5958 (0.244 sec/step)\n",
            "I0802 19:56:22.435123 140624834570112 learning.py:512] global step 9295: loss = 0.5958 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9296: loss = 0.6107 (0.235 sec/step)\n",
            "I0802 19:56:22.671508 140624834570112 learning.py:512] global step 9296: loss = 0.6107 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9297: loss = 0.8466 (0.234 sec/step)\n",
            "I0802 19:56:22.907541 140624834570112 learning.py:512] global step 9297: loss = 0.8466 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9298: loss = 0.5685 (0.238 sec/step)\n",
            "I0802 19:56:23.147160 140624834570112 learning.py:512] global step 9298: loss = 0.5685 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9299: loss = 0.4588 (0.237 sec/step)\n",
            "I0802 19:56:23.385272 140624834570112 learning.py:512] global step 9299: loss = 0.4588 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9300: loss = 0.9277 (0.240 sec/step)\n",
            "I0802 19:56:23.627237 140624834570112 learning.py:512] global step 9300: loss = 0.9277 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9301: loss = 0.7694 (0.232 sec/step)\n",
            "I0802 19:56:23.860793 140624834570112 learning.py:512] global step 9301: loss = 0.7694 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9302: loss = 0.6349 (0.249 sec/step)\n",
            "I0802 19:56:24.111092 140624834570112 learning.py:512] global step 9302: loss = 0.6349 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9303: loss = 0.7497 (0.235 sec/step)\n",
            "I0802 19:56:24.347676 140624834570112 learning.py:512] global step 9303: loss = 0.7497 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9304: loss = 0.9062 (0.240 sec/step)\n",
            "I0802 19:56:24.589658 140624834570112 learning.py:512] global step 9304: loss = 0.9062 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9305: loss = 0.6435 (0.240 sec/step)\n",
            "I0802 19:56:24.831617 140624834570112 learning.py:512] global step 9305: loss = 0.6435 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9306: loss = 0.6265 (0.236 sec/step)\n",
            "I0802 19:56:25.069432 140624834570112 learning.py:512] global step 9306: loss = 0.6265 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9307: loss = 0.6612 (0.254 sec/step)\n",
            "I0802 19:56:25.324778 140624834570112 learning.py:512] global step 9307: loss = 0.6612 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 9308: loss = 0.6884 (0.243 sec/step)\n",
            "I0802 19:56:25.569833 140624834570112 learning.py:512] global step 9308: loss = 0.6884 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9309: loss = 0.5956 (0.250 sec/step)\n",
            "I0802 19:56:25.821190 140624834570112 learning.py:512] global step 9309: loss = 0.5956 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9310: loss = 0.8064 (0.241 sec/step)\n",
            "I0802 19:56:26.063308 140624834570112 learning.py:512] global step 9310: loss = 0.8064 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9311: loss = 0.5985 (0.247 sec/step)\n",
            "I0802 19:56:26.312050 140624834570112 learning.py:512] global step 9311: loss = 0.5985 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9312: loss = 0.5022 (0.243 sec/step)\n",
            "I0802 19:56:26.556932 140624834570112 learning.py:512] global step 9312: loss = 0.5022 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9313: loss = 0.9576 (0.237 sec/step)\n",
            "I0802 19:56:26.795791 140624834570112 learning.py:512] global step 9313: loss = 0.9576 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9314: loss = 0.6649 (0.252 sec/step)\n",
            "I0802 19:56:27.049064 140624834570112 learning.py:512] global step 9314: loss = 0.6649 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9315: loss = 0.6152 (0.249 sec/step)\n",
            "I0802 19:56:27.299525 140624834570112 learning.py:512] global step 9315: loss = 0.6152 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9316: loss = 0.8487 (0.244 sec/step)\n",
            "I0802 19:56:27.545026 140624834570112 learning.py:512] global step 9316: loss = 0.8487 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9317: loss = 0.6692 (0.241 sec/step)\n",
            "I0802 19:56:27.787664 140624834570112 learning.py:512] global step 9317: loss = 0.6692 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9318: loss = 0.6242 (0.233 sec/step)\n",
            "I0802 19:56:28.022607 140624834570112 learning.py:512] global step 9318: loss = 0.6242 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9319: loss = 0.6516 (0.246 sec/step)\n",
            "I0802 19:56:28.269989 140624834570112 learning.py:512] global step 9319: loss = 0.6516 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9320: loss = 0.7962 (0.244 sec/step)\n",
            "I0802 19:56:28.515521 140624834570112 learning.py:512] global step 9320: loss = 0.7962 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9321: loss = 0.6417 (0.243 sec/step)\n",
            "I0802 19:56:28.760244 140624834570112 learning.py:512] global step 9321: loss = 0.6417 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9322: loss = 0.5572 (0.248 sec/step)\n",
            "I0802 19:56:29.009771 140624834570112 learning.py:512] global step 9322: loss = 0.5572 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9323: loss = 1.4102 (0.247 sec/step)\n",
            "I0802 19:56:29.258790 140624834570112 learning.py:512] global step 9323: loss = 1.4102 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9324: loss = 0.7085 (0.243 sec/step)\n",
            "I0802 19:56:29.503469 140624834570112 learning.py:512] global step 9324: loss = 0.7085 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9325: loss = 0.7951 (0.256 sec/step)\n",
            "I0802 19:56:29.760586 140624834570112 learning.py:512] global step 9325: loss = 0.7951 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 9326: loss = 0.5166 (0.250 sec/step)\n",
            "I0802 19:56:30.012013 140624834570112 learning.py:512] global step 9326: loss = 0.5166 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9327: loss = 0.5618 (0.233 sec/step)\n",
            "I0802 19:56:30.246638 140624834570112 learning.py:512] global step 9327: loss = 0.5618 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9328: loss = 0.6583 (0.231 sec/step)\n",
            "I0802 19:56:30.478559 140624834570112 learning.py:512] global step 9328: loss = 0.6583 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9329: loss = 0.5093 (0.249 sec/step)\n",
            "I0802 19:56:30.728880 140624834570112 learning.py:512] global step 9329: loss = 0.5093 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9330: loss = 0.8639 (0.249 sec/step)\n",
            "I0802 19:56:30.979751 140624834570112 learning.py:512] global step 9330: loss = 0.8639 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9331: loss = 0.6654 (0.229 sec/step)\n",
            "I0802 19:56:31.210391 140624834570112 learning.py:512] global step 9331: loss = 0.6654 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9332: loss = 0.7935 (0.246 sec/step)\n",
            "I0802 19:56:31.458193 140624834570112 learning.py:512] global step 9332: loss = 0.7935 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9333: loss = 0.7072 (0.244 sec/step)\n",
            "I0802 19:56:31.704167 140624834570112 learning.py:512] global step 9333: loss = 0.7072 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9334: loss = 0.7608 (0.248 sec/step)\n",
            "I0802 19:56:31.953332 140624834570112 learning.py:512] global step 9334: loss = 0.7608 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9335: loss = 0.7526 (0.238 sec/step)\n",
            "I0802 19:56:32.192859 140624834570112 learning.py:512] global step 9335: loss = 0.7526 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9336: loss = 0.5746 (0.246 sec/step)\n",
            "I0802 19:56:32.440070 140624834570112 learning.py:512] global step 9336: loss = 0.5746 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9337: loss = 0.6434 (0.255 sec/step)\n",
            "I0802 19:56:32.696555 140624834570112 learning.py:512] global step 9337: loss = 0.6434 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 9338: loss = 0.9194 (0.247 sec/step)\n",
            "I0802 19:56:32.945127 140624834570112 learning.py:512] global step 9338: loss = 0.9194 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9339: loss = 0.9571 (0.242 sec/step)\n",
            "I0802 19:56:33.188492 140624834570112 learning.py:512] global step 9339: loss = 0.9571 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9340: loss = 0.9372 (0.247 sec/step)\n",
            "I0802 19:56:33.437009 140624834570112 learning.py:512] global step 9340: loss = 0.9372 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9341: loss = 0.6786 (0.233 sec/step)\n",
            "I0802 19:56:33.671501 140624834570112 learning.py:512] global step 9341: loss = 0.6786 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9342: loss = 0.7493 (0.239 sec/step)\n",
            "I0802 19:56:33.911950 140624834570112 learning.py:512] global step 9342: loss = 0.7493 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9343: loss = 0.6340 (0.241 sec/step)\n",
            "I0802 19:56:34.154017 140624834570112 learning.py:512] global step 9343: loss = 0.6340 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9344: loss = 0.7614 (0.230 sec/step)\n",
            "I0802 19:56:34.385595 140624834570112 learning.py:512] global step 9344: loss = 0.7614 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9345: loss = 0.7871 (0.246 sec/step)\n",
            "I0802 19:56:34.632670 140624834570112 learning.py:512] global step 9345: loss = 0.7871 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9346: loss = 0.6780 (0.250 sec/step)\n",
            "I0802 19:56:34.883913 140624834570112 learning.py:512] global step 9346: loss = 0.6780 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9347: loss = 0.8121 (0.233 sec/step)\n",
            "I0802 19:56:35.118831 140624834570112 learning.py:512] global step 9347: loss = 0.8121 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9348: loss = 0.5713 (0.249 sec/step)\n",
            "I0802 19:56:35.369588 140624834570112 learning.py:512] global step 9348: loss = 0.5713 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9349: loss = 1.2012 (0.247 sec/step)\n",
            "I0802 19:56:35.618615 140624834570112 learning.py:512] global step 9349: loss = 1.2012 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9350: loss = 0.5548 (0.232 sec/step)\n",
            "I0802 19:56:35.851959 140624834570112 learning.py:512] global step 9350: loss = 0.5548 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9351: loss = 0.5641 (0.243 sec/step)\n",
            "I0802 19:56:36.097079 140624834570112 learning.py:512] global step 9351: loss = 0.5641 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9352: loss = 0.6407 (0.229 sec/step)\n",
            "I0802 19:56:36.327049 140624834570112 learning.py:512] global step 9352: loss = 0.6407 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9353: loss = 0.5900 (0.231 sec/step)\n",
            "I0802 19:56:36.559595 140624834570112 learning.py:512] global step 9353: loss = 0.5900 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9354: loss = 0.6540 (0.238 sec/step)\n",
            "I0802 19:56:36.799507 140624834570112 learning.py:512] global step 9354: loss = 0.6540 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9355: loss = 0.5688 (0.230 sec/step)\n",
            "I0802 19:56:37.031239 140624834570112 learning.py:512] global step 9355: loss = 0.5688 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9356: loss = 0.6187 (0.245 sec/step)\n",
            "I0802 19:56:37.278111 140624834570112 learning.py:512] global step 9356: loss = 0.6187 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9357: loss = 0.7522 (0.247 sec/step)\n",
            "I0802 19:56:37.526061 140624834570112 learning.py:512] global step 9357: loss = 0.7522 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9358: loss = 0.6326 (0.258 sec/step)\n",
            "I0802 19:56:37.785672 140624834570112 learning.py:512] global step 9358: loss = 0.6326 (0.258 sec/step)\n",
            "INFO:tensorflow:global step 9359: loss = 0.8186 (0.244 sec/step)\n",
            "I0802 19:56:38.031248 140624834570112 learning.py:512] global step 9359: loss = 0.8186 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9360: loss = 0.6321 (0.232 sec/step)\n",
            "I0802 19:56:38.264402 140624834570112 learning.py:512] global step 9360: loss = 0.6321 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9361: loss = 0.6922 (0.245 sec/step)\n",
            "I0802 19:56:38.510737 140624834570112 learning.py:512] global step 9361: loss = 0.6922 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9362: loss = 0.7033 (0.241 sec/step)\n",
            "I0802 19:56:38.753299 140624834570112 learning.py:512] global step 9362: loss = 0.7033 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9363: loss = 1.0436 (0.245 sec/step)\n",
            "I0802 19:56:38.999695 140624834570112 learning.py:512] global step 9363: loss = 1.0436 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9364: loss = 0.7883 (0.249 sec/step)\n",
            "I0802 19:56:39.250132 140624834570112 learning.py:512] global step 9364: loss = 0.7883 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9365: loss = 0.9495 (0.247 sec/step)\n",
            "I0802 19:56:39.499406 140624834570112 learning.py:512] global step 9365: loss = 0.9495 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9366: loss = 0.7480 (0.240 sec/step)\n",
            "I0802 19:56:39.740872 140624834570112 learning.py:512] global step 9366: loss = 0.7480 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9367: loss = 0.5210 (0.242 sec/step)\n",
            "I0802 19:56:39.984871 140624834570112 learning.py:512] global step 9367: loss = 0.5210 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9368: loss = 0.7364 (0.252 sec/step)\n",
            "I0802 19:56:40.238553 140624834570112 learning.py:512] global step 9368: loss = 0.7364 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9369: loss = 0.6662 (0.241 sec/step)\n",
            "I0802 19:56:40.481200 140624834570112 learning.py:512] global step 9369: loss = 0.6662 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9370: loss = 0.6347 (0.244 sec/step)\n",
            "I0802 19:56:40.726994 140624834570112 learning.py:512] global step 9370: loss = 0.6347 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9371: loss = 0.8856 (0.235 sec/step)\n",
            "I0802 19:56:40.963042 140624834570112 learning.py:512] global step 9371: loss = 0.8856 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9372: loss = 0.5429 (0.247 sec/step)\n",
            "I0802 19:56:41.211255 140624834570112 learning.py:512] global step 9372: loss = 0.5429 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9373: loss = 1.1526 (0.240 sec/step)\n",
            "I0802 19:56:41.453299 140624834570112 learning.py:512] global step 9373: loss = 1.1526 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9374: loss = 1.1817 (0.238 sec/step)\n",
            "I0802 19:56:41.693089 140624834570112 learning.py:512] global step 9374: loss = 1.1817 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9375: loss = 0.6154 (0.239 sec/step)\n",
            "I0802 19:56:41.933622 140624834570112 learning.py:512] global step 9375: loss = 0.6154 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9376: loss = 0.8628 (0.252 sec/step)\n",
            "I0802 19:56:42.187279 140624834570112 learning.py:512] global step 9376: loss = 0.8628 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9377: loss = 0.7597 (0.245 sec/step)\n",
            "I0802 19:56:42.434054 140624834570112 learning.py:512] global step 9377: loss = 0.7597 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9378: loss = 0.8035 (0.238 sec/step)\n",
            "I0802 19:56:42.673758 140624834570112 learning.py:512] global step 9378: loss = 0.8035 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9379: loss = 0.8523 (0.241 sec/step)\n",
            "I0802 19:56:42.915831 140624834570112 learning.py:512] global step 9379: loss = 0.8523 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9380: loss = 0.5491 (0.247 sec/step)\n",
            "I0802 19:56:43.164942 140624834570112 learning.py:512] global step 9380: loss = 0.5491 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9381: loss = 0.8615 (0.244 sec/step)\n",
            "I0802 19:56:43.410602 140624834570112 learning.py:512] global step 9381: loss = 0.8615 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9382: loss = 0.6710 (0.247 sec/step)\n",
            "I0802 19:56:43.659227 140624834570112 learning.py:512] global step 9382: loss = 0.6710 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9383: loss = 1.2915 (0.244 sec/step)\n",
            "I0802 19:56:43.905249 140624834570112 learning.py:512] global step 9383: loss = 1.2915 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9384: loss = 0.8614 (0.254 sec/step)\n",
            "I0802 19:56:44.161319 140624834570112 learning.py:512] global step 9384: loss = 0.8614 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 9385: loss = 0.5573 (0.229 sec/step)\n",
            "I0802 19:56:44.392440 140624834570112 learning.py:512] global step 9385: loss = 0.5573 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9386: loss = 0.7354 (0.225 sec/step)\n",
            "I0802 19:56:44.619353 140624834570112 learning.py:512] global step 9386: loss = 0.7354 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9387: loss = 1.0887 (0.236 sec/step)\n",
            "I0802 19:56:44.856949 140624834570112 learning.py:512] global step 9387: loss = 1.0887 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9388: loss = 0.7082 (0.243 sec/step)\n",
            "I0802 19:56:45.101397 140624834570112 learning.py:512] global step 9388: loss = 0.7082 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9389: loss = 0.5558 (0.250 sec/step)\n",
            "I0802 19:56:45.353245 140624834570112 learning.py:512] global step 9389: loss = 0.5558 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9390: loss = 0.7921 (0.240 sec/step)\n",
            "I0802 19:56:45.594466 140624834570112 learning.py:512] global step 9390: loss = 0.7921 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9391: loss = 0.6825 (0.236 sec/step)\n",
            "I0802 19:56:45.831838 140624834570112 learning.py:512] global step 9391: loss = 0.6825 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9392: loss = 0.7273 (0.244 sec/step)\n",
            "I0802 19:56:46.077152 140624834570112 learning.py:512] global step 9392: loss = 0.7273 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9393: loss = 0.7308 (0.246 sec/step)\n",
            "I0802 19:56:46.324394 140624834570112 learning.py:512] global step 9393: loss = 0.7308 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9394: loss = 0.7491 (0.258 sec/step)\n",
            "I0802 19:56:46.584265 140624834570112 learning.py:512] global step 9394: loss = 0.7491 (0.258 sec/step)\n",
            "INFO:tensorflow:global step 9395: loss = 1.0850 (0.237 sec/step)\n",
            "I0802 19:56:46.822407 140624834570112 learning.py:512] global step 9395: loss = 1.0850 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9396: loss = 0.7866 (0.251 sec/step)\n",
            "I0802 19:56:47.075347 140624834570112 learning.py:512] global step 9396: loss = 0.7866 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9397: loss = 0.5944 (0.246 sec/step)\n",
            "I0802 19:56:47.322841 140624834570112 learning.py:512] global step 9397: loss = 0.5944 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9398: loss = 0.7559 (0.242 sec/step)\n",
            "I0802 19:56:47.566292 140624834570112 learning.py:512] global step 9398: loss = 0.7559 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9399: loss = 0.6076 (0.225 sec/step)\n",
            "I0802 19:56:47.792297 140624834570112 learning.py:512] global step 9399: loss = 0.6076 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9400: loss = 0.7293 (0.242 sec/step)\n",
            "I0802 19:56:48.035214 140624834570112 learning.py:512] global step 9400: loss = 0.7293 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9401: loss = 0.7494 (0.243 sec/step)\n",
            "I0802 19:56:48.279551 140624834570112 learning.py:512] global step 9401: loss = 0.7494 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9402: loss = 0.8211 (0.225 sec/step)\n",
            "I0802 19:56:48.505565 140624834570112 learning.py:512] global step 9402: loss = 0.8211 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9403: loss = 0.6900 (0.244 sec/step)\n",
            "I0802 19:56:48.751263 140624834570112 learning.py:512] global step 9403: loss = 0.6900 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9404: loss = 0.7558 (0.244 sec/step)\n",
            "I0802 19:56:48.997087 140624834570112 learning.py:512] global step 9404: loss = 0.7558 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9405: loss = 0.6762 (0.244 sec/step)\n",
            "I0802 19:56:49.242521 140624834570112 learning.py:512] global step 9405: loss = 0.6762 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9406: loss = 0.9185 (0.248 sec/step)\n",
            "I0802 19:56:49.492151 140624834570112 learning.py:512] global step 9406: loss = 0.9185 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9407: loss = 0.4562 (0.241 sec/step)\n",
            "I0802 19:56:49.734406 140624834570112 learning.py:512] global step 9407: loss = 0.4562 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9408: loss = 0.6125 (0.242 sec/step)\n",
            "I0802 19:56:49.978145 140624834570112 learning.py:512] global step 9408: loss = 0.6125 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9409: loss = 0.6749 (0.244 sec/step)\n",
            "I0802 19:56:50.223867 140624834570112 learning.py:512] global step 9409: loss = 0.6749 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9410: loss = 0.6041 (0.254 sec/step)\n",
            "I0802 19:56:50.479322 140624834570112 learning.py:512] global step 9410: loss = 0.6041 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 9411: loss = 0.7867 (0.235 sec/step)\n",
            "I0802 19:56:50.715668 140624834570112 learning.py:512] global step 9411: loss = 0.7867 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9412: loss = 0.7619 (0.246 sec/step)\n",
            "I0802 19:56:50.962991 140624834570112 learning.py:512] global step 9412: loss = 0.7619 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9413: loss = 0.6989 (0.246 sec/step)\n",
            "I0802 19:56:51.210656 140624834570112 learning.py:512] global step 9413: loss = 0.6989 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9414: loss = 0.5881 (0.251 sec/step)\n",
            "I0802 19:56:51.463212 140624834570112 learning.py:512] global step 9414: loss = 0.5881 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9415: loss = 0.7943 (0.236 sec/step)\n",
            "I0802 19:56:51.700878 140624834570112 learning.py:512] global step 9415: loss = 0.7943 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9416: loss = 0.7177 (0.244 sec/step)\n",
            "I0802 19:56:51.946812 140624834570112 learning.py:512] global step 9416: loss = 0.7177 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9417: loss = 0.5631 (0.229 sec/step)\n",
            "I0802 19:56:52.177481 140624834570112 learning.py:512] global step 9417: loss = 0.5631 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9418: loss = 0.7465 (0.248 sec/step)\n",
            "I0802 19:56:52.427340 140624834570112 learning.py:512] global step 9418: loss = 0.7465 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9419: loss = 0.6904 (0.248 sec/step)\n",
            "I0802 19:56:52.676306 140624834570112 learning.py:512] global step 9419: loss = 0.6904 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9420: loss = 0.9266 (0.251 sec/step)\n",
            "I0802 19:56:52.928994 140624834570112 learning.py:512] global step 9420: loss = 0.9266 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9421: loss = 0.7817 (0.242 sec/step)\n",
            "I0802 19:56:53.172562 140624834570112 learning.py:512] global step 9421: loss = 0.7817 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9422: loss = 0.8341 (0.237 sec/step)\n",
            "I0802 19:56:53.411881 140624834570112 learning.py:512] global step 9422: loss = 0.8341 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9423: loss = 0.8903 (0.240 sec/step)\n",
            "I0802 19:56:53.653378 140624834570112 learning.py:512] global step 9423: loss = 0.8903 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9424: loss = 0.7815 (0.241 sec/step)\n",
            "I0802 19:56:53.895746 140624834570112 learning.py:512] global step 9424: loss = 0.7815 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9425: loss = 0.8678 (0.227 sec/step)\n",
            "I0802 19:56:54.124167 140624834570112 learning.py:512] global step 9425: loss = 0.8678 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9426: loss = 0.6829 (0.241 sec/step)\n",
            "I0802 19:56:54.366331 140624834570112 learning.py:512] global step 9426: loss = 0.6829 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9427: loss = 0.7620 (0.249 sec/step)\n",
            "I0802 19:56:54.619359 140624834570112 learning.py:512] global step 9427: loss = 0.7620 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9428: loss = 0.8205 (0.240 sec/step)\n",
            "I0802 19:56:54.860869 140624834570112 learning.py:512] global step 9428: loss = 0.8205 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9429: loss = 0.7220 (0.240 sec/step)\n",
            "I0802 19:56:55.102005 140624834570112 learning.py:512] global step 9429: loss = 0.7220 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9430: loss = 0.9178 (0.246 sec/step)\n",
            "I0802 19:56:55.349569 140624834570112 learning.py:512] global step 9430: loss = 0.9178 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9431: loss = 0.9431 (0.243 sec/step)\n",
            "I0802 19:56:55.593753 140624834570112 learning.py:512] global step 9431: loss = 0.9431 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9432: loss = 0.7385 (0.242 sec/step)\n",
            "I0802 19:56:55.837611 140624834570112 learning.py:512] global step 9432: loss = 0.7385 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9433: loss = 0.5771 (0.241 sec/step)\n",
            "I0802 19:56:56.080497 140624834570112 learning.py:512] global step 9433: loss = 0.5771 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9434: loss = 0.6736 (0.235 sec/step)\n",
            "I0802 19:56:56.316722 140624834570112 learning.py:512] global step 9434: loss = 0.6736 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9435: loss = 0.7941 (0.242 sec/step)\n",
            "I0802 19:56:56.560028 140624834570112 learning.py:512] global step 9435: loss = 0.7941 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9436: loss = 0.8945 (0.233 sec/step)\n",
            "I0802 19:56:56.795068 140624834570112 learning.py:512] global step 9436: loss = 0.8945 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9437: loss = 0.6412 (0.239 sec/step)\n",
            "I0802 19:56:57.035248 140624834570112 learning.py:512] global step 9437: loss = 0.6412 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9438: loss = 0.7815 (0.247 sec/step)\n",
            "I0802 19:56:57.283370 140624834570112 learning.py:512] global step 9438: loss = 0.7815 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9439: loss = 0.6686 (0.235 sec/step)\n",
            "I0802 19:56:57.520325 140624834570112 learning.py:512] global step 9439: loss = 0.6686 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9440: loss = 0.8720 (0.229 sec/step)\n",
            "I0802 19:56:57.750665 140624834570112 learning.py:512] global step 9440: loss = 0.8720 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9441: loss = 0.6212 (0.241 sec/step)\n",
            "I0802 19:56:57.993042 140624834570112 learning.py:512] global step 9441: loss = 0.6212 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9442: loss = 0.6601 (0.250 sec/step)\n",
            "I0802 19:56:58.244720 140624834570112 learning.py:512] global step 9442: loss = 0.6601 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9443: loss = 0.7209 (0.245 sec/step)\n",
            "I0802 19:56:58.491301 140624834570112 learning.py:512] global step 9443: loss = 0.7209 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9444: loss = 0.7072 (0.243 sec/step)\n",
            "I0802 19:56:58.735570 140624834570112 learning.py:512] global step 9444: loss = 0.7072 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9445: loss = 0.5914 (0.244 sec/step)\n",
            "I0802 19:56:58.981279 140624834570112 learning.py:512] global step 9445: loss = 0.5914 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9446: loss = 0.7184 (0.245 sec/step)\n",
            "I0802 19:56:59.228265 140624834570112 learning.py:512] global step 9446: loss = 0.7184 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9447: loss = 0.6648 (0.251 sec/step)\n",
            "I0802 19:56:59.480839 140624834570112 learning.py:512] global step 9447: loss = 0.6648 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9448: loss = 0.6533 (0.239 sec/step)\n",
            "I0802 19:56:59.721544 140624834570112 learning.py:512] global step 9448: loss = 0.6533 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9449: loss = 0.6227 (0.242 sec/step)\n",
            "I0802 19:56:59.965267 140624834570112 learning.py:512] global step 9449: loss = 0.6227 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9450: loss = 0.6366 (0.253 sec/step)\n",
            "I0802 19:57:00.220238 140624834570112 learning.py:512] global step 9450: loss = 0.6366 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9451: loss = 0.7585 (0.250 sec/step)\n",
            "I0802 19:57:00.471248 140624834570112 learning.py:512] global step 9451: loss = 0.7585 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9452: loss = 0.7141 (0.247 sec/step)\n",
            "I0802 19:57:00.719292 140624834570112 learning.py:512] global step 9452: loss = 0.7141 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9453: loss = 0.6447 (0.253 sec/step)\n",
            "I0802 19:57:00.974165 140624834570112 learning.py:512] global step 9453: loss = 0.6447 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9454: loss = 0.6751 (0.246 sec/step)\n",
            "I0802 19:57:01.222141 140624834570112 learning.py:512] global step 9454: loss = 0.6751 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9455: loss = 0.5001 (0.243 sec/step)\n",
            "I0802 19:57:01.466698 140624834570112 learning.py:512] global step 9455: loss = 0.5001 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9456: loss = 0.7054 (0.251 sec/step)\n",
            "I0802 19:57:01.719093 140624834570112 learning.py:512] global step 9456: loss = 0.7054 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9457: loss = 0.7429 (0.250 sec/step)\n",
            "I0802 19:57:01.970585 140624834570112 learning.py:512] global step 9457: loss = 0.7429 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9458: loss = 0.7652 (0.246 sec/step)\n",
            "I0802 19:57:02.218062 140624834570112 learning.py:512] global step 9458: loss = 0.7652 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9459: loss = 0.6599 (0.257 sec/step)\n",
            "I0802 19:57:02.477304 140624834570112 learning.py:512] global step 9459: loss = 0.6599 (0.257 sec/step)\n",
            "INFO:tensorflow:global step 9460: loss = 0.7300 (0.249 sec/step)\n",
            "I0802 19:57:02.729316 140624834570112 learning.py:512] global step 9460: loss = 0.7300 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9461: loss = 0.6232 (0.256 sec/step)\n",
            "I0802 19:57:02.987333 140624834570112 learning.py:512] global step 9461: loss = 0.6232 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 9462: loss = 0.5428 (0.228 sec/step)\n",
            "I0802 19:57:03.216795 140624834570112 learning.py:512] global step 9462: loss = 0.5428 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9463: loss = 0.5830 (0.253 sec/step)\n",
            "I0802 19:57:03.471284 140624834570112 learning.py:512] global step 9463: loss = 0.5830 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9464: loss = 0.6590 (0.236 sec/step)\n",
            "I0802 19:57:03.708894 140624834570112 learning.py:512] global step 9464: loss = 0.6590 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9465: loss = 0.9180 (0.243 sec/step)\n",
            "I0802 19:57:03.953462 140624834570112 learning.py:512] global step 9465: loss = 0.9180 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9466: loss = 0.5359 (0.247 sec/step)\n",
            "I0802 19:57:04.201684 140624834570112 learning.py:512] global step 9466: loss = 0.5359 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9467: loss = 0.5965 (0.249 sec/step)\n",
            "I0802 19:57:04.452270 140624834570112 learning.py:512] global step 9467: loss = 0.5965 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9468: loss = 0.9476 (0.254 sec/step)\n",
            "I0802 19:57:04.708102 140624834570112 learning.py:512] global step 9468: loss = 0.9476 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 9469: loss = 0.8279 (0.243 sec/step)\n",
            "I0802 19:57:04.952066 140624834570112 learning.py:512] global step 9469: loss = 0.8279 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9470: loss = 0.6444 (0.239 sec/step)\n",
            "I0802 19:57:05.192780 140624834570112 learning.py:512] global step 9470: loss = 0.6444 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9471: loss = 0.7041 (0.242 sec/step)\n",
            "I0802 19:57:05.437135 140624834570112 learning.py:512] global step 9471: loss = 0.7041 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9472: loss = 0.6185 (0.232 sec/step)\n",
            "I0802 19:57:05.670412 140624834570112 learning.py:512] global step 9472: loss = 0.6185 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9473: loss = 0.6240 (0.228 sec/step)\n",
            "I0802 19:57:05.900134 140624834570112 learning.py:512] global step 9473: loss = 0.6240 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9474: loss = 0.7968 (0.229 sec/step)\n",
            "I0802 19:57:06.130188 140624834570112 learning.py:512] global step 9474: loss = 0.7968 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9475: loss = 0.8166 (0.254 sec/step)\n",
            "I0802 19:57:06.386055 140624834570112 learning.py:512] global step 9475: loss = 0.8166 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 9476: loss = 0.5595 (0.255 sec/step)\n",
            "I0802 19:57:06.643085 140624834570112 learning.py:512] global step 9476: loss = 0.5595 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 9477: loss = 0.7056 (0.235 sec/step)\n",
            "I0802 19:57:06.879048 140624834570112 learning.py:512] global step 9477: loss = 0.7056 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9478: loss = 0.5931 (0.247 sec/step)\n",
            "I0802 19:57:07.127990 140624834570112 learning.py:512] global step 9478: loss = 0.5931 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9479: loss = 0.7931 (0.244 sec/step)\n",
            "I0802 19:57:07.373486 140624834570112 learning.py:512] global step 9479: loss = 0.7931 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9480: loss = 0.5999 (0.250 sec/step)\n",
            "I0802 19:57:07.624559 140624834570112 learning.py:512] global step 9480: loss = 0.5999 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9481: loss = 0.6084 (0.233 sec/step)\n",
            "I0802 19:57:07.858964 140624834570112 learning.py:512] global step 9481: loss = 0.6084 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9482: loss = 0.4918 (0.250 sec/step)\n",
            "I0802 19:57:08.110399 140624834570112 learning.py:512] global step 9482: loss = 0.4918 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9483: loss = 0.7483 (0.233 sec/step)\n",
            "I0802 19:57:08.345022 140624834570112 learning.py:512] global step 9483: loss = 0.7483 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9484: loss = 1.0177 (0.245 sec/step)\n",
            "I0802 19:57:08.591595 140624834570112 learning.py:512] global step 9484: loss = 1.0177 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9485: loss = 0.7593 (0.248 sec/step)\n",
            "I0802 19:57:08.840751 140624834570112 learning.py:512] global step 9485: loss = 0.7593 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9486: loss = 0.6741 (0.242 sec/step)\n",
            "I0802 19:57:09.084902 140624834570112 learning.py:512] global step 9486: loss = 0.6741 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9487: loss = 0.7524 (0.233 sec/step)\n",
            "I0802 19:57:09.320248 140624834570112 learning.py:512] global step 9487: loss = 0.7524 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9488: loss = 0.5767 (0.234 sec/step)\n",
            "I0802 19:57:09.555429 140624834570112 learning.py:512] global step 9488: loss = 0.5767 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9489: loss = 0.9287 (0.244 sec/step)\n",
            "I0802 19:57:09.801160 140624834570112 learning.py:512] global step 9489: loss = 0.9287 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9490: loss = 0.8189 (0.243 sec/step)\n",
            "I0802 19:57:10.045702 140624834570112 learning.py:512] global step 9490: loss = 0.8189 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9491: loss = 0.7021 (0.239 sec/step)\n",
            "I0802 19:57:10.286849 140624834570112 learning.py:512] global step 9491: loss = 0.7021 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9492: loss = 0.7189 (0.241 sec/step)\n",
            "I0802 19:57:10.529354 140624834570112 learning.py:512] global step 9492: loss = 0.7189 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9493: loss = 0.6777 (0.243 sec/step)\n",
            "I0802 19:57:10.773416 140624834570112 learning.py:512] global step 9493: loss = 0.6777 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9494: loss = 0.7348 (0.233 sec/step)\n",
            "I0802 19:57:11.007735 140624834570112 learning.py:512] global step 9494: loss = 0.7348 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9495: loss = 0.5812 (0.236 sec/step)\n",
            "I0802 19:57:11.245176 140624834570112 learning.py:512] global step 9495: loss = 0.5812 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9496: loss = 0.6107 (0.250 sec/step)\n",
            "I0802 19:57:11.496350 140624834570112 learning.py:512] global step 9496: loss = 0.6107 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9497: loss = 0.8147 (0.262 sec/step)\n",
            "I0802 19:57:11.760027 140624834570112 learning.py:512] global step 9497: loss = 0.8147 (0.262 sec/step)\n",
            "INFO:tensorflow:global step 9498: loss = 0.6728 (0.246 sec/step)\n",
            "I0802 19:57:12.007638 140624834570112 learning.py:512] global step 9498: loss = 0.6728 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9499: loss = 0.7941 (0.249 sec/step)\n",
            "I0802 19:57:12.257874 140624834570112 learning.py:512] global step 9499: loss = 0.7941 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9500: loss = 0.7167 (0.248 sec/step)\n",
            "I0802 19:57:12.507664 140624834570112 learning.py:512] global step 9500: loss = 0.7167 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9501: loss = 0.5884 (0.248 sec/step)\n",
            "I0802 19:57:12.757350 140624834570112 learning.py:512] global step 9501: loss = 0.5884 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9502: loss = 0.7494 (0.233 sec/step)\n",
            "I0802 19:57:12.991960 140624834570112 learning.py:512] global step 9502: loss = 0.7494 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9503: loss = 0.6217 (0.252 sec/step)\n",
            "I0802 19:57:13.245630 140624834570112 learning.py:512] global step 9503: loss = 0.6217 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9504: loss = 0.6450 (0.237 sec/step)\n",
            "I0802 19:57:13.484377 140624834570112 learning.py:512] global step 9504: loss = 0.6450 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9505: loss = 0.8869 (0.249 sec/step)\n",
            "I0802 19:57:13.735437 140624834570112 learning.py:512] global step 9505: loss = 0.8869 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9506: loss = 0.8045 (0.243 sec/step)\n",
            "I0802 19:57:13.980031 140624834570112 learning.py:512] global step 9506: loss = 0.8045 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9507: loss = 0.6350 (0.238 sec/step)\n",
            "I0802 19:57:14.219754 140624834570112 learning.py:512] global step 9507: loss = 0.6350 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9508: loss = 1.0200 (0.244 sec/step)\n",
            "I0802 19:57:14.465073 140624834570112 learning.py:512] global step 9508: loss = 1.0200 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9509: loss = 0.5897 (0.233 sec/step)\n",
            "I0802 19:57:14.700097 140624834570112 learning.py:512] global step 9509: loss = 0.5897 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9510: loss = 0.7413 (0.245 sec/step)\n",
            "I0802 19:57:14.946519 140624834570112 learning.py:512] global step 9510: loss = 0.7413 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9511: loss = 0.7421 (0.245 sec/step)\n",
            "I0802 19:57:15.192980 140624834570112 learning.py:512] global step 9511: loss = 0.7421 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9512: loss = 0.6085 (0.232 sec/step)\n",
            "I0802 19:57:15.426827 140624834570112 learning.py:512] global step 9512: loss = 0.6085 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9513: loss = 0.4853 (0.233 sec/step)\n",
            "I0802 19:57:15.660892 140624834570112 learning.py:512] global step 9513: loss = 0.4853 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9514: loss = 0.8011 (0.244 sec/step)\n",
            "I0802 19:57:15.906711 140624834570112 learning.py:512] global step 9514: loss = 0.8011 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9515: loss = 0.6591 (0.224 sec/step)\n",
            "I0802 19:57:16.132727 140624834570112 learning.py:512] global step 9515: loss = 0.6591 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9516: loss = 0.8190 (0.243 sec/step)\n",
            "I0802 19:57:16.376814 140624834570112 learning.py:512] global step 9516: loss = 0.8190 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9517: loss = 0.6680 (0.249 sec/step)\n",
            "I0802 19:57:16.626811 140624834570112 learning.py:512] global step 9517: loss = 0.6680 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9518: loss = 0.5879 (0.235 sec/step)\n",
            "I0802 19:57:16.863352 140624834570112 learning.py:512] global step 9518: loss = 0.5879 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9519: loss = 0.6838 (0.245 sec/step)\n",
            "I0802 19:57:17.109913 140624834570112 learning.py:512] global step 9519: loss = 0.6838 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9520: loss = 0.5909 (0.242 sec/step)\n",
            "I0802 19:57:17.353065 140624834570112 learning.py:512] global step 9520: loss = 0.5909 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9521: loss = 0.6832 (0.250 sec/step)\n",
            "I0802 19:57:17.605020 140624834570112 learning.py:512] global step 9521: loss = 0.6832 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9522: loss = 0.5966 (0.239 sec/step)\n",
            "I0802 19:57:17.845083 140624834570112 learning.py:512] global step 9522: loss = 0.5966 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9523: loss = 0.7440 (0.246 sec/step)\n",
            "I0802 19:57:18.092209 140624834570112 learning.py:512] global step 9523: loss = 0.7440 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9524: loss = 0.8120 (0.247 sec/step)\n",
            "I0802 19:57:18.340820 140624834570112 learning.py:512] global step 9524: loss = 0.8120 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9525: loss = 0.6601 (0.249 sec/step)\n",
            "I0802 19:57:18.591574 140624834570112 learning.py:512] global step 9525: loss = 0.6601 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9526: loss = 0.7596 (0.242 sec/step)\n",
            "I0802 19:57:18.835213 140624834570112 learning.py:512] global step 9526: loss = 0.7596 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9527: loss = 0.6045 (0.237 sec/step)\n",
            "I0802 19:57:19.073690 140624834570112 learning.py:512] global step 9527: loss = 0.6045 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9528: loss = 0.6653 (0.246 sec/step)\n",
            "I0802 19:57:19.321668 140624834570112 learning.py:512] global step 9528: loss = 0.6653 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9529: loss = 0.5995 (0.242 sec/step)\n",
            "I0802 19:57:19.565004 140624834570112 learning.py:512] global step 9529: loss = 0.5995 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9530: loss = 0.7024 (0.239 sec/step)\n",
            "I0802 19:57:19.805740 140624834570112 learning.py:512] global step 9530: loss = 0.7024 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9531: loss = 0.7447 (0.249 sec/step)\n",
            "I0802 19:57:20.055836 140624834570112 learning.py:512] global step 9531: loss = 0.7447 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9532: loss = 0.6561 (0.244 sec/step)\n",
            "I0802 19:57:20.302608 140624834570112 learning.py:512] global step 9532: loss = 0.6561 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9533: loss = 0.6512 (0.243 sec/step)\n",
            "I0802 19:57:20.547787 140624834570112 learning.py:512] global step 9533: loss = 0.6512 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9534: loss = 0.8672 (0.244 sec/step)\n",
            "I0802 19:57:20.793535 140624834570112 learning.py:512] global step 9534: loss = 0.8672 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9535: loss = 0.5995 (0.235 sec/step)\n",
            "I0802 19:57:21.030741 140624834570112 learning.py:512] global step 9535: loss = 0.5995 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9536: loss = 0.6435 (0.241 sec/step)\n",
            "I0802 19:57:21.274142 140624834570112 learning.py:512] global step 9536: loss = 0.6435 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9537: loss = 0.7146 (0.231 sec/step)\n",
            "I0802 19:57:21.506274 140624834570112 learning.py:512] global step 9537: loss = 0.7146 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9538: loss = 0.6814 (0.225 sec/step)\n",
            "I0802 19:57:21.733436 140624834570112 learning.py:512] global step 9538: loss = 0.6814 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9539: loss = 0.6459 (0.245 sec/step)\n",
            "I0802 19:57:21.979887 140624834570112 learning.py:512] global step 9539: loss = 0.6459 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9540: loss = 0.6602 (0.252 sec/step)\n",
            "I0802 19:57:22.234162 140624834570112 learning.py:512] global step 9540: loss = 0.6602 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9541: loss = 0.6318 (0.242 sec/step)\n",
            "I0802 19:57:22.477812 140624834570112 learning.py:512] global step 9541: loss = 0.6318 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9542: loss = 0.6517 (0.245 sec/step)\n",
            "I0802 19:57:22.724019 140624834570112 learning.py:512] global step 9542: loss = 0.6517 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9543: loss = 0.8771 (0.244 sec/step)\n",
            "I0802 19:57:22.969182 140624834570112 learning.py:512] global step 9543: loss = 0.8771 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9544: loss = 0.7457 (0.232 sec/step)\n",
            "I0802 19:57:23.202930 140624834570112 learning.py:512] global step 9544: loss = 0.7457 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9545: loss = 0.5668 (0.236 sec/step)\n",
            "I0802 19:57:23.440779 140624834570112 learning.py:512] global step 9545: loss = 0.5668 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9546: loss = 0.6889 (0.235 sec/step)\n",
            "I0802 19:57:23.677514 140624834570112 learning.py:512] global step 9546: loss = 0.6889 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9547: loss = 0.5272 (0.244 sec/step)\n",
            "I0802 19:57:23.922500 140624834570112 learning.py:512] global step 9547: loss = 0.5272 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9548: loss = 0.5994 (0.233 sec/step)\n",
            "I0802 19:57:24.157351 140624834570112 learning.py:512] global step 9548: loss = 0.5994 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9549: loss = 0.8301 (0.238 sec/step)\n",
            "I0802 19:57:24.396655 140624834570112 learning.py:512] global step 9549: loss = 0.8301 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9550: loss = 1.0116 (0.240 sec/step)\n",
            "I0802 19:57:24.638224 140624834570112 learning.py:512] global step 9550: loss = 1.0116 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9551: loss = 0.9551 (0.241 sec/step)\n",
            "I0802 19:57:24.880506 140624834570112 learning.py:512] global step 9551: loss = 0.9551 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9552: loss = 0.6183 (0.229 sec/step)\n",
            "I0802 19:57:25.110835 140624834570112 learning.py:512] global step 9552: loss = 0.6183 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9553: loss = 0.6386 (0.251 sec/step)\n",
            "I0802 19:57:25.363761 140624834570112 learning.py:512] global step 9553: loss = 0.6386 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9554: loss = 0.7763 (0.225 sec/step)\n",
            "I0802 19:57:25.590340 140624834570112 learning.py:512] global step 9554: loss = 0.7763 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9555: loss = 0.7464 (0.246 sec/step)\n",
            "I0802 19:57:25.838189 140624834570112 learning.py:512] global step 9555: loss = 0.7464 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9556: loss = 0.8890 (0.248 sec/step)\n",
            "I0802 19:57:26.087415 140624834570112 learning.py:512] global step 9556: loss = 0.8890 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9557: loss = 1.0694 (0.239 sec/step)\n",
            "I0802 19:57:26.328389 140624834570112 learning.py:512] global step 9557: loss = 1.0694 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9558: loss = 0.6473 (0.244 sec/step)\n",
            "I0802 19:57:26.573561 140624834570112 learning.py:512] global step 9558: loss = 0.6473 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9559: loss = 0.6463 (0.233 sec/step)\n",
            "I0802 19:57:26.807992 140624834570112 learning.py:512] global step 9559: loss = 0.6463 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9560: loss = 0.5591 (0.253 sec/step)\n",
            "I0802 19:57:27.062352 140624834570112 learning.py:512] global step 9560: loss = 0.5591 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9561: loss = 0.6636 (0.248 sec/step)\n",
            "I0802 19:57:27.312772 140624834570112 learning.py:512] global step 9561: loss = 0.6636 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9562: loss = 0.8388 (0.242 sec/step)\n",
            "I0802 19:57:27.556078 140624834570112 learning.py:512] global step 9562: loss = 0.8388 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9563: loss = 0.7656 (0.245 sec/step)\n",
            "I0802 19:57:27.802293 140624834570112 learning.py:512] global step 9563: loss = 0.7656 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9564: loss = 0.6619 (0.239 sec/step)\n",
            "I0802 19:57:28.043018 140624834570112 learning.py:512] global step 9564: loss = 0.6619 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9565: loss = 0.5915 (0.247 sec/step)\n",
            "I0802 19:57:28.291667 140624834570112 learning.py:512] global step 9565: loss = 0.5915 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9566: loss = 0.7822 (0.228 sec/step)\n",
            "I0802 19:57:28.521126 140624834570112 learning.py:512] global step 9566: loss = 0.7822 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9567: loss = 0.6279 (0.253 sec/step)\n",
            "I0802 19:57:28.775947 140624834570112 learning.py:512] global step 9567: loss = 0.6279 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9568: loss = 0.6787 (0.245 sec/step)\n",
            "I0802 19:57:29.022883 140624834570112 learning.py:512] global step 9568: loss = 0.6787 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9569: loss = 0.7486 (0.243 sec/step)\n",
            "I0802 19:57:29.267036 140624834570112 learning.py:512] global step 9569: loss = 0.7486 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9570: loss = 0.6518 (0.235 sec/step)\n",
            "I0802 19:57:29.503298 140624834570112 learning.py:512] global step 9570: loss = 0.6518 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9571: loss = 0.8417 (0.231 sec/step)\n",
            "I0802 19:57:29.735910 140624834570112 learning.py:512] global step 9571: loss = 0.8417 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9572: loss = 0.4885 (0.240 sec/step)\n",
            "I0802 19:57:29.977487 140624834570112 learning.py:512] global step 9572: loss = 0.4885 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9573: loss = 0.7242 (0.232 sec/step)\n",
            "I0802 19:57:30.211073 140624834570112 learning.py:512] global step 9573: loss = 0.7242 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9574: loss = 0.8252 (0.245 sec/step)\n",
            "I0802 19:57:30.458024 140624834570112 learning.py:512] global step 9574: loss = 0.8252 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9575: loss = 0.7494 (0.253 sec/step)\n",
            "I0802 19:57:30.712328 140624834570112 learning.py:512] global step 9575: loss = 0.7494 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9576: loss = 0.6859 (0.242 sec/step)\n",
            "I0802 19:57:30.955526 140624834570112 learning.py:512] global step 9576: loss = 0.6859 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9577: loss = 0.7933 (0.251 sec/step)\n",
            "I0802 19:57:31.208426 140624834570112 learning.py:512] global step 9577: loss = 0.7933 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9578: loss = 0.6202 (0.244 sec/step)\n",
            "I0802 19:57:31.453658 140624834570112 learning.py:512] global step 9578: loss = 0.6202 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9579: loss = 0.7375 (0.244 sec/step)\n",
            "I0802 19:57:31.699584 140624834570112 learning.py:512] global step 9579: loss = 0.7375 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9580: loss = 0.9177 (0.246 sec/step)\n",
            "I0802 19:57:31.946950 140624834570112 learning.py:512] global step 9580: loss = 0.9177 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9581: loss = 0.6713 (0.238 sec/step)\n",
            "I0802 19:57:32.185957 140624834570112 learning.py:512] global step 9581: loss = 0.6713 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9582: loss = 0.7768 (0.253 sec/step)\n",
            "I0802 19:57:32.440893 140624834570112 learning.py:512] global step 9582: loss = 0.7768 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9583: loss = 0.6630 (0.246 sec/step)\n",
            "I0802 19:57:32.688401 140624834570112 learning.py:512] global step 9583: loss = 0.6630 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9584: loss = 0.6926 (0.243 sec/step)\n",
            "I0802 19:57:32.932608 140624834570112 learning.py:512] global step 9584: loss = 0.6926 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9585: loss = 0.7423 (0.229 sec/step)\n",
            "I0802 19:57:33.162862 140624834570112 learning.py:512] global step 9585: loss = 0.7423 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9586: loss = 0.8296 (0.249 sec/step)\n",
            "I0802 19:57:33.413751 140624834570112 learning.py:512] global step 9586: loss = 0.8296 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9587: loss = 0.7342 (0.244 sec/step)\n",
            "I0802 19:57:33.659505 140624834570112 learning.py:512] global step 9587: loss = 0.7342 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9588: loss = 0.5045 (0.231 sec/step)\n",
            "I0802 19:57:33.891806 140624834570112 learning.py:512] global step 9588: loss = 0.5045 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9589: loss = 0.6105 (0.239 sec/step)\n",
            "I0802 19:57:34.132658 140624834570112 learning.py:512] global step 9589: loss = 0.6105 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9590: loss = 0.7354 (0.232 sec/step)\n",
            "I0802 19:57:34.365649 140624834570112 learning.py:512] global step 9590: loss = 0.7354 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9591: loss = 0.8039 (0.235 sec/step)\n",
            "I0802 19:57:34.601811 140624834570112 learning.py:512] global step 9591: loss = 0.8039 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9592: loss = 0.6453 (0.247 sec/step)\n",
            "I0802 19:57:34.850287 140624834570112 learning.py:512] global step 9592: loss = 0.6453 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9593: loss = 0.6823 (0.234 sec/step)\n",
            "I0802 19:57:35.085625 140624834570112 learning.py:512] global step 9593: loss = 0.6823 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9594: loss = 0.7016 (0.233 sec/step)\n",
            "I0802 19:57:35.320315 140624834570112 learning.py:512] global step 9594: loss = 0.7016 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9595: loss = 0.8364 (0.232 sec/step)\n",
            "I0802 19:57:35.553847 140624834570112 learning.py:512] global step 9595: loss = 0.8364 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9596: loss = 0.8613 (0.243 sec/step)\n",
            "I0802 19:57:35.798398 140624834570112 learning.py:512] global step 9596: loss = 0.8613 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9597: loss = 0.8009 (0.243 sec/step)\n",
            "I0802 19:57:36.042588 140624834570112 learning.py:512] global step 9597: loss = 0.8009 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9598: loss = 1.1115 (0.246 sec/step)\n",
            "I0802 19:57:36.289945 140624834570112 learning.py:512] global step 9598: loss = 1.1115 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9599: loss = 0.8402 (0.245 sec/step)\n",
            "I0802 19:57:36.536159 140624834570112 learning.py:512] global step 9599: loss = 0.8402 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9600: loss = 1.0507 (0.243 sec/step)\n",
            "I0802 19:57:36.781018 140624834570112 learning.py:512] global step 9600: loss = 1.0507 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9601: loss = 0.7134 (0.252 sec/step)\n",
            "I0802 19:57:37.033946 140624834570112 learning.py:512] global step 9601: loss = 0.7134 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9602: loss = 0.6284 (0.248 sec/step)\n",
            "I0802 19:57:37.282964 140624834570112 learning.py:512] global step 9602: loss = 0.6284 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9603: loss = 0.7387 (0.248 sec/step)\n",
            "I0802 19:57:37.532345 140624834570112 learning.py:512] global step 9603: loss = 0.7387 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9604: loss = 0.6552 (0.242 sec/step)\n",
            "I0802 19:57:37.776297 140624834570112 learning.py:512] global step 9604: loss = 0.6552 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9605: loss = 0.8689 (0.229 sec/step)\n",
            "I0802 19:57:38.006197 140624834570112 learning.py:512] global step 9605: loss = 0.8689 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9606: loss = 0.5787 (0.247 sec/step)\n",
            "I0802 19:57:38.254733 140624834570112 learning.py:512] global step 9606: loss = 0.5787 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9607: loss = 0.7509 (0.246 sec/step)\n",
            "I0802 19:57:38.501811 140624834570112 learning.py:512] global step 9607: loss = 0.7509 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9608: loss = 0.6706 (0.230 sec/step)\n",
            "I0802 19:57:38.733181 140624834570112 learning.py:512] global step 9608: loss = 0.6706 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9609: loss = 0.4948 (0.253 sec/step)\n",
            "I0802 19:57:38.987421 140624834570112 learning.py:512] global step 9609: loss = 0.4948 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9610: loss = 0.7903 (0.244 sec/step)\n",
            "I0802 19:57:39.233070 140624834570112 learning.py:512] global step 9610: loss = 0.7903 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9611: loss = 0.6804 (0.245 sec/step)\n",
            "I0802 19:57:39.479449 140624834570112 learning.py:512] global step 9611: loss = 0.6804 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9612: loss = 0.8265 (0.231 sec/step)\n",
            "I0802 19:57:39.712059 140624834570112 learning.py:512] global step 9612: loss = 0.8265 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9613: loss = 0.6772 (0.248 sec/step)\n",
            "I0802 19:57:39.961566 140624834570112 learning.py:512] global step 9613: loss = 0.6772 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9614: loss = 0.6085 (0.244 sec/step)\n",
            "I0802 19:57:40.206736 140624834570112 learning.py:512] global step 9614: loss = 0.6085 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9615: loss = 0.6537 (0.243 sec/step)\n",
            "I0802 19:57:40.451592 140624834570112 learning.py:512] global step 9615: loss = 0.6537 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9616: loss = 0.7072 (0.236 sec/step)\n",
            "I0802 19:57:40.689449 140624834570112 learning.py:512] global step 9616: loss = 0.7072 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9617: loss = 0.8563 (0.245 sec/step)\n",
            "I0802 19:57:40.935578 140624834570112 learning.py:512] global step 9617: loss = 0.8563 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9618: loss = 0.5476 (0.243 sec/step)\n",
            "I0802 19:57:41.180453 140624834570112 learning.py:512] global step 9618: loss = 0.5476 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9619: loss = 0.7633 (0.242 sec/step)\n",
            "I0802 19:57:41.424247 140624834570112 learning.py:512] global step 9619: loss = 0.7633 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9620: loss = 0.7782 (0.232 sec/step)\n",
            "I0802 19:57:41.657788 140624834570112 learning.py:512] global step 9620: loss = 0.7782 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9621: loss = 0.9399 (0.248 sec/step)\n",
            "I0802 19:57:41.907038 140624834570112 learning.py:512] global step 9621: loss = 0.9399 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9622: loss = 0.7612 (0.241 sec/step)\n",
            "I0802 19:57:42.149591 140624834570112 learning.py:512] global step 9622: loss = 0.7612 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9623: loss = 0.6728 (0.247 sec/step)\n",
            "I0802 19:57:42.398134 140624834570112 learning.py:512] global step 9623: loss = 0.6728 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9624: loss = 0.9178 (0.229 sec/step)\n",
            "I0802 19:57:42.628508 140624834570112 learning.py:512] global step 9624: loss = 0.9178 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9625: loss = 0.4735 (0.242 sec/step)\n",
            "I0802 19:57:42.871859 140624834570112 learning.py:512] global step 9625: loss = 0.4735 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9626: loss = 0.6125 (0.245 sec/step)\n",
            "I0802 19:57:43.118379 140624834570112 learning.py:512] global step 9626: loss = 0.6125 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9627: loss = 0.7676 (0.238 sec/step)\n",
            "I0802 19:57:43.357794 140624834570112 learning.py:512] global step 9627: loss = 0.7676 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9628: loss = 0.5285 (0.228 sec/step)\n",
            "I0802 19:57:43.587619 140624834570112 learning.py:512] global step 9628: loss = 0.5285 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9629: loss = 0.7834 (0.229 sec/step)\n",
            "I0802 19:57:43.817833 140624834570112 learning.py:512] global step 9629: loss = 0.7834 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9630: loss = 0.6742 (0.236 sec/step)\n",
            "I0802 19:57:44.054960 140624834570112 learning.py:512] global step 9630: loss = 0.6742 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9631: loss = 0.5970 (0.249 sec/step)\n",
            "I0802 19:57:44.305631 140624834570112 learning.py:512] global step 9631: loss = 0.5970 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9632: loss = 0.6751 (0.244 sec/step)\n",
            "I0802 19:57:44.550904 140624834570112 learning.py:512] global step 9632: loss = 0.6751 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9633: loss = 0.6934 (0.233 sec/step)\n",
            "I0802 19:57:44.790222 140624834570112 learning.py:512] global step 9633: loss = 0.6934 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9634: loss = 0.5878 (0.239 sec/step)\n",
            "I0802 19:57:45.031358 140624834570112 learning.py:512] global step 9634: loss = 0.5878 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9635: loss = 0.8173 (0.253 sec/step)\n",
            "I0802 19:57:45.285689 140624834570112 learning.py:512] global step 9635: loss = 0.8173 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9636: loss = 0.5718 (0.235 sec/step)\n",
            "I0802 19:57:45.522232 140624834570112 learning.py:512] global step 9636: loss = 0.5718 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9637: loss = 0.6337 (0.242 sec/step)\n",
            "I0802 19:57:45.766016 140624834570112 learning.py:512] global step 9637: loss = 0.6337 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9638: loss = 0.7899 (0.248 sec/step)\n",
            "I0802 19:57:46.015375 140624834570112 learning.py:512] global step 9638: loss = 0.7899 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9639: loss = 0.7635 (0.229 sec/step)\n",
            "I0802 19:57:46.246325 140624834570112 learning.py:512] global step 9639: loss = 0.7635 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9640: loss = 0.6949 (0.256 sec/step)\n",
            "I0802 19:57:46.504825 140624834570112 learning.py:512] global step 9640: loss = 0.6949 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 9641: loss = 0.6265 (0.243 sec/step)\n",
            "I0802 19:57:46.749671 140624834570112 learning.py:512] global step 9641: loss = 0.6265 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9642: loss = 0.5567 (0.252 sec/step)\n",
            "I0802 19:57:47.003372 140624834570112 learning.py:512] global step 9642: loss = 0.5567 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9643: loss = 0.6347 (0.233 sec/step)\n",
            "I0802 19:57:47.238028 140624834570112 learning.py:512] global step 9643: loss = 0.6347 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9644: loss = 0.6051 (0.250 sec/step)\n",
            "I0802 19:57:47.489257 140624834570112 learning.py:512] global step 9644: loss = 0.6051 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9645: loss = 0.5523 (0.232 sec/step)\n",
            "I0802 19:57:47.722343 140624834570112 learning.py:512] global step 9645: loss = 0.5523 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9646: loss = 0.8896 (0.234 sec/step)\n",
            "I0802 19:57:47.957940 140624834570112 learning.py:512] global step 9646: loss = 0.8896 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9647: loss = 0.6554 (0.255 sec/step)\n",
            "I0802 19:57:48.214759 140624834570112 learning.py:512] global step 9647: loss = 0.6554 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 9648: loss = 1.0432 (0.226 sec/step)\n",
            "I0802 19:57:48.442222 140624834570112 learning.py:512] global step 9648: loss = 1.0432 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9649: loss = 0.6084 (0.230 sec/step)\n",
            "I0802 19:57:48.673751 140624834570112 learning.py:512] global step 9649: loss = 0.6084 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9650: loss = 0.9087 (0.233 sec/step)\n",
            "I0802 19:57:48.908405 140624834570112 learning.py:512] global step 9650: loss = 0.9087 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9651: loss = 0.5706 (0.231 sec/step)\n",
            "I0802 19:57:49.141543 140624834570112 learning.py:512] global step 9651: loss = 0.5706 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9652: loss = 0.7042 (0.245 sec/step)\n",
            "I0802 19:57:49.388534 140624834570112 learning.py:512] global step 9652: loss = 0.7042 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9653: loss = 0.9858 (0.244 sec/step)\n",
            "I0802 19:57:49.633908 140624834570112 learning.py:512] global step 9653: loss = 0.9858 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9654: loss = 0.6076 (0.229 sec/step)\n",
            "I0802 19:57:49.864751 140624834570112 learning.py:512] global step 9654: loss = 0.6076 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9655: loss = 0.6963 (0.248 sec/step)\n",
            "I0802 19:57:50.114401 140624834570112 learning.py:512] global step 9655: loss = 0.6963 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9656: loss = 0.5460 (0.240 sec/step)\n",
            "I0802 19:57:50.355952 140624834570112 learning.py:512] global step 9656: loss = 0.5460 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9657: loss = 0.8755 (0.222 sec/step)\n",
            "I0802 19:57:50.579723 140624834570112 learning.py:512] global step 9657: loss = 0.8755 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9658: loss = 0.7013 (0.226 sec/step)\n",
            "I0802 19:57:50.807100 140624834570112 learning.py:512] global step 9658: loss = 0.7013 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9659: loss = 0.8782 (0.250 sec/step)\n",
            "I0802 19:57:51.058344 140624834570112 learning.py:512] global step 9659: loss = 0.8782 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9660: loss = 0.9428 (0.244 sec/step)\n",
            "I0802 19:57:51.303448 140624834570112 learning.py:512] global step 9660: loss = 0.9428 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9661: loss = 0.7161 (0.244 sec/step)\n",
            "I0802 19:57:51.549333 140624834570112 learning.py:512] global step 9661: loss = 0.7161 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9662: loss = 0.9946 (0.240 sec/step)\n",
            "I0802 19:57:51.791249 140624834570112 learning.py:512] global step 9662: loss = 0.9946 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9663: loss = 0.6670 (0.251 sec/step)\n",
            "I0802 19:57:52.043766 140624834570112 learning.py:512] global step 9663: loss = 0.6670 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9664: loss = 1.0527 (0.237 sec/step)\n",
            "I0802 19:57:52.282820 140624834570112 learning.py:512] global step 9664: loss = 1.0527 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9665: loss = 0.8008 (0.229 sec/step)\n",
            "I0802 19:57:52.513004 140624834570112 learning.py:512] global step 9665: loss = 0.8008 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9666: loss = 0.5864 (0.242 sec/step)\n",
            "I0802 19:57:52.756597 140624834570112 learning.py:512] global step 9666: loss = 0.5864 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9667: loss = 0.6020 (0.241 sec/step)\n",
            "I0802 19:57:52.998842 140624834570112 learning.py:512] global step 9667: loss = 0.6020 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9668: loss = 0.6780 (0.247 sec/step)\n",
            "I0802 19:57:53.247730 140624834570112 learning.py:512] global step 9668: loss = 0.6780 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9669: loss = 0.8524 (0.245 sec/step)\n",
            "I0802 19:57:53.494213 140624834570112 learning.py:512] global step 9669: loss = 0.8524 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9670: loss = 0.8383 (0.251 sec/step)\n",
            "I0802 19:57:53.746902 140624834570112 learning.py:512] global step 9670: loss = 0.8383 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9671: loss = 0.8317 (0.249 sec/step)\n",
            "I0802 19:57:53.997406 140624834570112 learning.py:512] global step 9671: loss = 0.8317 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9672: loss = 0.6270 (0.245 sec/step)\n",
            "I0802 19:57:54.243739 140624834570112 learning.py:512] global step 9672: loss = 0.6270 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9673: loss = 0.7996 (0.243 sec/step)\n",
            "I0802 19:57:54.488290 140624834570112 learning.py:512] global step 9673: loss = 0.7996 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9674: loss = 0.6944 (0.241 sec/step)\n",
            "I0802 19:57:54.730625 140624834570112 learning.py:512] global step 9674: loss = 0.6944 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9675: loss = 0.8485 (0.237 sec/step)\n",
            "I0802 19:57:54.969230 140624834570112 learning.py:512] global step 9675: loss = 0.8485 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9676: loss = 0.6578 (0.242 sec/step)\n",
            "I0802 19:57:55.212331 140624834570112 learning.py:512] global step 9676: loss = 0.6578 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9677: loss = 0.7962 (0.247 sec/step)\n",
            "I0802 19:57:55.460882 140624834570112 learning.py:512] global step 9677: loss = 0.7962 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9678: loss = 0.8088 (0.242 sec/step)\n",
            "I0802 19:57:55.704852 140624834570112 learning.py:512] global step 9678: loss = 0.8088 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9679: loss = 0.7068 (0.245 sec/step)\n",
            "I0802 19:57:55.951740 140624834570112 learning.py:512] global step 9679: loss = 0.7068 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9680: loss = 0.7440 (0.231 sec/step)\n",
            "I0802 19:57:56.184297 140624834570112 learning.py:512] global step 9680: loss = 0.7440 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9681: loss = 0.8321 (0.258 sec/step)\n",
            "I0802 19:57:56.444174 140624834570112 learning.py:512] global step 9681: loss = 0.8321 (0.258 sec/step)\n",
            "INFO:tensorflow:global step 9682: loss = 0.6989 (0.232 sec/step)\n",
            "I0802 19:57:56.677940 140624834570112 learning.py:512] global step 9682: loss = 0.6989 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9683: loss = 0.9769 (0.238 sec/step)\n",
            "I0802 19:57:56.917630 140624834570112 learning.py:512] global step 9683: loss = 0.9769 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9684: loss = 0.7568 (0.245 sec/step)\n",
            "I0802 19:57:57.165116 140624834570112 learning.py:512] global step 9684: loss = 0.7568 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9685: loss = 0.9581 (0.243 sec/step)\n",
            "I0802 19:57:57.409350 140624834570112 learning.py:512] global step 9685: loss = 0.9581 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9686: loss = 0.7216 (0.245 sec/step)\n",
            "I0802 19:57:57.655495 140624834570112 learning.py:512] global step 9686: loss = 0.7216 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9687: loss = 0.5684 (0.234 sec/step)\n",
            "I0802 19:57:57.891347 140624834570112 learning.py:512] global step 9687: loss = 0.5684 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9688: loss = 0.7962 (0.238 sec/step)\n",
            "I0802 19:57:58.131153 140624834570112 learning.py:512] global step 9688: loss = 0.7962 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9689: loss = 0.5668 (0.250 sec/step)\n",
            "I0802 19:57:58.382738 140624834570112 learning.py:512] global step 9689: loss = 0.5668 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9690: loss = 0.6132 (0.243 sec/step)\n",
            "I0802 19:57:58.627079 140624834570112 learning.py:512] global step 9690: loss = 0.6132 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9691: loss = 0.8559 (0.252 sec/step)\n",
            "I0802 19:57:58.880706 140624834570112 learning.py:512] global step 9691: loss = 0.8559 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9692: loss = 0.7705 (0.247 sec/step)\n",
            "I0802 19:57:59.129058 140624834570112 learning.py:512] global step 9692: loss = 0.7705 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9693: loss = 0.8359 (0.251 sec/step)\n",
            "I0802 19:57:59.381298 140624834570112 learning.py:512] global step 9693: loss = 0.8359 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9694: loss = 0.6119 (0.248 sec/step)\n",
            "I0802 19:57:59.630847 140624834570112 learning.py:512] global step 9694: loss = 0.6119 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9695: loss = 0.6405 (0.232 sec/step)\n",
            "I0802 19:57:59.863812 140624834570112 learning.py:512] global step 9695: loss = 0.6405 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9696: loss = 0.6720 (0.245 sec/step)\n",
            "I0802 19:58:00.110348 140624834570112 learning.py:512] global step 9696: loss = 0.6720 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9697: loss = 0.9838 (0.232 sec/step)\n",
            "I0802 19:58:00.344226 140624834570112 learning.py:512] global step 9697: loss = 0.9838 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9698: loss = 0.8029 (0.235 sec/step)\n",
            "I0802 19:58:00.581307 140624834570112 learning.py:512] global step 9698: loss = 0.8029 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9699: loss = 0.7796 (0.249 sec/step)\n",
            "I0802 19:58:00.831418 140624834570112 learning.py:512] global step 9699: loss = 0.7796 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9700: loss = 0.7333 (0.250 sec/step)\n",
            "I0802 19:58:01.083464 140624834570112 learning.py:512] global step 9700: loss = 0.7333 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9701: loss = 0.6451 (0.242 sec/step)\n",
            "I0802 19:58:01.326689 140624834570112 learning.py:512] global step 9701: loss = 0.6451 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9702: loss = 0.6649 (0.232 sec/step)\n",
            "I0802 19:58:01.560046 140624834570112 learning.py:512] global step 9702: loss = 0.6649 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9703: loss = 0.5761 (0.237 sec/step)\n",
            "I0802 19:58:01.798971 140624834570112 learning.py:512] global step 9703: loss = 0.5761 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9704: loss = 0.7062 (0.235 sec/step)\n",
            "I0802 19:58:02.035477 140624834570112 learning.py:512] global step 9704: loss = 0.7062 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9705: loss = 0.9879 (0.238 sec/step)\n",
            "I0802 19:58:02.274660 140624834570112 learning.py:512] global step 9705: loss = 0.9879 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9706: loss = 0.7244 (0.232 sec/step)\n",
            "I0802 19:58:02.508633 140624834570112 learning.py:512] global step 9706: loss = 0.7244 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9707: loss = 0.5799 (0.243 sec/step)\n",
            "I0802 19:58:02.753167 140624834570112 learning.py:512] global step 9707: loss = 0.5799 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9708: loss = 0.6413 (0.248 sec/step)\n",
            "I0802 19:58:03.002376 140624834570112 learning.py:512] global step 9708: loss = 0.6413 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9709: loss = 0.8091 (0.236 sec/step)\n",
            "I0802 19:58:03.240002 140624834570112 learning.py:512] global step 9709: loss = 0.8091 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9710: loss = 0.6905 (0.241 sec/step)\n",
            "I0802 19:58:03.482551 140624834570112 learning.py:512] global step 9710: loss = 0.6905 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9711: loss = 0.6126 (0.234 sec/step)\n",
            "I0802 19:58:03.718374 140624834570112 learning.py:512] global step 9711: loss = 0.6126 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9712: loss = 0.9673 (0.246 sec/step)\n",
            "I0802 19:58:03.965467 140624834570112 learning.py:512] global step 9712: loss = 0.9673 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9713: loss = 0.6849 (0.248 sec/step)\n",
            "I0802 19:58:04.214898 140624834570112 learning.py:512] global step 9713: loss = 0.6849 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9714: loss = 0.7513 (0.232 sec/step)\n",
            "I0802 19:58:04.449607 140624834570112 learning.py:512] global step 9714: loss = 0.7513 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9715: loss = 0.5738 (0.254 sec/step)\n",
            "I0802 19:58:04.704855 140624834570112 learning.py:512] global step 9715: loss = 0.5738 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 9716: loss = 0.7453 (0.250 sec/step)\n",
            "I0802 19:58:04.956311 140624834570112 learning.py:512] global step 9716: loss = 0.7453 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9717: loss = 0.7234 (0.247 sec/step)\n",
            "I0802 19:58:05.204864 140624834570112 learning.py:512] global step 9717: loss = 0.7234 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9718: loss = 0.5939 (0.246 sec/step)\n",
            "I0802 19:58:05.452112 140624834570112 learning.py:512] global step 9718: loss = 0.5939 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9719: loss = 0.5633 (0.244 sec/step)\n",
            "I0802 19:58:05.697286 140624834570112 learning.py:512] global step 9719: loss = 0.5633 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9720: loss = 0.7638 (0.245 sec/step)\n",
            "I0802 19:58:05.944266 140624834570112 learning.py:512] global step 9720: loss = 0.7638 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9721: loss = 0.6898 (0.249 sec/step)\n",
            "I0802 19:58:06.195093 140624834570112 learning.py:512] global step 9721: loss = 0.6898 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9722: loss = 0.8818 (0.242 sec/step)\n",
            "I0802 19:58:06.438576 140624834570112 learning.py:512] global step 9722: loss = 0.8818 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9723: loss = 0.4927 (0.247 sec/step)\n",
            "I0802 19:58:06.687609 140624834570112 learning.py:512] global step 9723: loss = 0.4927 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9724: loss = 0.6226 (0.244 sec/step)\n",
            "I0802 19:58:06.933238 140624834570112 learning.py:512] global step 9724: loss = 0.6226 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9725: loss = 0.6704 (0.236 sec/step)\n",
            "I0802 19:58:07.170288 140624834570112 learning.py:512] global step 9725: loss = 0.6704 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9726: loss = 0.7436 (0.246 sec/step)\n",
            "I0802 19:58:07.417995 140624834570112 learning.py:512] global step 9726: loss = 0.7436 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9727: loss = 0.6364 (0.250 sec/step)\n",
            "I0802 19:58:07.669736 140624834570112 learning.py:512] global step 9727: loss = 0.6364 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9728: loss = 0.9086 (0.242 sec/step)\n",
            "I0802 19:58:07.913048 140624834570112 learning.py:512] global step 9728: loss = 0.9086 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9729: loss = 0.5590 (0.243 sec/step)\n",
            "I0802 19:58:08.157856 140624834570112 learning.py:512] global step 9729: loss = 0.5590 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9730: loss = 0.6156 (0.249 sec/step)\n",
            "I0802 19:58:08.412273 140624834570112 learning.py:512] global step 9730: loss = 0.6156 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9731: loss = 0.9752 (0.238 sec/step)\n",
            "I0802 19:58:08.652253 140624834570112 learning.py:512] global step 9731: loss = 0.9752 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9732: loss = 0.9572 (0.239 sec/step)\n",
            "I0802 19:58:08.893000 140624834570112 learning.py:512] global step 9732: loss = 0.9572 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9733: loss = 0.8526 (0.248 sec/step)\n",
            "I0802 19:58:09.144469 140624834570112 learning.py:512] global step 9733: loss = 0.8526 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9734: loss = 0.7603 (0.253 sec/step)\n",
            "I0802 19:58:09.399061 140624834570112 learning.py:512] global step 9734: loss = 0.7603 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9735: loss = 0.6392 (0.247 sec/step)\n",
            "I0802 19:58:09.648090 140624834570112 learning.py:512] global step 9735: loss = 0.6392 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9736: loss = 0.6506 (0.234 sec/step)\n",
            "I0802 19:58:09.883512 140624834570112 learning.py:512] global step 9736: loss = 0.6506 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9737: loss = 0.7227 (0.246 sec/step)\n",
            "I0802 19:58:10.131320 140624834570112 learning.py:512] global step 9737: loss = 0.7227 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9738: loss = 0.7606 (0.238 sec/step)\n",
            "I0802 19:58:10.370500 140624834570112 learning.py:512] global step 9738: loss = 0.7606 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9739: loss = 0.7978 (0.231 sec/step)\n",
            "I0802 19:58:10.603343 140624834570112 learning.py:512] global step 9739: loss = 0.7978 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9740: loss = 0.7821 (0.243 sec/step)\n",
            "I0802 19:58:10.847426 140624834570112 learning.py:512] global step 9740: loss = 0.7821 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9741: loss = 0.6659 (0.247 sec/step)\n",
            "I0802 19:58:11.096753 140624834570112 learning.py:512] global step 9741: loss = 0.6659 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9742: loss = 0.7387 (0.248 sec/step)\n",
            "I0802 19:58:11.347340 140624834570112 learning.py:512] global step 9742: loss = 0.7387 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9743: loss = 0.6635 (0.245 sec/step)\n",
            "I0802 19:58:11.593733 140624834570112 learning.py:512] global step 9743: loss = 0.6635 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9744: loss = 0.6468 (0.249 sec/step)\n",
            "I0802 19:58:11.844091 140624834570112 learning.py:512] global step 9744: loss = 0.6468 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9745: loss = 0.8636 (0.234 sec/step)\n",
            "I0802 19:58:12.080040 140624834570112 learning.py:512] global step 9745: loss = 0.8636 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9746: loss = 0.8243 (0.246 sec/step)\n",
            "I0802 19:58:12.327098 140624834570112 learning.py:512] global step 9746: loss = 0.8243 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9747: loss = 0.5931 (0.244 sec/step)\n",
            "I0802 19:58:12.573174 140624834570112 learning.py:512] global step 9747: loss = 0.5931 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9748: loss = 0.8253 (0.251 sec/step)\n",
            "I0802 19:58:12.825734 140624834570112 learning.py:512] global step 9748: loss = 0.8253 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9749: loss = 0.8130 (0.235 sec/step)\n",
            "I0802 19:58:13.062838 140624834570112 learning.py:512] global step 9749: loss = 0.8130 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9750: loss = 0.8049 (0.250 sec/step)\n",
            "I0802 19:58:13.314065 140624834570112 learning.py:512] global step 9750: loss = 0.8049 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9751: loss = 0.8776 (0.247 sec/step)\n",
            "I0802 19:58:13.562570 140624834570112 learning.py:512] global step 9751: loss = 0.8776 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9752: loss = 0.6566 (0.251 sec/step)\n",
            "I0802 19:58:13.815083 140624834570112 learning.py:512] global step 9752: loss = 0.6566 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9753: loss = 0.4976 (0.229 sec/step)\n",
            "I0802 19:58:14.046022 140624834570112 learning.py:512] global step 9753: loss = 0.4976 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9754: loss = 0.8245 (0.253 sec/step)\n",
            "I0802 19:58:14.300737 140624834570112 learning.py:512] global step 9754: loss = 0.8245 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9755: loss = 0.6342 (0.243 sec/step)\n",
            "I0802 19:58:14.544779 140624834570112 learning.py:512] global step 9755: loss = 0.6342 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9756: loss = 0.6940 (0.245 sec/step)\n",
            "I0802 19:58:14.791396 140624834570112 learning.py:512] global step 9756: loss = 0.6940 (0.245 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /root/models/trained/model.ckpt\n",
            "I0802 19:58:14.867145 140620419835648 supervisor.py:1117] Saving checkpoint to path /root/models/trained/model.ckpt\n",
            "INFO:tensorflow:global step 9757: loss = 0.7438 (0.319 sec/step)\n",
            "I0802 19:58:15.197473 140624834570112 learning.py:512] global step 9757: loss = 0.7438 (0.319 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 9757.\n",
            "I0802 19:58:15.221162 140620445013760 supervisor.py:1050] Recording summary at step 9757.\n",
            "INFO:tensorflow:global step 9758: loss = 0.6814 (0.280 sec/step)\n",
            "I0802 19:58:15.485439 140624834570112 learning.py:512] global step 9758: loss = 0.6814 (0.280 sec/step)\n",
            "INFO:tensorflow:global step 9759: loss = 0.6418 (0.278 sec/step)\n",
            "I0802 19:58:15.775403 140624834570112 learning.py:512] global step 9759: loss = 0.6418 (0.278 sec/step)\n",
            "INFO:tensorflow:global step 9760: loss = 0.6636 (0.273 sec/step)\n",
            "I0802 19:58:16.060888 140624834570112 learning.py:512] global step 9760: loss = 0.6636 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 9761: loss = 0.7000 (0.320 sec/step)\n",
            "I0802 19:58:16.394203 140624834570112 learning.py:512] global step 9761: loss = 0.7000 (0.320 sec/step)\n",
            "INFO:tensorflow:global step 9762: loss = 0.7827 (0.564 sec/step)\n",
            "I0802 19:58:16.968002 140624834570112 learning.py:512] global step 9762: loss = 0.7827 (0.564 sec/step)\n",
            "INFO:tensorflow:global step 9763: loss = 0.8678 (0.294 sec/step)\n",
            "I0802 19:58:17.267224 140624834570112 learning.py:512] global step 9763: loss = 0.8678 (0.294 sec/step)\n",
            "INFO:tensorflow:global step 9764: loss = 0.8048 (0.251 sec/step)\n",
            "I0802 19:58:17.520431 140624834570112 learning.py:512] global step 9764: loss = 0.8048 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9765: loss = 0.5287 (0.231 sec/step)\n",
            "I0802 19:58:17.752548 140624834570112 learning.py:512] global step 9765: loss = 0.5287 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9766: loss = 0.7661 (0.236 sec/step)\n",
            "I0802 19:58:17.990564 140624834570112 learning.py:512] global step 9766: loss = 0.7661 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9767: loss = 0.8947 (0.250 sec/step)\n",
            "I0802 19:58:18.241895 140624834570112 learning.py:512] global step 9767: loss = 0.8947 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9768: loss = 0.6448 (0.244 sec/step)\n",
            "I0802 19:58:18.487634 140624834570112 learning.py:512] global step 9768: loss = 0.6448 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9769: loss = 0.6022 (0.256 sec/step)\n",
            "I0802 19:58:18.744485 140624834570112 learning.py:512] global step 9769: loss = 0.6022 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 9770: loss = 0.8244 (0.227 sec/step)\n",
            "I0802 19:58:18.972623 140624834570112 learning.py:512] global step 9770: loss = 0.8244 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9771: loss = 0.6685 (0.250 sec/step)\n",
            "I0802 19:58:19.223910 140624834570112 learning.py:512] global step 9771: loss = 0.6685 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9772: loss = 0.6451 (0.235 sec/step)\n",
            "I0802 19:58:19.460821 140624834570112 learning.py:512] global step 9772: loss = 0.6451 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9773: loss = 0.7429 (0.238 sec/step)\n",
            "I0802 19:58:19.700670 140624834570112 learning.py:512] global step 9773: loss = 0.7429 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9774: loss = 0.6577 (0.256 sec/step)\n",
            "I0802 19:58:19.958320 140624834570112 learning.py:512] global step 9774: loss = 0.6577 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 9775: loss = 0.7668 (0.241 sec/step)\n",
            "I0802 19:58:20.201226 140624834570112 learning.py:512] global step 9775: loss = 0.7668 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9776: loss = 0.6974 (0.242 sec/step)\n",
            "I0802 19:58:20.444301 140624834570112 learning.py:512] global step 9776: loss = 0.6974 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9777: loss = 0.6149 (0.231 sec/step)\n",
            "I0802 19:58:20.676399 140624834570112 learning.py:512] global step 9777: loss = 0.6149 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9778: loss = 0.6119 (0.243 sec/step)\n",
            "I0802 19:58:20.920740 140624834570112 learning.py:512] global step 9778: loss = 0.6119 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9779: loss = 0.5971 (0.242 sec/step)\n",
            "I0802 19:58:21.163865 140624834570112 learning.py:512] global step 9779: loss = 0.5971 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9780: loss = 0.6366 (0.236 sec/step)\n",
            "I0802 19:58:21.401146 140624834570112 learning.py:512] global step 9780: loss = 0.6366 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9781: loss = 0.6214 (0.245 sec/step)\n",
            "I0802 19:58:21.647533 140624834570112 learning.py:512] global step 9781: loss = 0.6214 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9782: loss = 0.7119 (0.247 sec/step)\n",
            "I0802 19:58:21.895977 140624834570112 learning.py:512] global step 9782: loss = 0.7119 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9783: loss = 0.9286 (0.229 sec/step)\n",
            "I0802 19:58:22.126127 140624834570112 learning.py:512] global step 9783: loss = 0.9286 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9784: loss = 0.5311 (0.230 sec/step)\n",
            "I0802 19:58:22.357212 140624834570112 learning.py:512] global step 9784: loss = 0.5311 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9785: loss = 0.6730 (0.235 sec/step)\n",
            "I0802 19:58:22.594076 140624834570112 learning.py:512] global step 9785: loss = 0.6730 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9786: loss = 0.6263 (0.247 sec/step)\n",
            "I0802 19:58:22.842680 140624834570112 learning.py:512] global step 9786: loss = 0.6263 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9787: loss = 0.6744 (0.229 sec/step)\n",
            "I0802 19:58:23.072985 140624834570112 learning.py:512] global step 9787: loss = 0.6744 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9788: loss = 0.8752 (0.239 sec/step)\n",
            "I0802 19:58:23.313309 140624834570112 learning.py:512] global step 9788: loss = 0.8752 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9789: loss = 0.7155 (0.242 sec/step)\n",
            "I0802 19:58:23.556559 140624834570112 learning.py:512] global step 9789: loss = 0.7155 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9790: loss = 0.5115 (0.229 sec/step)\n",
            "I0802 19:58:23.786880 140624834570112 learning.py:512] global step 9790: loss = 0.5115 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9791: loss = 0.6995 (0.248 sec/step)\n",
            "I0802 19:58:24.036077 140624834570112 learning.py:512] global step 9791: loss = 0.6995 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9792: loss = 0.6321 (0.235 sec/step)\n",
            "I0802 19:58:24.273003 140624834570112 learning.py:512] global step 9792: loss = 0.6321 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9793: loss = 0.7603 (0.238 sec/step)\n",
            "I0802 19:58:24.512670 140624834570112 learning.py:512] global step 9793: loss = 0.7603 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9794: loss = 0.6031 (0.236 sec/step)\n",
            "I0802 19:58:24.750287 140624834570112 learning.py:512] global step 9794: loss = 0.6031 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9795: loss = 0.7433 (0.235 sec/step)\n",
            "I0802 19:58:24.986251 140624834570112 learning.py:512] global step 9795: loss = 0.7433 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9796: loss = 0.5764 (0.227 sec/step)\n",
            "I0802 19:58:25.214807 140624834570112 learning.py:512] global step 9796: loss = 0.5764 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9797: loss = 0.6854 (0.242 sec/step)\n",
            "I0802 19:58:25.458300 140624834570112 learning.py:512] global step 9797: loss = 0.6854 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9798: loss = 0.7320 (0.237 sec/step)\n",
            "I0802 19:58:25.696600 140624834570112 learning.py:512] global step 9798: loss = 0.7320 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9799: loss = 0.5903 (0.230 sec/step)\n",
            "I0802 19:58:25.927868 140624834570112 learning.py:512] global step 9799: loss = 0.5903 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9800: loss = 0.6883 (0.251 sec/step)\n",
            "I0802 19:58:26.180012 140624834570112 learning.py:512] global step 9800: loss = 0.6883 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9801: loss = 0.6164 (0.248 sec/step)\n",
            "I0802 19:58:26.429335 140624834570112 learning.py:512] global step 9801: loss = 0.6164 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9802: loss = 0.8287 (0.248 sec/step)\n",
            "I0802 19:58:26.678703 140624834570112 learning.py:512] global step 9802: loss = 0.8287 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9803: loss = 0.6480 (0.241 sec/step)\n",
            "I0802 19:58:26.920981 140624834570112 learning.py:512] global step 9803: loss = 0.6480 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9804: loss = 0.6485 (0.239 sec/step)\n",
            "I0802 19:58:27.161143 140624834570112 learning.py:512] global step 9804: loss = 0.6485 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9805: loss = 0.9875 (0.249 sec/step)\n",
            "I0802 19:58:27.411683 140624834570112 learning.py:512] global step 9805: loss = 0.9875 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9806: loss = 0.7883 (0.239 sec/step)\n",
            "I0802 19:58:27.652079 140624834570112 learning.py:512] global step 9806: loss = 0.7883 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9807: loss = 1.0501 (0.241 sec/step)\n",
            "I0802 19:58:27.895144 140624834570112 learning.py:512] global step 9807: loss = 1.0501 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9808: loss = 0.5731 (0.238 sec/step)\n",
            "I0802 19:58:28.134101 140624834570112 learning.py:512] global step 9808: loss = 0.5731 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9809: loss = 0.8840 (0.231 sec/step)\n",
            "I0802 19:58:28.367351 140624834570112 learning.py:512] global step 9809: loss = 0.8840 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9810: loss = 0.7779 (0.247 sec/step)\n",
            "I0802 19:58:28.615595 140624834570112 learning.py:512] global step 9810: loss = 0.7779 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9811: loss = 0.5983 (0.246 sec/step)\n",
            "I0802 19:58:28.863018 140624834570112 learning.py:512] global step 9811: loss = 0.5983 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9812: loss = 0.6881 (0.245 sec/step)\n",
            "I0802 19:58:29.109040 140624834570112 learning.py:512] global step 9812: loss = 0.6881 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9813: loss = 0.6313 (0.245 sec/step)\n",
            "I0802 19:58:29.355793 140624834570112 learning.py:512] global step 9813: loss = 0.6313 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9814: loss = 0.8175 (0.237 sec/step)\n",
            "I0802 19:58:29.593767 140624834570112 learning.py:512] global step 9814: loss = 0.8175 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9815: loss = 0.5639 (0.235 sec/step)\n",
            "I0802 19:58:29.830566 140624834570112 learning.py:512] global step 9815: loss = 0.5639 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9816: loss = 0.9629 (0.245 sec/step)\n",
            "I0802 19:58:30.076778 140624834570112 learning.py:512] global step 9816: loss = 0.9629 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9817: loss = 0.7873 (0.239 sec/step)\n",
            "I0802 19:58:30.317114 140624834570112 learning.py:512] global step 9817: loss = 0.7873 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9818: loss = 0.8485 (0.247 sec/step)\n",
            "I0802 19:58:30.565622 140624834570112 learning.py:512] global step 9818: loss = 0.8485 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9819: loss = 0.5680 (0.239 sec/step)\n",
            "I0802 19:58:30.805824 140624834570112 learning.py:512] global step 9819: loss = 0.5680 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9820: loss = 0.8759 (0.237 sec/step)\n",
            "I0802 19:58:31.044764 140624834570112 learning.py:512] global step 9820: loss = 0.8759 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9821: loss = 0.4579 (0.243 sec/step)\n",
            "I0802 19:58:31.289366 140624834570112 learning.py:512] global step 9821: loss = 0.4579 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9822: loss = 0.6529 (0.245 sec/step)\n",
            "I0802 19:58:31.536021 140624834570112 learning.py:512] global step 9822: loss = 0.6529 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9823: loss = 0.6046 (0.241 sec/step)\n",
            "I0802 19:58:31.778709 140624834570112 learning.py:512] global step 9823: loss = 0.6046 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9824: loss = 0.7525 (0.232 sec/step)\n",
            "I0802 19:58:32.012556 140624834570112 learning.py:512] global step 9824: loss = 0.7525 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9825: loss = 0.5838 (0.235 sec/step)\n",
            "I0802 19:58:32.249404 140624834570112 learning.py:512] global step 9825: loss = 0.5838 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9826: loss = 0.5553 (0.238 sec/step)\n",
            "I0802 19:58:32.488729 140624834570112 learning.py:512] global step 9826: loss = 0.5553 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9827: loss = 0.6076 (0.245 sec/step)\n",
            "I0802 19:58:32.735132 140624834570112 learning.py:512] global step 9827: loss = 0.6076 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9828: loss = 0.7456 (0.237 sec/step)\n",
            "I0802 19:58:32.973726 140624834570112 learning.py:512] global step 9828: loss = 0.7456 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9829: loss = 0.6405 (0.248 sec/step)\n",
            "I0802 19:58:33.223574 140624834570112 learning.py:512] global step 9829: loss = 0.6405 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9830: loss = 0.8447 (0.226 sec/step)\n",
            "I0802 19:58:33.450532 140624834570112 learning.py:512] global step 9830: loss = 0.8447 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9831: loss = 0.8100 (0.240 sec/step)\n",
            "I0802 19:58:33.691848 140624834570112 learning.py:512] global step 9831: loss = 0.8100 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9832: loss = 0.6698 (0.249 sec/step)\n",
            "I0802 19:58:33.942018 140624834570112 learning.py:512] global step 9832: loss = 0.6698 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9833: loss = 0.7644 (0.234 sec/step)\n",
            "I0802 19:58:34.177342 140624834570112 learning.py:512] global step 9833: loss = 0.7644 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9834: loss = 0.7169 (0.249 sec/step)\n",
            "I0802 19:58:34.427950 140624834570112 learning.py:512] global step 9834: loss = 0.7169 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9835: loss = 0.6407 (0.222 sec/step)\n",
            "I0802 19:58:34.651755 140624834570112 learning.py:512] global step 9835: loss = 0.6407 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9836: loss = 0.6445 (0.236 sec/step)\n",
            "I0802 19:58:34.889308 140624834570112 learning.py:512] global step 9836: loss = 0.6445 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9837: loss = 0.8997 (0.245 sec/step)\n",
            "I0802 19:58:35.135794 140624834570112 learning.py:512] global step 9837: loss = 0.8997 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9838: loss = 0.6324 (0.228 sec/step)\n",
            "I0802 19:58:35.365503 140624834570112 learning.py:512] global step 9838: loss = 0.6324 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9839: loss = 0.9135 (0.236 sec/step)\n",
            "I0802 19:58:35.602748 140624834570112 learning.py:512] global step 9839: loss = 0.9135 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9840: loss = 0.6854 (0.235 sec/step)\n",
            "I0802 19:58:35.839166 140624834570112 learning.py:512] global step 9840: loss = 0.6854 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9841: loss = 0.6725 (0.247 sec/step)\n",
            "I0802 19:58:36.087394 140624834570112 learning.py:512] global step 9841: loss = 0.6725 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9842: loss = 0.6758 (0.248 sec/step)\n",
            "I0802 19:58:36.337080 140624834570112 learning.py:512] global step 9842: loss = 0.6758 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9843: loss = 0.7155 (0.251 sec/step)\n",
            "I0802 19:58:36.589075 140624834570112 learning.py:512] global step 9843: loss = 0.7155 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9844: loss = 0.7267 (0.240 sec/step)\n",
            "I0802 19:58:36.830831 140624834570112 learning.py:512] global step 9844: loss = 0.7267 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9845: loss = 0.7425 (0.242 sec/step)\n",
            "I0802 19:58:37.074465 140624834570112 learning.py:512] global step 9845: loss = 0.7425 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9846: loss = 0.6006 (0.235 sec/step)\n",
            "I0802 19:58:37.310889 140624834570112 learning.py:512] global step 9846: loss = 0.6006 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9847: loss = 0.6101 (0.241 sec/step)\n",
            "I0802 19:58:37.553008 140624834570112 learning.py:512] global step 9847: loss = 0.6101 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9848: loss = 0.7726 (0.233 sec/step)\n",
            "I0802 19:58:37.787926 140624834570112 learning.py:512] global step 9848: loss = 0.7726 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9849: loss = 0.5192 (0.245 sec/step)\n",
            "I0802 19:58:38.034816 140624834570112 learning.py:512] global step 9849: loss = 0.5192 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9850: loss = 0.5803 (0.231 sec/step)\n",
            "I0802 19:58:38.267546 140624834570112 learning.py:512] global step 9850: loss = 0.5803 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9851: loss = 0.6720 (0.239 sec/step)\n",
            "I0802 19:58:38.507640 140624834570112 learning.py:512] global step 9851: loss = 0.6720 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9852: loss = 0.6388 (0.249 sec/step)\n",
            "I0802 19:58:38.759748 140624834570112 learning.py:512] global step 9852: loss = 0.6388 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9853: loss = 0.7547 (0.256 sec/step)\n",
            "I0802 19:58:39.017775 140624834570112 learning.py:512] global step 9853: loss = 0.7547 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 9854: loss = 0.7008 (0.233 sec/step)\n",
            "I0802 19:58:39.251893 140624834570112 learning.py:512] global step 9854: loss = 0.7008 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9855: loss = 0.6729 (0.246 sec/step)\n",
            "I0802 19:58:39.499627 140624834570112 learning.py:512] global step 9855: loss = 0.6729 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9856: loss = 0.9115 (0.244 sec/step)\n",
            "I0802 19:58:39.744667 140624834570112 learning.py:512] global step 9856: loss = 0.9115 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9857: loss = 0.6899 (0.246 sec/step)\n",
            "I0802 19:58:39.992516 140624834570112 learning.py:512] global step 9857: loss = 0.6899 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9858: loss = 0.7576 (0.237 sec/step)\n",
            "I0802 19:58:40.231351 140624834570112 learning.py:512] global step 9858: loss = 0.7576 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9859: loss = 0.5544 (0.238 sec/step)\n",
            "I0802 19:58:40.471063 140624834570112 learning.py:512] global step 9859: loss = 0.5544 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9860: loss = 0.5653 (0.234 sec/step)\n",
            "I0802 19:58:40.706464 140624834570112 learning.py:512] global step 9860: loss = 0.5653 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9861: loss = 0.5538 (0.240 sec/step)\n",
            "I0802 19:58:40.947748 140624834570112 learning.py:512] global step 9861: loss = 0.5538 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9862: loss = 0.8736 (0.243 sec/step)\n",
            "I0802 19:58:41.192624 140624834570112 learning.py:512] global step 9862: loss = 0.8736 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9863: loss = 0.7823 (0.224 sec/step)\n",
            "I0802 19:58:41.418200 140624834570112 learning.py:512] global step 9863: loss = 0.7823 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9864: loss = 0.5991 (0.235 sec/step)\n",
            "I0802 19:58:41.654883 140624834570112 learning.py:512] global step 9864: loss = 0.5991 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9865: loss = 0.7702 (0.242 sec/step)\n",
            "I0802 19:58:41.897953 140624834570112 learning.py:512] global step 9865: loss = 0.7702 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9866: loss = 0.6808 (0.236 sec/step)\n",
            "I0802 19:58:42.135865 140624834570112 learning.py:512] global step 9866: loss = 0.6808 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9867: loss = 0.6129 (0.232 sec/step)\n",
            "I0802 19:58:42.369410 140624834570112 learning.py:512] global step 9867: loss = 0.6129 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9868: loss = 0.8405 (0.242 sec/step)\n",
            "I0802 19:58:42.612342 140624834570112 learning.py:512] global step 9868: loss = 0.8405 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9869: loss = 0.5610 (0.248 sec/step)\n",
            "I0802 19:58:42.862230 140624834570112 learning.py:512] global step 9869: loss = 0.5610 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9870: loss = 0.7052 (0.244 sec/step)\n",
            "I0802 19:58:43.107846 140624834570112 learning.py:512] global step 9870: loss = 0.7052 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9871: loss = 0.5578 (0.237 sec/step)\n",
            "I0802 19:58:43.346376 140624834570112 learning.py:512] global step 9871: loss = 0.5578 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9872: loss = 0.5766 (0.244 sec/step)\n",
            "I0802 19:58:43.592039 140624834570112 learning.py:512] global step 9872: loss = 0.5766 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9873: loss = 0.8153 (0.244 sec/step)\n",
            "I0802 19:58:43.837377 140624834570112 learning.py:512] global step 9873: loss = 0.8153 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9874: loss = 0.6606 (0.246 sec/step)\n",
            "I0802 19:58:44.084453 140624834570112 learning.py:512] global step 9874: loss = 0.6606 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9875: loss = 0.6668 (0.239 sec/step)\n",
            "I0802 19:58:44.325222 140624834570112 learning.py:512] global step 9875: loss = 0.6668 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9876: loss = 0.7909 (0.228 sec/step)\n",
            "I0802 19:58:44.554495 140624834570112 learning.py:512] global step 9876: loss = 0.7909 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9877: loss = 0.7716 (0.250 sec/step)\n",
            "I0802 19:58:44.805735 140624834570112 learning.py:512] global step 9877: loss = 0.7716 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9878: loss = 0.6189 (0.241 sec/step)\n",
            "I0802 19:58:45.048169 140624834570112 learning.py:512] global step 9878: loss = 0.6189 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9879: loss = 0.6200 (0.245 sec/step)\n",
            "I0802 19:58:45.294150 140624834570112 learning.py:512] global step 9879: loss = 0.6200 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9880: loss = 0.7147 (0.242 sec/step)\n",
            "I0802 19:58:45.537795 140624834570112 learning.py:512] global step 9880: loss = 0.7147 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9881: loss = 0.4959 (0.245 sec/step)\n",
            "I0802 19:58:45.784348 140624834570112 learning.py:512] global step 9881: loss = 0.4959 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9882: loss = 0.5606 (0.233 sec/step)\n",
            "I0802 19:58:46.020658 140624834570112 learning.py:512] global step 9882: loss = 0.5606 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9883: loss = 0.9257 (0.230 sec/step)\n",
            "I0802 19:58:46.251890 140624834570112 learning.py:512] global step 9883: loss = 0.9257 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9884: loss = 0.8293 (0.245 sec/step)\n",
            "I0802 19:58:46.498830 140624834570112 learning.py:512] global step 9884: loss = 0.8293 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9885: loss = 0.7826 (0.236 sec/step)\n",
            "I0802 19:58:46.736604 140624834570112 learning.py:512] global step 9885: loss = 0.7826 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9886: loss = 0.6206 (0.237 sec/step)\n",
            "I0802 19:58:46.975022 140624834570112 learning.py:512] global step 9886: loss = 0.6206 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9887: loss = 0.5167 (0.246 sec/step)\n",
            "I0802 19:58:47.222124 140624834570112 learning.py:512] global step 9887: loss = 0.5167 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9888: loss = 0.7794 (0.225 sec/step)\n",
            "I0802 19:58:47.448635 140624834570112 learning.py:512] global step 9888: loss = 0.7794 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9889: loss = 0.8002 (0.241 sec/step)\n",
            "I0802 19:58:47.691352 140624834570112 learning.py:512] global step 9889: loss = 0.8002 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9890: loss = 0.7238 (0.245 sec/step)\n",
            "I0802 19:58:47.938385 140624834570112 learning.py:512] global step 9890: loss = 0.7238 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9891: loss = 0.6729 (0.239 sec/step)\n",
            "I0802 19:58:48.179250 140624834570112 learning.py:512] global step 9891: loss = 0.6729 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9892: loss = 0.8472 (0.229 sec/step)\n",
            "I0802 19:58:48.409569 140624834570112 learning.py:512] global step 9892: loss = 0.8472 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9893: loss = 0.6537 (0.231 sec/step)\n",
            "I0802 19:58:48.643007 140624834570112 learning.py:512] global step 9893: loss = 0.6537 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9894: loss = 0.5023 (0.252 sec/step)\n",
            "I0802 19:58:48.896871 140624834570112 learning.py:512] global step 9894: loss = 0.5023 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9895: loss = 0.6479 (0.240 sec/step)\n",
            "I0802 19:58:49.138224 140624834570112 learning.py:512] global step 9895: loss = 0.6479 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9896: loss = 0.6256 (0.239 sec/step)\n",
            "I0802 19:58:49.378636 140624834570112 learning.py:512] global step 9896: loss = 0.6256 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9897: loss = 0.7054 (0.245 sec/step)\n",
            "I0802 19:58:49.625047 140624834570112 learning.py:512] global step 9897: loss = 0.7054 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9898: loss = 0.7041 (0.244 sec/step)\n",
            "I0802 19:58:49.870901 140624834570112 learning.py:512] global step 9898: loss = 0.7041 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9899: loss = 0.7634 (0.242 sec/step)\n",
            "I0802 19:58:50.113988 140624834570112 learning.py:512] global step 9899: loss = 0.7634 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9900: loss = 0.6213 (0.245 sec/step)\n",
            "I0802 19:58:50.360385 140624834570112 learning.py:512] global step 9900: loss = 0.6213 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9901: loss = 0.8067 (0.252 sec/step)\n",
            "I0802 19:58:50.613484 140624834570112 learning.py:512] global step 9901: loss = 0.8067 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9902: loss = 0.8540 (0.229 sec/step)\n",
            "I0802 19:58:50.843445 140624834570112 learning.py:512] global step 9902: loss = 0.8540 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9903: loss = 0.7890 (0.230 sec/step)\n",
            "I0802 19:58:51.075252 140624834570112 learning.py:512] global step 9903: loss = 0.7890 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9904: loss = 0.7570 (0.227 sec/step)\n",
            "I0802 19:58:51.303219 140624834570112 learning.py:512] global step 9904: loss = 0.7570 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9905: loss = 0.5938 (0.243 sec/step)\n",
            "I0802 19:58:51.547756 140624834570112 learning.py:512] global step 9905: loss = 0.5938 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9906: loss = 0.8438 (0.257 sec/step)\n",
            "I0802 19:58:51.806408 140624834570112 learning.py:512] global step 9906: loss = 0.8438 (0.257 sec/step)\n",
            "INFO:tensorflow:global step 9907: loss = 0.7188 (0.244 sec/step)\n",
            "I0802 19:58:52.051475 140624834570112 learning.py:512] global step 9907: loss = 0.7188 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9908: loss = 0.6628 (0.248 sec/step)\n",
            "I0802 19:58:52.301399 140624834570112 learning.py:512] global step 9908: loss = 0.6628 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9909: loss = 0.5535 (0.250 sec/step)\n",
            "I0802 19:58:52.552468 140624834570112 learning.py:512] global step 9909: loss = 0.5535 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9910: loss = 0.7882 (0.225 sec/step)\n",
            "I0802 19:58:52.778815 140624834570112 learning.py:512] global step 9910: loss = 0.7882 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9911: loss = 0.5540 (0.236 sec/step)\n",
            "I0802 19:58:53.016258 140624834570112 learning.py:512] global step 9911: loss = 0.5540 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9912: loss = 0.6651 (0.247 sec/step)\n",
            "I0802 19:58:53.264432 140624834570112 learning.py:512] global step 9912: loss = 0.6651 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9913: loss = 0.6648 (0.243 sec/step)\n",
            "I0802 19:58:53.508675 140624834570112 learning.py:512] global step 9913: loss = 0.6648 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9914: loss = 0.6354 (0.245 sec/step)\n",
            "I0802 19:58:53.755361 140624834570112 learning.py:512] global step 9914: loss = 0.6354 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9915: loss = 0.5571 (0.244 sec/step)\n",
            "I0802 19:58:54.000701 140624834570112 learning.py:512] global step 9915: loss = 0.5571 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9916: loss = 0.5852 (0.249 sec/step)\n",
            "I0802 19:58:54.250977 140624834570112 learning.py:512] global step 9916: loss = 0.5852 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9917: loss = 0.5699 (0.248 sec/step)\n",
            "I0802 19:58:54.500760 140624834570112 learning.py:512] global step 9917: loss = 0.5699 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9918: loss = 1.0080 (0.242 sec/step)\n",
            "I0802 19:58:54.744495 140624834570112 learning.py:512] global step 9918: loss = 1.0080 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9919: loss = 0.5834 (0.230 sec/step)\n",
            "I0802 19:58:54.976399 140624834570112 learning.py:512] global step 9919: loss = 0.5834 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9920: loss = 0.5292 (0.233 sec/step)\n",
            "I0802 19:58:55.211301 140624834570112 learning.py:512] global step 9920: loss = 0.5292 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9921: loss = 0.7524 (0.244 sec/step)\n",
            "I0802 19:58:55.456455 140624834570112 learning.py:512] global step 9921: loss = 0.7524 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9922: loss = 0.6256 (0.236 sec/step)\n",
            "I0802 19:58:55.693902 140624834570112 learning.py:512] global step 9922: loss = 0.6256 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9923: loss = 0.7985 (0.238 sec/step)\n",
            "I0802 19:58:55.932869 140624834570112 learning.py:512] global step 9923: loss = 0.7985 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9924: loss = 0.6573 (0.243 sec/step)\n",
            "I0802 19:58:56.177703 140624834570112 learning.py:512] global step 9924: loss = 0.6573 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9925: loss = 0.6693 (0.242 sec/step)\n",
            "I0802 19:58:56.421542 140624834570112 learning.py:512] global step 9925: loss = 0.6693 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9926: loss = 0.5461 (0.242 sec/step)\n",
            "I0802 19:58:56.665448 140624834570112 learning.py:512] global step 9926: loss = 0.5461 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9927: loss = 0.9455 (0.242 sec/step)\n",
            "I0802 19:58:56.908663 140624834570112 learning.py:512] global step 9927: loss = 0.9455 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9928: loss = 0.8125 (0.243 sec/step)\n",
            "I0802 19:58:57.153419 140624834570112 learning.py:512] global step 9928: loss = 0.8125 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9929: loss = 0.6685 (0.232 sec/step)\n",
            "I0802 19:58:57.387638 140624834570112 learning.py:512] global step 9929: loss = 0.6685 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9930: loss = 1.0001 (0.240 sec/step)\n",
            "I0802 19:58:57.629298 140624834570112 learning.py:512] global step 9930: loss = 1.0001 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9931: loss = 0.7870 (0.236 sec/step)\n",
            "I0802 19:58:57.867238 140624834570112 learning.py:512] global step 9931: loss = 0.7870 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9932: loss = 0.7191 (0.225 sec/step)\n",
            "I0802 19:58:58.093803 140624834570112 learning.py:512] global step 9932: loss = 0.7191 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9933: loss = 0.8722 (0.231 sec/step)\n",
            "I0802 19:58:58.326504 140624834570112 learning.py:512] global step 9933: loss = 0.8722 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9934: loss = 0.7584 (0.242 sec/step)\n",
            "I0802 19:58:58.569792 140624834570112 learning.py:512] global step 9934: loss = 0.7584 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9935: loss = 0.8589 (0.236 sec/step)\n",
            "I0802 19:58:58.807485 140624834570112 learning.py:512] global step 9935: loss = 0.8589 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9936: loss = 0.6195 (0.245 sec/step)\n",
            "I0802 19:58:59.053889 140624834570112 learning.py:512] global step 9936: loss = 0.6195 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9937: loss = 0.6632 (0.230 sec/step)\n",
            "I0802 19:58:59.285459 140624834570112 learning.py:512] global step 9937: loss = 0.6632 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9938: loss = 0.7880 (0.243 sec/step)\n",
            "I0802 19:58:59.530008 140624834570112 learning.py:512] global step 9938: loss = 0.7880 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9939: loss = 0.5007 (0.236 sec/step)\n",
            "I0802 19:58:59.767623 140624834570112 learning.py:512] global step 9939: loss = 0.5007 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9940: loss = 0.5735 (0.245 sec/step)\n",
            "I0802 19:59:00.014410 140624834570112 learning.py:512] global step 9940: loss = 0.5735 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9941: loss = 0.7631 (0.241 sec/step)\n",
            "I0802 19:59:00.257117 140624834570112 learning.py:512] global step 9941: loss = 0.7631 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9942: loss = 0.7408 (0.249 sec/step)\n",
            "I0802 19:59:00.508152 140624834570112 learning.py:512] global step 9942: loss = 0.7408 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9943: loss = 0.9805 (0.245 sec/step)\n",
            "I0802 19:59:00.754329 140624834570112 learning.py:512] global step 9943: loss = 0.9805 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9944: loss = 0.5418 (0.231 sec/step)\n",
            "I0802 19:59:00.986647 140624834570112 learning.py:512] global step 9944: loss = 0.5418 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9945: loss = 0.5773 (0.239 sec/step)\n",
            "I0802 19:59:01.227524 140624834570112 learning.py:512] global step 9945: loss = 0.5773 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9946: loss = 0.7132 (0.230 sec/step)\n",
            "I0802 19:59:01.458787 140624834570112 learning.py:512] global step 9946: loss = 0.7132 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9947: loss = 0.6765 (0.241 sec/step)\n",
            "I0802 19:59:01.701621 140624834570112 learning.py:512] global step 9947: loss = 0.6765 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9948: loss = 0.8852 (0.254 sec/step)\n",
            "I0802 19:59:01.956865 140624834570112 learning.py:512] global step 9948: loss = 0.8852 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 9949: loss = 0.7290 (0.238 sec/step)\n",
            "I0802 19:59:02.196312 140624834570112 learning.py:512] global step 9949: loss = 0.7290 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9950: loss = 0.7239 (0.245 sec/step)\n",
            "I0802 19:59:02.443074 140624834570112 learning.py:512] global step 9950: loss = 0.7239 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9951: loss = 0.6083 (0.237 sec/step)\n",
            "I0802 19:59:02.681531 140624834570112 learning.py:512] global step 9951: loss = 0.6083 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9952: loss = 0.5753 (0.253 sec/step)\n",
            "I0802 19:59:02.935830 140624834570112 learning.py:512] global step 9952: loss = 0.5753 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9953: loss = 1.0743 (0.247 sec/step)\n",
            "I0802 19:59:03.184764 140624834570112 learning.py:512] global step 9953: loss = 1.0743 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9954: loss = 0.5417 (0.242 sec/step)\n",
            "I0802 19:59:03.427846 140624834570112 learning.py:512] global step 9954: loss = 0.5417 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9955: loss = 0.7559 (0.233 sec/step)\n",
            "I0802 19:59:03.662594 140624834570112 learning.py:512] global step 9955: loss = 0.7559 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9956: loss = 0.7382 (0.255 sec/step)\n",
            "I0802 19:59:03.919126 140624834570112 learning.py:512] global step 9956: loss = 0.7382 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 9957: loss = 0.7197 (0.253 sec/step)\n",
            "I0802 19:59:04.173877 140624834570112 learning.py:512] global step 9957: loss = 0.7197 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9958: loss = 0.5571 (0.242 sec/step)\n",
            "I0802 19:59:04.417116 140624834570112 learning.py:512] global step 9958: loss = 0.5571 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9959: loss = 0.6537 (0.251 sec/step)\n",
            "I0802 19:59:04.669304 140624834570112 learning.py:512] global step 9959: loss = 0.6537 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9960: loss = 0.8334 (0.246 sec/step)\n",
            "I0802 19:59:04.917331 140624834570112 learning.py:512] global step 9960: loss = 0.8334 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9961: loss = 0.9679 (0.245 sec/step)\n",
            "I0802 19:59:05.164306 140624834570112 learning.py:512] global step 9961: loss = 0.9679 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9962: loss = 0.5654 (0.228 sec/step)\n",
            "I0802 19:59:05.393265 140624834570112 learning.py:512] global step 9962: loss = 0.5654 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9963: loss = 0.7673 (0.235 sec/step)\n",
            "I0802 19:59:05.629457 140624834570112 learning.py:512] global step 9963: loss = 0.7673 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9964: loss = 0.7542 (0.250 sec/step)\n",
            "I0802 19:59:05.880867 140624834570112 learning.py:512] global step 9964: loss = 0.7542 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9965: loss = 0.7307 (0.244 sec/step)\n",
            "I0802 19:59:06.126403 140624834570112 learning.py:512] global step 9965: loss = 0.7307 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9966: loss = 0.7406 (0.250 sec/step)\n",
            "I0802 19:59:06.378114 140624834570112 learning.py:512] global step 9966: loss = 0.7406 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9967: loss = 0.6127 (0.247 sec/step)\n",
            "I0802 19:59:06.626273 140624834570112 learning.py:512] global step 9967: loss = 0.6127 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9968: loss = 0.7555 (0.249 sec/step)\n",
            "I0802 19:59:06.877206 140624834570112 learning.py:512] global step 9968: loss = 0.7555 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9969: loss = 0.7237 (0.242 sec/step)\n",
            "I0802 19:59:07.120938 140624834570112 learning.py:512] global step 9969: loss = 0.7237 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9970: loss = 0.6109 (0.234 sec/step)\n",
            "I0802 19:59:07.355952 140624834570112 learning.py:512] global step 9970: loss = 0.6109 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9971: loss = 0.7762 (0.248 sec/step)\n",
            "I0802 19:59:07.605633 140624834570112 learning.py:512] global step 9971: loss = 0.7762 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9972: loss = 0.7284 (0.233 sec/step)\n",
            "I0802 19:59:07.840287 140624834570112 learning.py:512] global step 9972: loss = 0.7284 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9973: loss = 0.5951 (0.252 sec/step)\n",
            "I0802 19:59:08.094022 140624834570112 learning.py:512] global step 9973: loss = 0.5951 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9974: loss = 0.6631 (0.248 sec/step)\n",
            "I0802 19:59:08.343568 140624834570112 learning.py:512] global step 9974: loss = 0.6631 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9975: loss = 0.6195 (0.238 sec/step)\n",
            "I0802 19:59:08.582739 140624834570112 learning.py:512] global step 9975: loss = 0.6195 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9976: loss = 0.7187 (0.228 sec/step)\n",
            "I0802 19:59:08.812656 140624834570112 learning.py:512] global step 9976: loss = 0.7187 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9977: loss = 0.6950 (0.233 sec/step)\n",
            "I0802 19:59:09.046700 140624834570112 learning.py:512] global step 9977: loss = 0.6950 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9978: loss = 0.7268 (0.247 sec/step)\n",
            "I0802 19:59:09.295301 140624834570112 learning.py:512] global step 9978: loss = 0.7268 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9979: loss = 0.6936 (0.242 sec/step)\n",
            "I0802 19:59:09.538912 140624834570112 learning.py:512] global step 9979: loss = 0.6936 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9980: loss = 0.6882 (0.252 sec/step)\n",
            "I0802 19:59:09.792579 140624834570112 learning.py:512] global step 9980: loss = 0.6882 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9981: loss = 0.7976 (0.251 sec/step)\n",
            "I0802 19:59:10.044910 140624834570112 learning.py:512] global step 9981: loss = 0.7976 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9982: loss = 0.6936 (0.248 sec/step)\n",
            "I0802 19:59:10.294743 140624834570112 learning.py:512] global step 9982: loss = 0.6936 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9983: loss = 0.5646 (0.243 sec/step)\n",
            "I0802 19:59:10.539342 140624834570112 learning.py:512] global step 9983: loss = 0.5646 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9984: loss = 0.6524 (0.243 sec/step)\n",
            "I0802 19:59:10.784124 140624834570112 learning.py:512] global step 9984: loss = 0.6524 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9985: loss = 0.8300 (0.235 sec/step)\n",
            "I0802 19:59:11.020679 140624834570112 learning.py:512] global step 9985: loss = 0.8300 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9986: loss = 0.6026 (0.244 sec/step)\n",
            "I0802 19:59:11.267081 140624834570112 learning.py:512] global step 9986: loss = 0.6026 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9987: loss = 0.8776 (0.249 sec/step)\n",
            "I0802 19:59:11.517240 140624834570112 learning.py:512] global step 9987: loss = 0.8776 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9988: loss = 0.5980 (0.242 sec/step)\n",
            "I0802 19:59:11.760601 140624834570112 learning.py:512] global step 9988: loss = 0.5980 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9989: loss = 0.5476 (0.250 sec/step)\n",
            "I0802 19:59:12.012053 140624834570112 learning.py:512] global step 9989: loss = 0.5476 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9990: loss = 0.7461 (0.244 sec/step)\n",
            "I0802 19:59:12.257279 140624834570112 learning.py:512] global step 9990: loss = 0.7461 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9991: loss = 0.5697 (0.245 sec/step)\n",
            "I0802 19:59:12.503892 140624834570112 learning.py:512] global step 9991: loss = 0.5697 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9992: loss = 0.7361 (0.244 sec/step)\n",
            "I0802 19:59:12.750401 140624834570112 learning.py:512] global step 9992: loss = 0.7361 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9993: loss = 0.8811 (0.239 sec/step)\n",
            "I0802 19:59:12.990847 140624834570112 learning.py:512] global step 9993: loss = 0.8811 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9994: loss = 0.7923 (0.251 sec/step)\n",
            "I0802 19:59:13.243521 140624834570112 learning.py:512] global step 9994: loss = 0.7923 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9995: loss = 0.5979 (0.237 sec/step)\n",
            "I0802 19:59:13.482019 140624834570112 learning.py:512] global step 9995: loss = 0.5979 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9996: loss = 0.4467 (0.233 sec/step)\n",
            "I0802 19:59:13.716401 140624834570112 learning.py:512] global step 9996: loss = 0.4467 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9997: loss = 0.5982 (0.228 sec/step)\n",
            "I0802 19:59:13.946405 140624834570112 learning.py:512] global step 9997: loss = 0.5982 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9998: loss = 0.8169 (0.242 sec/step)\n",
            "I0802 19:59:14.190215 140624834570112 learning.py:512] global step 9998: loss = 0.8169 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9999: loss = 0.6079 (0.243 sec/step)\n",
            "I0802 19:59:14.434884 140624834570112 learning.py:512] global step 9999: loss = 0.6079 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 10000: loss = 0.9516 (0.244 sec/step)\n",
            "I0802 19:59:14.680003 140624834570112 learning.py:512] global step 10000: loss = 0.9516 (0.244 sec/step)\n",
            "INFO:tensorflow:Stopping Training.\n",
            "I0802 19:59:14.680889 140624834570112 learning.py:769] Stopping Training.\n",
            "INFO:tensorflow:Finished training! Saving model to disk.\n",
            "I0802 19:59:14.681160 140624834570112 learning.py:777] Finished training! Saving model to disk.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0802 19:59:15.246299 140624834570112 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n",
            "  warnings.warn(\"Attempting to use a closed FileWriter. \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmEqinlh76rC"
      },
      "source": [
        "Exporting Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fO4xnKenbfQK",
        "outputId": "89de33ea-2142-4de7-9a8e-c5fb58ca092a"
      },
      "source": [
        "#Export trained model \n",
        "%cd /root/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n",
        "!python /root/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=/root/models/ssd_mobilenet_v2_coco.config \\\n",
        "    --output_directory=/root/models/fine_tuned_model \\\n",
        "    --trained_checkpoint_prefix=/root/models/trained/model.ckpt-10000"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0802 19:59:22.380742 139863321806720 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 19:59:24.571809 139863321806720 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 19:59:24.613955 139863321806720 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 19:59:24.656203 139863321806720 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 19:59:24.694684 139863321806720 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 19:59:24.731013 139863321806720 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 19:59:24.765564 139863321806720 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/core/post_processing.py:601: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0802 19:59:25.015996 139863321806720 deprecation.py:323] From /root/models/research/object_detection/core/post_processing.py:601: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0802 19:59:25.333159 139863321806720 deprecation.py:323] From /root/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0802 19:59:25.336127 139863321806720 deprecation.py:323] From /root/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0802 19:59:25.336609 139863321806720 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "133 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/4.57m params)\n",
            "  BoxPredictor_0 (--/10.39k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/3.46k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (6, 6/6 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x576x6, 3.46k/3.46k params)\n",
            "  BoxPredictor_1 (--/46.12k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/15.37k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x1280x12, 15.36k/15.36k params)\n",
            "  BoxPredictor_2 (--/18.47k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/6.16k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x12, 6.14k/6.14k params)\n",
            "  BoxPredictor_3 (--/9.25k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_4 (--/9.25k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/3.08k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x12, 3.07k/3.07k params)\n",
            "  BoxPredictor_5 (--/4.64k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/1.55k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x12, 1.54k/1.54k params)\n",
            "  FeatureExtractor (--/4.48m params)\n",
            "    FeatureExtractor/MobilenetV2 (--/4.48m params)\n",
            "      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "133 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/13.71k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2021-08-02 19:59:27.187477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-08-02 19:59:27.214367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:27.214997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-02 19:59:27.215284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-02 19:59:27.217408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-02 19:59:27.219474: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-02 19:59:27.219824: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-02 19:59:27.226354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-02 19:59:27.227299: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-02 19:59:27.236308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-02 19:59:27.236445: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:27.237115: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:27.237644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-02 19:59:27.238091: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2021-08-02 19:59:27.243136: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000150000 Hz\n",
            "2021-08-02 19:59:27.243402: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56294dc92f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-08-02 19:59:27.243431: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-08-02 19:59:27.327644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:27.328586: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56294dc93100 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-08-02 19:59:27.328631: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2021-08-02 19:59:27.328865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:27.329564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-02 19:59:27.329647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-02 19:59:27.329669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-02 19:59:27.329683: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-02 19:59:27.329699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-02 19:59:27.329712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-02 19:59:27.329726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-02 19:59:27.329740: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-02 19:59:27.329816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:27.330438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:27.330998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-02 19:59:27.331089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-02 19:59:27.332329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-02 19:59:27.332381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-02 19:59:27.332391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-02 19:59:27.332602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:27.333345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:27.333911: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-08-02 19:59:27.333970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "INFO:tensorflow:Restoring parameters from /root/models/trained/model.ckpt-10000\n",
            "I0802 19:59:27.335644 139863321806720 saver.py:1284] Restoring parameters from /root/models/trained/model.ckpt-10000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0802 19:59:28.978587 139863321806720 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2021-08-02 19:59:29.478352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:29.479100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-02 19:59:29.479219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-02 19:59:29.479249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-02 19:59:29.479279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-02 19:59:29.479304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-02 19:59:29.479329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-02 19:59:29.479355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-02 19:59:29.479383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-02 19:59:29.479502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:29.480214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:29.480817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-02 19:59:29.480868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-02 19:59:29.480885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-02 19:59:29.480896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-02 19:59:29.481056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:29.481798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:29.482449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "INFO:tensorflow:Restoring parameters from /root/models/trained/model.ckpt-10000\n",
            "I0802 19:59:29.483792 139863321806720 saver.py:1284] Restoring parameters from /root/models/trained/model.ckpt-10000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0802 19:59:30.149032 139863321806720 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0802 19:59:30.149280 139863321806720 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 324 variables.\n",
            "I0802 19:59:30.505116 139863321806720 graph_util_impl.py:334] Froze 324 variables.\n",
            "INFO:tensorflow:Converted 324 variables to const ops.\n",
            "I0802 19:59:30.578782 139863321806720 graph_util_impl.py:394] Converted 324 variables to const ops.\n",
            "2021-08-02 19:59:30.709433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:30.710125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-02 19:59:30.710193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-02 19:59:30.710214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-02 19:59:30.710228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-02 19:59:30.710243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-02 19:59:30.710256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-02 19:59:30.710269: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-02 19:59:30.710283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-02 19:59:30.710347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:30.710898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:30.711463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-02 19:59:30.711499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-02 19:59:30.711517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-02 19:59:30.711524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-02 19:59:30.711606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:30.712191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 19:59:30.712744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15060 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0802 19:59:31.068392 139863321806720 deprecation.py:323] From /root/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0802 19:59:31.069123 139863321806720 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0802 19:59:31.069242 139863321806720 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /root/models/fine_tuned_model/saved_model/saved_model.pb\n",
            "I0802 19:59:31.314490 139863321806720 builder_impl.py:425] SavedModel written to: /root/models/fine_tuned_model/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to /root/models/fine_tuned_model/pipeline.config\n",
            "I0802 19:59:31.331862 139863321806720 config_util.py:254] Writing pipeline config file to /root/models/fine_tuned_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZA8XMKc8pCv"
      },
      "source": [
        "Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsAJxWRysFRe"
      },
      "source": [
        "#!cp -r  /root /content/drive/MyDrive/root_odometer_trained_longer"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM49socs3iAY"
      },
      "source": [
        "#save checkpoints \n",
        "#!cp -r  /root/models/trained  /content/drive/MyDrive/odo_trained_v2_140k "
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaWddm70sU4G"
      },
      "source": [
        "#save inference graph\n",
        "#!cp -r  /root/models/fine_tuned_model/frozen_inference_graph.pb /content/drive/MyDrive/frozen_inference_graph_odo_v2_2.pb"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQknj0c3TtJa"
      },
      "source": [
        "import pathlib\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L_sQ3JZdKen"
      },
      "source": [
        "# What model to download.\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = '/root/models/fine_tuned_model' + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = '/root/models/odometer/data/object-detection.pbtxt'\n",
        "\n",
        "NUM_CLASSES = 1\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cJ8FuN8U4r4"
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqEm90PKVe9t"
      },
      "source": [
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWE6RVQ1WamB"
      },
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sswn4gUEWcux"
      },
      "source": [
        "import pandas as pd\n",
        "dfs = pd.read_csv(\"/root/models/odometer/data/test_labels.csv\")\n",
        "file_names = dfs['filename']\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = '/root/models/Odometer_project/small_data/small_odometer_dataset'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, file_names[i]) for i in range(len(file_names)) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28qSav2rWmsG"
      },
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.1), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HzhjfGwtWqY0",
        "outputId": "0c8168dc-c801-485d-f132-f11377646b51"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import json\n",
        "from PIL import ImageFile, Image\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "columns = ['filename', 'box1_xmin','box1_ymin','box1_ymax','box1_xmax','box2_xmin','box2_ymin','box2_ymax','box2_xmax','box3_xmin','box3_ymin','box3_ymax','box3_xmax', 'box4_xmin','box4_ymin','box4_ymax','box4_xmax','box1_score','box2_score','box3_score','box4_score']\n",
        "N = range(len(file_names))\n",
        "print(N)\n",
        "df_ = pd.DataFrame(index=N,  columns=columns)\n",
        "df_ = df_.fillna(0) # with 0s rather than NaNs\n",
        "file_name = df_['filename']\n",
        "box1_xmin = df_['box1_xmin']\n",
        "box1_ymin = df_['box1_ymin']\n",
        "box1_ymax = df_['box1_ymax']\n",
        "box1_xmax = df_['box1_xmax']\n",
        "box2_xmin = df_['box2_xmin']\n",
        "box2_ymin = df_['box2_ymin']\n",
        "box2_ymax = df_['box2_ymax']\n",
        "box2_xmax = df_['box2_xmax']\n",
        "box3_xmin = df_['box3_xmin']\n",
        "box3_ymin = df_['box3_ymin']\n",
        "box3_ymax = df_['box3_ymax']\n",
        "box3_xmax = df_['box3_xmax']\n",
        "box4_xmin = df_['box4_xmin']\n",
        "box4_ymin = df_['box4_ymin']\n",
        "box4_ymax = df_['box4_ymax']\n",
        "box4_xmax = df_['box4_xmax']\n",
        "box1_score =df_['box1_score']\n",
        "box2_score =df_['box2_score']\n",
        "box3_score =df_['box3_score']\n",
        "box4_score =df_['box4_score']\n",
        "count = 0;\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  image = Image.open(image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "  boxs = output_dict['detection_boxes']\n",
        "  score = output_dict['detection_scores']\n",
        "  file_name[count] = image_path[34:]\n",
        "  box1_xmin[count] = float(boxs[0][0]) * 100\n",
        "  box1_ymin[count] = boxs[0][1] * 100\n",
        "  box1_ymax[count] = boxs[0][2] * 100 \n",
        "  box1_xmax[count] = boxs[0][3] * 100 \n",
        "  box2_xmin[count] = boxs[1][0] * 100 \n",
        "  box2_ymin[count] = boxs[1][1] * 100\n",
        "  box2_ymax[count] = boxs[1][2] * 100\n",
        "  box2_xmax[count] = boxs[1][3] * 100 \n",
        "  box3_xmin[count] = boxs[2][0] * 100\n",
        "  box3_ymin[count] = boxs[2][1] * 100\n",
        "  box3_ymax[count] = boxs[2][2] * 100\n",
        "  box3_xmax[count] = boxs[2][3] * 100\n",
        "  box4_xmin[count] = boxs[3][0] * 100\n",
        "  box4_ymin[count] = boxs[3][1] * 100\n",
        "  box4_ymax[count] = boxs[3][2] * 100\n",
        "  box4_xmax[count] = boxs[3][3] * 100\n",
        "  box1_score[count] = score[0] * 100\n",
        "  box2_score[count] = score[1] * 100\n",
        "  box3_score[count] = score[2] * 100\n",
        "  box4_score[count] = score[3] * 100\n",
        "  #print(box4_score)\n",
        "  count = count + 1;\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8, mask_alpha = .1, min_score_thresh = .05, max_boxes_to_draw = 1)\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  plt.imshow(image_np)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(0, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:53: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:66: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNuh4ZfS3idl"
      },
      "source": [
        "#for i in range(len(file_names)):\n",
        " # df_['filename'][i] = file_names[i]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I3OItKMByK8"
      },
      "source": [
        "# create csv file with test results for screen detection\n",
        "compression_opts = dict(method='zip',\n",
        "                        archive_name='odometer_small.csv') \n",
        "df_.to_csv('odometer_small.zip', index=False,\n",
        "          compression=compression_opts) "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FFc033D9ns0",
        "outputId": "26143271-21fe-42ae-a357-8497e8c08b78"
      },
      "source": [
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  odometer_small.zip\n",
            "  inflating: odometer_small.csv      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azs4cYlx9_N-"
      },
      "source": [
        "### DIGIT DETECTION SECTION "
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qgph0_bA-BTY",
        "outputId": "1ac585b0-94c7-4d42-8c01-73ea1c3fd7e9"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib\n",
        "import tarfile\n",
        "from requests import get\n",
        "source = '/root/models/Odometer_project/character'\n",
        "destination = '/root/models/'\n",
        "shutil.move('/root/models/Odometer_project/character',  '/root/models/') "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/models/character'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_tSRWov-M0O"
      },
      "source": [
        "#create train / test datasets\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/root/models/Odometer_project/small_data/Character_small_dataset.csv')\n",
        "#df['split'] = np.random.randn(df.shape[0], 1)\n",
        "msk = np.random.rand(len(df)) <= 0.85\n",
        "\n",
        "train = df[msk]\n",
        "test = df[~msk]\n",
        "train = train.reset_index(drop=True)\n",
        "test = test.reset_index(drop=True)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NY2AhRjAsuK",
        "outputId": "f2d8df19-cda0-498c-8383-aeff7b115263"
      },
      "source": [
        "%cd /root"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KxIukaL-u1e"
      },
      "source": [
        "compression_opts = dict(method='zip',\n",
        "                        archive_name='train_1.csv') \n",
        "train.to_csv('train_1.zip', index=False,\n",
        "          compression=compression_opts) \n",
        "compression_opts = dict(method='zip',\n",
        "                        archive_name='test_1.csv') \n",
        "test.to_csv('test_1.zip', index=False,\n",
        "             compression=compression_opts) "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Hmt_1Pu-ygk",
        "outputId": "acf87e5d-3634-4290-e827-248f9b7656e7"
      },
      "source": [
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  test_1.zip\n",
            "  inflating: test_1.csv              \n",
            "\n",
            "Archive:  train_1.zip\n",
            "  inflating: train_1.csv             \n",
            "\n",
            "2 archives were successfully processed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLxeEyZSAlxX",
        "outputId": "84f6bd08-b1d3-48e4-c439-363c2d9dcdff"
      },
      "source": [
        "ls"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mmodels\u001b[0m/  test_1.csv  train_1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3DD4wY7-y8X"
      },
      "source": [
        "!cp -r /root/test_1.csv /root/models/character/data/test_labels.csv"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt2vyf7U-17c"
      },
      "source": [
        "!cp -r /root/train_1.csv /root/models/character/data/train_labels.csv"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC1_qFJX-7ia"
      },
      "source": [
        "from PIL import Image\n",
        "import json\n",
        "from PIL import ImageFile, Image\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S8oi0Mi_aYH"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P9mqKMD_c1a",
        "outputId": "0e9eb05c-eede-4c62-e297-398bb74f3802"
      },
      "source": [
        "%cd /root/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n",
        "\"\"\"\n",
        "Usage:\n",
        "  # From tensorflow/models/\n",
        "  # Create train data:\n",
        "  python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record\n",
        "\n",
        "  # Create test data:\n",
        "  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record\n",
        "\"\"\"\n",
        "%cd /root/models/character/tfrecord\n",
        "!python generate_tfrecord.py --csv_input=/root/models/character/data/train_labels.csv  --output_path=train.record --image_dir=/root/models/Odometer_project/small_data/small_cropped_images_bicubic_result_sharpen\n",
        "!python generate_tfrecord.py --csv_input=/root/models/character/data/test_labels.csv  --output_path=train.record --image_dir=/root/models/Odometer_project/small_data/small_cropped_images_bicubic_result_sharpen\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n",
            "/root/models/character/tfrecord\n",
            "WARNING:tensorflow:From generate_tfrecord.py:132: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:118: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0802 19:59:39.312452 140165439756160 module_wrapper.py:139] From generate_tfrecord.py:118: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:77: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0802 19:59:39.318762 140165439756160 module_wrapper.py:139] From generate_tfrecord.py:77: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /root/models/character/tfrecord/train.record\n",
            "WARNING:tensorflow:From generate_tfrecord.py:132: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:118: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0802 19:59:41.449229 140427819550592 module_wrapper.py:139] From generate_tfrecord.py:118: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:77: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0802 19:59:41.454772 140427819550592 module_wrapper.py:139] From generate_tfrecord.py:77: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /root/models/character/tfrecord/train.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JQbIUTbBCXC",
        "outputId": "f28d8ef1-6d17-4ad0-b229-04fd9c234c97"
      },
      "source": [
        "%cd /root/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n",
        "\n",
        "# Edit Pipeline \n",
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "from google.protobuf import text_format\n",
        "from object_detection.protos import pipeline_pb2\n",
        "\n",
        "pipeline = pipeline_pb2.TrainEvalPipelineConfig()                                                                                                                                                                                                          \n",
        "config_path = '/root/models/ssd_mobilenet_v2_coco.config'\n",
        "\n",
        "with tf.gfile.GFile( config_path, \"r\") as f:                                                                                                                                                                                                                     \n",
        "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
        "    text_format.Merge(proto_str, pipeline)\n",
        "\n",
        "pipeline.train_input_reader.tf_record_input_reader.input_path[:] = ['/root/models/character/tfrecord/train.record'] \n",
        "pipeline.train_input_reader.label_map_path = '/root/models/character/data/object-detection.pbtxt'\n",
        "pipeline.eval_input_reader[0].tf_record_input_reader.input_path[:] = ['/root/models/character/tfrecord/test.record'] \n",
        "pipeline.eval_input_reader[0].label_map_path = '/root/models/character/data/object-detection.pbtxt'\n",
        "pipeline.train_config.fine_tune_checkpoint = '/root/models/pretrained_model/model.ckpt'\n",
        "pipeline.train_config.num_steps = 10000\n",
        "pipeline.model.ssd.num_classes = 11\n",
        "pipeline.eval_config.num_examples = 16640\n",
        "\n",
        "config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        \n",
        "with tf.gfile.Open( config_path, \"wb\") as f:                                                                                                                                                                                                                       \n",
        "    f.write(config_text)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZaDPmNeBImd",
        "outputId": "d741aa84-6093-41ea-d688-8d841e85d089"
      },
      "source": [
        "# Change into the models directory\n",
        "%cd /root/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n",
        "\n",
        "# Begin training\n",
        "!python /root/models/research/object_detection/legacy/train.py \\\n",
        "    --logtostderr \\\n",
        "    --train_dir=/root/models/trained_2 \\\n",
        "    --pipeline_config_path=/root/models/ssd_mobilenet_v2_coco.config\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "INFO:tensorflow:global step 7517: loss = 0.7801 (0.236 sec/step)\n",
            "I0802 20:33:01.788806 139820296341376 learning.py:512] global step 7517: loss = 0.7801 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7518: loss = 0.8985 (0.236 sec/step)\n",
            "I0802 20:33:02.026754 139820296341376 learning.py:512] global step 7518: loss = 0.8985 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7519: loss = 0.9038 (0.246 sec/step)\n",
            "I0802 20:33:02.274887 139820296341376 learning.py:512] global step 7519: loss = 0.9038 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7520: loss = 0.7310 (0.224 sec/step)\n",
            "I0802 20:33:02.500606 139820296341376 learning.py:512] global step 7520: loss = 0.7310 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7521: loss = 1.0453 (0.231 sec/step)\n",
            "I0802 20:33:02.733130 139820296341376 learning.py:512] global step 7521: loss = 1.0453 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7522: loss = 0.9531 (0.232 sec/step)\n",
            "I0802 20:33:02.966732 139820296341376 learning.py:512] global step 7522: loss = 0.9531 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7523: loss = 0.9662 (0.239 sec/step)\n",
            "I0802 20:33:03.207664 139820296341376 learning.py:512] global step 7523: loss = 0.9662 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7524: loss = 1.0557 (0.224 sec/step)\n",
            "I0802 20:33:03.433480 139820296341376 learning.py:512] global step 7524: loss = 1.0557 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7525: loss = 0.7466 (0.238 sec/step)\n",
            "I0802 20:33:03.673092 139820296341376 learning.py:512] global step 7525: loss = 0.7466 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7526: loss = 1.0902 (0.243 sec/step)\n",
            "I0802 20:33:03.917618 139820296341376 learning.py:512] global step 7526: loss = 1.0902 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7527: loss = 1.0916 (0.224 sec/step)\n",
            "I0802 20:33:04.142945 139820296341376 learning.py:512] global step 7527: loss = 1.0916 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7528: loss = 1.0016 (0.244 sec/step)\n",
            "I0802 20:33:04.388883 139820296341376 learning.py:512] global step 7528: loss = 1.0016 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7529: loss = 1.0112 (0.242 sec/step)\n",
            "I0802 20:33:04.632257 139820296341376 learning.py:512] global step 7529: loss = 1.0112 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7530: loss = 1.1907 (0.236 sec/step)\n",
            "I0802 20:33:04.869240 139820296341376 learning.py:512] global step 7530: loss = 1.1907 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7531: loss = 1.2694 (0.243 sec/step)\n",
            "I0802 20:33:05.113733 139820296341376 learning.py:512] global step 7531: loss = 1.2694 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7532: loss = 0.8191 (0.235 sec/step)\n",
            "I0802 20:33:05.350149 139820296341376 learning.py:512] global step 7532: loss = 0.8191 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7533: loss = 0.7395 (0.237 sec/step)\n",
            "I0802 20:33:05.588299 139820296341376 learning.py:512] global step 7533: loss = 0.7395 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7534: loss = 0.9318 (0.236 sec/step)\n",
            "I0802 20:33:05.826493 139820296341376 learning.py:512] global step 7534: loss = 0.9318 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7535: loss = 1.0776 (0.235 sec/step)\n",
            "I0802 20:33:06.062855 139820296341376 learning.py:512] global step 7535: loss = 1.0776 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7536: loss = 0.9868 (0.235 sec/step)\n",
            "I0802 20:33:06.299807 139820296341376 learning.py:512] global step 7536: loss = 0.9868 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7537: loss = 0.9622 (0.243 sec/step)\n",
            "I0802 20:33:06.543998 139820296341376 learning.py:512] global step 7537: loss = 0.9622 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7538: loss = 0.8752 (0.238 sec/step)\n",
            "I0802 20:33:06.783746 139820296341376 learning.py:512] global step 7538: loss = 0.8752 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7539: loss = 1.1246 (0.236 sec/step)\n",
            "I0802 20:33:07.022679 139820296341376 learning.py:512] global step 7539: loss = 1.1246 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7540: loss = 1.1045 (0.242 sec/step)\n",
            "I0802 20:33:07.266257 139820296341376 learning.py:512] global step 7540: loss = 1.1045 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7541: loss = 0.6670 (0.237 sec/step)\n",
            "I0802 20:33:07.504545 139820296341376 learning.py:512] global step 7541: loss = 0.6670 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7542: loss = 0.8979 (0.244 sec/step)\n",
            "I0802 20:33:07.750181 139820296341376 learning.py:512] global step 7542: loss = 0.8979 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7543: loss = 0.9572 (0.244 sec/step)\n",
            "I0802 20:33:07.996050 139820296341376 learning.py:512] global step 7543: loss = 0.9572 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7544: loss = 0.8257 (0.228 sec/step)\n",
            "I0802 20:33:08.225183 139820296341376 learning.py:512] global step 7544: loss = 0.8257 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7545: loss = 0.8802 (0.223 sec/step)\n",
            "I0802 20:33:08.449741 139820296341376 learning.py:512] global step 7545: loss = 0.8802 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 7546: loss = 1.0555 (0.238 sec/step)\n",
            "I0802 20:33:08.689744 139820296341376 learning.py:512] global step 7546: loss = 1.0555 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7547: loss = 0.8208 (0.248 sec/step)\n",
            "I0802 20:33:08.939589 139820296341376 learning.py:512] global step 7547: loss = 0.8208 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7548: loss = 1.0120 (0.256 sec/step)\n",
            "I0802 20:33:09.197408 139820296341376 learning.py:512] global step 7548: loss = 1.0120 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 7549: loss = 0.8347 (0.240 sec/step)\n",
            "I0802 20:33:09.438628 139820296341376 learning.py:512] global step 7549: loss = 0.8347 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7550: loss = 1.0913 (0.240 sec/step)\n",
            "I0802 20:33:09.680739 139820296341376 learning.py:512] global step 7550: loss = 1.0913 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7551: loss = 0.8881 (0.236 sec/step)\n",
            "I0802 20:33:09.918501 139820296341376 learning.py:512] global step 7551: loss = 0.8881 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7552: loss = 1.0413 (0.230 sec/step)\n",
            "I0802 20:33:10.150547 139820296341376 learning.py:512] global step 7552: loss = 1.0413 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7553: loss = 0.8748 (0.243 sec/step)\n",
            "I0802 20:33:10.395373 139820296341376 learning.py:512] global step 7553: loss = 0.8748 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7554: loss = 0.8841 (0.232 sec/step)\n",
            "I0802 20:33:10.629324 139820296341376 learning.py:512] global step 7554: loss = 0.8841 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7555: loss = 0.8188 (0.242 sec/step)\n",
            "I0802 20:33:10.873296 139820296341376 learning.py:512] global step 7555: loss = 0.8188 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7556: loss = 0.8700 (0.237 sec/step)\n",
            "I0802 20:33:11.111776 139820296341376 learning.py:512] global step 7556: loss = 0.8700 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7557: loss = 0.7886 (0.243 sec/step)\n",
            "I0802 20:33:11.356285 139820296341376 learning.py:512] global step 7557: loss = 0.7886 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7558: loss = 1.0004 (0.244 sec/step)\n",
            "I0802 20:33:11.603914 139820296341376 learning.py:512] global step 7558: loss = 1.0004 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7559: loss = 0.8476 (0.240 sec/step)\n",
            "I0802 20:33:11.845396 139820296341376 learning.py:512] global step 7559: loss = 0.8476 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7560: loss = 0.9201 (0.237 sec/step)\n",
            "I0802 20:33:12.084135 139820296341376 learning.py:512] global step 7560: loss = 0.9201 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7561: loss = 0.7234 (0.223 sec/step)\n",
            "I0802 20:33:12.308291 139820296341376 learning.py:512] global step 7561: loss = 0.7234 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 7562: loss = 0.6410 (0.231 sec/step)\n",
            "I0802 20:33:12.540681 139820296341376 learning.py:512] global step 7562: loss = 0.6410 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7563: loss = 1.0604 (0.239 sec/step)\n",
            "I0802 20:33:12.781315 139820296341376 learning.py:512] global step 7563: loss = 1.0604 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7564: loss = 1.0191 (0.230 sec/step)\n",
            "I0802 20:33:13.012325 139820296341376 learning.py:512] global step 7564: loss = 1.0191 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7565: loss = 1.6194 (0.245 sec/step)\n",
            "I0802 20:33:13.259075 139820296341376 learning.py:512] global step 7565: loss = 1.6194 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7566: loss = 0.9263 (0.252 sec/step)\n",
            "I0802 20:33:13.512587 139820296341376 learning.py:512] global step 7566: loss = 0.9263 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 7567: loss = 0.8178 (0.238 sec/step)\n",
            "I0802 20:33:13.751767 139820296341376 learning.py:512] global step 7567: loss = 0.8178 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7568: loss = 1.2395 (0.243 sec/step)\n",
            "I0802 20:33:13.996572 139820296341376 learning.py:512] global step 7568: loss = 1.2395 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7569: loss = 0.7517 (0.232 sec/step)\n",
            "I0802 20:33:14.229640 139820296341376 learning.py:512] global step 7569: loss = 0.7517 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7570: loss = 0.8092 (0.228 sec/step)\n",
            "I0802 20:33:14.458827 139820296341376 learning.py:512] global step 7570: loss = 0.8092 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7571: loss = 0.6836 (0.241 sec/step)\n",
            "I0802 20:33:14.700965 139820296341376 learning.py:512] global step 7571: loss = 0.6836 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7572: loss = 0.9490 (0.233 sec/step)\n",
            "I0802 20:33:14.935738 139820296341376 learning.py:512] global step 7572: loss = 0.9490 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7573: loss = 0.7754 (0.242 sec/step)\n",
            "I0802 20:33:15.179070 139820296341376 learning.py:512] global step 7573: loss = 0.7754 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7574: loss = 1.2131 (0.244 sec/step)\n",
            "I0802 20:33:15.424695 139820296341376 learning.py:512] global step 7574: loss = 1.2131 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7575: loss = 0.9882 (0.239 sec/step)\n",
            "I0802 20:33:15.665185 139820296341376 learning.py:512] global step 7575: loss = 0.9882 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7576: loss = 0.6938 (0.236 sec/step)\n",
            "I0802 20:33:15.902671 139820296341376 learning.py:512] global step 7576: loss = 0.6938 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7577: loss = 0.9539 (0.222 sec/step)\n",
            "I0802 20:33:16.126067 139820296341376 learning.py:512] global step 7577: loss = 0.9539 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 7578: loss = 0.9824 (0.225 sec/step)\n",
            "I0802 20:33:16.352178 139820296341376 learning.py:512] global step 7578: loss = 0.9824 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7579: loss = 0.8778 (0.243 sec/step)\n",
            "I0802 20:33:16.596490 139820296341376 learning.py:512] global step 7579: loss = 0.8778 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7580: loss = 1.0010 (0.235 sec/step)\n",
            "I0802 20:33:16.832571 139820296341376 learning.py:512] global step 7580: loss = 1.0010 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7581: loss = 1.0505 (0.227 sec/step)\n",
            "I0802 20:33:17.060637 139820296341376 learning.py:512] global step 7581: loss = 1.0505 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7582: loss = 0.8236 (0.240 sec/step)\n",
            "I0802 20:33:17.302292 139820296341376 learning.py:512] global step 7582: loss = 0.8236 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7583: loss = 0.8746 (0.252 sec/step)\n",
            "I0802 20:33:17.556001 139820296341376 learning.py:512] global step 7583: loss = 0.8746 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 7584: loss = 1.1028 (0.241 sec/step)\n",
            "I0802 20:33:17.799363 139820296341376 learning.py:512] global step 7584: loss = 1.1028 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7585: loss = 0.8243 (0.239 sec/step)\n",
            "I0802 20:33:18.041261 139820296341376 learning.py:512] global step 7585: loss = 0.8243 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7586: loss = 0.8747 (0.250 sec/step)\n",
            "I0802 20:33:18.292651 139820296341376 learning.py:512] global step 7586: loss = 0.8747 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7587: loss = 1.0372 (0.243 sec/step)\n",
            "I0802 20:33:18.536966 139820296341376 learning.py:512] global step 7587: loss = 1.0372 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7588: loss = 1.0565 (0.235 sec/step)\n",
            "I0802 20:33:18.773825 139820296341376 learning.py:512] global step 7588: loss = 1.0565 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7589: loss = 1.0755 (0.243 sec/step)\n",
            "I0802 20:33:19.018707 139820296341376 learning.py:512] global step 7589: loss = 1.0755 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7590: loss = 0.9510 (0.243 sec/step)\n",
            "I0802 20:33:19.263295 139820296341376 learning.py:512] global step 7590: loss = 0.9510 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7591: loss = 1.0075 (0.232 sec/step)\n",
            "I0802 20:33:19.497077 139820296341376 learning.py:512] global step 7591: loss = 1.0075 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7592: loss = 0.7044 (0.238 sec/step)\n",
            "I0802 20:33:19.737149 139820296341376 learning.py:512] global step 7592: loss = 0.7044 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7593: loss = 1.1218 (0.223 sec/step)\n",
            "I0802 20:33:19.961284 139820296341376 learning.py:512] global step 7593: loss = 1.1218 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 7594: loss = 0.9959 (0.244 sec/step)\n",
            "I0802 20:33:20.207315 139820296341376 learning.py:512] global step 7594: loss = 0.9959 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7595: loss = 0.9619 (0.256 sec/step)\n",
            "I0802 20:33:20.464748 139820296341376 learning.py:512] global step 7595: loss = 0.9619 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 7596: loss = 0.9011 (0.242 sec/step)\n",
            "I0802 20:33:20.708765 139820296341376 learning.py:512] global step 7596: loss = 0.9011 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7597: loss = 0.8424 (0.240 sec/step)\n",
            "I0802 20:33:20.950904 139820296341376 learning.py:512] global step 7597: loss = 0.8424 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7598: loss = 0.8753 (0.236 sec/step)\n",
            "I0802 20:33:21.188635 139820296341376 learning.py:512] global step 7598: loss = 0.8753 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7599: loss = 0.8530 (0.229 sec/step)\n",
            "I0802 20:33:21.419610 139820296341376 learning.py:512] global step 7599: loss = 0.8530 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7600: loss = 0.8855 (0.241 sec/step)\n",
            "I0802 20:33:21.662333 139820296341376 learning.py:512] global step 7600: loss = 0.8855 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7601: loss = 0.7825 (0.239 sec/step)\n",
            "I0802 20:33:21.903530 139820296341376 learning.py:512] global step 7601: loss = 0.7825 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7602: loss = 0.8231 (0.228 sec/step)\n",
            "I0802 20:33:22.133438 139820296341376 learning.py:512] global step 7602: loss = 0.8231 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7603: loss = 1.0322 (0.250 sec/step)\n",
            "I0802 20:33:22.384699 139820296341376 learning.py:512] global step 7603: loss = 1.0322 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7604: loss = 1.0365 (0.240 sec/step)\n",
            "I0802 20:33:22.626551 139820296341376 learning.py:512] global step 7604: loss = 1.0365 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7605: loss = 0.9589 (0.239 sec/step)\n",
            "I0802 20:33:22.866636 139820296341376 learning.py:512] global step 7605: loss = 0.9589 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7606: loss = 0.9299 (0.229 sec/step)\n",
            "I0802 20:33:23.097472 139820296341376 learning.py:512] global step 7606: loss = 0.9299 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7607: loss = 0.8283 (0.244 sec/step)\n",
            "I0802 20:33:23.343528 139820296341376 learning.py:512] global step 7607: loss = 0.8283 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7608: loss = 1.1598 (0.227 sec/step)\n",
            "I0802 20:33:23.572246 139820296341376 learning.py:512] global step 7608: loss = 1.1598 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7609: loss = 1.0297 (0.238 sec/step)\n",
            "I0802 20:33:23.811686 139820296341376 learning.py:512] global step 7609: loss = 1.0297 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7610: loss = 0.9269 (0.244 sec/step)\n",
            "I0802 20:33:24.059178 139820296341376 learning.py:512] global step 7610: loss = 0.9269 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7611: loss = 0.9803 (0.236 sec/step)\n",
            "I0802 20:33:24.296934 139820296341376 learning.py:512] global step 7611: loss = 0.9803 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7612: loss = 0.8222 (0.243 sec/step)\n",
            "I0802 20:33:24.540882 139820296341376 learning.py:512] global step 7612: loss = 0.8222 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7613: loss = 0.7571 (0.239 sec/step)\n",
            "I0802 20:33:24.781812 139820296341376 learning.py:512] global step 7613: loss = 0.7571 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7614: loss = 1.1303 (0.241 sec/step)\n",
            "I0802 20:33:25.024477 139820296341376 learning.py:512] global step 7614: loss = 1.1303 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7615: loss = 0.6554 (0.243 sec/step)\n",
            "I0802 20:33:25.269223 139820296341376 learning.py:512] global step 7615: loss = 0.6554 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7616: loss = 0.9791 (0.228 sec/step)\n",
            "I0802 20:33:25.499291 139820296341376 learning.py:512] global step 7616: loss = 0.9791 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7617: loss = 0.9638 (0.247 sec/step)\n",
            "I0802 20:33:25.748159 139820296341376 learning.py:512] global step 7617: loss = 0.9638 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7618: loss = 0.7793 (0.241 sec/step)\n",
            "I0802 20:33:25.990774 139820296341376 learning.py:512] global step 7618: loss = 0.7793 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7619: loss = 0.7011 (0.244 sec/step)\n",
            "I0802 20:33:26.236044 139820296341376 learning.py:512] global step 7619: loss = 0.7011 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7620: loss = 1.1472 (0.243 sec/step)\n",
            "I0802 20:33:26.480196 139820296341376 learning.py:512] global step 7620: loss = 1.1472 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7621: loss = 0.9143 (0.229 sec/step)\n",
            "I0802 20:33:26.711128 139820296341376 learning.py:512] global step 7621: loss = 0.9143 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7622: loss = 0.6744 (0.229 sec/step)\n",
            "I0802 20:33:26.941819 139820296341376 learning.py:512] global step 7622: loss = 0.6744 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7623: loss = 0.8566 (0.240 sec/step)\n",
            "I0802 20:33:27.183601 139820296341376 learning.py:512] global step 7623: loss = 0.8566 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7624: loss = 0.8448 (0.247 sec/step)\n",
            "I0802 20:33:27.432061 139820296341376 learning.py:512] global step 7624: loss = 0.8448 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7625: loss = 0.8852 (0.250 sec/step)\n",
            "I0802 20:33:27.683671 139820296341376 learning.py:512] global step 7625: loss = 0.8852 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7626: loss = 0.8622 (0.244 sec/step)\n",
            "I0802 20:33:27.929619 139820296341376 learning.py:512] global step 7626: loss = 0.8622 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7627: loss = 0.8064 (0.224 sec/step)\n",
            "I0802 20:33:28.155317 139820296341376 learning.py:512] global step 7627: loss = 0.8064 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7628: loss = 0.8001 (0.241 sec/step)\n",
            "I0802 20:33:28.397827 139820296341376 learning.py:512] global step 7628: loss = 0.8001 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7629: loss = 0.8157 (0.228 sec/step)\n",
            "I0802 20:33:28.627597 139820296341376 learning.py:512] global step 7629: loss = 0.8157 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7630: loss = 0.8550 (0.242 sec/step)\n",
            "I0802 20:33:28.870806 139820296341376 learning.py:512] global step 7630: loss = 0.8550 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7631: loss = 0.8728 (0.241 sec/step)\n",
            "I0802 20:33:29.113141 139820296341376 learning.py:512] global step 7631: loss = 0.8728 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7632: loss = 0.8397 (0.229 sec/step)\n",
            "I0802 20:33:29.344717 139820296341376 learning.py:512] global step 7632: loss = 0.8397 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7633: loss = 1.1400 (0.244 sec/step)\n",
            "I0802 20:33:29.590063 139820296341376 learning.py:512] global step 7633: loss = 1.1400 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7634: loss = 0.6055 (0.237 sec/step)\n",
            "I0802 20:33:29.828440 139820296341376 learning.py:512] global step 7634: loss = 0.6055 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7635: loss = 1.1674 (0.236 sec/step)\n",
            "I0802 20:33:30.065353 139820296341376 learning.py:512] global step 7635: loss = 1.1674 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7636: loss = 1.0134 (0.236 sec/step)\n",
            "I0802 20:33:30.303148 139820296341376 learning.py:512] global step 7636: loss = 1.0134 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7637: loss = 0.8103 (0.238 sec/step)\n",
            "I0802 20:33:30.542692 139820296341376 learning.py:512] global step 7637: loss = 0.8103 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7638: loss = 0.7986 (0.245 sec/step)\n",
            "I0802 20:33:30.789214 139820296341376 learning.py:512] global step 7638: loss = 0.7986 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7639: loss = 0.7952 (0.224 sec/step)\n",
            "I0802 20:33:31.015470 139820296341376 learning.py:512] global step 7639: loss = 0.7952 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7640: loss = 0.7824 (0.240 sec/step)\n",
            "I0802 20:33:31.256872 139820296341376 learning.py:512] global step 7640: loss = 0.7824 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7641: loss = 0.9206 (0.253 sec/step)\n",
            "I0802 20:33:31.511853 139820296341376 learning.py:512] global step 7641: loss = 0.9206 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 7642: loss = 0.8918 (0.243 sec/step)\n",
            "I0802 20:33:31.756465 139820296341376 learning.py:512] global step 7642: loss = 0.8918 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7643: loss = 0.8069 (0.238 sec/step)\n",
            "I0802 20:33:31.995896 139820296341376 learning.py:512] global step 7643: loss = 0.8069 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7644: loss = 1.1913 (0.241 sec/step)\n",
            "I0802 20:33:32.238631 139820296341376 learning.py:512] global step 7644: loss = 1.1913 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7645: loss = 0.9204 (0.242 sec/step)\n",
            "I0802 20:33:32.481971 139820296341376 learning.py:512] global step 7645: loss = 0.9204 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7646: loss = 0.9955 (0.237 sec/step)\n",
            "I0802 20:33:32.721142 139820296341376 learning.py:512] global step 7646: loss = 0.9955 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7647: loss = 1.4965 (0.239 sec/step)\n",
            "I0802 20:33:32.961489 139820296341376 learning.py:512] global step 7647: loss = 1.4965 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7648: loss = 0.9691 (0.249 sec/step)\n",
            "I0802 20:33:33.213905 139820296341376 learning.py:512] global step 7648: loss = 0.9691 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7649: loss = 0.7610 (0.244 sec/step)\n",
            "I0802 20:33:33.459942 139820296341376 learning.py:512] global step 7649: loss = 0.7610 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7650: loss = 0.7842 (0.235 sec/step)\n",
            "I0802 20:33:33.696705 139820296341376 learning.py:512] global step 7650: loss = 0.7842 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7651: loss = 0.8625 (0.228 sec/step)\n",
            "I0802 20:33:33.926091 139820296341376 learning.py:512] global step 7651: loss = 0.8625 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7652: loss = 0.9556 (0.244 sec/step)\n",
            "I0802 20:33:34.172020 139820296341376 learning.py:512] global step 7652: loss = 0.9556 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7653: loss = 0.8954 (0.239 sec/step)\n",
            "I0802 20:33:34.412574 139820296341376 learning.py:512] global step 7653: loss = 0.8954 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7654: loss = 1.0009 (0.239 sec/step)\n",
            "I0802 20:33:34.652944 139820296341376 learning.py:512] global step 7654: loss = 1.0009 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7655: loss = 0.8022 (0.221 sec/step)\n",
            "I0802 20:33:34.875863 139820296341376 learning.py:512] global step 7655: loss = 0.8022 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 7656: loss = 0.9038 (0.235 sec/step)\n",
            "I0802 20:33:35.112756 139820296341376 learning.py:512] global step 7656: loss = 0.9038 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7657: loss = 1.1202 (0.240 sec/step)\n",
            "I0802 20:33:35.354585 139820296341376 learning.py:512] global step 7657: loss = 1.1202 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7658: loss = 0.7413 (0.229 sec/step)\n",
            "I0802 20:33:35.585304 139820296341376 learning.py:512] global step 7658: loss = 0.7413 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7659: loss = 0.7984 (0.225 sec/step)\n",
            "I0802 20:33:35.811553 139820296341376 learning.py:512] global step 7659: loss = 0.7984 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7660: loss = 0.9766 (0.239 sec/step)\n",
            "I0802 20:33:36.052083 139820296341376 learning.py:512] global step 7660: loss = 0.9766 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7661: loss = 0.8159 (0.242 sec/step)\n",
            "I0802 20:33:36.295636 139820296341376 learning.py:512] global step 7661: loss = 0.8159 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7662: loss = 0.8109 (0.240 sec/step)\n",
            "I0802 20:33:36.536893 139820296341376 learning.py:512] global step 7662: loss = 0.8109 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7663: loss = 0.6871 (0.235 sec/step)\n",
            "I0802 20:33:36.773778 139820296341376 learning.py:512] global step 7663: loss = 0.6871 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7664: loss = 0.9175 (0.237 sec/step)\n",
            "I0802 20:33:37.012484 139820296341376 learning.py:512] global step 7664: loss = 0.9175 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7665: loss = 0.8374 (0.242 sec/step)\n",
            "I0802 20:33:37.256406 139820296341376 learning.py:512] global step 7665: loss = 0.8374 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7666: loss = 0.8996 (0.229 sec/step)\n",
            "I0802 20:33:37.486866 139820296341376 learning.py:512] global step 7666: loss = 0.8996 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7667: loss = 0.7848 (0.223 sec/step)\n",
            "I0802 20:33:37.711663 139820296341376 learning.py:512] global step 7667: loss = 0.7848 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 7668: loss = 1.3066 (0.235 sec/step)\n",
            "I0802 20:33:37.948088 139820296341376 learning.py:512] global step 7668: loss = 1.3066 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7669: loss = 0.8143 (0.239 sec/step)\n",
            "I0802 20:33:38.188949 139820296341376 learning.py:512] global step 7669: loss = 0.8143 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7670: loss = 1.1629 (0.236 sec/step)\n",
            "I0802 20:33:38.426733 139820296341376 learning.py:512] global step 7670: loss = 1.1629 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7671: loss = 0.9211 (0.236 sec/step)\n",
            "I0802 20:33:38.664245 139820296341376 learning.py:512] global step 7671: loss = 0.9211 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7672: loss = 0.9488 (0.235 sec/step)\n",
            "I0802 20:33:38.900329 139820296341376 learning.py:512] global step 7672: loss = 0.9488 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7673: loss = 0.8078 (0.224 sec/step)\n",
            "I0802 20:33:39.126016 139820296341376 learning.py:512] global step 7673: loss = 0.8078 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7674: loss = 0.7015 (0.247 sec/step)\n",
            "I0802 20:33:39.375149 139820296341376 learning.py:512] global step 7674: loss = 0.7015 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7675: loss = 0.8241 (0.237 sec/step)\n",
            "I0802 20:33:39.613964 139820296341376 learning.py:512] global step 7675: loss = 0.8241 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7676: loss = 0.8656 (0.230 sec/step)\n",
            "I0802 20:33:39.845608 139820296341376 learning.py:512] global step 7676: loss = 0.8656 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7677: loss = 0.9345 (0.235 sec/step)\n",
            "I0802 20:33:40.082459 139820296341376 learning.py:512] global step 7677: loss = 0.9345 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7678: loss = 0.8669 (0.233 sec/step)\n",
            "I0802 20:33:40.317471 139820296341376 learning.py:512] global step 7678: loss = 0.8669 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7679: loss = 0.8984 (0.240 sec/step)\n",
            "I0802 20:33:40.559197 139820296341376 learning.py:512] global step 7679: loss = 0.8984 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7680: loss = 1.8512 (0.224 sec/step)\n",
            "I0802 20:33:40.784372 139820296341376 learning.py:512] global step 7680: loss = 1.8512 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7681: loss = 0.8524 (0.236 sec/step)\n",
            "I0802 20:33:41.022288 139820296341376 learning.py:512] global step 7681: loss = 0.8524 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7682: loss = 0.9590 (0.244 sec/step)\n",
            "I0802 20:33:41.267670 139820296341376 learning.py:512] global step 7682: loss = 0.9590 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7683: loss = 0.8602 (0.238 sec/step)\n",
            "I0802 20:33:41.507674 139820296341376 learning.py:512] global step 7683: loss = 0.8602 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7684: loss = 0.8164 (0.234 sec/step)\n",
            "I0802 20:33:41.743151 139820296341376 learning.py:512] global step 7684: loss = 0.8164 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7685: loss = 0.8577 (0.238 sec/step)\n",
            "I0802 20:33:41.983173 139820296341376 learning.py:512] global step 7685: loss = 0.8577 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7686: loss = 0.7624 (0.236 sec/step)\n",
            "I0802 20:33:42.220463 139820296341376 learning.py:512] global step 7686: loss = 0.7624 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7687: loss = 0.7218 (0.247 sec/step)\n",
            "I0802 20:33:42.469287 139820296341376 learning.py:512] global step 7687: loss = 0.7218 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7688: loss = 0.9696 (0.240 sec/step)\n",
            "I0802 20:33:42.710767 139820296341376 learning.py:512] global step 7688: loss = 0.9696 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7689: loss = 0.7837 (0.232 sec/step)\n",
            "I0802 20:33:42.944242 139820296341376 learning.py:512] global step 7689: loss = 0.7837 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7690: loss = 0.9568 (0.238 sec/step)\n",
            "I0802 20:33:43.183981 139820296341376 learning.py:512] global step 7690: loss = 0.9568 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7691: loss = 0.8693 (0.240 sec/step)\n",
            "I0802 20:33:43.425466 139820296341376 learning.py:512] global step 7691: loss = 0.8693 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7692: loss = 0.9526 (0.243 sec/step)\n",
            "I0802 20:33:43.669727 139820296341376 learning.py:512] global step 7692: loss = 0.9526 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7693: loss = 0.8144 (0.243 sec/step)\n",
            "I0802 20:33:43.913745 139820296341376 learning.py:512] global step 7693: loss = 0.8144 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7694: loss = 1.0973 (0.237 sec/step)\n",
            "I0802 20:33:44.152036 139820296341376 learning.py:512] global step 7694: loss = 1.0973 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7695: loss = 0.8712 (0.242 sec/step)\n",
            "I0802 20:33:44.395765 139820296341376 learning.py:512] global step 7695: loss = 0.8712 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7696: loss = 0.7107 (0.240 sec/step)\n",
            "I0802 20:33:44.637119 139820296341376 learning.py:512] global step 7696: loss = 0.7107 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7697: loss = 1.0113 (0.233 sec/step)\n",
            "I0802 20:33:44.871389 139820296341376 learning.py:512] global step 7697: loss = 1.0113 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7698: loss = 0.7044 (0.238 sec/step)\n",
            "I0802 20:33:45.111395 139820296341376 learning.py:512] global step 7698: loss = 0.7044 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7699: loss = 1.0550 (0.236 sec/step)\n",
            "I0802 20:33:45.349720 139820296341376 learning.py:512] global step 7699: loss = 1.0550 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7700: loss = 0.6726 (0.236 sec/step)\n",
            "I0802 20:33:45.586908 139820296341376 learning.py:512] global step 7700: loss = 0.6726 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7701: loss = 0.7546 (0.226 sec/step)\n",
            "I0802 20:33:45.814265 139820296341376 learning.py:512] global step 7701: loss = 0.7546 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 7702: loss = 1.0704 (0.234 sec/step)\n",
            "I0802 20:33:46.050257 139820296341376 learning.py:512] global step 7702: loss = 1.0704 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7703: loss = 0.8994 (0.240 sec/step)\n",
            "I0802 20:33:46.291225 139820296341376 learning.py:512] global step 7703: loss = 0.8994 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7704: loss = 0.8394 (0.233 sec/step)\n",
            "I0802 20:33:46.525309 139820296341376 learning.py:512] global step 7704: loss = 0.8394 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7705: loss = 0.8799 (0.236 sec/step)\n",
            "I0802 20:33:46.763381 139820296341376 learning.py:512] global step 7705: loss = 0.8799 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7706: loss = 0.8498 (0.240 sec/step)\n",
            "I0802 20:33:47.004734 139820296341376 learning.py:512] global step 7706: loss = 0.8498 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7707: loss = 1.3146 (0.246 sec/step)\n",
            "I0802 20:33:47.252238 139820296341376 learning.py:512] global step 7707: loss = 1.3146 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7708: loss = 0.7766 (0.237 sec/step)\n",
            "I0802 20:33:47.490533 139820296341376 learning.py:512] global step 7708: loss = 0.7766 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7709: loss = 0.6384 (0.241 sec/step)\n",
            "I0802 20:33:47.732901 139820296341376 learning.py:512] global step 7709: loss = 0.6384 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7710: loss = 0.9407 (0.221 sec/step)\n",
            "I0802 20:33:47.955072 139820296341376 learning.py:512] global step 7710: loss = 0.9407 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 7711: loss = 1.0358 (0.231 sec/step)\n",
            "I0802 20:33:48.187398 139820296341376 learning.py:512] global step 7711: loss = 1.0358 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7712: loss = 0.8714 (0.226 sec/step)\n",
            "I0802 20:33:48.414549 139820296341376 learning.py:512] global step 7712: loss = 0.8714 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 7713: loss = 0.6468 (0.236 sec/step)\n",
            "I0802 20:33:48.652201 139820296341376 learning.py:512] global step 7713: loss = 0.6468 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7714: loss = 0.7243 (0.236 sec/step)\n",
            "I0802 20:33:48.889562 139820296341376 learning.py:512] global step 7714: loss = 0.7243 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7715: loss = 0.9341 (0.237 sec/step)\n",
            "I0802 20:33:49.128084 139820296341376 learning.py:512] global step 7715: loss = 0.9341 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7716: loss = 1.2634 (0.224 sec/step)\n",
            "I0802 20:33:49.353218 139820296341376 learning.py:512] global step 7716: loss = 1.2634 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7717: loss = 1.2972 (0.239 sec/step)\n",
            "I0802 20:33:49.593226 139820296341376 learning.py:512] global step 7717: loss = 1.2972 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7718: loss = 0.6719 (0.229 sec/step)\n",
            "I0802 20:33:49.823715 139820296341376 learning.py:512] global step 7718: loss = 0.6719 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7719: loss = 1.4069 (0.224 sec/step)\n",
            "I0802 20:33:50.049535 139820296341376 learning.py:512] global step 7719: loss = 1.4069 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7720: loss = 0.7915 (0.228 sec/step)\n",
            "I0802 20:33:50.278835 139820296341376 learning.py:512] global step 7720: loss = 0.7915 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7721: loss = 0.8366 (0.235 sec/step)\n",
            "I0802 20:33:50.514949 139820296341376 learning.py:512] global step 7721: loss = 0.8366 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7722: loss = 0.9630 (0.234 sec/step)\n",
            "I0802 20:33:50.751755 139820296341376 learning.py:512] global step 7722: loss = 0.9630 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7723: loss = 0.7607 (0.225 sec/step)\n",
            "I0802 20:33:50.978126 139820296341376 learning.py:512] global step 7723: loss = 0.7607 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7724: loss = 0.9012 (0.237 sec/step)\n",
            "I0802 20:33:51.216245 139820296341376 learning.py:512] global step 7724: loss = 0.9012 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7725: loss = 0.7324 (0.234 sec/step)\n",
            "I0802 20:33:51.451596 139820296341376 learning.py:512] global step 7725: loss = 0.7324 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7726: loss = 0.5845 (0.242 sec/step)\n",
            "I0802 20:33:51.695382 139820296341376 learning.py:512] global step 7726: loss = 0.5845 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7727: loss = 0.7722 (0.243 sec/step)\n",
            "I0802 20:33:51.940021 139820296341376 learning.py:512] global step 7727: loss = 0.7722 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7728: loss = 0.8581 (0.239 sec/step)\n",
            "I0802 20:33:52.181204 139820296341376 learning.py:512] global step 7728: loss = 0.8581 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7729: loss = 1.1963 (0.230 sec/step)\n",
            "I0802 20:33:52.412412 139820296341376 learning.py:512] global step 7729: loss = 1.1963 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7730: loss = 1.5153 (0.240 sec/step)\n",
            "I0802 20:33:52.654067 139820296341376 learning.py:512] global step 7730: loss = 1.5153 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7731: loss = 0.9343 (0.243 sec/step)\n",
            "I0802 20:33:52.898358 139820296341376 learning.py:512] global step 7731: loss = 0.9343 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7732: loss = 0.9276 (0.235 sec/step)\n",
            "I0802 20:33:53.134906 139820296341376 learning.py:512] global step 7732: loss = 0.9276 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7733: loss = 0.9236 (0.239 sec/step)\n",
            "I0802 20:33:53.375170 139820296341376 learning.py:512] global step 7733: loss = 0.9236 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7734: loss = 0.9044 (0.238 sec/step)\n",
            "I0802 20:33:53.614941 139820296341376 learning.py:512] global step 7734: loss = 0.9044 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7735: loss = 0.8261 (0.227 sec/step)\n",
            "I0802 20:33:53.843330 139820296341376 learning.py:512] global step 7735: loss = 0.8261 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7736: loss = 0.8602 (0.232 sec/step)\n",
            "I0802 20:33:54.076833 139820296341376 learning.py:512] global step 7736: loss = 0.8602 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7737: loss = 0.7818 (0.221 sec/step)\n",
            "I0802 20:33:54.298863 139820296341376 learning.py:512] global step 7737: loss = 0.7818 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 7738: loss = 1.0177 (0.235 sec/step)\n",
            "I0802 20:33:54.535448 139820296341376 learning.py:512] global step 7738: loss = 1.0177 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7739: loss = 0.8060 (0.239 sec/step)\n",
            "I0802 20:33:54.775420 139820296341376 learning.py:512] global step 7739: loss = 0.8060 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7740: loss = 0.8191 (0.245 sec/step)\n",
            "I0802 20:33:55.021478 139820296341376 learning.py:512] global step 7740: loss = 0.8191 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7741: loss = 0.7714 (0.238 sec/step)\n",
            "I0802 20:33:55.261498 139820296341376 learning.py:512] global step 7741: loss = 0.7714 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7742: loss = 0.8856 (0.237 sec/step)\n",
            "I0802 20:33:55.499993 139820296341376 learning.py:512] global step 7742: loss = 0.8856 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7743: loss = 0.8846 (0.239 sec/step)\n",
            "I0802 20:33:55.740388 139820296341376 learning.py:512] global step 7743: loss = 0.8846 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7744: loss = 0.9046 (0.244 sec/step)\n",
            "I0802 20:33:55.986487 139820296341376 learning.py:512] global step 7744: loss = 0.9046 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7745: loss = 0.8731 (0.240 sec/step)\n",
            "I0802 20:33:56.227586 139820296341376 learning.py:512] global step 7745: loss = 0.8731 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7746: loss = 0.9338 (0.249 sec/step)\n",
            "I0802 20:33:56.478224 139820296341376 learning.py:512] global step 7746: loss = 0.9338 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7747: loss = 0.9542 (0.259 sec/step)\n",
            "I0802 20:33:56.738551 139820296341376 learning.py:512] global step 7747: loss = 0.9542 (0.259 sec/step)\n",
            "INFO:tensorflow:global step 7748: loss = 1.0412 (0.224 sec/step)\n",
            "I0802 20:33:56.964459 139820296341376 learning.py:512] global step 7748: loss = 1.0412 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 7749: loss = 1.0799 (0.232 sec/step)\n",
            "I0802 20:33:57.201977 139820296341376 learning.py:512] global step 7749: loss = 1.0799 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7750: loss = 1.0170 (0.225 sec/step)\n",
            "I0802 20:33:57.429031 139820296341376 learning.py:512] global step 7750: loss = 1.0170 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7751: loss = 1.2557 (0.230 sec/step)\n",
            "I0802 20:33:57.660532 139820296341376 learning.py:512] global step 7751: loss = 1.2557 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7752: loss = 0.9269 (0.240 sec/step)\n",
            "I0802 20:33:57.902692 139820296341376 learning.py:512] global step 7752: loss = 0.9269 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7753: loss = 0.6766 (0.237 sec/step)\n",
            "I0802 20:33:58.141324 139820296341376 learning.py:512] global step 7753: loss = 0.6766 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7754: loss = 0.9490 (0.221 sec/step)\n",
            "I0802 20:33:58.363769 139820296341376 learning.py:512] global step 7754: loss = 0.9490 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 7755: loss = 1.1405 (0.238 sec/step)\n",
            "I0802 20:33:58.603820 139820296341376 learning.py:512] global step 7755: loss = 1.1405 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7756: loss = 0.8223 (0.242 sec/step)\n",
            "I0802 20:33:58.848903 139820296341376 learning.py:512] global step 7756: loss = 0.8223 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7757: loss = 0.7308 (0.227 sec/step)\n",
            "I0802 20:33:59.077774 139820296341376 learning.py:512] global step 7757: loss = 0.7308 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7758: loss = 0.8280 (0.247 sec/step)\n",
            "I0802 20:33:59.326179 139820296341376 learning.py:512] global step 7758: loss = 0.8280 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7759: loss = 0.8462 (0.232 sec/step)\n",
            "I0802 20:33:59.559512 139820296341376 learning.py:512] global step 7759: loss = 0.8462 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7760: loss = 0.8780 (0.243 sec/step)\n",
            "I0802 20:33:59.804215 139820296341376 learning.py:512] global step 7760: loss = 0.8780 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7761: loss = 0.8028 (0.225 sec/step)\n",
            "I0802 20:34:00.030711 139820296341376 learning.py:512] global step 7761: loss = 0.8028 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7762: loss = 0.8935 (0.237 sec/step)\n",
            "I0802 20:34:00.269351 139820296341376 learning.py:512] global step 7762: loss = 0.8935 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7763: loss = 0.9039 (0.236 sec/step)\n",
            "I0802 20:34:00.506968 139820296341376 learning.py:512] global step 7763: loss = 0.9039 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7764: loss = 0.6995 (0.231 sec/step)\n",
            "I0802 20:34:00.739675 139820296341376 learning.py:512] global step 7764: loss = 0.6995 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7765: loss = 0.8659 (0.245 sec/step)\n",
            "I0802 20:34:00.985797 139820296341376 learning.py:512] global step 7765: loss = 0.8659 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7766: loss = 0.8520 (0.236 sec/step)\n",
            "I0802 20:34:01.222799 139820296341376 learning.py:512] global step 7766: loss = 0.8520 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7767: loss = 0.9922 (0.221 sec/step)\n",
            "I0802 20:34:01.445314 139820296341376 learning.py:512] global step 7767: loss = 0.9922 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 7768: loss = 0.7877 (0.233 sec/step)\n",
            "I0802 20:34:01.680191 139820296341376 learning.py:512] global step 7768: loss = 0.7877 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7769: loss = 0.8022 (0.222 sec/step)\n",
            "I0802 20:34:01.903903 139820296341376 learning.py:512] global step 7769: loss = 0.8022 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 7770: loss = 0.7232 (0.241 sec/step)\n",
            "I0802 20:34:02.146663 139820296341376 learning.py:512] global step 7770: loss = 0.7232 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7771: loss = 0.8881 (0.233 sec/step)\n",
            "I0802 20:34:02.380995 139820296341376 learning.py:512] global step 7771: loss = 0.8881 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7772: loss = 2.1979 (0.239 sec/step)\n",
            "I0802 20:34:02.623198 139820296341376 learning.py:512] global step 7772: loss = 2.1979 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7773: loss = 0.8653 (0.238 sec/step)\n",
            "I0802 20:34:02.862898 139820296341376 learning.py:512] global step 7773: loss = 0.8653 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7774: loss = 1.0208 (0.241 sec/step)\n",
            "I0802 20:34:03.105549 139820296341376 learning.py:512] global step 7774: loss = 1.0208 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7775: loss = 0.8742 (0.236 sec/step)\n",
            "I0802 20:34:03.343384 139820296341376 learning.py:512] global step 7775: loss = 0.8742 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7776: loss = 0.7218 (0.228 sec/step)\n",
            "I0802 20:34:03.573324 139820296341376 learning.py:512] global step 7776: loss = 0.7218 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7777: loss = 0.8029 (0.235 sec/step)\n",
            "I0802 20:34:03.809845 139820296341376 learning.py:512] global step 7777: loss = 0.8029 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7778: loss = 0.8568 (0.244 sec/step)\n",
            "I0802 20:34:04.055114 139820296341376 learning.py:512] global step 7778: loss = 0.8568 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7779: loss = 1.0740 (0.241 sec/step)\n",
            "I0802 20:34:04.297361 139820296341376 learning.py:512] global step 7779: loss = 1.0740 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7780: loss = 1.0392 (0.247 sec/step)\n",
            "I0802 20:34:04.545881 139820296341376 learning.py:512] global step 7780: loss = 1.0392 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7781: loss = 0.8455 (0.237 sec/step)\n",
            "I0802 20:34:04.784232 139820296341376 learning.py:512] global step 7781: loss = 0.8455 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7782: loss = 0.7572 (0.243 sec/step)\n",
            "I0802 20:34:05.029219 139820296341376 learning.py:512] global step 7782: loss = 0.7572 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7783: loss = 0.8764 (0.238 sec/step)\n",
            "I0802 20:34:05.268721 139820296341376 learning.py:512] global step 7783: loss = 0.8764 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7784: loss = 0.8322 (0.233 sec/step)\n",
            "I0802 20:34:05.503530 139820296341376 learning.py:512] global step 7784: loss = 0.8322 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7785: loss = 0.8009 (0.242 sec/step)\n",
            "I0802 20:34:05.747472 139820296341376 learning.py:512] global step 7785: loss = 0.8009 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7786: loss = 0.9949 (0.238 sec/step)\n",
            "I0802 20:34:05.986974 139820296341376 learning.py:512] global step 7786: loss = 0.9949 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7787: loss = 0.8063 (0.232 sec/step)\n",
            "I0802 20:34:06.220965 139820296341376 learning.py:512] global step 7787: loss = 0.8063 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7788: loss = 0.9003 (0.217 sec/step)\n",
            "I0802 20:34:06.439260 139820296341376 learning.py:512] global step 7788: loss = 0.9003 (0.217 sec/step)\n",
            "INFO:tensorflow:global step 7789: loss = 0.9011 (0.235 sec/step)\n",
            "I0802 20:34:06.676172 139820296341376 learning.py:512] global step 7789: loss = 0.9011 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7790: loss = 0.9161 (0.226 sec/step)\n",
            "I0802 20:34:06.903202 139820296341376 learning.py:512] global step 7790: loss = 0.9161 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 7791: loss = 0.9974 (0.247 sec/step)\n",
            "I0802 20:34:07.151703 139820296341376 learning.py:512] global step 7791: loss = 0.9974 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7792: loss = 0.9447 (0.233 sec/step)\n",
            "I0802 20:34:07.386270 139820296341376 learning.py:512] global step 7792: loss = 0.9447 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7793: loss = 1.0925 (0.234 sec/step)\n",
            "I0802 20:34:07.621196 139820296341376 learning.py:512] global step 7793: loss = 1.0925 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7794: loss = 0.8011 (0.244 sec/step)\n",
            "I0802 20:34:07.866467 139820296341376 learning.py:512] global step 7794: loss = 0.8011 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7795: loss = 1.5655 (0.241 sec/step)\n",
            "I0802 20:34:08.108621 139820296341376 learning.py:512] global step 7795: loss = 1.5655 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7796: loss = 1.0284 (0.238 sec/step)\n",
            "I0802 20:34:08.348320 139820296341376 learning.py:512] global step 7796: loss = 1.0284 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7797: loss = 0.7944 (0.237 sec/step)\n",
            "I0802 20:34:08.586364 139820296341376 learning.py:512] global step 7797: loss = 0.7944 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7798: loss = 0.8085 (0.234 sec/step)\n",
            "I0802 20:34:08.822274 139820296341376 learning.py:512] global step 7798: loss = 0.8085 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7799: loss = 0.7197 (0.238 sec/step)\n",
            "I0802 20:34:09.062351 139820296341376 learning.py:512] global step 7799: loss = 0.7197 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7800: loss = 0.8367 (0.240 sec/step)\n",
            "I0802 20:34:09.303419 139820296341376 learning.py:512] global step 7800: loss = 0.8367 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7801: loss = 0.8315 (0.225 sec/step)\n",
            "I0802 20:34:09.529774 139820296341376 learning.py:512] global step 7801: loss = 0.8315 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7802: loss = 0.9299 (0.235 sec/step)\n",
            "I0802 20:34:09.766126 139820296341376 learning.py:512] global step 7802: loss = 0.9299 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7803: loss = 0.6870 (0.239 sec/step)\n",
            "I0802 20:34:10.006662 139820296341376 learning.py:512] global step 7803: loss = 0.6870 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7804: loss = 0.8816 (0.240 sec/step)\n",
            "I0802 20:34:10.248378 139820296341376 learning.py:512] global step 7804: loss = 0.8816 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7805: loss = 0.8450 (0.233 sec/step)\n",
            "I0802 20:34:10.482730 139820296341376 learning.py:512] global step 7805: loss = 0.8450 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7806: loss = 0.6286 (0.231 sec/step)\n",
            "I0802 20:34:10.715441 139820296341376 learning.py:512] global step 7806: loss = 0.6286 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7807: loss = 0.6597 (0.231 sec/step)\n",
            "I0802 20:34:10.947792 139820296341376 learning.py:512] global step 7807: loss = 0.6597 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7808: loss = 0.9456 (0.239 sec/step)\n",
            "I0802 20:34:11.188364 139820296341376 learning.py:512] global step 7808: loss = 0.9456 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7809: loss = 1.0646 (0.237 sec/step)\n",
            "I0802 20:34:11.427205 139820296341376 learning.py:512] global step 7809: loss = 1.0646 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7810: loss = 0.7928 (0.238 sec/step)\n",
            "I0802 20:34:11.666537 139820296341376 learning.py:512] global step 7810: loss = 0.7928 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7811: loss = 0.8515 (0.241 sec/step)\n",
            "I0802 20:34:11.909165 139820296341376 learning.py:512] global step 7811: loss = 0.8515 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7812: loss = 0.7229 (0.232 sec/step)\n",
            "I0802 20:34:12.143048 139820296341376 learning.py:512] global step 7812: loss = 0.7229 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7813: loss = 1.0582 (0.237 sec/step)\n",
            "I0802 20:34:12.381511 139820296341376 learning.py:512] global step 7813: loss = 1.0582 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7814: loss = 1.1596 (0.243 sec/step)\n",
            "I0802 20:34:12.626569 139820296341376 learning.py:512] global step 7814: loss = 1.1596 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7815: loss = 0.8281 (0.230 sec/step)\n",
            "I0802 20:34:12.857830 139820296341376 learning.py:512] global step 7815: loss = 0.8281 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7816: loss = 0.9317 (0.222 sec/step)\n",
            "I0802 20:34:13.081187 139820296341376 learning.py:512] global step 7816: loss = 0.9317 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 7817: loss = 1.0739 (0.232 sec/step)\n",
            "I0802 20:34:13.314866 139820296341376 learning.py:512] global step 7817: loss = 1.0739 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7818: loss = 0.7808 (0.225 sec/step)\n",
            "I0802 20:34:13.541793 139820296341376 learning.py:512] global step 7818: loss = 0.7808 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7819: loss = 0.9020 (0.255 sec/step)\n",
            "I0802 20:34:13.798596 139820296341376 learning.py:512] global step 7819: loss = 0.9020 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 7820: loss = 0.7957 (0.233 sec/step)\n",
            "I0802 20:34:14.033105 139820296341376 learning.py:512] global step 7820: loss = 0.7957 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7821: loss = 1.3216 (0.230 sec/step)\n",
            "I0802 20:34:14.264774 139820296341376 learning.py:512] global step 7821: loss = 1.3216 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7822: loss = 0.8989 (0.234 sec/step)\n",
            "I0802 20:34:14.500477 139820296341376 learning.py:512] global step 7822: loss = 0.8989 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7823: loss = 0.8267 (0.243 sec/step)\n",
            "I0802 20:34:14.745753 139820296341376 learning.py:512] global step 7823: loss = 0.8267 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7824: loss = 0.8027 (0.234 sec/step)\n",
            "I0802 20:34:14.981792 139820296341376 learning.py:512] global step 7824: loss = 0.8027 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7825: loss = 0.8998 (0.242 sec/step)\n",
            "I0802 20:34:15.225268 139820296341376 learning.py:512] global step 7825: loss = 0.8998 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7826: loss = 1.2830 (0.230 sec/step)\n",
            "I0802 20:34:15.456373 139820296341376 learning.py:512] global step 7826: loss = 1.2830 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7827: loss = 0.9980 (0.233 sec/step)\n",
            "I0802 20:34:15.690856 139820296341376 learning.py:512] global step 7827: loss = 0.9980 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7828: loss = 0.9580 (0.240 sec/step)\n",
            "I0802 20:34:15.932311 139820296341376 learning.py:512] global step 7828: loss = 0.9580 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7829: loss = 0.8440 (0.239 sec/step)\n",
            "I0802 20:34:16.172538 139820296341376 learning.py:512] global step 7829: loss = 0.8440 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7830: loss = 0.7809 (0.237 sec/step)\n",
            "I0802 20:34:16.411199 139820296341376 learning.py:512] global step 7830: loss = 0.7809 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7831: loss = 1.1474 (0.244 sec/step)\n",
            "I0802 20:34:16.657350 139820296341376 learning.py:512] global step 7831: loss = 1.1474 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7832: loss = 1.0760 (0.241 sec/step)\n",
            "I0802 20:34:16.899663 139820296341376 learning.py:512] global step 7832: loss = 1.0760 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7833: loss = 0.9132 (0.242 sec/step)\n",
            "I0802 20:34:17.143097 139820296341376 learning.py:512] global step 7833: loss = 0.9132 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7834: loss = 1.2960 (0.241 sec/step)\n",
            "I0802 20:34:17.385750 139820296341376 learning.py:512] global step 7834: loss = 1.2960 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7835: loss = 1.0148 (0.229 sec/step)\n",
            "I0802 20:34:17.616769 139820296341376 learning.py:512] global step 7835: loss = 1.0148 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7836: loss = 0.8973 (0.240 sec/step)\n",
            "I0802 20:34:17.861109 139820296341376 learning.py:512] global step 7836: loss = 0.8973 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7837: loss = 1.1512 (0.234 sec/step)\n",
            "I0802 20:34:18.097458 139820296341376 learning.py:512] global step 7837: loss = 1.1512 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7838: loss = 0.8518 (0.239 sec/step)\n",
            "I0802 20:34:18.338294 139820296341376 learning.py:512] global step 7838: loss = 0.8518 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7839: loss = 0.8446 (0.240 sec/step)\n",
            "I0802 20:34:18.579869 139820296341376 learning.py:512] global step 7839: loss = 0.8446 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7840: loss = 1.1080 (0.287 sec/step)\n",
            "I0802 20:34:18.870708 139820296341376 learning.py:512] global step 7840: loss = 1.1080 (0.287 sec/step)\n",
            "INFO:tensorflow:global step 7841: loss = 0.7925 (0.300 sec/step)\n",
            "I0802 20:34:19.173346 139820296341376 learning.py:512] global step 7841: loss = 0.7925 (0.300 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 7841.\n",
            "I0802 20:34:19.210751 139815876826880 supervisor.py:1050] Recording summary at step 7841.\n",
            "INFO:tensorflow:global step 7842: loss = 0.9750 (0.233 sec/step)\n",
            "I0802 20:34:19.409354 139820296341376 learning.py:512] global step 7842: loss = 0.9750 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7843: loss = 0.9106 (0.235 sec/step)\n",
            "I0802 20:34:19.645627 139820296341376 learning.py:512] global step 7843: loss = 0.9106 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7844: loss = 0.8355 (0.244 sec/step)\n",
            "I0802 20:34:19.890995 139820296341376 learning.py:512] global step 7844: loss = 0.8355 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7845: loss = 1.1669 (0.239 sec/step)\n",
            "I0802 20:34:20.131955 139820296341376 learning.py:512] global step 7845: loss = 1.1669 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7846: loss = 1.0064 (0.239 sec/step)\n",
            "I0802 20:34:20.372567 139820296341376 learning.py:512] global step 7846: loss = 1.0064 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7847: loss = 0.7616 (0.219 sec/step)\n",
            "I0802 20:34:20.593160 139820296341376 learning.py:512] global step 7847: loss = 0.7616 (0.219 sec/step)\n",
            "INFO:tensorflow:global step 7848: loss = 0.8216 (0.241 sec/step)\n",
            "I0802 20:34:20.836164 139820296341376 learning.py:512] global step 7848: loss = 0.8216 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7849: loss = 1.3262 (0.247 sec/step)\n",
            "I0802 20:34:21.084770 139820296341376 learning.py:512] global step 7849: loss = 1.3262 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7850: loss = 1.1055 (0.227 sec/step)\n",
            "I0802 20:34:21.313936 139820296341376 learning.py:512] global step 7850: loss = 1.1055 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7851: loss = 0.8694 (0.242 sec/step)\n",
            "I0802 20:34:21.557978 139820296341376 learning.py:512] global step 7851: loss = 0.8694 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7852: loss = 0.8183 (0.232 sec/step)\n",
            "I0802 20:34:21.791373 139820296341376 learning.py:512] global step 7852: loss = 0.8183 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7853: loss = 1.0514 (0.244 sec/step)\n",
            "I0802 20:34:22.037062 139820296341376 learning.py:512] global step 7853: loss = 1.0514 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7854: loss = 0.9984 (0.233 sec/step)\n",
            "I0802 20:34:22.271409 139820296341376 learning.py:512] global step 7854: loss = 0.9984 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7855: loss = 0.7441 (0.236 sec/step)\n",
            "I0802 20:34:22.509264 139820296341376 learning.py:512] global step 7855: loss = 0.7441 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7856: loss = 0.6832 (0.242 sec/step)\n",
            "I0802 20:34:22.752864 139820296341376 learning.py:512] global step 7856: loss = 0.6832 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7857: loss = 1.2518 (0.240 sec/step)\n",
            "I0802 20:34:22.994886 139820296341376 learning.py:512] global step 7857: loss = 1.2518 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7858: loss = 0.9735 (0.247 sec/step)\n",
            "I0802 20:34:23.243470 139820296341376 learning.py:512] global step 7858: loss = 0.9735 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7859: loss = 0.8974 (0.241 sec/step)\n",
            "I0802 20:34:23.486095 139820296341376 learning.py:512] global step 7859: loss = 0.8974 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7860: loss = 0.8418 (0.239 sec/step)\n",
            "I0802 20:34:23.726180 139820296341376 learning.py:512] global step 7860: loss = 0.8418 (0.239 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 4.18334\n",
            "I0802 20:34:23.879529 139815885219584 supervisor.py:1099] global_step/sec: 4.18334\n",
            "INFO:tensorflow:global step 7861: loss = 0.8953 (0.236 sec/step)\n",
            "I0802 20:34:23.963896 139820296341376 learning.py:512] global step 7861: loss = 0.8953 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7862: loss = 0.9370 (0.243 sec/step)\n",
            "I0802 20:34:24.208101 139820296341376 learning.py:512] global step 7862: loss = 0.9370 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7863: loss = 0.9079 (0.226 sec/step)\n",
            "I0802 20:34:24.435949 139820296341376 learning.py:512] global step 7863: loss = 0.9079 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 7864: loss = 0.8785 (0.240 sec/step)\n",
            "I0802 20:34:24.677192 139820296341376 learning.py:512] global step 7864: loss = 0.8785 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7865: loss = 0.6816 (0.225 sec/step)\n",
            "I0802 20:34:24.903582 139820296341376 learning.py:512] global step 7865: loss = 0.6816 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7866: loss = 0.8908 (0.241 sec/step)\n",
            "I0802 20:34:25.146690 139820296341376 learning.py:512] global step 7866: loss = 0.8908 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7867: loss = 1.2062 (0.247 sec/step)\n",
            "I0802 20:34:25.395572 139820296341376 learning.py:512] global step 7867: loss = 1.2062 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7868: loss = 1.1617 (0.234 sec/step)\n",
            "I0802 20:34:25.631311 139820296341376 learning.py:512] global step 7868: loss = 1.1617 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7869: loss = 0.8762 (0.225 sec/step)\n",
            "I0802 20:34:25.858051 139820296341376 learning.py:512] global step 7869: loss = 0.8762 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7870: loss = 1.0234 (0.249 sec/step)\n",
            "I0802 20:34:26.108786 139820296341376 learning.py:512] global step 7870: loss = 1.0234 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7871: loss = 0.7739 (0.238 sec/step)\n",
            "I0802 20:34:26.348857 139820296341376 learning.py:512] global step 7871: loss = 0.7739 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7872: loss = 0.9285 (0.232 sec/step)\n",
            "I0802 20:34:26.582117 139820296341376 learning.py:512] global step 7872: loss = 0.9285 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7873: loss = 0.8231 (0.238 sec/step)\n",
            "I0802 20:34:26.821064 139820296341376 learning.py:512] global step 7873: loss = 0.8231 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7874: loss = 1.0830 (0.243 sec/step)\n",
            "I0802 20:34:27.065283 139820296341376 learning.py:512] global step 7874: loss = 1.0830 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7875: loss = 0.7244 (0.248 sec/step)\n",
            "I0802 20:34:27.314598 139820296341376 learning.py:512] global step 7875: loss = 0.7244 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7876: loss = 1.1152 (0.240 sec/step)\n",
            "I0802 20:34:27.556090 139820296341376 learning.py:512] global step 7876: loss = 1.1152 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7877: loss = 0.8350 (0.230 sec/step)\n",
            "I0802 20:34:27.787510 139820296341376 learning.py:512] global step 7877: loss = 0.8350 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7878: loss = 0.7659 (0.236 sec/step)\n",
            "I0802 20:34:28.024580 139820296341376 learning.py:512] global step 7878: loss = 0.7659 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7879: loss = 0.7748 (0.240 sec/step)\n",
            "I0802 20:34:28.266794 139820296341376 learning.py:512] global step 7879: loss = 0.7748 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7880: loss = 1.0362 (0.244 sec/step)\n",
            "I0802 20:34:28.512045 139820296341376 learning.py:512] global step 7880: loss = 1.0362 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7881: loss = 0.9404 (0.249 sec/step)\n",
            "I0802 20:34:28.762704 139820296341376 learning.py:512] global step 7881: loss = 0.9404 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7882: loss = 0.8290 (0.242 sec/step)\n",
            "I0802 20:34:29.005987 139820296341376 learning.py:512] global step 7882: loss = 0.8290 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7883: loss = 0.7793 (0.245 sec/step)\n",
            "I0802 20:34:29.252289 139820296341376 learning.py:512] global step 7883: loss = 0.7793 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7884: loss = 0.9650 (0.236 sec/step)\n",
            "I0802 20:34:29.489442 139820296341376 learning.py:512] global step 7884: loss = 0.9650 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7885: loss = 0.7859 (0.243 sec/step)\n",
            "I0802 20:34:29.733490 139820296341376 learning.py:512] global step 7885: loss = 0.7859 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7886: loss = 0.8400 (0.239 sec/step)\n",
            "I0802 20:34:29.974316 139820296341376 learning.py:512] global step 7886: loss = 0.8400 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7887: loss = 0.8866 (0.250 sec/step)\n",
            "I0802 20:34:30.226153 139820296341376 learning.py:512] global step 7887: loss = 0.8866 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7888: loss = 1.0814 (0.241 sec/step)\n",
            "I0802 20:34:30.468787 139820296341376 learning.py:512] global step 7888: loss = 1.0814 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7889: loss = 0.8528 (0.230 sec/step)\n",
            "I0802 20:34:30.700639 139820296341376 learning.py:512] global step 7889: loss = 0.8528 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7890: loss = 1.5304 (0.242 sec/step)\n",
            "I0802 20:34:30.944535 139820296341376 learning.py:512] global step 7890: loss = 1.5304 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7891: loss = 0.9166 (0.244 sec/step)\n",
            "I0802 20:34:31.190371 139820296341376 learning.py:512] global step 7891: loss = 0.9166 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7892: loss = 1.0009 (0.238 sec/step)\n",
            "I0802 20:34:31.430422 139820296341376 learning.py:512] global step 7892: loss = 1.0009 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7893: loss = 0.7905 (0.239 sec/step)\n",
            "I0802 20:34:31.670974 139820296341376 learning.py:512] global step 7893: loss = 0.7905 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7894: loss = 0.7968 (0.232 sec/step)\n",
            "I0802 20:34:31.904440 139820296341376 learning.py:512] global step 7894: loss = 0.7968 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7895: loss = 0.9194 (0.237 sec/step)\n",
            "I0802 20:34:32.143807 139820296341376 learning.py:512] global step 7895: loss = 0.9194 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7896: loss = 0.9566 (0.231 sec/step)\n",
            "I0802 20:34:32.376458 139820296341376 learning.py:512] global step 7896: loss = 0.9566 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7897: loss = 0.6374 (0.234 sec/step)\n",
            "I0802 20:34:32.612021 139820296341376 learning.py:512] global step 7897: loss = 0.6374 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7898: loss = 0.8468 (0.226 sec/step)\n",
            "I0802 20:34:32.839767 139820296341376 learning.py:512] global step 7898: loss = 0.8468 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 7899: loss = 0.7672 (0.231 sec/step)\n",
            "I0802 20:34:33.074131 139820296341376 learning.py:512] global step 7899: loss = 0.7672 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7900: loss = 0.8462 (0.239 sec/step)\n",
            "I0802 20:34:33.314849 139820296341376 learning.py:512] global step 7900: loss = 0.8462 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7901: loss = 0.9318 (0.243 sec/step)\n",
            "I0802 20:34:33.559739 139820296341376 learning.py:512] global step 7901: loss = 0.9318 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7902: loss = 0.9509 (0.245 sec/step)\n",
            "I0802 20:34:33.806766 139820296341376 learning.py:512] global step 7902: loss = 0.9509 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7903: loss = 0.8453 (0.249 sec/step)\n",
            "I0802 20:34:34.057102 139820296341376 learning.py:512] global step 7903: loss = 0.8453 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 7904: loss = 1.0688 (0.227 sec/step)\n",
            "I0802 20:34:34.287427 139820296341376 learning.py:512] global step 7904: loss = 1.0688 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7905: loss = 0.8902 (0.239 sec/step)\n",
            "I0802 20:34:34.527884 139820296341376 learning.py:512] global step 7905: loss = 0.8902 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7906: loss = 0.8235 (0.237 sec/step)\n",
            "I0802 20:34:34.766292 139820296341376 learning.py:512] global step 7906: loss = 0.8235 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7907: loss = 0.9694 (0.239 sec/step)\n",
            "I0802 20:34:35.007064 139820296341376 learning.py:512] global step 7907: loss = 0.9694 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7908: loss = 1.1333 (0.245 sec/step)\n",
            "I0802 20:34:35.254071 139820296341376 learning.py:512] global step 7908: loss = 1.1333 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7909: loss = 0.8397 (0.242 sec/step)\n",
            "I0802 20:34:35.497094 139820296341376 learning.py:512] global step 7909: loss = 0.8397 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7910: loss = 0.7727 (0.244 sec/step)\n",
            "I0802 20:34:35.742223 139820296341376 learning.py:512] global step 7910: loss = 0.7727 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7911: loss = 1.0998 (0.229 sec/step)\n",
            "I0802 20:34:35.973020 139820296341376 learning.py:512] global step 7911: loss = 1.0998 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7912: loss = 0.8586 (0.242 sec/step)\n",
            "I0802 20:34:36.216338 139820296341376 learning.py:512] global step 7912: loss = 0.8586 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7913: loss = 1.1129 (0.237 sec/step)\n",
            "I0802 20:34:36.455290 139820296341376 learning.py:512] global step 7913: loss = 1.1129 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7914: loss = 1.1206 (0.241 sec/step)\n",
            "I0802 20:34:36.697804 139820296341376 learning.py:512] global step 7914: loss = 1.1206 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7915: loss = 1.1224 (0.240 sec/step)\n",
            "I0802 20:34:36.939884 139820296341376 learning.py:512] global step 7915: loss = 1.1224 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7916: loss = 1.1087 (0.246 sec/step)\n",
            "I0802 20:34:37.187301 139820296341376 learning.py:512] global step 7916: loss = 1.1087 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 7917: loss = 0.7910 (0.229 sec/step)\n",
            "I0802 20:34:37.418016 139820296341376 learning.py:512] global step 7917: loss = 0.7910 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7918: loss = 0.6890 (0.236 sec/step)\n",
            "I0802 20:34:37.655937 139820296341376 learning.py:512] global step 7918: loss = 0.6890 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7919: loss = 0.7759 (0.248 sec/step)\n",
            "I0802 20:34:37.905073 139820296341376 learning.py:512] global step 7919: loss = 0.7759 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 7920: loss = 0.9441 (0.242 sec/step)\n",
            "I0802 20:34:38.148822 139820296341376 learning.py:512] global step 7920: loss = 0.9441 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7921: loss = 0.9161 (0.238 sec/step)\n",
            "I0802 20:34:38.389164 139820296341376 learning.py:512] global step 7921: loss = 0.9161 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7922: loss = 1.3290 (0.222 sec/step)\n",
            "I0802 20:34:38.612455 139820296341376 learning.py:512] global step 7922: loss = 1.3290 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 7923: loss = 0.8447 (0.241 sec/step)\n",
            "I0802 20:34:38.855168 139820296341376 learning.py:512] global step 7923: loss = 0.8447 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 7924: loss = 0.8239 (0.234 sec/step)\n",
            "I0802 20:34:39.091189 139820296341376 learning.py:512] global step 7924: loss = 0.8239 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7925: loss = 1.0757 (0.223 sec/step)\n",
            "I0802 20:34:39.315806 139820296341376 learning.py:512] global step 7925: loss = 1.0757 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 7926: loss = 0.9855 (0.235 sec/step)\n",
            "I0802 20:34:39.551992 139820296341376 learning.py:512] global step 7926: loss = 0.9855 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7927: loss = 0.6914 (0.236 sec/step)\n",
            "I0802 20:34:39.789491 139820296341376 learning.py:512] global step 7927: loss = 0.6914 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7928: loss = 0.8463 (0.228 sec/step)\n",
            "I0802 20:34:40.019055 139820296341376 learning.py:512] global step 7928: loss = 0.8463 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7929: loss = 1.2637 (0.226 sec/step)\n",
            "I0802 20:34:40.246703 139820296341376 learning.py:512] global step 7929: loss = 1.2637 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 7930: loss = 1.0107 (0.243 sec/step)\n",
            "I0802 20:34:40.491741 139820296341376 learning.py:512] global step 7930: loss = 1.0107 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7931: loss = 0.7610 (0.235 sec/step)\n",
            "I0802 20:34:40.728703 139820296341376 learning.py:512] global step 7931: loss = 0.7610 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7932: loss = 1.0668 (0.243 sec/step)\n",
            "I0802 20:34:40.973099 139820296341376 learning.py:512] global step 7932: loss = 1.0668 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7933: loss = 1.0637 (0.245 sec/step)\n",
            "I0802 20:34:41.219341 139820296341376 learning.py:512] global step 7933: loss = 1.0637 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7934: loss = 0.9667 (0.231 sec/step)\n",
            "I0802 20:34:41.451871 139820296341376 learning.py:512] global step 7934: loss = 0.9667 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7935: loss = 0.7752 (0.228 sec/step)\n",
            "I0802 20:34:41.681342 139820296341376 learning.py:512] global step 7935: loss = 0.7752 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7936: loss = 0.9882 (0.223 sec/step)\n",
            "I0802 20:34:41.905493 139820296341376 learning.py:512] global step 7936: loss = 0.9882 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 7937: loss = 0.8933 (0.237 sec/step)\n",
            "I0802 20:34:42.144069 139820296341376 learning.py:512] global step 7937: loss = 0.8933 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7938: loss = 0.8894 (0.239 sec/step)\n",
            "I0802 20:34:42.384736 139820296341376 learning.py:512] global step 7938: loss = 0.8894 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7939: loss = 0.8765 (0.233 sec/step)\n",
            "I0802 20:34:42.618988 139820296341376 learning.py:512] global step 7939: loss = 0.8765 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7940: loss = 1.1565 (0.220 sec/step)\n",
            "I0802 20:34:42.839999 139820296341376 learning.py:512] global step 7940: loss = 1.1565 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 7941: loss = 0.7794 (0.233 sec/step)\n",
            "I0802 20:34:43.074098 139820296341376 learning.py:512] global step 7941: loss = 0.7794 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 7942: loss = 0.8876 (0.247 sec/step)\n",
            "I0802 20:34:43.322613 139820296341376 learning.py:512] global step 7942: loss = 0.8876 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 7943: loss = 0.9485 (0.239 sec/step)\n",
            "I0802 20:34:43.563064 139820296341376 learning.py:512] global step 7943: loss = 0.9485 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7944: loss = 0.8703 (0.238 sec/step)\n",
            "I0802 20:34:43.802928 139820296341376 learning.py:512] global step 7944: loss = 0.8703 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7945: loss = 0.9137 (0.236 sec/step)\n",
            "I0802 20:34:44.040392 139820296341376 learning.py:512] global step 7945: loss = 0.9137 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7946: loss = 0.8969 (0.244 sec/step)\n",
            "I0802 20:34:44.286011 139820296341376 learning.py:512] global step 7946: loss = 0.8969 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7947: loss = 0.8523 (0.236 sec/step)\n",
            "I0802 20:34:44.523083 139820296341376 learning.py:512] global step 7947: loss = 0.8523 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7948: loss = 0.6557 (0.232 sec/step)\n",
            "I0802 20:34:44.756223 139820296341376 learning.py:512] global step 7948: loss = 0.6557 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 7949: loss = 1.0838 (0.227 sec/step)\n",
            "I0802 20:34:44.984528 139820296341376 learning.py:512] global step 7949: loss = 1.0838 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7950: loss = 1.0031 (0.251 sec/step)\n",
            "I0802 20:34:45.238161 139820296341376 learning.py:512] global step 7950: loss = 1.0031 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 7951: loss = 0.8541 (0.236 sec/step)\n",
            "I0802 20:34:45.476864 139820296341376 learning.py:512] global step 7951: loss = 0.8541 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7952: loss = 0.8104 (0.225 sec/step)\n",
            "I0802 20:34:45.702935 139820296341376 learning.py:512] global step 7952: loss = 0.8104 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7953: loss = 0.7897 (0.240 sec/step)\n",
            "I0802 20:34:45.944393 139820296341376 learning.py:512] global step 7953: loss = 0.7897 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7954: loss = 0.7888 (0.225 sec/step)\n",
            "I0802 20:34:46.171274 139820296341376 learning.py:512] global step 7954: loss = 0.7888 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7955: loss = 0.8468 (0.239 sec/step)\n",
            "I0802 20:34:46.412209 139820296341376 learning.py:512] global step 7955: loss = 0.8468 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7956: loss = 0.7411 (0.243 sec/step)\n",
            "I0802 20:34:46.656391 139820296341376 learning.py:512] global step 7956: loss = 0.7411 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7957: loss = 0.7262 (0.231 sec/step)\n",
            "I0802 20:34:46.888491 139820296341376 learning.py:512] global step 7957: loss = 0.7262 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7958: loss = 1.0170 (0.239 sec/step)\n",
            "I0802 20:34:47.128851 139820296341376 learning.py:512] global step 7958: loss = 1.0170 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7959: loss = 0.9794 (0.236 sec/step)\n",
            "I0802 20:34:47.366603 139820296341376 learning.py:512] global step 7959: loss = 0.9794 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7960: loss = 1.5534 (0.236 sec/step)\n",
            "I0802 20:34:47.604463 139820296341376 learning.py:512] global step 7960: loss = 1.5534 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7961: loss = 0.6896 (0.227 sec/step)\n",
            "I0802 20:34:47.832863 139820296341376 learning.py:512] global step 7961: loss = 0.6896 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7962: loss = 0.6933 (0.236 sec/step)\n",
            "I0802 20:34:48.070303 139820296341376 learning.py:512] global step 7962: loss = 0.6933 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7963: loss = 0.7083 (0.242 sec/step)\n",
            "I0802 20:34:48.313544 139820296341376 learning.py:512] global step 7963: loss = 0.7083 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7964: loss = 0.8489 (0.237 sec/step)\n",
            "I0802 20:34:48.551963 139820296341376 learning.py:512] global step 7964: loss = 0.8489 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 7965: loss = 0.8682 (0.236 sec/step)\n",
            "I0802 20:34:48.789446 139820296341376 learning.py:512] global step 7965: loss = 0.8682 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7966: loss = 0.6653 (0.238 sec/step)\n",
            "I0802 20:34:49.029217 139820296341376 learning.py:512] global step 7966: loss = 0.6653 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7967: loss = 0.9561 (0.244 sec/step)\n",
            "I0802 20:34:49.274949 139820296341376 learning.py:512] global step 7967: loss = 0.9561 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 7968: loss = 0.9656 (0.250 sec/step)\n",
            "I0802 20:34:49.526696 139820296341376 learning.py:512] global step 7968: loss = 0.9656 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 7969: loss = 0.8848 (0.243 sec/step)\n",
            "I0802 20:34:49.770713 139820296341376 learning.py:512] global step 7969: loss = 0.8848 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7970: loss = 0.9462 (0.238 sec/step)\n",
            "I0802 20:34:50.010622 139820296341376 learning.py:512] global step 7970: loss = 0.9462 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7971: loss = 0.6853 (0.243 sec/step)\n",
            "I0802 20:34:50.254831 139820296341376 learning.py:512] global step 7971: loss = 0.6853 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7972: loss = 1.1722 (0.238 sec/step)\n",
            "I0802 20:34:50.494327 139820296341376 learning.py:512] global step 7972: loss = 1.1722 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7973: loss = 0.8153 (0.245 sec/step)\n",
            "I0802 20:34:50.741080 139820296341376 learning.py:512] global step 7973: loss = 0.8153 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7974: loss = 0.8690 (0.236 sec/step)\n",
            "I0802 20:34:50.978813 139820296341376 learning.py:512] global step 7974: loss = 0.8690 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 7975: loss = 0.8174 (0.230 sec/step)\n",
            "I0802 20:34:51.210599 139820296341376 learning.py:512] global step 7975: loss = 0.8174 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 7976: loss = 0.9215 (0.231 sec/step)\n",
            "I0802 20:34:51.443561 139820296341376 learning.py:512] global step 7976: loss = 0.9215 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 7977: loss = 1.0450 (0.238 sec/step)\n",
            "I0802 20:34:51.683083 139820296341376 learning.py:512] global step 7977: loss = 1.0450 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7978: loss = 0.7500 (0.239 sec/step)\n",
            "I0802 20:34:51.923995 139820296341376 learning.py:512] global step 7978: loss = 0.7500 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7979: loss = 1.0583 (0.245 sec/step)\n",
            "I0802 20:34:52.170612 139820296341376 learning.py:512] global step 7979: loss = 1.0583 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 7980: loss = 0.9006 (0.229 sec/step)\n",
            "I0802 20:34:52.401039 139820296341376 learning.py:512] global step 7980: loss = 0.9006 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7981: loss = 0.8124 (0.240 sec/step)\n",
            "I0802 20:34:52.643102 139820296341376 learning.py:512] global step 7981: loss = 0.8124 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7982: loss = 0.9594 (0.243 sec/step)\n",
            "I0802 20:34:52.887623 139820296341376 learning.py:512] global step 7982: loss = 0.9594 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7983: loss = 0.7914 (0.243 sec/step)\n",
            "I0802 20:34:53.131881 139820296341376 learning.py:512] global step 7983: loss = 0.7914 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7984: loss = 0.8540 (0.243 sec/step)\n",
            "I0802 20:34:53.377040 139820296341376 learning.py:512] global step 7984: loss = 0.8540 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 7985: loss = 0.8340 (0.223 sec/step)\n",
            "I0802 20:34:53.601826 139820296341376 learning.py:512] global step 7985: loss = 0.8340 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 7986: loss = 0.8491 (0.225 sec/step)\n",
            "I0802 20:34:53.828731 139820296341376 learning.py:512] global step 7986: loss = 0.8491 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7987: loss = 0.7840 (0.235 sec/step)\n",
            "I0802 20:34:54.065754 139820296341376 learning.py:512] global step 7987: loss = 0.7840 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 7988: loss = 0.7862 (0.239 sec/step)\n",
            "I0802 20:34:54.306388 139820296341376 learning.py:512] global step 7988: loss = 0.7862 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7989: loss = 0.9096 (0.242 sec/step)\n",
            "I0802 20:34:54.550160 139820296341376 learning.py:512] global step 7989: loss = 0.9096 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 7990: loss = 0.9306 (0.238 sec/step)\n",
            "I0802 20:34:54.789547 139820296341376 learning.py:512] global step 7990: loss = 0.9306 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 7991: loss = 1.3974 (0.227 sec/step)\n",
            "I0802 20:34:55.018496 139820296341376 learning.py:512] global step 7991: loss = 1.3974 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 7992: loss = 0.9378 (0.234 sec/step)\n",
            "I0802 20:34:55.254122 139820296341376 learning.py:512] global step 7992: loss = 0.9378 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 7993: loss = 0.7853 (0.229 sec/step)\n",
            "I0802 20:34:55.484551 139820296341376 learning.py:512] global step 7993: loss = 0.7853 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 7994: loss = 1.0168 (0.226 sec/step)\n",
            "I0802 20:34:55.712828 139820296341376 learning.py:512] global step 7994: loss = 1.0168 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 7995: loss = 0.7567 (0.225 sec/step)\n",
            "I0802 20:34:55.939102 139820296341376 learning.py:512] global step 7995: loss = 0.7567 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 7996: loss = 0.7657 (0.240 sec/step)\n",
            "I0802 20:34:56.180337 139820296341376 learning.py:512] global step 7996: loss = 0.7657 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 7997: loss = 0.9371 (0.239 sec/step)\n",
            "I0802 20:34:56.420626 139820296341376 learning.py:512] global step 7997: loss = 0.9371 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 7998: loss = 0.6924 (0.228 sec/step)\n",
            "I0802 20:34:56.650670 139820296341376 learning.py:512] global step 7998: loss = 0.6924 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 7999: loss = 1.1328 (0.247 sec/step)\n",
            "I0802 20:34:56.901164 139820296341376 learning.py:512] global step 7999: loss = 1.1328 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8000: loss = 1.1255 (0.237 sec/step)\n",
            "I0802 20:34:57.139635 139820296341376 learning.py:512] global step 8000: loss = 1.1255 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8001: loss = 0.9883 (0.230 sec/step)\n",
            "I0802 20:34:57.370885 139820296341376 learning.py:512] global step 8001: loss = 0.9883 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8002: loss = 0.9219 (0.247 sec/step)\n",
            "I0802 20:34:57.619746 139820296341376 learning.py:512] global step 8002: loss = 0.9219 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8003: loss = 1.1571 (0.245 sec/step)\n",
            "I0802 20:34:57.866599 139820296341376 learning.py:512] global step 8003: loss = 1.1571 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8004: loss = 0.7454 (0.250 sec/step)\n",
            "I0802 20:34:58.117984 139820296341376 learning.py:512] global step 8004: loss = 0.7454 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8005: loss = 0.8146 (0.239 sec/step)\n",
            "I0802 20:34:58.358371 139820296341376 learning.py:512] global step 8005: loss = 0.8146 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8006: loss = 0.7296 (0.230 sec/step)\n",
            "I0802 20:34:58.589718 139820296341376 learning.py:512] global step 8006: loss = 0.7296 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8007: loss = 0.7050 (0.240 sec/step)\n",
            "I0802 20:34:58.830943 139820296341376 learning.py:512] global step 8007: loss = 0.7050 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8008: loss = 0.6748 (0.241 sec/step)\n",
            "I0802 20:34:59.073184 139820296341376 learning.py:512] global step 8008: loss = 0.6748 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8009: loss = 1.1041 (0.249 sec/step)\n",
            "I0802 20:34:59.323842 139820296341376 learning.py:512] global step 8009: loss = 1.1041 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8010: loss = 0.8075 (0.248 sec/step)\n",
            "I0802 20:34:59.573624 139820296341376 learning.py:512] global step 8010: loss = 0.8075 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8011: loss = 0.8812 (0.247 sec/step)\n",
            "I0802 20:34:59.822664 139820296341376 learning.py:512] global step 8011: loss = 0.8812 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8012: loss = 1.1123 (0.238 sec/step)\n",
            "I0802 20:35:00.062819 139820296341376 learning.py:512] global step 8012: loss = 1.1123 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8013: loss = 0.9305 (0.252 sec/step)\n",
            "I0802 20:35:00.316360 139820296341376 learning.py:512] global step 8013: loss = 0.9305 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8014: loss = 1.0270 (0.236 sec/step)\n",
            "I0802 20:35:00.554146 139820296341376 learning.py:512] global step 8014: loss = 1.0270 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8015: loss = 0.8188 (0.247 sec/step)\n",
            "I0802 20:35:00.802322 139820296341376 learning.py:512] global step 8015: loss = 0.8188 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8016: loss = 0.7734 (0.246 sec/step)\n",
            "I0802 20:35:01.049623 139820296341376 learning.py:512] global step 8016: loss = 0.7734 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8017: loss = 0.9306 (0.237 sec/step)\n",
            "I0802 20:35:01.287724 139820296341376 learning.py:512] global step 8017: loss = 0.9306 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8018: loss = 1.0348 (0.238 sec/step)\n",
            "I0802 20:35:01.526832 139820296341376 learning.py:512] global step 8018: loss = 1.0348 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8019: loss = 1.3430 (0.229 sec/step)\n",
            "I0802 20:35:01.757196 139820296341376 learning.py:512] global step 8019: loss = 1.3430 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8020: loss = 1.0845 (0.247 sec/step)\n",
            "I0802 20:35:02.005486 139820296341376 learning.py:512] global step 8020: loss = 1.0845 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8021: loss = 1.0284 (0.242 sec/step)\n",
            "I0802 20:35:02.249574 139820296341376 learning.py:512] global step 8021: loss = 1.0284 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8022: loss = 0.8007 (0.245 sec/step)\n",
            "I0802 20:35:02.496104 139820296341376 learning.py:512] global step 8022: loss = 0.8007 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8023: loss = 0.8225 (0.263 sec/step)\n",
            "I0802 20:35:02.761577 139820296341376 learning.py:512] global step 8023: loss = 0.8225 (0.263 sec/step)\n",
            "INFO:tensorflow:global step 8024: loss = 0.8969 (0.317 sec/step)\n",
            "I0802 20:35:03.082280 139820296341376 learning.py:512] global step 8024: loss = 0.8969 (0.317 sec/step)\n",
            "INFO:tensorflow:global step 8025: loss = 0.9998 (0.282 sec/step)\n",
            "I0802 20:35:03.367119 139820296341376 learning.py:512] global step 8025: loss = 0.9998 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 8026: loss = 0.8472 (0.238 sec/step)\n",
            "I0802 20:35:03.606181 139820296341376 learning.py:512] global step 8026: loss = 0.8472 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8027: loss = 0.9903 (0.245 sec/step)\n",
            "I0802 20:35:03.852650 139820296341376 learning.py:512] global step 8027: loss = 0.9903 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8028: loss = 0.9194 (0.243 sec/step)\n",
            "I0802 20:35:04.097557 139820296341376 learning.py:512] global step 8028: loss = 0.9194 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8029: loss = 0.8546 (0.239 sec/step)\n",
            "I0802 20:35:04.337790 139820296341376 learning.py:512] global step 8029: loss = 0.8546 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8030: loss = 1.0109 (0.235 sec/step)\n",
            "I0802 20:35:04.574246 139820296341376 learning.py:512] global step 8030: loss = 1.0109 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8031: loss = 0.7863 (0.234 sec/step)\n",
            "I0802 20:35:04.809716 139820296341376 learning.py:512] global step 8031: loss = 0.7863 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8032: loss = 1.0517 (0.246 sec/step)\n",
            "I0802 20:35:05.057651 139820296341376 learning.py:512] global step 8032: loss = 1.0517 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8033: loss = 1.0532 (0.237 sec/step)\n",
            "I0802 20:35:05.295608 139820296341376 learning.py:512] global step 8033: loss = 1.0532 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8034: loss = 0.8487 (0.232 sec/step)\n",
            "I0802 20:35:05.529625 139820296341376 learning.py:512] global step 8034: loss = 0.8487 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8035: loss = 0.9006 (0.248 sec/step)\n",
            "I0802 20:35:05.779180 139820296341376 learning.py:512] global step 8035: loss = 0.9006 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8036: loss = 1.0353 (0.242 sec/step)\n",
            "I0802 20:35:06.022627 139820296341376 learning.py:512] global step 8036: loss = 1.0353 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8037: loss = 0.7430 (0.226 sec/step)\n",
            "I0802 20:35:06.250012 139820296341376 learning.py:512] global step 8037: loss = 0.7430 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8038: loss = 1.1028 (0.227 sec/step)\n",
            "I0802 20:35:06.478279 139820296341376 learning.py:512] global step 8038: loss = 1.1028 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8039: loss = 0.7184 (0.238 sec/step)\n",
            "I0802 20:35:06.718004 139820296341376 learning.py:512] global step 8039: loss = 0.7184 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8040: loss = 0.9527 (0.250 sec/step)\n",
            "I0802 20:35:06.970074 139820296341376 learning.py:512] global step 8040: loss = 0.9527 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8041: loss = 0.7837 (0.241 sec/step)\n",
            "I0802 20:35:07.212704 139820296341376 learning.py:512] global step 8041: loss = 0.7837 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8042: loss = 0.6723 (0.232 sec/step)\n",
            "I0802 20:35:07.446085 139820296341376 learning.py:512] global step 8042: loss = 0.6723 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8043: loss = 0.6888 (0.242 sec/step)\n",
            "I0802 20:35:07.689661 139820296341376 learning.py:512] global step 8043: loss = 0.6888 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8044: loss = 0.9127 (0.240 sec/step)\n",
            "I0802 20:35:07.931383 139820296341376 learning.py:512] global step 8044: loss = 0.9127 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8045: loss = 0.8857 (0.251 sec/step)\n",
            "I0802 20:35:08.184400 139820296341376 learning.py:512] global step 8045: loss = 0.8857 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8046: loss = 0.8478 (0.235 sec/step)\n",
            "I0802 20:35:08.420343 139820296341376 learning.py:512] global step 8046: loss = 0.8478 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8047: loss = 1.2361 (0.239 sec/step)\n",
            "I0802 20:35:08.661061 139820296341376 learning.py:512] global step 8047: loss = 1.2361 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8048: loss = 1.1036 (0.236 sec/step)\n",
            "I0802 20:35:08.898788 139820296341376 learning.py:512] global step 8048: loss = 1.1036 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8049: loss = 0.9671 (0.238 sec/step)\n",
            "I0802 20:35:09.138382 139820296341376 learning.py:512] global step 8049: loss = 0.9671 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8050: loss = 1.0963 (0.225 sec/step)\n",
            "I0802 20:35:09.365181 139820296341376 learning.py:512] global step 8050: loss = 1.0963 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8051: loss = 1.1413 (0.234 sec/step)\n",
            "I0802 20:35:09.600517 139820296341376 learning.py:512] global step 8051: loss = 1.1413 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8052: loss = 0.9353 (0.241 sec/step)\n",
            "I0802 20:35:09.843129 139820296341376 learning.py:512] global step 8052: loss = 0.9353 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8053: loss = 0.6512 (0.245 sec/step)\n",
            "I0802 20:35:10.089306 139820296341376 learning.py:512] global step 8053: loss = 0.6512 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8054: loss = 0.8646 (0.229 sec/step)\n",
            "I0802 20:35:10.320238 139820296341376 learning.py:512] global step 8054: loss = 0.8646 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8055: loss = 0.9311 (0.225 sec/step)\n",
            "I0802 20:35:10.546821 139820296341376 learning.py:512] global step 8055: loss = 0.9311 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8056: loss = 1.0600 (0.251 sec/step)\n",
            "I0802 20:35:10.800474 139820296341376 learning.py:512] global step 8056: loss = 1.0600 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8057: loss = 0.7430 (0.241 sec/step)\n",
            "I0802 20:35:11.042812 139820296341376 learning.py:512] global step 8057: loss = 0.7430 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8058: loss = 0.9183 (0.223 sec/step)\n",
            "I0802 20:35:11.267260 139820296341376 learning.py:512] global step 8058: loss = 0.9183 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8059: loss = 0.9106 (0.236 sec/step)\n",
            "I0802 20:35:11.505073 139820296341376 learning.py:512] global step 8059: loss = 0.9106 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8060: loss = 1.0951 (0.245 sec/step)\n",
            "I0802 20:35:11.751469 139820296341376 learning.py:512] global step 8060: loss = 1.0951 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8061: loss = 0.8474 (0.244 sec/step)\n",
            "I0802 20:35:11.997027 139820296341376 learning.py:512] global step 8061: loss = 0.8474 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8062: loss = 0.8560 (0.236 sec/step)\n",
            "I0802 20:35:12.234469 139820296341376 learning.py:512] global step 8062: loss = 0.8560 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8063: loss = 0.9611 (0.225 sec/step)\n",
            "I0802 20:35:12.460601 139820296341376 learning.py:512] global step 8063: loss = 0.9611 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8064: loss = 0.7625 (0.242 sec/step)\n",
            "I0802 20:35:12.704044 139820296341376 learning.py:512] global step 8064: loss = 0.7625 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8065: loss = 0.8270 (0.245 sec/step)\n",
            "I0802 20:35:12.950880 139820296341376 learning.py:512] global step 8065: loss = 0.8270 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8066: loss = 1.2190 (0.222 sec/step)\n",
            "I0802 20:35:13.174556 139820296341376 learning.py:512] global step 8066: loss = 1.2190 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8067: loss = 1.3354 (0.234 sec/step)\n",
            "I0802 20:35:13.409540 139820296341376 learning.py:512] global step 8067: loss = 1.3354 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8068: loss = 1.4466 (0.224 sec/step)\n",
            "I0802 20:35:13.634541 139820296341376 learning.py:512] global step 8068: loss = 1.4466 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8069: loss = 0.8859 (0.227 sec/step)\n",
            "I0802 20:35:13.863313 139820296341376 learning.py:512] global step 8069: loss = 0.8859 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8070: loss = 0.8075 (0.242 sec/step)\n",
            "I0802 20:35:14.106420 139820296341376 learning.py:512] global step 8070: loss = 0.8075 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8071: loss = 0.9817 (0.242 sec/step)\n",
            "I0802 20:35:14.350224 139820296341376 learning.py:512] global step 8071: loss = 0.9817 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8072: loss = 1.0320 (0.236 sec/step)\n",
            "I0802 20:35:14.588108 139820296341376 learning.py:512] global step 8072: loss = 1.0320 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8073: loss = 0.8795 (0.250 sec/step)\n",
            "I0802 20:35:14.839220 139820296341376 learning.py:512] global step 8073: loss = 0.8795 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8074: loss = 0.9248 (0.236 sec/step)\n",
            "I0802 20:35:15.077387 139820296341376 learning.py:512] global step 8074: loss = 0.9248 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8075: loss = 1.1205 (0.243 sec/step)\n",
            "I0802 20:35:15.321377 139820296341376 learning.py:512] global step 8075: loss = 1.1205 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8076: loss = 1.0040 (0.222 sec/step)\n",
            "I0802 20:35:15.544697 139820296341376 learning.py:512] global step 8076: loss = 1.0040 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8077: loss = 0.9559 (0.225 sec/step)\n",
            "I0802 20:35:15.771450 139820296341376 learning.py:512] global step 8077: loss = 0.9559 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8078: loss = 1.2523 (0.241 sec/step)\n",
            "I0802 20:35:16.014343 139820296341376 learning.py:512] global step 8078: loss = 1.2523 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8079: loss = 0.8345 (0.238 sec/step)\n",
            "I0802 20:35:16.254511 139820296341376 learning.py:512] global step 8079: loss = 0.8345 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8080: loss = 0.8128 (0.239 sec/step)\n",
            "I0802 20:35:16.495309 139820296341376 learning.py:512] global step 8080: loss = 0.8128 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8081: loss = 0.9449 (0.223 sec/step)\n",
            "I0802 20:35:16.719911 139820296341376 learning.py:512] global step 8081: loss = 0.9449 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8082: loss = 0.7695 (0.248 sec/step)\n",
            "I0802 20:35:16.969393 139820296341376 learning.py:512] global step 8082: loss = 0.7695 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8083: loss = 0.9959 (0.245 sec/step)\n",
            "I0802 20:35:17.215998 139820296341376 learning.py:512] global step 8083: loss = 0.9959 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8084: loss = 1.0621 (0.235 sec/step)\n",
            "I0802 20:35:17.452661 139820296341376 learning.py:512] global step 8084: loss = 1.0621 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8085: loss = 1.0474 (0.240 sec/step)\n",
            "I0802 20:35:17.694477 139820296341376 learning.py:512] global step 8085: loss = 1.0474 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8086: loss = 1.1053 (0.251 sec/step)\n",
            "I0802 20:35:17.946595 139820296341376 learning.py:512] global step 8086: loss = 1.1053 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8087: loss = 0.8085 (0.240 sec/step)\n",
            "I0802 20:35:18.188100 139820296341376 learning.py:512] global step 8087: loss = 0.8085 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8088: loss = 0.8539 (0.235 sec/step)\n",
            "I0802 20:35:18.425079 139820296341376 learning.py:512] global step 8088: loss = 0.8539 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8089: loss = 1.0449 (0.230 sec/step)\n",
            "I0802 20:35:18.656055 139820296341376 learning.py:512] global step 8089: loss = 1.0449 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8090: loss = 0.7978 (0.240 sec/step)\n",
            "I0802 20:35:18.897934 139820296341376 learning.py:512] global step 8090: loss = 0.7978 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8091: loss = 0.9265 (0.243 sec/step)\n",
            "I0802 20:35:19.142390 139820296341376 learning.py:512] global step 8091: loss = 0.9265 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8092: loss = 0.6561 (0.241 sec/step)\n",
            "I0802 20:35:19.384787 139820296341376 learning.py:512] global step 8092: loss = 0.6561 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8093: loss = 0.9658 (0.230 sec/step)\n",
            "I0802 20:35:19.616451 139820296341376 learning.py:512] global step 8093: loss = 0.9658 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8094: loss = 0.9478 (0.242 sec/step)\n",
            "I0802 20:35:19.860098 139820296341376 learning.py:512] global step 8094: loss = 0.9478 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8095: loss = 0.7200 (0.239 sec/step)\n",
            "I0802 20:35:20.101235 139820296341376 learning.py:512] global step 8095: loss = 0.7200 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8096: loss = 0.7221 (0.241 sec/step)\n",
            "I0802 20:35:20.343956 139820296341376 learning.py:512] global step 8096: loss = 0.7221 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8097: loss = 0.8002 (0.231 sec/step)\n",
            "I0802 20:35:20.576614 139820296341376 learning.py:512] global step 8097: loss = 0.8002 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8098: loss = 1.1605 (0.224 sec/step)\n",
            "I0802 20:35:20.802185 139820296341376 learning.py:512] global step 8098: loss = 1.1605 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8099: loss = 0.8359 (0.247 sec/step)\n",
            "I0802 20:35:21.050676 139820296341376 learning.py:512] global step 8099: loss = 0.8359 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8100: loss = 0.8305 (0.241 sec/step)\n",
            "I0802 20:35:21.293553 139820296341376 learning.py:512] global step 8100: loss = 0.8305 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8101: loss = 0.7464 (0.235 sec/step)\n",
            "I0802 20:35:21.529432 139820296341376 learning.py:512] global step 8101: loss = 0.7464 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8102: loss = 0.9968 (0.241 sec/step)\n",
            "I0802 20:35:21.771340 139820296341376 learning.py:512] global step 8102: loss = 0.9968 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8103: loss = 0.7860 (0.230 sec/step)\n",
            "I0802 20:35:22.002542 139820296341376 learning.py:512] global step 8103: loss = 0.7860 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8104: loss = 1.1533 (0.237 sec/step)\n",
            "I0802 20:35:22.240565 139820296341376 learning.py:512] global step 8104: loss = 1.1533 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8105: loss = 0.7721 (0.238 sec/step)\n",
            "I0802 20:35:22.480043 139820296341376 learning.py:512] global step 8105: loss = 0.7721 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8106: loss = 0.7645 (0.244 sec/step)\n",
            "I0802 20:35:22.725285 139820296341376 learning.py:512] global step 8106: loss = 0.7645 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8107: loss = 1.1790 (0.250 sec/step)\n",
            "I0802 20:35:22.979932 139820296341376 learning.py:512] global step 8107: loss = 1.1790 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8108: loss = 0.6235 (0.245 sec/step)\n",
            "I0802 20:35:23.226901 139820296341376 learning.py:512] global step 8108: loss = 0.6235 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8109: loss = 0.8915 (0.235 sec/step)\n",
            "I0802 20:35:23.463261 139820296341376 learning.py:512] global step 8109: loss = 0.8915 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8110: loss = 0.8985 (0.242 sec/step)\n",
            "I0802 20:35:23.706736 139820296341376 learning.py:512] global step 8110: loss = 0.8985 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8111: loss = 0.9260 (0.226 sec/step)\n",
            "I0802 20:35:23.933977 139820296341376 learning.py:512] global step 8111: loss = 0.9260 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8112: loss = 0.6969 (0.240 sec/step)\n",
            "I0802 20:35:24.174957 139820296341376 learning.py:512] global step 8112: loss = 0.6969 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8113: loss = 0.9880 (0.229 sec/step)\n",
            "I0802 20:35:24.405598 139820296341376 learning.py:512] global step 8113: loss = 0.9880 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8114: loss = 0.8470 (0.224 sec/step)\n",
            "I0802 20:35:24.630610 139820296341376 learning.py:512] global step 8114: loss = 0.8470 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8115: loss = 0.8136 (0.241 sec/step)\n",
            "I0802 20:35:24.873349 139820296341376 learning.py:512] global step 8115: loss = 0.8136 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8116: loss = 0.8852 (0.239 sec/step)\n",
            "I0802 20:35:25.113555 139820296341376 learning.py:512] global step 8116: loss = 0.8852 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8117: loss = 0.9192 (0.220 sec/step)\n",
            "I0802 20:35:25.334750 139820296341376 learning.py:512] global step 8117: loss = 0.9192 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 8118: loss = 1.0175 (0.242 sec/step)\n",
            "I0802 20:35:25.577858 139820296341376 learning.py:512] global step 8118: loss = 1.0175 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8119: loss = 0.9206 (0.233 sec/step)\n",
            "I0802 20:35:25.812072 139820296341376 learning.py:512] global step 8119: loss = 0.9206 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8120: loss = 0.6627 (0.236 sec/step)\n",
            "I0802 20:35:26.049806 139820296341376 learning.py:512] global step 8120: loss = 0.6627 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8121: loss = 0.8161 (0.236 sec/step)\n",
            "I0802 20:35:26.287096 139820296341376 learning.py:512] global step 8121: loss = 0.8161 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8122: loss = 1.0372 (0.235 sec/step)\n",
            "I0802 20:35:26.523575 139820296341376 learning.py:512] global step 8122: loss = 1.0372 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8123: loss = 0.9932 (0.235 sec/step)\n",
            "I0802 20:35:26.759799 139820296341376 learning.py:512] global step 8123: loss = 0.9932 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8124: loss = 0.7354 (0.253 sec/step)\n",
            "I0802 20:35:27.014411 139820296341376 learning.py:512] global step 8124: loss = 0.7354 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8125: loss = 1.0089 (0.242 sec/step)\n",
            "I0802 20:35:27.257956 139820296341376 learning.py:512] global step 8125: loss = 1.0089 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8126: loss = 0.8023 (0.239 sec/step)\n",
            "I0802 20:35:27.498216 139820296341376 learning.py:512] global step 8126: loss = 0.8023 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8127: loss = 0.8057 (0.240 sec/step)\n",
            "I0802 20:35:27.739506 139820296341376 learning.py:512] global step 8127: loss = 0.8057 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8128: loss = 0.8246 (0.241 sec/step)\n",
            "I0802 20:35:27.981727 139820296341376 learning.py:512] global step 8128: loss = 0.8246 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8129: loss = 0.7680 (0.252 sec/step)\n",
            "I0802 20:35:28.235630 139820296341376 learning.py:512] global step 8129: loss = 0.7680 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8130: loss = 0.8884 (0.225 sec/step)\n",
            "I0802 20:35:28.462122 139820296341376 learning.py:512] global step 8130: loss = 0.8884 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8131: loss = 0.9581 (0.250 sec/step)\n",
            "I0802 20:35:28.713550 139820296341376 learning.py:512] global step 8131: loss = 0.9581 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8132: loss = 0.9500 (0.230 sec/step)\n",
            "I0802 20:35:28.945292 139820296341376 learning.py:512] global step 8132: loss = 0.9500 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8133: loss = 0.9481 (0.233 sec/step)\n",
            "I0802 20:35:29.179811 139820296341376 learning.py:512] global step 8133: loss = 0.9481 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8134: loss = 0.7696 (0.226 sec/step)\n",
            "I0802 20:35:29.407484 139820296341376 learning.py:512] global step 8134: loss = 0.7696 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8135: loss = 1.0804 (0.228 sec/step)\n",
            "I0802 20:35:29.636805 139820296341376 learning.py:512] global step 8135: loss = 1.0804 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8136: loss = 0.7159 (0.242 sec/step)\n",
            "I0802 20:35:29.880032 139820296341376 learning.py:512] global step 8136: loss = 0.7159 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8137: loss = 1.3044 (0.240 sec/step)\n",
            "I0802 20:35:30.121623 139820296341376 learning.py:512] global step 8137: loss = 1.3044 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8138: loss = 0.9914 (0.236 sec/step)\n",
            "I0802 20:35:30.359349 139820296341376 learning.py:512] global step 8138: loss = 0.9914 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8139: loss = 1.0194 (0.240 sec/step)\n",
            "I0802 20:35:30.601212 139820296341376 learning.py:512] global step 8139: loss = 1.0194 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8140: loss = 1.1129 (0.233 sec/step)\n",
            "I0802 20:35:30.835842 139820296341376 learning.py:512] global step 8140: loss = 1.1129 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8141: loss = 0.6849 (0.243 sec/step)\n",
            "I0802 20:35:31.080016 139820296341376 learning.py:512] global step 8141: loss = 0.6849 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8142: loss = 0.7473 (0.237 sec/step)\n",
            "I0802 20:35:31.318321 139820296341376 learning.py:512] global step 8142: loss = 0.7473 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8143: loss = 0.8529 (0.229 sec/step)\n",
            "I0802 20:35:31.548549 139820296341376 learning.py:512] global step 8143: loss = 0.8529 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8144: loss = 0.7620 (0.241 sec/step)\n",
            "I0802 20:35:31.791626 139820296341376 learning.py:512] global step 8144: loss = 0.7620 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8145: loss = 0.6708 (0.244 sec/step)\n",
            "I0802 20:35:32.037547 139820296341376 learning.py:512] global step 8145: loss = 0.6708 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8146: loss = 0.7015 (0.240 sec/step)\n",
            "I0802 20:35:32.278790 139820296341376 learning.py:512] global step 8146: loss = 0.7015 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8147: loss = 0.6756 (0.244 sec/step)\n",
            "I0802 20:35:32.524346 139820296341376 learning.py:512] global step 8147: loss = 0.6756 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8148: loss = 0.8063 (0.244 sec/step)\n",
            "I0802 20:35:32.770059 139820296341376 learning.py:512] global step 8148: loss = 0.8063 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8149: loss = 0.8207 (0.240 sec/step)\n",
            "I0802 20:35:33.011802 139820296341376 learning.py:512] global step 8149: loss = 0.8207 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8150: loss = 0.7938 (0.243 sec/step)\n",
            "I0802 20:35:33.256391 139820296341376 learning.py:512] global step 8150: loss = 0.7938 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8151: loss = 1.0894 (0.239 sec/step)\n",
            "I0802 20:35:33.497338 139820296341376 learning.py:512] global step 8151: loss = 1.0894 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8152: loss = 0.6365 (0.242 sec/step)\n",
            "I0802 20:35:33.741269 139820296341376 learning.py:512] global step 8152: loss = 0.6365 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8153: loss = 0.7896 (0.240 sec/step)\n",
            "I0802 20:35:33.982872 139820296341376 learning.py:512] global step 8153: loss = 0.7896 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8154: loss = 1.0041 (0.226 sec/step)\n",
            "I0802 20:35:34.210318 139820296341376 learning.py:512] global step 8154: loss = 1.0041 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8155: loss = 0.8715 (0.224 sec/step)\n",
            "I0802 20:35:34.435806 139820296341376 learning.py:512] global step 8155: loss = 0.8715 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8156: loss = 0.6314 (0.233 sec/step)\n",
            "I0802 20:35:34.670791 139820296341376 learning.py:512] global step 8156: loss = 0.6314 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8157: loss = 1.0425 (0.233 sec/step)\n",
            "I0802 20:35:34.905801 139820296341376 learning.py:512] global step 8157: loss = 1.0425 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8158: loss = 1.1764 (0.240 sec/step)\n",
            "I0802 20:35:35.147340 139820296341376 learning.py:512] global step 8158: loss = 1.1764 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8159: loss = 0.8590 (0.241 sec/step)\n",
            "I0802 20:35:35.390208 139820296341376 learning.py:512] global step 8159: loss = 0.8590 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8160: loss = 0.8785 (0.223 sec/step)\n",
            "I0802 20:35:35.614888 139820296341376 learning.py:512] global step 8160: loss = 0.8785 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8161: loss = 0.8603 (0.251 sec/step)\n",
            "I0802 20:35:35.867238 139820296341376 learning.py:512] global step 8161: loss = 0.8603 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8162: loss = 0.8307 (0.235 sec/step)\n",
            "I0802 20:35:36.104178 139820296341376 learning.py:512] global step 8162: loss = 0.8307 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8163: loss = 2.1965 (0.237 sec/step)\n",
            "I0802 20:35:36.342527 139820296341376 learning.py:512] global step 8163: loss = 2.1965 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8164: loss = 0.7399 (0.241 sec/step)\n",
            "I0802 20:35:36.584790 139820296341376 learning.py:512] global step 8164: loss = 0.7399 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8165: loss = 0.5983 (0.240 sec/step)\n",
            "I0802 20:35:36.825996 139820296341376 learning.py:512] global step 8165: loss = 0.5983 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8166: loss = 0.8750 (0.237 sec/step)\n",
            "I0802 20:35:37.063872 139820296341376 learning.py:512] global step 8166: loss = 0.8750 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8167: loss = 0.9590 (0.233 sec/step)\n",
            "I0802 20:35:37.298016 139820296341376 learning.py:512] global step 8167: loss = 0.9590 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8168: loss = 0.9316 (0.235 sec/step)\n",
            "I0802 20:35:37.534423 139820296341376 learning.py:512] global step 8168: loss = 0.9316 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8169: loss = 0.9938 (0.240 sec/step)\n",
            "I0802 20:35:37.775751 139820296341376 learning.py:512] global step 8169: loss = 0.9938 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8170: loss = 0.8779 (0.228 sec/step)\n",
            "I0802 20:35:38.005208 139820296341376 learning.py:512] global step 8170: loss = 0.8779 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8171: loss = 0.8019 (0.243 sec/step)\n",
            "I0802 20:35:38.249317 139820296341376 learning.py:512] global step 8171: loss = 0.8019 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8172: loss = 0.6236 (0.242 sec/step)\n",
            "I0802 20:35:38.493143 139820296341376 learning.py:512] global step 8172: loss = 0.6236 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8173: loss = 1.0887 (0.241 sec/step)\n",
            "I0802 20:35:38.735533 139820296341376 learning.py:512] global step 8173: loss = 1.0887 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8174: loss = 0.7342 (0.240 sec/step)\n",
            "I0802 20:35:38.980278 139820296341376 learning.py:512] global step 8174: loss = 0.7342 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8175: loss = 1.0976 (0.234 sec/step)\n",
            "I0802 20:35:39.216141 139820296341376 learning.py:512] global step 8175: loss = 1.0976 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8176: loss = 1.0834 (0.234 sec/step)\n",
            "I0802 20:35:39.451964 139820296341376 learning.py:512] global step 8176: loss = 1.0834 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8177: loss = 1.2319 (0.241 sec/step)\n",
            "I0802 20:35:39.694073 139820296341376 learning.py:512] global step 8177: loss = 1.2319 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8178: loss = 0.9968 (0.253 sec/step)\n",
            "I0802 20:35:39.948570 139820296341376 learning.py:512] global step 8178: loss = 0.9968 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8179: loss = 0.7604 (0.238 sec/step)\n",
            "I0802 20:35:40.188377 139820296341376 learning.py:512] global step 8179: loss = 0.7604 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8180: loss = 0.6790 (0.242 sec/step)\n",
            "I0802 20:35:40.431657 139820296341376 learning.py:512] global step 8180: loss = 0.6790 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8181: loss = 0.7187 (0.239 sec/step)\n",
            "I0802 20:35:40.672178 139820296341376 learning.py:512] global step 8181: loss = 0.7187 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8182: loss = 0.8337 (0.244 sec/step)\n",
            "I0802 20:35:40.918213 139820296341376 learning.py:512] global step 8182: loss = 0.8337 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8183: loss = 1.0298 (0.237 sec/step)\n",
            "I0802 20:35:41.156659 139820296341376 learning.py:512] global step 8183: loss = 1.0298 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8184: loss = 0.8375 (0.244 sec/step)\n",
            "I0802 20:35:41.401621 139820296341376 learning.py:512] global step 8184: loss = 0.8375 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8185: loss = 0.6734 (0.237 sec/step)\n",
            "I0802 20:35:41.640622 139820296341376 learning.py:512] global step 8185: loss = 0.6734 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8186: loss = 0.9311 (0.234 sec/step)\n",
            "I0802 20:35:41.875911 139820296341376 learning.py:512] global step 8186: loss = 0.9311 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8187: loss = 1.2731 (0.232 sec/step)\n",
            "I0802 20:35:42.109045 139820296341376 learning.py:512] global step 8187: loss = 1.2731 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8188: loss = 1.0901 (0.235 sec/step)\n",
            "I0802 20:35:42.345461 139820296341376 learning.py:512] global step 8188: loss = 1.0901 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8189: loss = 1.0560 (0.244 sec/step)\n",
            "I0802 20:35:42.591003 139820296341376 learning.py:512] global step 8189: loss = 1.0560 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8190: loss = 1.1502 (0.242 sec/step)\n",
            "I0802 20:35:42.834579 139820296341376 learning.py:512] global step 8190: loss = 1.1502 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8191: loss = 0.8422 (0.241 sec/step)\n",
            "I0802 20:35:43.077496 139820296341376 learning.py:512] global step 8191: loss = 0.8422 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8192: loss = 0.9758 (0.243 sec/step)\n",
            "I0802 20:35:43.321755 139820296341376 learning.py:512] global step 8192: loss = 0.9758 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8193: loss = 0.9791 (0.226 sec/step)\n",
            "I0802 20:35:43.549670 139820296341376 learning.py:512] global step 8193: loss = 0.9791 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8194: loss = 0.6867 (0.241 sec/step)\n",
            "I0802 20:35:43.791732 139820296341376 learning.py:512] global step 8194: loss = 0.6867 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8195: loss = 1.0344 (0.240 sec/step)\n",
            "I0802 20:35:44.032795 139820296341376 learning.py:512] global step 8195: loss = 1.0344 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8196: loss = 0.8801 (0.239 sec/step)\n",
            "I0802 20:35:44.273941 139820296341376 learning.py:512] global step 8196: loss = 0.8801 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8197: loss = 0.8114 (0.241 sec/step)\n",
            "I0802 20:35:44.516547 139820296341376 learning.py:512] global step 8197: loss = 0.8114 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8198: loss = 0.7302 (0.226 sec/step)\n",
            "I0802 20:35:44.744517 139820296341376 learning.py:512] global step 8198: loss = 0.7302 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8199: loss = 1.2373 (0.221 sec/step)\n",
            "I0802 20:35:44.966969 139820296341376 learning.py:512] global step 8199: loss = 1.2373 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 8200: loss = 0.8831 (0.237 sec/step)\n",
            "I0802 20:35:45.205151 139820296341376 learning.py:512] global step 8200: loss = 0.8831 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8201: loss = 0.9226 (0.251 sec/step)\n",
            "I0802 20:35:45.457264 139820296341376 learning.py:512] global step 8201: loss = 0.9226 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8202: loss = 0.8506 (0.228 sec/step)\n",
            "I0802 20:35:45.687361 139820296341376 learning.py:512] global step 8202: loss = 0.8506 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8203: loss = 1.2902 (0.239 sec/step)\n",
            "I0802 20:35:45.927460 139820296341376 learning.py:512] global step 8203: loss = 1.2902 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8204: loss = 0.6982 (0.235 sec/step)\n",
            "I0802 20:35:46.163746 139820296341376 learning.py:512] global step 8204: loss = 0.6982 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8205: loss = 0.7671 (0.227 sec/step)\n",
            "I0802 20:35:46.392748 139820296341376 learning.py:512] global step 8205: loss = 0.7671 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8206: loss = 1.0505 (0.243 sec/step)\n",
            "I0802 20:35:46.637953 139820296341376 learning.py:512] global step 8206: loss = 1.0505 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8207: loss = 0.8979 (0.234 sec/step)\n",
            "I0802 20:35:46.874121 139820296341376 learning.py:512] global step 8207: loss = 0.8979 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8208: loss = 0.8062 (0.223 sec/step)\n",
            "I0802 20:35:47.098301 139820296341376 learning.py:512] global step 8208: loss = 0.8062 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8209: loss = 1.4870 (0.233 sec/step)\n",
            "I0802 20:35:47.333075 139820296341376 learning.py:512] global step 8209: loss = 1.4870 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8210: loss = 0.9616 (0.246 sec/step)\n",
            "I0802 20:35:47.580131 139820296341376 learning.py:512] global step 8210: loss = 0.9616 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8211: loss = 0.7166 (0.240 sec/step)\n",
            "I0802 20:35:47.822207 139820296341376 learning.py:512] global step 8211: loss = 0.7166 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8212: loss = 0.6590 (0.225 sec/step)\n",
            "I0802 20:35:48.048761 139820296341376 learning.py:512] global step 8212: loss = 0.6590 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8213: loss = 0.7557 (0.243 sec/step)\n",
            "I0802 20:35:48.293076 139820296341376 learning.py:512] global step 8213: loss = 0.7557 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8214: loss = 0.8254 (0.244 sec/step)\n",
            "I0802 20:35:48.538865 139820296341376 learning.py:512] global step 8214: loss = 0.8254 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8215: loss = 0.8965 (0.240 sec/step)\n",
            "I0802 20:35:48.779988 139820296341376 learning.py:512] global step 8215: loss = 0.8965 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8216: loss = 1.1519 (0.236 sec/step)\n",
            "I0802 20:35:49.017598 139820296341376 learning.py:512] global step 8216: loss = 1.1519 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8217: loss = 0.7007 (0.246 sec/step)\n",
            "I0802 20:35:49.265144 139820296341376 learning.py:512] global step 8217: loss = 0.7007 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8218: loss = 0.9852 (0.240 sec/step)\n",
            "I0802 20:35:49.507020 139820296341376 learning.py:512] global step 8218: loss = 0.9852 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8219: loss = 1.0711 (0.238 sec/step)\n",
            "I0802 20:35:49.746861 139820296341376 learning.py:512] global step 8219: loss = 1.0711 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8220: loss = 0.9619 (0.241 sec/step)\n",
            "I0802 20:35:49.989368 139820296341376 learning.py:512] global step 8220: loss = 0.9619 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8221: loss = 0.9501 (0.236 sec/step)\n",
            "I0802 20:35:50.226685 139820296341376 learning.py:512] global step 8221: loss = 0.9501 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8222: loss = 0.8773 (0.240 sec/step)\n",
            "I0802 20:35:50.468594 139820296341376 learning.py:512] global step 8222: loss = 0.8773 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8223: loss = 0.8822 (0.248 sec/step)\n",
            "I0802 20:35:50.718465 139820296341376 learning.py:512] global step 8223: loss = 0.8822 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8224: loss = 0.9692 (0.242 sec/step)\n",
            "I0802 20:35:50.962237 139820296341376 learning.py:512] global step 8224: loss = 0.9692 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8225: loss = 0.8617 (0.248 sec/step)\n",
            "I0802 20:35:51.211330 139820296341376 learning.py:512] global step 8225: loss = 0.8617 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8226: loss = 0.6420 (0.224 sec/step)\n",
            "I0802 20:35:51.436823 139820296341376 learning.py:512] global step 8226: loss = 0.6420 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8227: loss = 0.9090 (0.245 sec/step)\n",
            "I0802 20:35:51.683785 139820296341376 learning.py:512] global step 8227: loss = 0.9090 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8228: loss = 0.7800 (0.233 sec/step)\n",
            "I0802 20:35:51.918173 139820296341376 learning.py:512] global step 8228: loss = 0.7800 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8229: loss = 0.6941 (0.242 sec/step)\n",
            "I0802 20:35:52.162036 139820296341376 learning.py:512] global step 8229: loss = 0.6941 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8230: loss = 0.8337 (0.248 sec/step)\n",
            "I0802 20:35:52.411374 139820296341376 learning.py:512] global step 8230: loss = 0.8337 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8231: loss = 0.8733 (0.248 sec/step)\n",
            "I0802 20:35:52.660370 139820296341376 learning.py:512] global step 8231: loss = 0.8733 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8232: loss = 1.0905 (0.236 sec/step)\n",
            "I0802 20:35:52.897292 139820296341376 learning.py:512] global step 8232: loss = 1.0905 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8233: loss = 0.9572 (0.230 sec/step)\n",
            "I0802 20:35:53.128426 139820296341376 learning.py:512] global step 8233: loss = 0.9572 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8234: loss = 0.7820 (0.227 sec/step)\n",
            "I0802 20:35:53.357319 139820296341376 learning.py:512] global step 8234: loss = 0.7820 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8235: loss = 0.8485 (0.225 sec/step)\n",
            "I0802 20:35:53.584050 139820296341376 learning.py:512] global step 8235: loss = 0.8485 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8236: loss = 0.6702 (0.240 sec/step)\n",
            "I0802 20:35:53.825139 139820296341376 learning.py:512] global step 8236: loss = 0.6702 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8237: loss = 1.2886 (0.240 sec/step)\n",
            "I0802 20:35:54.066727 139820296341376 learning.py:512] global step 8237: loss = 1.2886 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8238: loss = 0.8013 (0.230 sec/step)\n",
            "I0802 20:35:54.298233 139820296341376 learning.py:512] global step 8238: loss = 0.8013 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8239: loss = 0.9067 (0.237 sec/step)\n",
            "I0802 20:35:54.537130 139820296341376 learning.py:512] global step 8239: loss = 0.9067 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8240: loss = 1.0361 (0.240 sec/step)\n",
            "I0802 20:35:54.778357 139820296341376 learning.py:512] global step 8240: loss = 1.0361 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8241: loss = 1.0077 (0.235 sec/step)\n",
            "I0802 20:35:55.015046 139820296341376 learning.py:512] global step 8241: loss = 1.0077 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8242: loss = 1.4112 (0.246 sec/step)\n",
            "I0802 20:35:55.262848 139820296341376 learning.py:512] global step 8242: loss = 1.4112 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8243: loss = 1.0513 (0.242 sec/step)\n",
            "I0802 20:35:55.506120 139820296341376 learning.py:512] global step 8243: loss = 1.0513 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8244: loss = 0.7567 (0.237 sec/step)\n",
            "I0802 20:35:55.744125 139820296341376 learning.py:512] global step 8244: loss = 0.7567 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8245: loss = 0.8392 (0.241 sec/step)\n",
            "I0802 20:35:55.986418 139820296341376 learning.py:512] global step 8245: loss = 0.8392 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8246: loss = 0.8977 (0.245 sec/step)\n",
            "I0802 20:35:56.232313 139820296341376 learning.py:512] global step 8246: loss = 0.8977 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8247: loss = 0.8297 (0.242 sec/step)\n",
            "I0802 20:35:56.475961 139820296341376 learning.py:512] global step 8247: loss = 0.8297 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8248: loss = 0.7886 (0.241 sec/step)\n",
            "I0802 20:35:56.718838 139820296341376 learning.py:512] global step 8248: loss = 0.7886 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8249: loss = 0.8234 (0.227 sec/step)\n",
            "I0802 20:35:56.946797 139820296341376 learning.py:512] global step 8249: loss = 0.8234 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8250: loss = 1.1222 (0.237 sec/step)\n",
            "I0802 20:35:57.185635 139820296341376 learning.py:512] global step 8250: loss = 1.1222 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8251: loss = 0.7689 (0.238 sec/step)\n",
            "I0802 20:35:57.424807 139820296341376 learning.py:512] global step 8251: loss = 0.7689 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8252: loss = 1.1198 (0.243 sec/step)\n",
            "I0802 20:35:57.669348 139820296341376 learning.py:512] global step 8252: loss = 1.1198 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8253: loss = 1.0434 (0.240 sec/step)\n",
            "I0802 20:35:57.910644 139820296341376 learning.py:512] global step 8253: loss = 1.0434 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8254: loss = 0.7951 (0.247 sec/step)\n",
            "I0802 20:35:58.158661 139820296341376 learning.py:512] global step 8254: loss = 0.7951 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8255: loss = 0.9384 (0.243 sec/step)\n",
            "I0802 20:35:58.403178 139820296341376 learning.py:512] global step 8255: loss = 0.9384 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8256: loss = 0.7068 (0.225 sec/step)\n",
            "I0802 20:35:58.630213 139820296341376 learning.py:512] global step 8256: loss = 0.7068 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8257: loss = 0.7901 (0.221 sec/step)\n",
            "I0802 20:35:58.852851 139820296341376 learning.py:512] global step 8257: loss = 0.7901 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 8258: loss = 0.6647 (0.233 sec/step)\n",
            "I0802 20:35:59.087014 139820296341376 learning.py:512] global step 8258: loss = 0.6647 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8259: loss = 0.7366 (0.251 sec/step)\n",
            "I0802 20:35:59.339484 139820296341376 learning.py:512] global step 8259: loss = 0.7366 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8260: loss = 0.8105 (0.238 sec/step)\n",
            "I0802 20:35:59.579100 139820296341376 learning.py:512] global step 8260: loss = 0.8105 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8261: loss = 0.7815 (0.245 sec/step)\n",
            "I0802 20:35:59.825455 139820296341376 learning.py:512] global step 8261: loss = 0.7815 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8262: loss = 1.0058 (0.239 sec/step)\n",
            "I0802 20:36:00.066189 139820296341376 learning.py:512] global step 8262: loss = 1.0058 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8263: loss = 0.9536 (0.243 sec/step)\n",
            "I0802 20:36:00.310819 139820296341376 learning.py:512] global step 8263: loss = 0.9536 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8264: loss = 0.8169 (0.237 sec/step)\n",
            "I0802 20:36:00.549760 139820296341376 learning.py:512] global step 8264: loss = 0.8169 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8265: loss = 1.1898 (0.225 sec/step)\n",
            "I0802 20:36:00.776336 139820296341376 learning.py:512] global step 8265: loss = 1.1898 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8266: loss = 1.0152 (0.242 sec/step)\n",
            "I0802 20:36:01.020114 139820296341376 learning.py:512] global step 8266: loss = 1.0152 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8267: loss = 1.0213 (0.231 sec/step)\n",
            "I0802 20:36:01.252481 139820296341376 learning.py:512] global step 8267: loss = 1.0213 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8268: loss = 0.8632 (0.244 sec/step)\n",
            "I0802 20:36:01.498046 139820296341376 learning.py:512] global step 8268: loss = 0.8632 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8269: loss = 0.9457 (0.241 sec/step)\n",
            "I0802 20:36:01.742590 139820296341376 learning.py:512] global step 8269: loss = 0.9457 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8270: loss = 0.7791 (0.226 sec/step)\n",
            "I0802 20:36:01.970861 139820296341376 learning.py:512] global step 8270: loss = 0.7791 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8271: loss = 0.8911 (0.242 sec/step)\n",
            "I0802 20:36:02.214390 139820296341376 learning.py:512] global step 8271: loss = 0.8911 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8272: loss = 1.1034 (0.239 sec/step)\n",
            "I0802 20:36:02.455247 139820296341376 learning.py:512] global step 8272: loss = 1.1034 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8273: loss = 0.9893 (0.238 sec/step)\n",
            "I0802 20:36:02.694729 139820296341376 learning.py:512] global step 8273: loss = 0.9893 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8274: loss = 1.5280 (0.239 sec/step)\n",
            "I0802 20:36:02.935330 139820296341376 learning.py:512] global step 8274: loss = 1.5280 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8275: loss = 0.8780 (0.241 sec/step)\n",
            "I0802 20:36:03.177596 139820296341376 learning.py:512] global step 8275: loss = 0.8780 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8276: loss = 0.8302 (0.243 sec/step)\n",
            "I0802 20:36:03.422074 139820296341376 learning.py:512] global step 8276: loss = 0.8302 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8277: loss = 0.7306 (0.237 sec/step)\n",
            "I0802 20:36:03.660889 139820296341376 learning.py:512] global step 8277: loss = 0.7306 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8278: loss = 0.8157 (0.237 sec/step)\n",
            "I0802 20:36:03.899137 139820296341376 learning.py:512] global step 8278: loss = 0.8157 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8279: loss = 0.8146 (0.239 sec/step)\n",
            "I0802 20:36:04.139541 139820296341376 learning.py:512] global step 8279: loss = 0.8146 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8280: loss = 1.0270 (0.231 sec/step)\n",
            "I0802 20:36:04.372447 139820296341376 learning.py:512] global step 8280: loss = 1.0270 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8281: loss = 0.9571 (0.238 sec/step)\n",
            "I0802 20:36:04.612332 139820296341376 learning.py:512] global step 8281: loss = 0.9571 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8282: loss = 0.7482 (0.245 sec/step)\n",
            "I0802 20:36:04.858850 139820296341376 learning.py:512] global step 8282: loss = 0.7482 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8283: loss = 0.9174 (0.238 sec/step)\n",
            "I0802 20:36:05.097913 139820296341376 learning.py:512] global step 8283: loss = 0.9174 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8284: loss = 1.0196 (0.234 sec/step)\n",
            "I0802 20:36:05.334372 139820296341376 learning.py:512] global step 8284: loss = 1.0196 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8285: loss = 0.7870 (0.242 sec/step)\n",
            "I0802 20:36:05.577715 139820296341376 learning.py:512] global step 8285: loss = 0.7870 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8286: loss = 1.0111 (0.233 sec/step)\n",
            "I0802 20:36:05.811735 139820296341376 learning.py:512] global step 8286: loss = 1.0111 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8287: loss = 0.6781 (0.240 sec/step)\n",
            "I0802 20:36:06.052973 139820296341376 learning.py:512] global step 8287: loss = 0.6781 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8288: loss = 0.7073 (0.244 sec/step)\n",
            "I0802 20:36:06.297943 139820296341376 learning.py:512] global step 8288: loss = 0.7073 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8289: loss = 0.7169 (0.244 sec/step)\n",
            "I0802 20:36:06.543706 139820296341376 learning.py:512] global step 8289: loss = 0.7169 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8290: loss = 0.8234 (0.241 sec/step)\n",
            "I0802 20:36:06.786613 139820296341376 learning.py:512] global step 8290: loss = 0.8234 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8291: loss = 0.8790 (0.227 sec/step)\n",
            "I0802 20:36:07.014848 139820296341376 learning.py:512] global step 8291: loss = 0.8790 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8292: loss = 0.8585 (0.244 sec/step)\n",
            "I0802 20:36:07.260666 139820296341376 learning.py:512] global step 8292: loss = 0.8585 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8293: loss = 0.9140 (0.250 sec/step)\n",
            "I0802 20:36:07.512533 139820296341376 learning.py:512] global step 8293: loss = 0.9140 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8294: loss = 0.9468 (0.224 sec/step)\n",
            "I0802 20:36:07.737996 139820296341376 learning.py:512] global step 8294: loss = 0.9468 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8295: loss = 0.7101 (0.239 sec/step)\n",
            "I0802 20:36:07.978097 139820296341376 learning.py:512] global step 8295: loss = 0.7101 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8296: loss = 0.8997 (0.237 sec/step)\n",
            "I0802 20:36:08.217087 139820296341376 learning.py:512] global step 8296: loss = 0.8997 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8297: loss = 0.7825 (0.243 sec/step)\n",
            "I0802 20:36:08.462116 139820296341376 learning.py:512] global step 8297: loss = 0.7825 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8298: loss = 0.7571 (0.242 sec/step)\n",
            "I0802 20:36:08.706030 139820296341376 learning.py:512] global step 8298: loss = 0.7571 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8299: loss = 0.9258 (0.240 sec/step)\n",
            "I0802 20:36:08.947104 139820296341376 learning.py:512] global step 8299: loss = 0.9258 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8300: loss = 0.9078 (0.226 sec/step)\n",
            "I0802 20:36:09.174137 139820296341376 learning.py:512] global step 8300: loss = 0.9078 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8301: loss = 0.9518 (0.244 sec/step)\n",
            "I0802 20:36:09.419652 139820296341376 learning.py:512] global step 8301: loss = 0.9518 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8302: loss = 0.7728 (0.228 sec/step)\n",
            "I0802 20:36:09.649628 139820296341376 learning.py:512] global step 8302: loss = 0.7728 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8303: loss = 0.8251 (0.240 sec/step)\n",
            "I0802 20:36:09.891431 139820296341376 learning.py:512] global step 8303: loss = 0.8251 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8304: loss = 0.7891 (0.238 sec/step)\n",
            "I0802 20:36:10.131274 139820296341376 learning.py:512] global step 8304: loss = 0.7891 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8305: loss = 1.0926 (0.245 sec/step)\n",
            "I0802 20:36:10.377462 139820296341376 learning.py:512] global step 8305: loss = 1.0926 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8306: loss = 0.8666 (0.244 sec/step)\n",
            "I0802 20:36:10.622561 139820296341376 learning.py:512] global step 8306: loss = 0.8666 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8307: loss = 0.8364 (0.228 sec/step)\n",
            "I0802 20:36:10.852534 139820296341376 learning.py:512] global step 8307: loss = 0.8364 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8308: loss = 0.9551 (0.232 sec/step)\n",
            "I0802 20:36:11.085567 139820296341376 learning.py:512] global step 8308: loss = 0.9551 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8309: loss = 1.0842 (0.248 sec/step)\n",
            "I0802 20:36:11.334785 139820296341376 learning.py:512] global step 8309: loss = 1.0842 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8310: loss = 1.1197 (0.241 sec/step)\n",
            "I0802 20:36:11.577438 139820296341376 learning.py:512] global step 8310: loss = 1.1197 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8311: loss = 1.0025 (0.227 sec/step)\n",
            "I0802 20:36:11.806578 139820296341376 learning.py:512] global step 8311: loss = 1.0025 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8312: loss = 0.8728 (0.235 sec/step)\n",
            "I0802 20:36:12.042954 139820296341376 learning.py:512] global step 8312: loss = 0.8728 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8313: loss = 0.8925 (0.227 sec/step)\n",
            "I0802 20:36:12.271595 139820296341376 learning.py:512] global step 8313: loss = 0.8925 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8314: loss = 0.9539 (0.247 sec/step)\n",
            "I0802 20:36:12.520528 139820296341376 learning.py:512] global step 8314: loss = 0.9539 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8315: loss = 0.9529 (0.220 sec/step)\n",
            "I0802 20:36:12.742136 139820296341376 learning.py:512] global step 8315: loss = 0.9529 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 8316: loss = 0.7828 (0.238 sec/step)\n",
            "I0802 20:36:12.981467 139820296341376 learning.py:512] global step 8316: loss = 0.7828 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8317: loss = 0.7658 (0.228 sec/step)\n",
            "I0802 20:36:13.210535 139820296341376 learning.py:512] global step 8317: loss = 0.7658 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8318: loss = 1.1363 (0.243 sec/step)\n",
            "I0802 20:36:13.454626 139820296341376 learning.py:512] global step 8318: loss = 1.1363 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8319: loss = 0.8883 (0.242 sec/step)\n",
            "I0802 20:36:13.698060 139820296341376 learning.py:512] global step 8319: loss = 0.8883 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8320: loss = 0.8736 (0.245 sec/step)\n",
            "I0802 20:36:13.944429 139820296341376 learning.py:512] global step 8320: loss = 0.8736 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8321: loss = 0.8712 (0.240 sec/step)\n",
            "I0802 20:36:14.186398 139820296341376 learning.py:512] global step 8321: loss = 0.8712 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8322: loss = 0.9574 (0.241 sec/step)\n",
            "I0802 20:36:14.429408 139820296341376 learning.py:512] global step 8322: loss = 0.9574 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8323: loss = 0.8220 (0.245 sec/step)\n",
            "I0802 20:36:14.675324 139820296341376 learning.py:512] global step 8323: loss = 0.8220 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8324: loss = 0.8363 (0.227 sec/step)\n",
            "I0802 20:36:14.904173 139820296341376 learning.py:512] global step 8324: loss = 0.8363 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8325: loss = 0.9584 (0.236 sec/step)\n",
            "I0802 20:36:15.141985 139820296341376 learning.py:512] global step 8325: loss = 0.9584 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8326: loss = 1.0389 (0.244 sec/step)\n",
            "I0802 20:36:15.387671 139820296341376 learning.py:512] global step 8326: loss = 1.0389 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8327: loss = 0.7149 (0.244 sec/step)\n",
            "I0802 20:36:15.633372 139820296341376 learning.py:512] global step 8327: loss = 0.7149 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8328: loss = 0.6444 (0.243 sec/step)\n",
            "I0802 20:36:15.879209 139820296341376 learning.py:512] global step 8328: loss = 0.6444 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8329: loss = 1.0486 (0.232 sec/step)\n",
            "I0802 20:36:16.113229 139820296341376 learning.py:512] global step 8329: loss = 1.0486 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8330: loss = 0.7156 (0.242 sec/step)\n",
            "I0802 20:36:16.357319 139820296341376 learning.py:512] global step 8330: loss = 0.7156 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8331: loss = 0.8397 (0.229 sec/step)\n",
            "I0802 20:36:16.588390 139820296341376 learning.py:512] global step 8331: loss = 0.8397 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8332: loss = 1.0199 (0.241 sec/step)\n",
            "I0802 20:36:16.831255 139820296341376 learning.py:512] global step 8332: loss = 1.0199 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8333: loss = 1.0035 (0.248 sec/step)\n",
            "I0802 20:36:17.080561 139820296341376 learning.py:512] global step 8333: loss = 1.0035 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8334: loss = 0.9433 (0.227 sec/step)\n",
            "I0802 20:36:17.309016 139820296341376 learning.py:512] global step 8334: loss = 0.9433 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8335: loss = 0.7480 (0.245 sec/step)\n",
            "I0802 20:36:17.555651 139820296341376 learning.py:512] global step 8335: loss = 0.7480 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8336: loss = 0.9123 (0.228 sec/step)\n",
            "I0802 20:36:17.785049 139820296341376 learning.py:512] global step 8336: loss = 0.9123 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8337: loss = 0.6554 (0.237 sec/step)\n",
            "I0802 20:36:18.023859 139820296341376 learning.py:512] global step 8337: loss = 0.6554 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8338: loss = 0.9524 (0.239 sec/step)\n",
            "I0802 20:36:18.264785 139820296341376 learning.py:512] global step 8338: loss = 0.9524 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8339: loss = 1.2640 (0.240 sec/step)\n",
            "I0802 20:36:18.506991 139820296341376 learning.py:512] global step 8339: loss = 1.2640 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8340: loss = 1.2348 (0.243 sec/step)\n",
            "I0802 20:36:18.752658 139820296341376 learning.py:512] global step 8340: loss = 1.2348 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8341: loss = 0.9761 (0.291 sec/step)\n",
            "I0802 20:36:19.053426 139820296341376 learning.py:512] global step 8341: loss = 0.9761 (0.291 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 8341.\n",
            "I0802 20:36:19.122175 139815876826880 supervisor.py:1050] Recording summary at step 8341.\n",
            "INFO:tensorflow:global step 8342: loss = 0.9090 (0.247 sec/step)\n",
            "I0802 20:36:19.303349 139820296341376 learning.py:512] global step 8342: loss = 0.9090 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8343: loss = 0.8683 (0.230 sec/step)\n",
            "I0802 20:36:19.534914 139820296341376 learning.py:512] global step 8343: loss = 0.8683 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8344: loss = 0.8294 (0.238 sec/step)\n",
            "I0802 20:36:19.774391 139820296341376 learning.py:512] global step 8344: loss = 0.8294 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8345: loss = 1.0430 (0.240 sec/step)\n",
            "I0802 20:36:20.016301 139820296341376 learning.py:512] global step 8345: loss = 1.0430 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8346: loss = 0.7222 (0.240 sec/step)\n",
            "I0802 20:36:20.257983 139820296341376 learning.py:512] global step 8346: loss = 0.7222 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8347: loss = 0.9780 (0.220 sec/step)\n",
            "I0802 20:36:20.479870 139820296341376 learning.py:512] global step 8347: loss = 0.9780 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 8348: loss = 1.0103 (0.235 sec/step)\n",
            "I0802 20:36:20.716361 139820296341376 learning.py:512] global step 8348: loss = 1.0103 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8349: loss = 0.7133 (0.240 sec/step)\n",
            "I0802 20:36:20.957271 139820296341376 learning.py:512] global step 8349: loss = 0.7133 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8350: loss = 0.9210 (0.236 sec/step)\n",
            "I0802 20:36:21.195062 139820296341376 learning.py:512] global step 8350: loss = 0.9210 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8351: loss = 1.3422 (0.231 sec/step)\n",
            "I0802 20:36:21.427282 139820296341376 learning.py:512] global step 8351: loss = 1.3422 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8352: loss = 0.9562 (0.238 sec/step)\n",
            "I0802 20:36:21.666664 139820296341376 learning.py:512] global step 8352: loss = 0.9562 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8353: loss = 0.7627 (0.232 sec/step)\n",
            "I0802 20:36:21.901720 139820296341376 learning.py:512] global step 8353: loss = 0.7627 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8354: loss = 0.6564 (0.234 sec/step)\n",
            "I0802 20:36:22.137212 139820296341376 learning.py:512] global step 8354: loss = 0.6564 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8355: loss = 0.7221 (0.242 sec/step)\n",
            "I0802 20:36:22.386989 139820296341376 learning.py:512] global step 8355: loss = 0.7221 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8356: loss = 0.8029 (0.239 sec/step)\n",
            "I0802 20:36:22.627602 139820296341376 learning.py:512] global step 8356: loss = 0.8029 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8357: loss = 1.7192 (0.235 sec/step)\n",
            "I0802 20:36:22.864346 139820296341376 learning.py:512] global step 8357: loss = 1.7192 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8358: loss = 1.0057 (0.239 sec/step)\n",
            "I0802 20:36:23.104865 139820296341376 learning.py:512] global step 8358: loss = 1.0057 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8359: loss = 0.7103 (0.240 sec/step)\n",
            "I0802 20:36:23.346828 139820296341376 learning.py:512] global step 8359: loss = 0.7103 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8360: loss = 0.9455 (0.239 sec/step)\n",
            "I0802 20:36:23.587400 139820296341376 learning.py:512] global step 8360: loss = 0.9455 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8361: loss = 0.7511 (0.235 sec/step)\n",
            "I0802 20:36:23.823658 139820296341376 learning.py:512] global step 8361: loss = 0.7511 (0.235 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 4.17499\n",
            "I0802 20:36:23.879799 139815885219584 supervisor.py:1099] global_step/sec: 4.17499\n",
            "INFO:tensorflow:global step 8362: loss = 0.8985 (0.239 sec/step)\n",
            "I0802 20:36:24.064037 139820296341376 learning.py:512] global step 8362: loss = 0.8985 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8363: loss = 0.7502 (0.234 sec/step)\n",
            "I0802 20:36:24.299555 139820296341376 learning.py:512] global step 8363: loss = 0.7502 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8364: loss = 0.8337 (0.241 sec/step)\n",
            "I0802 20:36:24.542229 139820296341376 learning.py:512] global step 8364: loss = 0.8337 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8365: loss = 0.8233 (0.240 sec/step)\n",
            "I0802 20:36:24.783910 139820296341376 learning.py:512] global step 8365: loss = 0.8233 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8366: loss = 0.6161 (0.242 sec/step)\n",
            "I0802 20:36:25.027603 139820296341376 learning.py:512] global step 8366: loss = 0.6161 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8367: loss = 0.7512 (0.230 sec/step)\n",
            "I0802 20:36:25.259520 139820296341376 learning.py:512] global step 8367: loss = 0.7512 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8368: loss = 0.7321 (0.229 sec/step)\n",
            "I0802 20:36:25.490172 139820296341376 learning.py:512] global step 8368: loss = 0.7321 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8369: loss = 0.9385 (0.227 sec/step)\n",
            "I0802 20:36:25.718970 139820296341376 learning.py:512] global step 8369: loss = 0.9385 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8370: loss = 0.9223 (0.239 sec/step)\n",
            "I0802 20:36:25.959611 139820296341376 learning.py:512] global step 8370: loss = 0.9223 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8371: loss = 0.9798 (0.226 sec/step)\n",
            "I0802 20:36:26.186832 139820296341376 learning.py:512] global step 8371: loss = 0.9798 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8372: loss = 0.7083 (0.237 sec/step)\n",
            "I0802 20:36:26.425098 139820296341376 learning.py:512] global step 8372: loss = 0.7083 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8373: loss = 0.7540 (0.219 sec/step)\n",
            "I0802 20:36:26.645565 139820296341376 learning.py:512] global step 8373: loss = 0.7540 (0.219 sec/step)\n",
            "INFO:tensorflow:global step 8374: loss = 0.9282 (0.234 sec/step)\n",
            "I0802 20:36:26.880570 139820296341376 learning.py:512] global step 8374: loss = 0.9282 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8375: loss = 0.7749 (0.250 sec/step)\n",
            "I0802 20:36:27.131550 139820296341376 learning.py:512] global step 8375: loss = 0.7749 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8376: loss = 1.0584 (0.240 sec/step)\n",
            "I0802 20:36:27.372644 139820296341376 learning.py:512] global step 8376: loss = 1.0584 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8377: loss = 0.7212 (0.246 sec/step)\n",
            "I0802 20:36:27.621635 139820296341376 learning.py:512] global step 8377: loss = 0.7212 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8378: loss = 0.7530 (0.237 sec/step)\n",
            "I0802 20:36:27.860998 139820296341376 learning.py:512] global step 8378: loss = 0.7530 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8379: loss = 0.8816 (0.241 sec/step)\n",
            "I0802 20:36:28.103541 139820296341376 learning.py:512] global step 8379: loss = 0.8816 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8380: loss = 0.9306 (0.239 sec/step)\n",
            "I0802 20:36:28.343609 139820296341376 learning.py:512] global step 8380: loss = 0.9306 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8381: loss = 0.7929 (0.221 sec/step)\n",
            "I0802 20:36:28.566033 139820296341376 learning.py:512] global step 8381: loss = 0.7929 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 8382: loss = 0.9969 (0.238 sec/step)\n",
            "I0802 20:36:28.805506 139820296341376 learning.py:512] global step 8382: loss = 0.9969 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8383: loss = 0.9428 (0.254 sec/step)\n",
            "I0802 20:36:29.060609 139820296341376 learning.py:512] global step 8383: loss = 0.9428 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8384: loss = 0.8370 (0.232 sec/step)\n",
            "I0802 20:36:29.294077 139820296341376 learning.py:512] global step 8384: loss = 0.8370 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8385: loss = 0.7020 (0.239 sec/step)\n",
            "I0802 20:36:29.534296 139820296341376 learning.py:512] global step 8385: loss = 0.7020 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8386: loss = 0.8388 (0.244 sec/step)\n",
            "I0802 20:36:29.779670 139820296341376 learning.py:512] global step 8386: loss = 0.8388 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8387: loss = 0.8630 (0.237 sec/step)\n",
            "I0802 20:36:30.018670 139820296341376 learning.py:512] global step 8387: loss = 0.8630 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8388: loss = 0.8585 (0.245 sec/step)\n",
            "I0802 20:36:30.265238 139820296341376 learning.py:512] global step 8388: loss = 0.8585 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8389: loss = 0.7828 (0.228 sec/step)\n",
            "I0802 20:36:30.495045 139820296341376 learning.py:512] global step 8389: loss = 0.7828 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8390: loss = 1.3816 (0.220 sec/step)\n",
            "I0802 20:36:30.716190 139820296341376 learning.py:512] global step 8390: loss = 1.3816 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 8391: loss = 0.9529 (0.241 sec/step)\n",
            "I0802 20:36:30.958146 139820296341376 learning.py:512] global step 8391: loss = 0.9529 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8392: loss = 0.9684 (0.242 sec/step)\n",
            "I0802 20:36:31.201345 139820296341376 learning.py:512] global step 8392: loss = 0.9684 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8393: loss = 1.1259 (0.237 sec/step)\n",
            "I0802 20:36:31.439776 139820296341376 learning.py:512] global step 8393: loss = 1.1259 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8394: loss = 0.8147 (0.235 sec/step)\n",
            "I0802 20:36:31.676123 139820296341376 learning.py:512] global step 8394: loss = 0.8147 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8395: loss = 0.7146 (0.240 sec/step)\n",
            "I0802 20:36:31.917352 139820296341376 learning.py:512] global step 8395: loss = 0.7146 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8396: loss = 0.8412 (0.228 sec/step)\n",
            "I0802 20:36:32.147308 139820296341376 learning.py:512] global step 8396: loss = 0.8412 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8397: loss = 0.8394 (0.230 sec/step)\n",
            "I0802 20:36:32.379220 139820296341376 learning.py:512] global step 8397: loss = 0.8394 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8398: loss = 0.8420 (0.240 sec/step)\n",
            "I0802 20:36:32.620738 139820296341376 learning.py:512] global step 8398: loss = 0.8420 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8399: loss = 1.0040 (0.247 sec/step)\n",
            "I0802 20:36:32.869501 139820296341376 learning.py:512] global step 8399: loss = 1.0040 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8400: loss = 0.6577 (0.239 sec/step)\n",
            "I0802 20:36:33.109992 139820296341376 learning.py:512] global step 8400: loss = 0.6577 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8401: loss = 0.8460 (0.246 sec/step)\n",
            "I0802 20:36:33.357875 139820296341376 learning.py:512] global step 8401: loss = 0.8460 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8402: loss = 0.8522 (0.240 sec/step)\n",
            "I0802 20:36:33.599564 139820296341376 learning.py:512] global step 8402: loss = 0.8522 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8403: loss = 1.2256 (0.244 sec/step)\n",
            "I0802 20:36:33.844654 139820296341376 learning.py:512] global step 8403: loss = 1.2256 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8404: loss = 1.1214 (0.241 sec/step)\n",
            "I0802 20:36:34.087622 139820296341376 learning.py:512] global step 8404: loss = 1.1214 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8405: loss = 0.8708 (0.237 sec/step)\n",
            "I0802 20:36:34.325938 139820296341376 learning.py:512] global step 8405: loss = 0.8708 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8406: loss = 0.9296 (0.234 sec/step)\n",
            "I0802 20:36:34.560977 139820296341376 learning.py:512] global step 8406: loss = 0.9296 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8407: loss = 1.2647 (0.231 sec/step)\n",
            "I0802 20:36:34.793174 139820296341376 learning.py:512] global step 8407: loss = 1.2647 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8408: loss = 0.8375 (0.235 sec/step)\n",
            "I0802 20:36:35.029715 139820296341376 learning.py:512] global step 8408: loss = 0.8375 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8409: loss = 0.7938 (0.236 sec/step)\n",
            "I0802 20:36:35.267358 139820296341376 learning.py:512] global step 8409: loss = 0.7938 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8410: loss = 0.6777 (0.233 sec/step)\n",
            "I0802 20:36:35.502128 139820296341376 learning.py:512] global step 8410: loss = 0.6777 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8411: loss = 0.9071 (0.233 sec/step)\n",
            "I0802 20:36:35.736956 139820296341376 learning.py:512] global step 8411: loss = 0.9071 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8412: loss = 1.1516 (0.236 sec/step)\n",
            "I0802 20:36:35.974011 139820296341376 learning.py:512] global step 8412: loss = 1.1516 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8413: loss = 0.9796 (0.237 sec/step)\n",
            "I0802 20:36:36.212960 139820296341376 learning.py:512] global step 8413: loss = 0.9796 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8414: loss = 0.6394 (0.236 sec/step)\n",
            "I0802 20:36:36.450555 139820296341376 learning.py:512] global step 8414: loss = 0.6394 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8415: loss = 0.8463 (0.223 sec/step)\n",
            "I0802 20:36:36.675209 139820296341376 learning.py:512] global step 8415: loss = 0.8463 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8416: loss = 0.8618 (0.245 sec/step)\n",
            "I0802 20:36:36.921189 139820296341376 learning.py:512] global step 8416: loss = 0.8618 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8417: loss = 1.1142 (0.235 sec/step)\n",
            "I0802 20:36:37.157943 139820296341376 learning.py:512] global step 8417: loss = 1.1142 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8418: loss = 0.8156 (0.227 sec/step)\n",
            "I0802 20:36:37.386884 139820296341376 learning.py:512] global step 8418: loss = 0.8156 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8419: loss = 0.5158 (0.228 sec/step)\n",
            "I0802 20:36:37.616485 139820296341376 learning.py:512] global step 8419: loss = 0.5158 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8420: loss = 0.8161 (0.241 sec/step)\n",
            "I0802 20:36:37.858801 139820296341376 learning.py:512] global step 8420: loss = 0.8161 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8421: loss = 1.1889 (0.246 sec/step)\n",
            "I0802 20:36:38.106037 139820296341376 learning.py:512] global step 8421: loss = 1.1889 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8422: loss = 1.1107 (0.244 sec/step)\n",
            "I0802 20:36:38.351223 139820296341376 learning.py:512] global step 8422: loss = 1.1107 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8423: loss = 0.9265 (0.233 sec/step)\n",
            "I0802 20:36:38.585984 139820296341376 learning.py:512] global step 8423: loss = 0.9265 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8424: loss = 1.1031 (0.238 sec/step)\n",
            "I0802 20:36:38.825108 139820296341376 learning.py:512] global step 8424: loss = 1.1031 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8425: loss = 0.9108 (0.235 sec/step)\n",
            "I0802 20:36:39.061218 139820296341376 learning.py:512] global step 8425: loss = 0.9108 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8426: loss = 0.8120 (0.237 sec/step)\n",
            "I0802 20:36:39.299514 139820296341376 learning.py:512] global step 8426: loss = 0.8120 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8427: loss = 1.3282 (0.220 sec/step)\n",
            "I0802 20:36:39.522183 139820296341376 learning.py:512] global step 8427: loss = 1.3282 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 8428: loss = 0.8320 (0.234 sec/step)\n",
            "I0802 20:36:39.757482 139820296341376 learning.py:512] global step 8428: loss = 0.8320 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8429: loss = 0.9431 (0.222 sec/step)\n",
            "I0802 20:36:39.980355 139820296341376 learning.py:512] global step 8429: loss = 0.9431 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8430: loss = 0.7614 (0.234 sec/step)\n",
            "I0802 20:36:40.215853 139820296341376 learning.py:512] global step 8430: loss = 0.7614 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8431: loss = 0.8363 (0.245 sec/step)\n",
            "I0802 20:36:40.462846 139820296341376 learning.py:512] global step 8431: loss = 0.8363 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8432: loss = 0.7291 (0.235 sec/step)\n",
            "I0802 20:36:40.699609 139820296341376 learning.py:512] global step 8432: loss = 0.7291 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8433: loss = 1.0027 (0.245 sec/step)\n",
            "I0802 20:36:40.946295 139820296341376 learning.py:512] global step 8433: loss = 1.0027 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8434: loss = 0.7713 (0.241 sec/step)\n",
            "I0802 20:36:41.188765 139820296341376 learning.py:512] global step 8434: loss = 0.7713 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8435: loss = 1.0592 (0.245 sec/step)\n",
            "I0802 20:36:41.435278 139820296341376 learning.py:512] global step 8435: loss = 1.0592 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8436: loss = 0.7274 (0.244 sec/step)\n",
            "I0802 20:36:41.682157 139820296341376 learning.py:512] global step 8436: loss = 0.7274 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8437: loss = 0.9407 (0.220 sec/step)\n",
            "I0802 20:36:41.903423 139820296341376 learning.py:512] global step 8437: loss = 0.9407 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 8438: loss = 1.4101 (0.224 sec/step)\n",
            "I0802 20:36:42.129177 139820296341376 learning.py:512] global step 8438: loss = 1.4101 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8439: loss = 0.8245 (0.235 sec/step)\n",
            "I0802 20:36:42.365849 139820296341376 learning.py:512] global step 8439: loss = 0.8245 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8440: loss = 0.9564 (0.235 sec/step)\n",
            "I0802 20:36:42.602833 139820296341376 learning.py:512] global step 8440: loss = 0.9564 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8441: loss = 1.1877 (0.237 sec/step)\n",
            "I0802 20:36:42.841419 139820296341376 learning.py:512] global step 8441: loss = 1.1877 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8442: loss = 0.7919 (0.237 sec/step)\n",
            "I0802 20:36:43.080052 139820296341376 learning.py:512] global step 8442: loss = 0.7919 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8443: loss = 1.0870 (0.237 sec/step)\n",
            "I0802 20:36:43.318699 139820296341376 learning.py:512] global step 8443: loss = 1.0870 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8444: loss = 0.8625 (0.248 sec/step)\n",
            "I0802 20:36:43.567884 139820296341376 learning.py:512] global step 8444: loss = 0.8625 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8445: loss = 0.9058 (0.239 sec/step)\n",
            "I0802 20:36:43.807822 139820296341376 learning.py:512] global step 8445: loss = 0.9058 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8446: loss = 0.5446 (0.239 sec/step)\n",
            "I0802 20:36:44.048344 139820296341376 learning.py:512] global step 8446: loss = 0.5446 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8447: loss = 0.8889 (0.231 sec/step)\n",
            "I0802 20:36:44.280972 139820296341376 learning.py:512] global step 8447: loss = 0.8889 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8448: loss = 1.0206 (0.237 sec/step)\n",
            "I0802 20:36:44.519044 139820296341376 learning.py:512] global step 8448: loss = 1.0206 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8449: loss = 0.5789 (0.223 sec/step)\n",
            "I0802 20:36:44.743168 139820296341376 learning.py:512] global step 8449: loss = 0.5789 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8450: loss = 0.9517 (0.238 sec/step)\n",
            "I0802 20:36:44.982509 139820296341376 learning.py:512] global step 8450: loss = 0.9517 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8451: loss = 1.0370 (0.236 sec/step)\n",
            "I0802 20:36:45.219916 139820296341376 learning.py:512] global step 8451: loss = 1.0370 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8452: loss = 0.9691 (0.240 sec/step)\n",
            "I0802 20:36:45.461697 139820296341376 learning.py:512] global step 8452: loss = 0.9691 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8453: loss = 1.4003 (0.234 sec/step)\n",
            "I0802 20:36:45.697502 139820296341376 learning.py:512] global step 8453: loss = 1.4003 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8454: loss = 1.2493 (0.236 sec/step)\n",
            "I0802 20:36:45.935306 139820296341376 learning.py:512] global step 8454: loss = 1.2493 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8455: loss = 0.7919 (0.238 sec/step)\n",
            "I0802 20:36:46.176690 139820296341376 learning.py:512] global step 8455: loss = 0.7919 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8456: loss = 0.8475 (0.236 sec/step)\n",
            "I0802 20:36:46.414114 139820296341376 learning.py:512] global step 8456: loss = 0.8475 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8457: loss = 0.7351 (0.229 sec/step)\n",
            "I0802 20:36:46.644820 139820296341376 learning.py:512] global step 8457: loss = 0.7351 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8458: loss = 0.7617 (0.234 sec/step)\n",
            "I0802 20:36:46.881205 139820296341376 learning.py:512] global step 8458: loss = 0.7617 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8459: loss = 0.9060 (0.228 sec/step)\n",
            "I0802 20:36:47.110826 139820296341376 learning.py:512] global step 8459: loss = 0.9060 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8460: loss = 0.6875 (0.234 sec/step)\n",
            "I0802 20:36:47.346213 139820296341376 learning.py:512] global step 8460: loss = 0.6875 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8461: loss = 0.6798 (0.237 sec/step)\n",
            "I0802 20:36:47.585148 139820296341376 learning.py:512] global step 8461: loss = 0.6798 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8462: loss = 1.1839 (0.234 sec/step)\n",
            "I0802 20:36:47.820147 139820296341376 learning.py:512] global step 8462: loss = 1.1839 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8463: loss = 0.6728 (0.239 sec/step)\n",
            "I0802 20:36:48.060128 139820296341376 learning.py:512] global step 8463: loss = 0.6728 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8464: loss = 0.7576 (0.222 sec/step)\n",
            "I0802 20:36:48.283793 139820296341376 learning.py:512] global step 8464: loss = 0.7576 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8465: loss = 0.9348 (0.232 sec/step)\n",
            "I0802 20:36:48.517648 139820296341376 learning.py:512] global step 8465: loss = 0.9348 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8466: loss = 0.8462 (0.221 sec/step)\n",
            "I0802 20:36:48.739712 139820296341376 learning.py:512] global step 8466: loss = 0.8462 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 8467: loss = 1.2485 (0.234 sec/step)\n",
            "I0802 20:36:48.975554 139820296341376 learning.py:512] global step 8467: loss = 1.2485 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8468: loss = 0.8130 (0.233 sec/step)\n",
            "I0802 20:36:49.209694 139820296341376 learning.py:512] global step 8468: loss = 0.8130 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8469: loss = 0.9653 (0.231 sec/step)\n",
            "I0802 20:36:49.442318 139820296341376 learning.py:512] global step 8469: loss = 0.9653 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8470: loss = 0.9233 (0.236 sec/step)\n",
            "I0802 20:36:49.679906 139820296341376 learning.py:512] global step 8470: loss = 0.9233 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8471: loss = 0.7808 (0.234 sec/step)\n",
            "I0802 20:36:49.916077 139820296341376 learning.py:512] global step 8471: loss = 0.7808 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8472: loss = 1.0077 (0.236 sec/step)\n",
            "I0802 20:36:50.154038 139820296341376 learning.py:512] global step 8472: loss = 1.0077 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8473: loss = 0.8196 (0.234 sec/step)\n",
            "I0802 20:36:50.389884 139820296341376 learning.py:512] global step 8473: loss = 0.8196 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8474: loss = 0.8299 (0.234 sec/step)\n",
            "I0802 20:36:50.624812 139820296341376 learning.py:512] global step 8474: loss = 0.8299 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8475: loss = 1.0855 (0.223 sec/step)\n",
            "I0802 20:36:50.849199 139820296341376 learning.py:512] global step 8475: loss = 1.0855 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8476: loss = 0.8203 (0.236 sec/step)\n",
            "I0802 20:36:51.087156 139820296341376 learning.py:512] global step 8476: loss = 0.8203 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8477: loss = 1.0259 (0.239 sec/step)\n",
            "I0802 20:36:51.327735 139820296341376 learning.py:512] global step 8477: loss = 1.0259 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8478: loss = 0.8031 (0.220 sec/step)\n",
            "I0802 20:36:51.548984 139820296341376 learning.py:512] global step 8478: loss = 0.8031 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 8479: loss = 0.9000 (0.236 sec/step)\n",
            "I0802 20:36:51.786814 139820296341376 learning.py:512] global step 8479: loss = 0.9000 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8480: loss = 0.6936 (0.237 sec/step)\n",
            "I0802 20:36:52.024762 139820296341376 learning.py:512] global step 8480: loss = 0.6936 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8481: loss = 0.9114 (0.238 sec/step)\n",
            "I0802 20:36:52.264547 139820296341376 learning.py:512] global step 8481: loss = 0.9114 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8482: loss = 1.2610 (0.235 sec/step)\n",
            "I0802 20:36:52.500514 139820296341376 learning.py:512] global step 8482: loss = 1.2610 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8483: loss = 0.9087 (0.235 sec/step)\n",
            "I0802 20:36:52.737096 139820296341376 learning.py:512] global step 8483: loss = 0.9087 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8484: loss = 1.1645 (0.233 sec/step)\n",
            "I0802 20:36:52.971459 139820296341376 learning.py:512] global step 8484: loss = 1.1645 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8485: loss = 1.0540 (0.238 sec/step)\n",
            "I0802 20:36:53.211132 139820296341376 learning.py:512] global step 8485: loss = 1.0540 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8486: loss = 0.9670 (0.234 sec/step)\n",
            "I0802 20:36:53.446352 139820296341376 learning.py:512] global step 8486: loss = 0.9670 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8487: loss = 0.9367 (0.233 sec/step)\n",
            "I0802 20:36:53.681046 139820296341376 learning.py:512] global step 8487: loss = 0.9367 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8488: loss = 0.9371 (0.248 sec/step)\n",
            "I0802 20:36:53.930434 139820296341376 learning.py:512] global step 8488: loss = 0.9371 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8489: loss = 0.9215 (0.242 sec/step)\n",
            "I0802 20:36:54.173968 139820296341376 learning.py:512] global step 8489: loss = 0.9215 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8490: loss = 0.8716 (0.238 sec/step)\n",
            "I0802 20:36:54.413669 139820296341376 learning.py:512] global step 8490: loss = 0.8716 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8491: loss = 0.8862 (0.235 sec/step)\n",
            "I0802 20:36:54.650377 139820296341376 learning.py:512] global step 8491: loss = 0.8862 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8492: loss = 1.0644 (0.237 sec/step)\n",
            "I0802 20:36:54.889232 139820296341376 learning.py:512] global step 8492: loss = 1.0644 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8493: loss = 1.0279 (0.234 sec/step)\n",
            "I0802 20:36:55.124631 139820296341376 learning.py:512] global step 8493: loss = 1.0279 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8494: loss = 0.7323 (0.233 sec/step)\n",
            "I0802 20:36:55.359062 139820296341376 learning.py:512] global step 8494: loss = 0.7323 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8495: loss = 0.9489 (0.234 sec/step)\n",
            "I0802 20:36:55.594938 139820296341376 learning.py:512] global step 8495: loss = 0.9489 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8496: loss = 0.9326 (0.234 sec/step)\n",
            "I0802 20:36:55.830299 139820296341376 learning.py:512] global step 8496: loss = 0.9326 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8497: loss = 0.7991 (0.242 sec/step)\n",
            "I0802 20:36:56.073267 139820296341376 learning.py:512] global step 8497: loss = 0.7991 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8498: loss = 1.2134 (0.235 sec/step)\n",
            "I0802 20:36:56.309256 139820296341376 learning.py:512] global step 8498: loss = 1.2134 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8499: loss = 1.3247 (0.236 sec/step)\n",
            "I0802 20:36:56.546863 139820296341376 learning.py:512] global step 8499: loss = 1.3247 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8500: loss = 0.9402 (0.242 sec/step)\n",
            "I0802 20:36:56.790807 139820296341376 learning.py:512] global step 8500: loss = 0.9402 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8501: loss = 0.8076 (0.224 sec/step)\n",
            "I0802 20:36:57.015861 139820296341376 learning.py:512] global step 8501: loss = 0.8076 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8502: loss = 0.9205 (0.221 sec/step)\n",
            "I0802 20:36:57.238562 139820296341376 learning.py:512] global step 8502: loss = 0.9205 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 8503: loss = 0.8548 (0.244 sec/step)\n",
            "I0802 20:36:57.484035 139820296341376 learning.py:512] global step 8503: loss = 0.8548 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8504: loss = 0.9648 (0.242 sec/step)\n",
            "I0802 20:36:57.727717 139820296341376 learning.py:512] global step 8504: loss = 0.9648 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8505: loss = 0.9954 (0.249 sec/step)\n",
            "I0802 20:36:57.978552 139820296341376 learning.py:512] global step 8505: loss = 0.9954 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8506: loss = 0.9397 (0.228 sec/step)\n",
            "I0802 20:36:58.208544 139820296341376 learning.py:512] global step 8506: loss = 0.9397 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8507: loss = 0.7842 (0.238 sec/step)\n",
            "I0802 20:36:58.448356 139820296341376 learning.py:512] global step 8507: loss = 0.7842 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8508: loss = 0.6387 (0.228 sec/step)\n",
            "I0802 20:36:58.677952 139820296341376 learning.py:512] global step 8508: loss = 0.6387 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8509: loss = 1.0429 (0.235 sec/step)\n",
            "I0802 20:36:58.914286 139820296341376 learning.py:512] global step 8509: loss = 1.0429 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8510: loss = 0.7390 (0.236 sec/step)\n",
            "I0802 20:36:59.151699 139820296341376 learning.py:512] global step 8510: loss = 0.7390 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8511: loss = 0.8458 (0.241 sec/step)\n",
            "I0802 20:36:59.394321 139820296341376 learning.py:512] global step 8511: loss = 0.8458 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8512: loss = 0.8586 (0.224 sec/step)\n",
            "I0802 20:36:59.620053 139820296341376 learning.py:512] global step 8512: loss = 0.8586 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8513: loss = 0.9861 (0.240 sec/step)\n",
            "I0802 20:36:59.861438 139820296341376 learning.py:512] global step 8513: loss = 0.9861 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8514: loss = 0.9523 (0.238 sec/step)\n",
            "I0802 20:37:00.103300 139820296341376 learning.py:512] global step 8514: loss = 0.9523 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8515: loss = 0.7148 (0.235 sec/step)\n",
            "I0802 20:37:00.339317 139820296341376 learning.py:512] global step 8515: loss = 0.7148 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8516: loss = 0.7185 (0.244 sec/step)\n",
            "I0802 20:37:00.584996 139820296341376 learning.py:512] global step 8516: loss = 0.7185 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8517: loss = 1.0776 (0.238 sec/step)\n",
            "I0802 20:37:00.824395 139820296341376 learning.py:512] global step 8517: loss = 1.0776 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8518: loss = 0.7889 (0.243 sec/step)\n",
            "I0802 20:37:01.069744 139820296341376 learning.py:512] global step 8518: loss = 0.7889 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8519: loss = 1.0441 (0.242 sec/step)\n",
            "I0802 20:37:01.313534 139820296341376 learning.py:512] global step 8519: loss = 1.0441 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8520: loss = 0.8682 (0.245 sec/step)\n",
            "I0802 20:37:01.559723 139820296341376 learning.py:512] global step 8520: loss = 0.8682 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8521: loss = 0.7198 (0.248 sec/step)\n",
            "I0802 20:37:01.809521 139820296341376 learning.py:512] global step 8521: loss = 0.7198 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8522: loss = 0.7239 (0.238 sec/step)\n",
            "I0802 20:37:02.048789 139820296341376 learning.py:512] global step 8522: loss = 0.7239 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8523: loss = 0.8075 (0.234 sec/step)\n",
            "I0802 20:37:02.283809 139820296341376 learning.py:512] global step 8523: loss = 0.8075 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8524: loss = 0.8469 (0.241 sec/step)\n",
            "I0802 20:37:02.526454 139820296341376 learning.py:512] global step 8524: loss = 0.8469 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8525: loss = 1.0029 (0.242 sec/step)\n",
            "I0802 20:37:02.769677 139820296341376 learning.py:512] global step 8525: loss = 1.0029 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8526: loss = 0.8504 (0.241 sec/step)\n",
            "I0802 20:37:03.012073 139820296341376 learning.py:512] global step 8526: loss = 0.8504 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8527: loss = 0.8415 (0.240 sec/step)\n",
            "I0802 20:37:03.253796 139820296341376 learning.py:512] global step 8527: loss = 0.8415 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8528: loss = 0.6523 (0.258 sec/step)\n",
            "I0802 20:37:03.513288 139820296341376 learning.py:512] global step 8528: loss = 0.6523 (0.258 sec/step)\n",
            "INFO:tensorflow:global step 8529: loss = 0.9211 (0.239 sec/step)\n",
            "I0802 20:37:03.753701 139820296341376 learning.py:512] global step 8529: loss = 0.9211 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8530: loss = 0.9082 (0.234 sec/step)\n",
            "I0802 20:37:03.989543 139820296341376 learning.py:512] global step 8530: loss = 0.9082 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8531: loss = 0.9831 (0.246 sec/step)\n",
            "I0802 20:37:04.237065 139820296341376 learning.py:512] global step 8531: loss = 0.9831 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8532: loss = 0.7388 (0.241 sec/step)\n",
            "I0802 20:37:04.479362 139820296341376 learning.py:512] global step 8532: loss = 0.7388 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8533: loss = 0.8655 (0.230 sec/step)\n",
            "I0802 20:37:04.710976 139820296341376 learning.py:512] global step 8533: loss = 0.8655 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8534: loss = 0.6664 (0.239 sec/step)\n",
            "I0802 20:37:04.951514 139820296341376 learning.py:512] global step 8534: loss = 0.6664 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8535: loss = 0.7193 (0.240 sec/step)\n",
            "I0802 20:37:05.193216 139820296341376 learning.py:512] global step 8535: loss = 0.7193 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8536: loss = 1.0221 (0.245 sec/step)\n",
            "I0802 20:37:05.439888 139820296341376 learning.py:512] global step 8536: loss = 1.0221 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8537: loss = 0.7544 (0.235 sec/step)\n",
            "I0802 20:37:05.676521 139820296341376 learning.py:512] global step 8537: loss = 0.7544 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8538: loss = 0.8157 (0.244 sec/step)\n",
            "I0802 20:37:05.922045 139820296341376 learning.py:512] global step 8538: loss = 0.8157 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8539: loss = 0.7018 (0.240 sec/step)\n",
            "I0802 20:37:06.163101 139820296341376 learning.py:512] global step 8539: loss = 0.7018 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8540: loss = 0.8927 (0.242 sec/step)\n",
            "I0802 20:37:06.407154 139820296341376 learning.py:512] global step 8540: loss = 0.8927 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8541: loss = 0.8391 (0.236 sec/step)\n",
            "I0802 20:37:06.644663 139820296341376 learning.py:512] global step 8541: loss = 0.8391 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8542: loss = 1.0110 (0.238 sec/step)\n",
            "I0802 20:37:06.883814 139820296341376 learning.py:512] global step 8542: loss = 1.0110 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8543: loss = 0.7555 (0.244 sec/step)\n",
            "I0802 20:37:07.129017 139820296341376 learning.py:512] global step 8543: loss = 0.7555 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8544: loss = 0.7397 (0.244 sec/step)\n",
            "I0802 20:37:07.374663 139820296341376 learning.py:512] global step 8544: loss = 0.7397 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8545: loss = 0.8715 (0.236 sec/step)\n",
            "I0802 20:37:07.613353 139820296341376 learning.py:512] global step 8545: loss = 0.8715 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8546: loss = 0.9050 (0.240 sec/step)\n",
            "I0802 20:37:07.855069 139820296341376 learning.py:512] global step 8546: loss = 0.9050 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8547: loss = 1.1677 (0.245 sec/step)\n",
            "I0802 20:37:08.101598 139820296341376 learning.py:512] global step 8547: loss = 1.1677 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8548: loss = 0.8970 (0.252 sec/step)\n",
            "I0802 20:37:08.354636 139820296341376 learning.py:512] global step 8548: loss = 0.8970 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8549: loss = 1.2393 (0.235 sec/step)\n",
            "I0802 20:37:08.591289 139820296341376 learning.py:512] global step 8549: loss = 1.2393 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8550: loss = 1.1185 (0.239 sec/step)\n",
            "I0802 20:37:08.832385 139820296341376 learning.py:512] global step 8550: loss = 1.1185 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8551: loss = 0.7761 (0.239 sec/step)\n",
            "I0802 20:37:09.073842 139820296341376 learning.py:512] global step 8551: loss = 0.7761 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8552: loss = 0.7690 (0.247 sec/step)\n",
            "I0802 20:37:09.322176 139820296341376 learning.py:512] global step 8552: loss = 0.7690 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8553: loss = 0.8038 (0.239 sec/step)\n",
            "I0802 20:37:09.562139 139820296341376 learning.py:512] global step 8553: loss = 0.8038 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8554: loss = 1.2302 (0.236 sec/step)\n",
            "I0802 20:37:09.799499 139820296341376 learning.py:512] global step 8554: loss = 1.2302 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8555: loss = 0.7674 (0.236 sec/step)\n",
            "I0802 20:37:10.037278 139820296341376 learning.py:512] global step 8555: loss = 0.7674 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8556: loss = 0.7457 (0.238 sec/step)\n",
            "I0802 20:37:10.277079 139820296341376 learning.py:512] global step 8556: loss = 0.7457 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8557: loss = 0.8161 (0.238 sec/step)\n",
            "I0802 20:37:10.516377 139820296341376 learning.py:512] global step 8557: loss = 0.8161 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8558: loss = 0.9774 (0.238 sec/step)\n",
            "I0802 20:37:10.755329 139820296341376 learning.py:512] global step 8558: loss = 0.9774 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8559: loss = 1.0718 (0.226 sec/step)\n",
            "I0802 20:37:10.982468 139820296341376 learning.py:512] global step 8559: loss = 1.0718 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8560: loss = 0.7032 (0.232 sec/step)\n",
            "I0802 20:37:11.216402 139820296341376 learning.py:512] global step 8560: loss = 0.7032 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8561: loss = 0.9398 (0.241 sec/step)\n",
            "I0802 20:37:11.459438 139820296341376 learning.py:512] global step 8561: loss = 0.9398 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8562: loss = 0.6986 (0.233 sec/step)\n",
            "I0802 20:37:11.693895 139820296341376 learning.py:512] global step 8562: loss = 0.6986 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8563: loss = 0.8561 (0.235 sec/step)\n",
            "I0802 20:37:11.930214 139820296341376 learning.py:512] global step 8563: loss = 0.8561 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8564: loss = 1.5079 (0.242 sec/step)\n",
            "I0802 20:37:12.173653 139820296341376 learning.py:512] global step 8564: loss = 1.5079 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8565: loss = 0.9779 (0.249 sec/step)\n",
            "I0802 20:37:12.424638 139820296341376 learning.py:512] global step 8565: loss = 0.9779 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8566: loss = 0.9269 (0.238 sec/step)\n",
            "I0802 20:37:12.664527 139820296341376 learning.py:512] global step 8566: loss = 0.9269 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8567: loss = 1.1821 (0.237 sec/step)\n",
            "I0802 20:37:12.902893 139820296341376 learning.py:512] global step 8567: loss = 1.1821 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8568: loss = 0.9665 (0.223 sec/step)\n",
            "I0802 20:37:13.127340 139820296341376 learning.py:512] global step 8568: loss = 0.9665 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8569: loss = 0.8852 (0.247 sec/step)\n",
            "I0802 20:37:13.375426 139820296341376 learning.py:512] global step 8569: loss = 0.8852 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8570: loss = 1.1411 (0.238 sec/step)\n",
            "I0802 20:37:13.614736 139820296341376 learning.py:512] global step 8570: loss = 1.1411 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8571: loss = 0.8932 (0.238 sec/step)\n",
            "I0802 20:37:13.853686 139820296341376 learning.py:512] global step 8571: loss = 0.8932 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8572: loss = 0.6750 (0.239 sec/step)\n",
            "I0802 20:37:14.093940 139820296341376 learning.py:512] global step 8572: loss = 0.6750 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8573: loss = 0.8960 (0.240 sec/step)\n",
            "I0802 20:37:14.335720 139820296341376 learning.py:512] global step 8573: loss = 0.8960 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8574: loss = 0.9706 (0.242 sec/step)\n",
            "I0802 20:37:14.579214 139820296341376 learning.py:512] global step 8574: loss = 0.9706 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8575: loss = 0.7326 (0.235 sec/step)\n",
            "I0802 20:37:14.815645 139820296341376 learning.py:512] global step 8575: loss = 0.7326 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8576: loss = 0.8703 (0.240 sec/step)\n",
            "I0802 20:37:15.057246 139820296341376 learning.py:512] global step 8576: loss = 0.8703 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8577: loss = 0.7745 (0.244 sec/step)\n",
            "I0802 20:37:15.302543 139820296341376 learning.py:512] global step 8577: loss = 0.7745 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8578: loss = 1.0010 (0.243 sec/step)\n",
            "I0802 20:37:15.547197 139820296341376 learning.py:512] global step 8578: loss = 1.0010 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8579: loss = 0.7783 (0.243 sec/step)\n",
            "I0802 20:37:15.791906 139820296341376 learning.py:512] global step 8579: loss = 0.7783 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8580: loss = 0.9133 (0.231 sec/step)\n",
            "I0802 20:37:16.024853 139820296341376 learning.py:512] global step 8580: loss = 0.9133 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8581: loss = 0.7842 (0.236 sec/step)\n",
            "I0802 20:37:16.264251 139820296341376 learning.py:512] global step 8581: loss = 0.7842 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8582: loss = 1.0915 (0.246 sec/step)\n",
            "I0802 20:37:16.512305 139820296341376 learning.py:512] global step 8582: loss = 1.0915 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8583: loss = 0.8344 (0.238 sec/step)\n",
            "I0802 20:37:16.751603 139820296341376 learning.py:512] global step 8583: loss = 0.8344 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8584: loss = 0.7497 (0.241 sec/step)\n",
            "I0802 20:37:16.994261 139820296341376 learning.py:512] global step 8584: loss = 0.7497 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8585: loss = 0.8211 (0.231 sec/step)\n",
            "I0802 20:37:17.226729 139820296341376 learning.py:512] global step 8585: loss = 0.8211 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8586: loss = 0.6772 (0.250 sec/step)\n",
            "I0802 20:37:17.478762 139820296341376 learning.py:512] global step 8586: loss = 0.6772 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8587: loss = 1.0559 (0.228 sec/step)\n",
            "I0802 20:37:17.707974 139820296341376 learning.py:512] global step 8587: loss = 1.0559 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8588: loss = 0.8732 (0.236 sec/step)\n",
            "I0802 20:37:17.945330 139820296341376 learning.py:512] global step 8588: loss = 0.8732 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8589: loss = 0.7239 (0.236 sec/step)\n",
            "I0802 20:37:18.182629 139820296341376 learning.py:512] global step 8589: loss = 0.7239 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8590: loss = 0.9817 (0.243 sec/step)\n",
            "I0802 20:37:18.427612 139820296341376 learning.py:512] global step 8590: loss = 0.9817 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8591: loss = 1.0037 (0.241 sec/step)\n",
            "I0802 20:37:18.669833 139820296341376 learning.py:512] global step 8591: loss = 1.0037 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8592: loss = 1.0006 (0.245 sec/step)\n",
            "I0802 20:37:18.916769 139820296341376 learning.py:512] global step 8592: loss = 1.0006 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8593: loss = 0.6897 (0.228 sec/step)\n",
            "I0802 20:37:19.146152 139820296341376 learning.py:512] global step 8593: loss = 0.6897 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8594: loss = 1.0152 (0.248 sec/step)\n",
            "I0802 20:37:19.396198 139820296341376 learning.py:512] global step 8594: loss = 1.0152 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8595: loss = 0.9697 (0.243 sec/step)\n",
            "I0802 20:37:19.641164 139820296341376 learning.py:512] global step 8595: loss = 0.9697 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8596: loss = 0.9768 (0.234 sec/step)\n",
            "I0802 20:37:19.877183 139820296341376 learning.py:512] global step 8596: loss = 0.9768 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8597: loss = 0.8229 (0.241 sec/step)\n",
            "I0802 20:37:20.119845 139820296341376 learning.py:512] global step 8597: loss = 0.8229 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8598: loss = 0.8452 (0.243 sec/step)\n",
            "I0802 20:37:20.364073 139820296341376 learning.py:512] global step 8598: loss = 0.8452 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8599: loss = 0.8153 (0.229 sec/step)\n",
            "I0802 20:37:20.594766 139820296341376 learning.py:512] global step 8599: loss = 0.8153 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8600: loss = 0.8226 (0.253 sec/step)\n",
            "I0802 20:37:20.849444 139820296341376 learning.py:512] global step 8600: loss = 0.8226 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8601: loss = 1.0360 (0.237 sec/step)\n",
            "I0802 20:37:21.088299 139820296341376 learning.py:512] global step 8601: loss = 1.0360 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8602: loss = 1.1781 (0.240 sec/step)\n",
            "I0802 20:37:21.330243 139820296341376 learning.py:512] global step 8602: loss = 1.1781 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8603: loss = 0.9109 (0.240 sec/step)\n",
            "I0802 20:37:21.572398 139820296341376 learning.py:512] global step 8603: loss = 0.9109 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8604: loss = 1.0928 (0.234 sec/step)\n",
            "I0802 20:37:21.808423 139820296341376 learning.py:512] global step 8604: loss = 1.0928 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8605: loss = 0.8814 (0.238 sec/step)\n",
            "I0802 20:37:22.047807 139820296341376 learning.py:512] global step 8605: loss = 0.8814 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8606: loss = 0.7847 (0.240 sec/step)\n",
            "I0802 20:37:22.289136 139820296341376 learning.py:512] global step 8606: loss = 0.7847 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8607: loss = 0.8149 (0.237 sec/step)\n",
            "I0802 20:37:22.528190 139820296341376 learning.py:512] global step 8607: loss = 0.8149 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8608: loss = 0.7431 (0.228 sec/step)\n",
            "I0802 20:37:22.757903 139820296341376 learning.py:512] global step 8608: loss = 0.7431 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8609: loss = 0.8436 (0.225 sec/step)\n",
            "I0802 20:37:22.984611 139820296341376 learning.py:512] global step 8609: loss = 0.8436 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8610: loss = 0.8532 (0.238 sec/step)\n",
            "I0802 20:37:23.224488 139820296341376 learning.py:512] global step 8610: loss = 0.8532 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8611: loss = 0.7416 (0.238 sec/step)\n",
            "I0802 20:37:23.463670 139820296341376 learning.py:512] global step 8611: loss = 0.7416 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8612: loss = 0.5605 (0.226 sec/step)\n",
            "I0802 20:37:23.690881 139820296341376 learning.py:512] global step 8612: loss = 0.5605 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8613: loss = 0.8666 (0.237 sec/step)\n",
            "I0802 20:37:23.929368 139820296341376 learning.py:512] global step 8613: loss = 0.8666 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8614: loss = 0.7921 (0.236 sec/step)\n",
            "I0802 20:37:24.166534 139820296341376 learning.py:512] global step 8614: loss = 0.7921 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8615: loss = 0.8327 (0.236 sec/step)\n",
            "I0802 20:37:24.404101 139820296341376 learning.py:512] global step 8615: loss = 0.8327 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8616: loss = 0.7700 (0.231 sec/step)\n",
            "I0802 20:37:24.636977 139820296341376 learning.py:512] global step 8616: loss = 0.7700 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8617: loss = 0.6561 (0.237 sec/step)\n",
            "I0802 20:37:24.874962 139820296341376 learning.py:512] global step 8617: loss = 0.6561 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8618: loss = 0.8444 (0.231 sec/step)\n",
            "I0802 20:37:25.107417 139820296341376 learning.py:512] global step 8618: loss = 0.8444 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8619: loss = 0.8953 (0.231 sec/step)\n",
            "I0802 20:37:25.339522 139820296341376 learning.py:512] global step 8619: loss = 0.8953 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8620: loss = 0.6820 (0.235 sec/step)\n",
            "I0802 20:37:25.576790 139820296341376 learning.py:512] global step 8620: loss = 0.6820 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8621: loss = 0.8397 (0.235 sec/step)\n",
            "I0802 20:37:25.813915 139820296341376 learning.py:512] global step 8621: loss = 0.8397 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8622: loss = 0.9498 (0.226 sec/step)\n",
            "I0802 20:37:26.041665 139820296341376 learning.py:512] global step 8622: loss = 0.9498 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8623: loss = 0.7695 (0.241 sec/step)\n",
            "I0802 20:37:26.284544 139820296341376 learning.py:512] global step 8623: loss = 0.7695 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8624: loss = 0.9599 (0.241 sec/step)\n",
            "I0802 20:37:26.526933 139820296341376 learning.py:512] global step 8624: loss = 0.9599 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8625: loss = 0.8023 (0.244 sec/step)\n",
            "I0802 20:37:26.772191 139820296341376 learning.py:512] global step 8625: loss = 0.8023 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8626: loss = 0.9835 (0.235 sec/step)\n",
            "I0802 20:37:27.008336 139820296341376 learning.py:512] global step 8626: loss = 0.9835 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8627: loss = 0.7710 (0.244 sec/step)\n",
            "I0802 20:37:27.253991 139820296341376 learning.py:512] global step 8627: loss = 0.7710 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8628: loss = 1.0777 (0.222 sec/step)\n",
            "I0802 20:37:27.477444 139820296341376 learning.py:512] global step 8628: loss = 1.0777 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8629: loss = 0.7189 (0.223 sec/step)\n",
            "I0802 20:37:27.702184 139820296341376 learning.py:512] global step 8629: loss = 0.7189 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8630: loss = 0.7408 (0.241 sec/step)\n",
            "I0802 20:37:27.944499 139820296341376 learning.py:512] global step 8630: loss = 0.7408 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8631: loss = 0.8725 (0.227 sec/step)\n",
            "I0802 20:37:28.175123 139820296341376 learning.py:512] global step 8631: loss = 0.8725 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8632: loss = 1.2615 (0.239 sec/step)\n",
            "I0802 20:37:28.415987 139820296341376 learning.py:512] global step 8632: loss = 1.2615 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8633: loss = 0.7244 (0.228 sec/step)\n",
            "I0802 20:37:28.645565 139820296341376 learning.py:512] global step 8633: loss = 0.7244 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8634: loss = 0.8335 (0.245 sec/step)\n",
            "I0802 20:37:28.892457 139820296341376 learning.py:512] global step 8634: loss = 0.8335 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8635: loss = 0.7741 (0.225 sec/step)\n",
            "I0802 20:37:29.119029 139820296341376 learning.py:512] global step 8635: loss = 0.7741 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8636: loss = 1.0776 (0.248 sec/step)\n",
            "I0802 20:37:29.368029 139820296341376 learning.py:512] global step 8636: loss = 1.0776 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8637: loss = 0.8392 (0.233 sec/step)\n",
            "I0802 20:37:29.602935 139820296341376 learning.py:512] global step 8637: loss = 0.8392 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8638: loss = 0.9150 (0.241 sec/step)\n",
            "I0802 20:37:29.845851 139820296341376 learning.py:512] global step 8638: loss = 0.9150 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8639: loss = 0.8564 (0.238 sec/step)\n",
            "I0802 20:37:30.085305 139820296341376 learning.py:512] global step 8639: loss = 0.8564 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8640: loss = 0.8697 (0.236 sec/step)\n",
            "I0802 20:37:30.322989 139820296341376 learning.py:512] global step 8640: loss = 0.8697 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8641: loss = 1.2459 (0.226 sec/step)\n",
            "I0802 20:37:30.550714 139820296341376 learning.py:512] global step 8641: loss = 1.2459 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8642: loss = 0.7945 (0.240 sec/step)\n",
            "I0802 20:37:30.792109 139820296341376 learning.py:512] global step 8642: loss = 0.7945 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8643: loss = 0.7127 (0.235 sec/step)\n",
            "I0802 20:37:31.029530 139820296341376 learning.py:512] global step 8643: loss = 0.7127 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8644: loss = 0.8554 (0.233 sec/step)\n",
            "I0802 20:37:31.264480 139820296341376 learning.py:512] global step 8644: loss = 0.8554 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8645: loss = 1.1314 (0.237 sec/step)\n",
            "I0802 20:37:31.503217 139820296341376 learning.py:512] global step 8645: loss = 1.1314 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8646: loss = 1.1252 (0.239 sec/step)\n",
            "I0802 20:37:31.744009 139820296341376 learning.py:512] global step 8646: loss = 1.1252 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8647: loss = 0.7580 (0.238 sec/step)\n",
            "I0802 20:37:31.984170 139820296341376 learning.py:512] global step 8647: loss = 0.7580 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8648: loss = 0.9188 (0.239 sec/step)\n",
            "I0802 20:37:32.224574 139820296341376 learning.py:512] global step 8648: loss = 0.9188 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8649: loss = 0.9579 (0.233 sec/step)\n",
            "I0802 20:37:32.458737 139820296341376 learning.py:512] global step 8649: loss = 0.9579 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8650: loss = 0.8303 (0.240 sec/step)\n",
            "I0802 20:37:32.699936 139820296341376 learning.py:512] global step 8650: loss = 0.8303 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8651: loss = 0.6904 (0.230 sec/step)\n",
            "I0802 20:37:32.931264 139820296341376 learning.py:512] global step 8651: loss = 0.6904 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8652: loss = 0.8895 (0.243 sec/step)\n",
            "I0802 20:37:33.175472 139820296341376 learning.py:512] global step 8652: loss = 0.8895 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8653: loss = 1.0131 (0.235 sec/step)\n",
            "I0802 20:37:33.412042 139820296341376 learning.py:512] global step 8653: loss = 1.0131 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8654: loss = 1.0370 (0.236 sec/step)\n",
            "I0802 20:37:33.649146 139820296341376 learning.py:512] global step 8654: loss = 1.0370 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8655: loss = 0.7611 (0.241 sec/step)\n",
            "I0802 20:37:33.891124 139820296341376 learning.py:512] global step 8655: loss = 0.7611 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8656: loss = 0.7597 (0.231 sec/step)\n",
            "I0802 20:37:34.123763 139820296341376 learning.py:512] global step 8656: loss = 0.7597 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8657: loss = 0.7646 (0.237 sec/step)\n",
            "I0802 20:37:34.362025 139820296341376 learning.py:512] global step 8657: loss = 0.7646 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8658: loss = 0.8656 (0.237 sec/step)\n",
            "I0802 20:37:34.600037 139820296341376 learning.py:512] global step 8658: loss = 0.8656 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8659: loss = 1.0599 (0.245 sec/step)\n",
            "I0802 20:37:34.846951 139820296341376 learning.py:512] global step 8659: loss = 1.0599 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8660: loss = 0.7702 (0.240 sec/step)\n",
            "I0802 20:37:35.088371 139820296341376 learning.py:512] global step 8660: loss = 0.7702 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8661: loss = 1.0210 (0.238 sec/step)\n",
            "I0802 20:37:35.328285 139820296341376 learning.py:512] global step 8661: loss = 1.0210 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8662: loss = 0.7464 (0.237 sec/step)\n",
            "I0802 20:37:35.567167 139820296341376 learning.py:512] global step 8662: loss = 0.7464 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8663: loss = 0.5739 (0.245 sec/step)\n",
            "I0802 20:37:35.814074 139820296341376 learning.py:512] global step 8663: loss = 0.5739 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8664: loss = 1.0143 (0.240 sec/step)\n",
            "I0802 20:37:36.056479 139820296341376 learning.py:512] global step 8664: loss = 1.0143 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8665: loss = 0.7595 (0.235 sec/step)\n",
            "I0802 20:37:36.293248 139820296341376 learning.py:512] global step 8665: loss = 0.7595 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8666: loss = 0.8064 (0.238 sec/step)\n",
            "I0802 20:37:36.532222 139820296341376 learning.py:512] global step 8666: loss = 0.8064 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8667: loss = 0.8464 (0.232 sec/step)\n",
            "I0802 20:37:36.765373 139820296341376 learning.py:512] global step 8667: loss = 0.8464 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8668: loss = 0.9116 (0.236 sec/step)\n",
            "I0802 20:37:37.002888 139820296341376 learning.py:512] global step 8668: loss = 0.9116 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8669: loss = 1.1655 (0.234 sec/step)\n",
            "I0802 20:37:37.238167 139820296341376 learning.py:512] global step 8669: loss = 1.1655 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8670: loss = 0.7741 (0.226 sec/step)\n",
            "I0802 20:37:37.465467 139820296341376 learning.py:512] global step 8670: loss = 0.7741 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8671: loss = 0.9220 (0.232 sec/step)\n",
            "I0802 20:37:37.698508 139820296341376 learning.py:512] global step 8671: loss = 0.9220 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8672: loss = 0.7945 (0.222 sec/step)\n",
            "I0802 20:37:37.921894 139820296341376 learning.py:512] global step 8672: loss = 0.7945 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8673: loss = 1.1870 (0.244 sec/step)\n",
            "I0802 20:37:38.167804 139820296341376 learning.py:512] global step 8673: loss = 1.1870 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8674: loss = 0.9164 (0.236 sec/step)\n",
            "I0802 20:37:38.405575 139820296341376 learning.py:512] global step 8674: loss = 0.9164 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8675: loss = 0.9222 (0.238 sec/step)\n",
            "I0802 20:37:38.645099 139820296341376 learning.py:512] global step 8675: loss = 0.9222 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8676: loss = 0.8713 (0.233 sec/step)\n",
            "I0802 20:37:38.879783 139820296341376 learning.py:512] global step 8676: loss = 0.8713 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8677: loss = 0.9664 (0.236 sec/step)\n",
            "I0802 20:37:39.117119 139820296341376 learning.py:512] global step 8677: loss = 0.9664 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8678: loss = 0.8918 (0.242 sec/step)\n",
            "I0802 20:37:39.360179 139820296341376 learning.py:512] global step 8678: loss = 0.8918 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8679: loss = 0.8451 (0.239 sec/step)\n",
            "I0802 20:37:39.601336 139820296341376 learning.py:512] global step 8679: loss = 0.8451 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8680: loss = 0.9011 (0.235 sec/step)\n",
            "I0802 20:37:39.838120 139820296341376 learning.py:512] global step 8680: loss = 0.9011 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8681: loss = 0.7778 (0.241 sec/step)\n",
            "I0802 20:37:40.080089 139820296341376 learning.py:512] global step 8681: loss = 0.7778 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8682: loss = 0.9079 (0.235 sec/step)\n",
            "I0802 20:37:40.316556 139820296341376 learning.py:512] global step 8682: loss = 0.9079 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8683: loss = 0.9796 (0.234 sec/step)\n",
            "I0802 20:37:40.552620 139820296341376 learning.py:512] global step 8683: loss = 0.9796 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8684: loss = 0.8503 (0.231 sec/step)\n",
            "I0802 20:37:40.785770 139820296341376 learning.py:512] global step 8684: loss = 0.8503 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8685: loss = 0.8686 (0.238 sec/step)\n",
            "I0802 20:37:41.025623 139820296341376 learning.py:512] global step 8685: loss = 0.8686 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8686: loss = 0.8396 (0.236 sec/step)\n",
            "I0802 20:37:41.263007 139820296341376 learning.py:512] global step 8686: loss = 0.8396 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8687: loss = 0.8455 (0.228 sec/step)\n",
            "I0802 20:37:41.492276 139820296341376 learning.py:512] global step 8687: loss = 0.8455 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8688: loss = 0.7473 (0.244 sec/step)\n",
            "I0802 20:37:41.737627 139820296341376 learning.py:512] global step 8688: loss = 0.7473 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8689: loss = 0.8077 (0.228 sec/step)\n",
            "I0802 20:37:41.966786 139820296341376 learning.py:512] global step 8689: loss = 0.8077 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8690: loss = 0.8958 (0.236 sec/step)\n",
            "I0802 20:37:42.204253 139820296341376 learning.py:512] global step 8690: loss = 0.8958 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8691: loss = 1.0058 (0.236 sec/step)\n",
            "I0802 20:37:42.442064 139820296341376 learning.py:512] global step 8691: loss = 1.0058 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8692: loss = 1.0653 (0.243 sec/step)\n",
            "I0802 20:37:42.686318 139820296341376 learning.py:512] global step 8692: loss = 1.0653 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8693: loss = 0.9581 (0.234 sec/step)\n",
            "I0802 20:37:42.922165 139820296341376 learning.py:512] global step 8693: loss = 0.9581 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8694: loss = 0.9700 (0.234 sec/step)\n",
            "I0802 20:37:43.157483 139820296341376 learning.py:512] global step 8694: loss = 0.9700 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8695: loss = 0.8830 (0.221 sec/step)\n",
            "I0802 20:37:43.380322 139820296341376 learning.py:512] global step 8695: loss = 0.8830 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 8696: loss = 0.8609 (0.237 sec/step)\n",
            "I0802 20:37:43.622330 139820296341376 learning.py:512] global step 8696: loss = 0.8609 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8697: loss = 0.7477 (0.225 sec/step)\n",
            "I0802 20:37:43.849498 139820296341376 learning.py:512] global step 8697: loss = 0.7477 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8698: loss = 0.8716 (0.242 sec/step)\n",
            "I0802 20:37:44.093387 139820296341376 learning.py:512] global step 8698: loss = 0.8716 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8699: loss = 0.9153 (0.235 sec/step)\n",
            "I0802 20:37:44.329835 139820296341376 learning.py:512] global step 8699: loss = 0.9153 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8700: loss = 0.9893 (0.238 sec/step)\n",
            "I0802 20:37:44.569300 139820296341376 learning.py:512] global step 8700: loss = 0.9893 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8701: loss = 1.4969 (0.232 sec/step)\n",
            "I0802 20:37:44.803370 139820296341376 learning.py:512] global step 8701: loss = 1.4969 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8702: loss = 0.8134 (0.243 sec/step)\n",
            "I0802 20:37:45.048320 139820296341376 learning.py:512] global step 8702: loss = 0.8134 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8703: loss = 0.7994 (0.242 sec/step)\n",
            "I0802 20:37:45.291438 139820296341376 learning.py:512] global step 8703: loss = 0.7994 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8704: loss = 0.8506 (0.239 sec/step)\n",
            "I0802 20:37:45.531853 139820296341376 learning.py:512] global step 8704: loss = 0.8506 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8705: loss = 0.9546 (0.240 sec/step)\n",
            "I0802 20:37:45.773121 139820296341376 learning.py:512] global step 8705: loss = 0.9546 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8706: loss = 0.7411 (0.235 sec/step)\n",
            "I0802 20:37:46.009226 139820296341376 learning.py:512] global step 8706: loss = 0.7411 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8707: loss = 0.9004 (0.241 sec/step)\n",
            "I0802 20:37:46.251437 139820296341376 learning.py:512] global step 8707: loss = 0.9004 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8708: loss = 0.7819 (0.240 sec/step)\n",
            "I0802 20:37:46.492626 139820296341376 learning.py:512] global step 8708: loss = 0.7819 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8709: loss = 1.0547 (0.252 sec/step)\n",
            "I0802 20:37:46.746270 139820296341376 learning.py:512] global step 8709: loss = 1.0547 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 8710: loss = 0.7320 (0.226 sec/step)\n",
            "I0802 20:37:46.973594 139820296341376 learning.py:512] global step 8710: loss = 0.7320 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8711: loss = 0.6839 (0.241 sec/step)\n",
            "I0802 20:37:47.215991 139820296341376 learning.py:512] global step 8711: loss = 0.6839 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8712: loss = 0.7197 (0.234 sec/step)\n",
            "I0802 20:37:47.451659 139820296341376 learning.py:512] global step 8712: loss = 0.7197 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8713: loss = 0.8129 (0.235 sec/step)\n",
            "I0802 20:37:47.687825 139820296341376 learning.py:512] global step 8713: loss = 0.8129 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8714: loss = 0.8139 (0.227 sec/step)\n",
            "I0802 20:37:47.916092 139820296341376 learning.py:512] global step 8714: loss = 0.8139 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 8715: loss = 0.8242 (0.219 sec/step)\n",
            "I0802 20:37:48.136758 139820296341376 learning.py:512] global step 8715: loss = 0.8242 (0.219 sec/step)\n",
            "INFO:tensorflow:global step 8716: loss = 0.7951 (0.232 sec/step)\n",
            "I0802 20:37:48.370160 139820296341376 learning.py:512] global step 8716: loss = 0.7951 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8717: loss = 0.9010 (0.234 sec/step)\n",
            "I0802 20:37:48.605969 139820296341376 learning.py:512] global step 8717: loss = 0.9010 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8718: loss = 0.9715 (0.230 sec/step)\n",
            "I0802 20:37:48.837949 139820296341376 learning.py:512] global step 8718: loss = 0.9715 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8719: loss = 1.0279 (0.240 sec/step)\n",
            "I0802 20:37:49.079787 139820296341376 learning.py:512] global step 8719: loss = 1.0279 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8720: loss = 0.9227 (0.220 sec/step)\n",
            "I0802 20:37:49.301029 139820296341376 learning.py:512] global step 8720: loss = 0.9227 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 8721: loss = 0.8972 (0.236 sec/step)\n",
            "I0802 20:37:49.538466 139820296341376 learning.py:512] global step 8721: loss = 0.8972 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8722: loss = 0.9642 (0.239 sec/step)\n",
            "I0802 20:37:49.779413 139820296341376 learning.py:512] global step 8722: loss = 0.9642 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8723: loss = 1.2198 (0.241 sec/step)\n",
            "I0802 20:37:50.022427 139820296341376 learning.py:512] global step 8723: loss = 1.2198 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8724: loss = 0.9001 (0.220 sec/step)\n",
            "I0802 20:37:50.243373 139820296341376 learning.py:512] global step 8724: loss = 0.9001 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 8725: loss = 0.6854 (0.237 sec/step)\n",
            "I0802 20:37:50.481614 139820296341376 learning.py:512] global step 8725: loss = 0.6854 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8726: loss = 1.0243 (0.241 sec/step)\n",
            "I0802 20:37:50.724287 139820296341376 learning.py:512] global step 8726: loss = 1.0243 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8727: loss = 0.9579 (0.233 sec/step)\n",
            "I0802 20:37:50.958971 139820296341376 learning.py:512] global step 8727: loss = 0.9579 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8728: loss = 1.0631 (0.238 sec/step)\n",
            "I0802 20:37:51.198491 139820296341376 learning.py:512] global step 8728: loss = 1.0631 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8729: loss = 0.8363 (0.235 sec/step)\n",
            "I0802 20:37:51.434754 139820296341376 learning.py:512] global step 8729: loss = 0.8363 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8730: loss = 0.7880 (0.241 sec/step)\n",
            "I0802 20:37:51.678166 139820296341376 learning.py:512] global step 8730: loss = 0.7880 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8731: loss = 1.0181 (0.241 sec/step)\n",
            "I0802 20:37:51.921077 139820296341376 learning.py:512] global step 8731: loss = 1.0181 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8732: loss = 0.6975 (0.236 sec/step)\n",
            "I0802 20:37:52.158682 139820296341376 learning.py:512] global step 8732: loss = 0.6975 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8733: loss = 0.5804 (0.225 sec/step)\n",
            "I0802 20:37:52.384845 139820296341376 learning.py:512] global step 8733: loss = 0.5804 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8734: loss = 0.7579 (0.220 sec/step)\n",
            "I0802 20:37:52.605802 139820296341376 learning.py:512] global step 8734: loss = 0.7579 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 8735: loss = 0.7982 (0.236 sec/step)\n",
            "I0802 20:37:52.843228 139820296341376 learning.py:512] global step 8735: loss = 0.7982 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8736: loss = 0.9730 (0.233 sec/step)\n",
            "I0802 20:37:53.077935 139820296341376 learning.py:512] global step 8736: loss = 0.9730 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8737: loss = 1.0337 (0.240 sec/step)\n",
            "I0802 20:37:53.319787 139820296341376 learning.py:512] global step 8737: loss = 1.0337 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8738: loss = 0.9433 (0.243 sec/step)\n",
            "I0802 20:37:53.563867 139820296341376 learning.py:512] global step 8738: loss = 0.9433 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8739: loss = 0.7821 (0.231 sec/step)\n",
            "I0802 20:37:53.796169 139820296341376 learning.py:512] global step 8739: loss = 0.7821 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8740: loss = 1.0760 (0.231 sec/step)\n",
            "I0802 20:37:54.028426 139820296341376 learning.py:512] global step 8740: loss = 1.0760 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8741: loss = 0.7355 (0.226 sec/step)\n",
            "I0802 20:37:54.256696 139820296341376 learning.py:512] global step 8741: loss = 0.7355 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8742: loss = 0.8126 (0.235 sec/step)\n",
            "I0802 20:37:54.493324 139820296341376 learning.py:512] global step 8742: loss = 0.8126 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8743: loss = 0.7147 (0.234 sec/step)\n",
            "I0802 20:37:54.728336 139820296341376 learning.py:512] global step 8743: loss = 0.7147 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8744: loss = 0.8288 (0.226 sec/step)\n",
            "I0802 20:37:54.955735 139820296341376 learning.py:512] global step 8744: loss = 0.8288 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8745: loss = 0.7747 (0.226 sec/step)\n",
            "I0802 20:37:55.183645 139820296341376 learning.py:512] global step 8745: loss = 0.7747 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8746: loss = 0.8872 (0.241 sec/step)\n",
            "I0802 20:37:55.425829 139820296341376 learning.py:512] global step 8746: loss = 0.8872 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8747: loss = 0.9194 (0.224 sec/step)\n",
            "I0802 20:37:55.651135 139820296341376 learning.py:512] global step 8747: loss = 0.9194 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8748: loss = 1.1135 (0.222 sec/step)\n",
            "I0802 20:37:55.875135 139820296341376 learning.py:512] global step 8748: loss = 1.1135 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8749: loss = 1.0027 (0.232 sec/step)\n",
            "I0802 20:37:56.108232 139820296341376 learning.py:512] global step 8749: loss = 1.0027 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8750: loss = 1.0039 (0.220 sec/step)\n",
            "I0802 20:37:56.329724 139820296341376 learning.py:512] global step 8750: loss = 1.0039 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 8751: loss = 0.7994 (0.242 sec/step)\n",
            "I0802 20:37:56.573182 139820296341376 learning.py:512] global step 8751: loss = 0.7994 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8752: loss = 0.7529 (0.237 sec/step)\n",
            "I0802 20:37:56.811904 139820296341376 learning.py:512] global step 8752: loss = 0.7529 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8753: loss = 0.8866 (0.245 sec/step)\n",
            "I0802 20:37:57.058618 139820296341376 learning.py:512] global step 8753: loss = 0.8866 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8754: loss = 0.9729 (0.234 sec/step)\n",
            "I0802 20:37:57.294308 139820296341376 learning.py:512] global step 8754: loss = 0.9729 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8755: loss = 1.0054 (0.234 sec/step)\n",
            "I0802 20:37:57.530297 139820296341376 learning.py:512] global step 8755: loss = 1.0054 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8756: loss = 1.1662 (0.241 sec/step)\n",
            "I0802 20:37:57.772859 139820296341376 learning.py:512] global step 8756: loss = 1.1662 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8757: loss = 0.8551 (0.222 sec/step)\n",
            "I0802 20:37:57.996348 139820296341376 learning.py:512] global step 8757: loss = 0.8551 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8758: loss = 0.9267 (0.240 sec/step)\n",
            "I0802 20:37:58.237542 139820296341376 learning.py:512] global step 8758: loss = 0.9267 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8759: loss = 0.7109 (0.224 sec/step)\n",
            "I0802 20:37:58.463993 139820296341376 learning.py:512] global step 8759: loss = 0.7109 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8760: loss = 0.6898 (0.246 sec/step)\n",
            "I0802 20:37:58.712529 139820296341376 learning.py:512] global step 8760: loss = 0.6898 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8761: loss = 0.7382 (0.240 sec/step)\n",
            "I0802 20:37:58.954323 139820296341376 learning.py:512] global step 8761: loss = 0.7382 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8762: loss = 0.9391 (0.231 sec/step)\n",
            "I0802 20:37:59.187121 139820296341376 learning.py:512] global step 8762: loss = 0.9391 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8763: loss = 0.7838 (0.239 sec/step)\n",
            "I0802 20:37:59.427815 139820296341376 learning.py:512] global step 8763: loss = 0.7838 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8764: loss = 0.6971 (0.234 sec/step)\n",
            "I0802 20:37:59.663021 139820296341376 learning.py:512] global step 8764: loss = 0.6971 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8765: loss = 0.8756 (0.242 sec/step)\n",
            "I0802 20:37:59.906440 139820296341376 learning.py:512] global step 8765: loss = 0.8756 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8766: loss = 0.6967 (0.241 sec/step)\n",
            "I0802 20:38:00.149235 139820296341376 learning.py:512] global step 8766: loss = 0.6967 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8767: loss = 0.7236 (0.241 sec/step)\n",
            "I0802 20:38:00.392118 139820296341376 learning.py:512] global step 8767: loss = 0.7236 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8768: loss = 0.9942 (0.240 sec/step)\n",
            "I0802 20:38:00.633405 139820296341376 learning.py:512] global step 8768: loss = 0.9942 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8769: loss = 0.8506 (0.240 sec/step)\n",
            "I0802 20:38:00.874746 139820296341376 learning.py:512] global step 8769: loss = 0.8506 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8770: loss = 1.0921 (0.246 sec/step)\n",
            "I0802 20:38:01.122002 139820296341376 learning.py:512] global step 8770: loss = 1.0921 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8771: loss = 0.7817 (0.238 sec/step)\n",
            "I0802 20:38:01.361013 139820296341376 learning.py:512] global step 8771: loss = 0.7817 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8772: loss = 1.2859 (0.244 sec/step)\n",
            "I0802 20:38:01.606182 139820296341376 learning.py:512] global step 8772: loss = 1.2859 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8773: loss = 0.8021 (0.238 sec/step)\n",
            "I0802 20:38:01.845996 139820296341376 learning.py:512] global step 8773: loss = 0.8021 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8774: loss = 1.0458 (0.237 sec/step)\n",
            "I0802 20:38:02.085692 139820296341376 learning.py:512] global step 8774: loss = 1.0458 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8775: loss = 0.8992 (0.243 sec/step)\n",
            "I0802 20:38:02.329646 139820296341376 learning.py:512] global step 8775: loss = 0.8992 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8776: loss = 0.7511 (0.234 sec/step)\n",
            "I0802 20:38:02.565071 139820296341376 learning.py:512] global step 8776: loss = 0.7511 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8777: loss = 0.8197 (0.247 sec/step)\n",
            "I0802 20:38:02.813113 139820296341376 learning.py:512] global step 8777: loss = 0.8197 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8778: loss = 0.9680 (0.241 sec/step)\n",
            "I0802 20:38:03.055902 139820296341376 learning.py:512] global step 8778: loss = 0.9680 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8779: loss = 0.6737 (0.240 sec/step)\n",
            "I0802 20:38:03.297545 139820296341376 learning.py:512] global step 8779: loss = 0.6737 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8780: loss = 0.6996 (0.239 sec/step)\n",
            "I0802 20:38:03.537987 139820296341376 learning.py:512] global step 8780: loss = 0.6996 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8781: loss = 0.5969 (0.245 sec/step)\n",
            "I0802 20:38:03.784237 139820296341376 learning.py:512] global step 8781: loss = 0.5969 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8782: loss = 0.7533 (0.242 sec/step)\n",
            "I0802 20:38:04.027551 139820296341376 learning.py:512] global step 8782: loss = 0.7533 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8783: loss = 0.8230 (0.234 sec/step)\n",
            "I0802 20:38:04.262922 139820296341376 learning.py:512] global step 8783: loss = 0.8230 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8784: loss = 1.0656 (0.247 sec/step)\n",
            "I0802 20:38:04.511724 139820296341376 learning.py:512] global step 8784: loss = 1.0656 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8785: loss = 0.9261 (0.225 sec/step)\n",
            "I0802 20:38:04.738623 139820296341376 learning.py:512] global step 8785: loss = 0.9261 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8786: loss = 0.7807 (0.235 sec/step)\n",
            "I0802 20:38:04.975300 139820296341376 learning.py:512] global step 8786: loss = 0.7807 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8787: loss = 0.7618 (0.234 sec/step)\n",
            "I0802 20:38:05.211274 139820296341376 learning.py:512] global step 8787: loss = 0.7618 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8788: loss = 0.8781 (0.231 sec/step)\n",
            "I0802 20:38:05.444085 139820296341376 learning.py:512] global step 8788: loss = 0.8781 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8789: loss = 0.8064 (0.242 sec/step)\n",
            "I0802 20:38:05.687779 139820296341376 learning.py:512] global step 8789: loss = 0.8064 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8790: loss = 0.7198 (0.242 sec/step)\n",
            "I0802 20:38:05.931160 139820296341376 learning.py:512] global step 8790: loss = 0.7198 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8791: loss = 0.6205 (0.230 sec/step)\n",
            "I0802 20:38:06.162341 139820296341376 learning.py:512] global step 8791: loss = 0.6205 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8792: loss = 0.9456 (0.244 sec/step)\n",
            "I0802 20:38:06.408360 139820296341376 learning.py:512] global step 8792: loss = 0.9456 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8793: loss = 0.7182 (0.243 sec/step)\n",
            "I0802 20:38:06.652947 139820296341376 learning.py:512] global step 8793: loss = 0.7182 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8794: loss = 0.7185 (0.238 sec/step)\n",
            "I0802 20:38:06.892763 139820296341376 learning.py:512] global step 8794: loss = 0.7185 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8795: loss = 0.8596 (0.241 sec/step)\n",
            "I0802 20:38:07.134617 139820296341376 learning.py:512] global step 8795: loss = 0.8596 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8796: loss = 0.9871 (0.237 sec/step)\n",
            "I0802 20:38:07.373243 139820296341376 learning.py:512] global step 8796: loss = 0.9871 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8797: loss = 0.7835 (0.243 sec/step)\n",
            "I0802 20:38:07.617898 139820296341376 learning.py:512] global step 8797: loss = 0.7835 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8798: loss = 0.9383 (0.239 sec/step)\n",
            "I0802 20:38:07.858531 139820296341376 learning.py:512] global step 8798: loss = 0.9383 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8799: loss = 0.7696 (0.241 sec/step)\n",
            "I0802 20:38:08.101191 139820296341376 learning.py:512] global step 8799: loss = 0.7696 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8800: loss = 0.8531 (0.248 sec/step)\n",
            "I0802 20:38:08.350687 139820296341376 learning.py:512] global step 8800: loss = 0.8531 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8801: loss = 0.9155 (0.243 sec/step)\n",
            "I0802 20:38:08.595344 139820296341376 learning.py:512] global step 8801: loss = 0.9155 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8802: loss = 0.7785 (0.248 sec/step)\n",
            "I0802 20:38:08.844629 139820296341376 learning.py:512] global step 8802: loss = 0.7785 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8803: loss = 1.2179 (0.251 sec/step)\n",
            "I0802 20:38:09.097679 139820296341376 learning.py:512] global step 8803: loss = 1.2179 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8804: loss = 1.0812 (0.248 sec/step)\n",
            "I0802 20:38:09.346906 139820296341376 learning.py:512] global step 8804: loss = 1.0812 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8805: loss = 0.9347 (0.240 sec/step)\n",
            "I0802 20:38:09.588964 139820296341376 learning.py:512] global step 8805: loss = 0.9347 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8806: loss = 0.9205 (0.239 sec/step)\n",
            "I0802 20:38:09.829846 139820296341376 learning.py:512] global step 8806: loss = 0.9205 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8807: loss = 1.0043 (0.232 sec/step)\n",
            "I0802 20:38:10.062981 139820296341376 learning.py:512] global step 8807: loss = 1.0043 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8808: loss = 0.9576 (0.241 sec/step)\n",
            "I0802 20:38:10.305411 139820296341376 learning.py:512] global step 8808: loss = 0.9576 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8809: loss = 0.8317 (0.233 sec/step)\n",
            "I0802 20:38:10.540318 139820296341376 learning.py:512] global step 8809: loss = 0.8317 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8810: loss = 0.8318 (0.228 sec/step)\n",
            "I0802 20:38:10.769947 139820296341376 learning.py:512] global step 8810: loss = 0.8318 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8811: loss = 1.1943 (0.240 sec/step)\n",
            "I0802 20:38:11.011838 139820296341376 learning.py:512] global step 8811: loss = 1.1943 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8812: loss = 0.7971 (0.258 sec/step)\n",
            "I0802 20:38:11.271010 139820296341376 learning.py:512] global step 8812: loss = 0.7971 (0.258 sec/step)\n",
            "INFO:tensorflow:global step 8813: loss = 0.9306 (0.240 sec/step)\n",
            "I0802 20:38:11.512901 139820296341376 learning.py:512] global step 8813: loss = 0.9306 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8814: loss = 0.9021 (0.234 sec/step)\n",
            "I0802 20:38:11.748643 139820296341376 learning.py:512] global step 8814: loss = 0.9021 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8815: loss = 0.7283 (0.245 sec/step)\n",
            "I0802 20:38:11.995190 139820296341376 learning.py:512] global step 8815: loss = 0.7283 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8816: loss = 1.0143 (0.245 sec/step)\n",
            "I0802 20:38:12.242069 139820296341376 learning.py:512] global step 8816: loss = 1.0143 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8817: loss = 1.0940 (0.228 sec/step)\n",
            "I0802 20:38:12.472006 139820296341376 learning.py:512] global step 8817: loss = 1.0940 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8818: loss = 0.8236 (0.237 sec/step)\n",
            "I0802 20:38:12.710094 139820296341376 learning.py:512] global step 8818: loss = 0.8236 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8819: loss = 0.8294 (0.236 sec/step)\n",
            "I0802 20:38:12.947316 139820296341376 learning.py:512] global step 8819: loss = 0.8294 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8820: loss = 0.8247 (0.248 sec/step)\n",
            "I0802 20:38:13.197404 139820296341376 learning.py:512] global step 8820: loss = 0.8247 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8821: loss = 0.8811 (0.244 sec/step)\n",
            "I0802 20:38:13.442734 139820296341376 learning.py:512] global step 8821: loss = 0.8811 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8822: loss = 0.7869 (0.241 sec/step)\n",
            "I0802 20:38:13.685298 139820296341376 learning.py:512] global step 8822: loss = 0.7869 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8823: loss = 1.0882 (0.225 sec/step)\n",
            "I0802 20:38:13.911653 139820296341376 learning.py:512] global step 8823: loss = 1.0882 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8824: loss = 0.8319 (0.241 sec/step)\n",
            "I0802 20:38:14.154254 139820296341376 learning.py:512] global step 8824: loss = 0.8319 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8825: loss = 1.1009 (0.245 sec/step)\n",
            "I0802 20:38:14.401616 139820296341376 learning.py:512] global step 8825: loss = 1.1009 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8826: loss = 1.1236 (0.239 sec/step)\n",
            "I0802 20:38:14.641889 139820296341376 learning.py:512] global step 8826: loss = 1.1236 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8827: loss = 0.9126 (0.249 sec/step)\n",
            "I0802 20:38:14.892281 139820296341376 learning.py:512] global step 8827: loss = 0.9126 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8828: loss = 0.7425 (0.225 sec/step)\n",
            "I0802 20:38:15.118612 139820296341376 learning.py:512] global step 8828: loss = 0.7425 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8829: loss = 0.9109 (0.242 sec/step)\n",
            "I0802 20:38:15.362542 139820296341376 learning.py:512] global step 8829: loss = 0.9109 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8830: loss = 0.7236 (0.241 sec/step)\n",
            "I0802 20:38:15.605163 139820296341376 learning.py:512] global step 8830: loss = 0.7236 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8831: loss = 0.9577 (0.234 sec/step)\n",
            "I0802 20:38:15.840706 139820296341376 learning.py:512] global step 8831: loss = 0.9577 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8832: loss = 1.0173 (0.254 sec/step)\n",
            "I0802 20:38:16.096567 139820296341376 learning.py:512] global step 8832: loss = 1.0173 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 8833: loss = 1.2341 (0.244 sec/step)\n",
            "I0802 20:38:16.342729 139820296341376 learning.py:512] global step 8833: loss = 1.2341 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8834: loss = 1.1028 (0.243 sec/step)\n",
            "I0802 20:38:16.587505 139820296341376 learning.py:512] global step 8834: loss = 1.1028 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8835: loss = 1.3715 (0.234 sec/step)\n",
            "I0802 20:38:16.823218 139820296341376 learning.py:512] global step 8835: loss = 1.3715 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8836: loss = 0.7888 (0.251 sec/step)\n",
            "I0802 20:38:17.075886 139820296341376 learning.py:512] global step 8836: loss = 0.7888 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8837: loss = 1.2627 (0.249 sec/step)\n",
            "I0802 20:38:17.326884 139820296341376 learning.py:512] global step 8837: loss = 1.2627 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 8838: loss = 0.6818 (0.239 sec/step)\n",
            "I0802 20:38:17.567482 139820296341376 learning.py:512] global step 8838: loss = 0.6818 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8839: loss = 0.7852 (0.233 sec/step)\n",
            "I0802 20:38:17.805177 139820296341376 learning.py:512] global step 8839: loss = 0.7852 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8840: loss = 1.0020 (0.250 sec/step)\n",
            "I0802 20:38:18.056603 139820296341376 learning.py:512] global step 8840: loss = 1.0020 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8841: loss = 0.5951 (0.250 sec/step)\n",
            "I0802 20:38:18.308112 139820296341376 learning.py:512] global step 8841: loss = 0.5951 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8842: loss = 0.8831 (0.240 sec/step)\n",
            "I0802 20:38:18.549967 139820296341376 learning.py:512] global step 8842: loss = 0.8831 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8843: loss = 0.6329 (0.270 sec/step)\n",
            "I0802 20:38:18.821572 139820296341376 learning.py:512] global step 8843: loss = 0.6329 (0.270 sec/step)\n",
            "INFO:tensorflow:global step 8844: loss = 0.9190 (0.297 sec/step)\n",
            "I0802 20:38:19.121324 139820296341376 learning.py:512] global step 8844: loss = 0.9190 (0.297 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 8844.\n",
            "I0802 20:38:19.223657 139815876826880 supervisor.py:1050] Recording summary at step 8844.\n",
            "INFO:tensorflow:global step 8845: loss = 0.7875 (0.267 sec/step)\n",
            "I0802 20:38:19.390187 139820296341376 learning.py:512] global step 8845: loss = 0.7875 (0.267 sec/step)\n",
            "INFO:tensorflow:global step 8846: loss = 0.8183 (0.237 sec/step)\n",
            "I0802 20:38:19.628906 139820296341376 learning.py:512] global step 8846: loss = 0.8183 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8847: loss = 0.8472 (0.241 sec/step)\n",
            "I0802 20:38:19.871481 139820296341376 learning.py:512] global step 8847: loss = 0.8472 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8848: loss = 1.0214 (0.232 sec/step)\n",
            "I0802 20:38:20.105036 139820296341376 learning.py:512] global step 8848: loss = 1.0214 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8849: loss = 0.9004 (0.240 sec/step)\n",
            "I0802 20:38:20.346201 139820296341376 learning.py:512] global step 8849: loss = 0.9004 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8850: loss = 0.9252 (0.243 sec/step)\n",
            "I0802 20:38:20.590989 139820296341376 learning.py:512] global step 8850: loss = 0.9252 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8851: loss = 0.9378 (0.231 sec/step)\n",
            "I0802 20:38:20.823617 139820296341376 learning.py:512] global step 8851: loss = 0.9378 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8852: loss = 0.8649 (0.231 sec/step)\n",
            "I0802 20:38:21.056638 139820296341376 learning.py:512] global step 8852: loss = 0.8649 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8853: loss = 0.7108 (0.241 sec/step)\n",
            "I0802 20:38:21.298927 139820296341376 learning.py:512] global step 8853: loss = 0.7108 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8854: loss = 0.8286 (0.239 sec/step)\n",
            "I0802 20:38:21.539123 139820296341376 learning.py:512] global step 8854: loss = 0.8286 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8855: loss = 0.8859 (0.241 sec/step)\n",
            "I0802 20:38:21.781568 139820296341376 learning.py:512] global step 8855: loss = 0.8859 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8856: loss = 0.9802 (0.240 sec/step)\n",
            "I0802 20:38:22.023094 139820296341376 learning.py:512] global step 8856: loss = 0.9802 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8857: loss = 0.6816 (0.246 sec/step)\n",
            "I0802 20:38:22.270687 139820296341376 learning.py:512] global step 8857: loss = 0.6816 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8858: loss = 0.6455 (0.242 sec/step)\n",
            "I0802 20:38:22.514177 139820296341376 learning.py:512] global step 8858: loss = 0.6455 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8859: loss = 0.8888 (0.246 sec/step)\n",
            "I0802 20:38:22.761568 139820296341376 learning.py:512] global step 8859: loss = 0.8888 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8860: loss = 0.8586 (0.240 sec/step)\n",
            "I0802 20:38:23.002994 139820296341376 learning.py:512] global step 8860: loss = 0.8586 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8861: loss = 1.0262 (0.236 sec/step)\n",
            "I0802 20:38:23.240884 139820296341376 learning.py:512] global step 8861: loss = 1.0262 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8862: loss = 1.1779 (0.240 sec/step)\n",
            "I0802 20:38:23.482104 139820296341376 learning.py:512] global step 8862: loss = 1.1779 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8863: loss = 0.9105 (0.246 sec/step)\n",
            "I0802 20:38:23.729700 139820296341376 learning.py:512] global step 8863: loss = 0.9105 (0.246 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 4.18334\n",
            "I0802 20:38:23.879558 139815885219584 supervisor.py:1099] global_step/sec: 4.18334\n",
            "INFO:tensorflow:global step 8864: loss = 0.8907 (0.234 sec/step)\n",
            "I0802 20:38:23.965758 139820296341376 learning.py:512] global step 8864: loss = 0.8907 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8865: loss = 0.8006 (0.247 sec/step)\n",
            "I0802 20:38:24.214566 139820296341376 learning.py:512] global step 8865: loss = 0.8006 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8866: loss = 0.7252 (0.240 sec/step)\n",
            "I0802 20:38:24.456154 139820296341376 learning.py:512] global step 8866: loss = 0.7252 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8867: loss = 0.8881 (0.241 sec/step)\n",
            "I0802 20:38:24.698570 139820296341376 learning.py:512] global step 8867: loss = 0.8881 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8868: loss = 1.0600 (0.242 sec/step)\n",
            "I0802 20:38:24.941719 139820296341376 learning.py:512] global step 8868: loss = 1.0600 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8869: loss = 0.9221 (0.244 sec/step)\n",
            "I0802 20:38:25.187530 139820296341376 learning.py:512] global step 8869: loss = 0.9221 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8870: loss = 0.7972 (0.240 sec/step)\n",
            "I0802 20:38:25.428761 139820296341376 learning.py:512] global step 8870: loss = 0.7972 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8871: loss = 0.9515 (0.243 sec/step)\n",
            "I0802 20:38:25.673120 139820296341376 learning.py:512] global step 8871: loss = 0.9515 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8872: loss = 1.0098 (0.237 sec/step)\n",
            "I0802 20:38:25.911751 139820296341376 learning.py:512] global step 8872: loss = 1.0098 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8873: loss = 0.9354 (0.242 sec/step)\n",
            "I0802 20:38:26.155297 139820296341376 learning.py:512] global step 8873: loss = 0.9354 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8874: loss = 0.9031 (0.243 sec/step)\n",
            "I0802 20:38:26.399356 139820296341376 learning.py:512] global step 8874: loss = 0.9031 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8875: loss = 0.7707 (0.242 sec/step)\n",
            "I0802 20:38:26.642941 139820296341376 learning.py:512] global step 8875: loss = 0.7707 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8876: loss = 0.7912 (0.242 sec/step)\n",
            "I0802 20:38:26.886126 139820296341376 learning.py:512] global step 8876: loss = 0.7912 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8877: loss = 0.8025 (0.234 sec/step)\n",
            "I0802 20:38:27.121907 139820296341376 learning.py:512] global step 8877: loss = 0.8025 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8878: loss = 0.8700 (0.250 sec/step)\n",
            "I0802 20:38:27.373390 139820296341376 learning.py:512] global step 8878: loss = 0.8700 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 8879: loss = 1.1031 (0.242 sec/step)\n",
            "I0802 20:38:27.616759 139820296341376 learning.py:512] global step 8879: loss = 1.1031 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8880: loss = 0.8986 (0.242 sec/step)\n",
            "I0802 20:38:27.860343 139820296341376 learning.py:512] global step 8880: loss = 0.8986 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8881: loss = 0.8594 (0.239 sec/step)\n",
            "I0802 20:38:28.100959 139820296341376 learning.py:512] global step 8881: loss = 0.8594 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8882: loss = 0.8309 (0.240 sec/step)\n",
            "I0802 20:38:28.342886 139820296341376 learning.py:512] global step 8882: loss = 0.8309 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8883: loss = 1.0122 (0.242 sec/step)\n",
            "I0802 20:38:28.586098 139820296341376 learning.py:512] global step 8883: loss = 1.0122 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8884: loss = 0.8492 (0.243 sec/step)\n",
            "I0802 20:38:28.830534 139820296341376 learning.py:512] global step 8884: loss = 0.8492 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8885: loss = 0.9139 (0.228 sec/step)\n",
            "I0802 20:38:29.060389 139820296341376 learning.py:512] global step 8885: loss = 0.9139 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8886: loss = 0.9425 (0.244 sec/step)\n",
            "I0802 20:38:29.305672 139820296341376 learning.py:512] global step 8886: loss = 0.9425 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8887: loss = 0.8484 (0.238 sec/step)\n",
            "I0802 20:38:29.545699 139820296341376 learning.py:512] global step 8887: loss = 0.8484 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8888: loss = 0.9453 (0.240 sec/step)\n",
            "I0802 20:38:29.787132 139820296341376 learning.py:512] global step 8888: loss = 0.9453 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8889: loss = 0.7004 (0.233 sec/step)\n",
            "I0802 20:38:30.021982 139820296341376 learning.py:512] global step 8889: loss = 0.7004 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8890: loss = 0.8763 (0.248 sec/step)\n",
            "I0802 20:38:30.271592 139820296341376 learning.py:512] global step 8890: loss = 0.8763 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8891: loss = 0.8800 (0.239 sec/step)\n",
            "I0802 20:38:30.512309 139820296341376 learning.py:512] global step 8891: loss = 0.8800 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8892: loss = 0.9276 (0.246 sec/step)\n",
            "I0802 20:38:30.759607 139820296341376 learning.py:512] global step 8892: loss = 0.9276 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8893: loss = 0.8822 (0.241 sec/step)\n",
            "I0802 20:38:31.002471 139820296341376 learning.py:512] global step 8893: loss = 0.8822 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8894: loss = 0.8509 (0.246 sec/step)\n",
            "I0802 20:38:31.250240 139820296341376 learning.py:512] global step 8894: loss = 0.8509 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 8895: loss = 1.0297 (0.231 sec/step)\n",
            "I0802 20:38:31.484569 139820296341376 learning.py:512] global step 8895: loss = 1.0297 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8896: loss = 0.8230 (0.234 sec/step)\n",
            "I0802 20:38:31.720180 139820296341376 learning.py:512] global step 8896: loss = 0.8230 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8897: loss = 0.9468 (0.238 sec/step)\n",
            "I0802 20:38:31.959152 139820296341376 learning.py:512] global step 8897: loss = 0.9468 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8898: loss = 0.7771 (0.224 sec/step)\n",
            "I0802 20:38:32.184967 139820296341376 learning.py:512] global step 8898: loss = 0.7771 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8899: loss = 0.7936 (0.230 sec/step)\n",
            "I0802 20:38:32.416256 139820296341376 learning.py:512] global step 8899: loss = 0.7936 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 8900: loss = 0.6905 (0.240 sec/step)\n",
            "I0802 20:38:32.657442 139820296341376 learning.py:512] global step 8900: loss = 0.6905 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8901: loss = 0.8042 (0.244 sec/step)\n",
            "I0802 20:38:32.902575 139820296341376 learning.py:512] global step 8901: loss = 0.8042 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8902: loss = 0.8181 (0.223 sec/step)\n",
            "I0802 20:38:33.126829 139820296341376 learning.py:512] global step 8902: loss = 0.8181 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8903: loss = 0.7890 (0.236 sec/step)\n",
            "I0802 20:38:33.364182 139820296341376 learning.py:512] global step 8903: loss = 0.7890 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8904: loss = 0.9845 (0.225 sec/step)\n",
            "I0802 20:38:33.591064 139820296341376 learning.py:512] global step 8904: loss = 0.9845 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8905: loss = 1.0569 (0.234 sec/step)\n",
            "I0802 20:38:33.826311 139820296341376 learning.py:512] global step 8905: loss = 1.0569 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8906: loss = 0.5886 (0.235 sec/step)\n",
            "I0802 20:38:34.062777 139820296341376 learning.py:512] global step 8906: loss = 0.5886 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8907: loss = 1.0283 (0.244 sec/step)\n",
            "I0802 20:38:34.311333 139820296341376 learning.py:512] global step 8907: loss = 1.0283 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8908: loss = 0.8125 (0.238 sec/step)\n",
            "I0802 20:38:34.551471 139820296341376 learning.py:512] global step 8908: loss = 0.8125 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8909: loss = 0.7221 (0.224 sec/step)\n",
            "I0802 20:38:34.777039 139820296341376 learning.py:512] global step 8909: loss = 0.7221 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8910: loss = 0.8173 (0.236 sec/step)\n",
            "I0802 20:38:35.014810 139820296341376 learning.py:512] global step 8910: loss = 0.8173 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8911: loss = 0.9931 (0.235 sec/step)\n",
            "I0802 20:38:35.251292 139820296341376 learning.py:512] global step 8911: loss = 0.9931 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8912: loss = 0.8542 (0.238 sec/step)\n",
            "I0802 20:38:35.490876 139820296341376 learning.py:512] global step 8912: loss = 0.8542 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8913: loss = 0.5923 (0.238 sec/step)\n",
            "I0802 20:38:35.730826 139820296341376 learning.py:512] global step 8913: loss = 0.5923 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8914: loss = 0.9202 (0.224 sec/step)\n",
            "I0802 20:38:35.956259 139820296341376 learning.py:512] global step 8914: loss = 0.9202 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8915: loss = 0.8936 (0.232 sec/step)\n",
            "I0802 20:38:36.189580 139820296341376 learning.py:512] global step 8915: loss = 0.8936 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8916: loss = 1.2230 (0.222 sec/step)\n",
            "I0802 20:38:36.412872 139820296341376 learning.py:512] global step 8916: loss = 1.2230 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8917: loss = 0.6400 (0.233 sec/step)\n",
            "I0802 20:38:36.647757 139820296341376 learning.py:512] global step 8917: loss = 0.6400 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 8918: loss = 0.7845 (0.236 sec/step)\n",
            "I0802 20:38:36.885168 139820296341376 learning.py:512] global step 8918: loss = 0.7845 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8919: loss = 0.7984 (0.245 sec/step)\n",
            "I0802 20:38:37.131266 139820296341376 learning.py:512] global step 8919: loss = 0.7984 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8920: loss = 0.8151 (0.236 sec/step)\n",
            "I0802 20:38:37.368509 139820296341376 learning.py:512] global step 8920: loss = 0.8151 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8921: loss = 1.1107 (0.223 sec/step)\n",
            "I0802 20:38:37.592509 139820296341376 learning.py:512] global step 8921: loss = 1.1107 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8922: loss = 0.8812 (0.237 sec/step)\n",
            "I0802 20:38:37.831139 139820296341376 learning.py:512] global step 8922: loss = 0.8812 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8923: loss = 0.9292 (0.238 sec/step)\n",
            "I0802 20:38:38.071079 139820296341376 learning.py:512] global step 8923: loss = 0.9292 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8924: loss = 0.8582 (0.225 sec/step)\n",
            "I0802 20:38:38.297519 139820296341376 learning.py:512] global step 8924: loss = 0.8582 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8925: loss = 1.1981 (0.248 sec/step)\n",
            "I0802 20:38:38.547641 139820296341376 learning.py:512] global step 8925: loss = 1.1981 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8926: loss = 0.8927 (0.248 sec/step)\n",
            "I0802 20:38:38.797067 139820296341376 learning.py:512] global step 8926: loss = 0.8927 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8927: loss = 0.8273 (0.245 sec/step)\n",
            "I0802 20:38:39.048078 139820296341376 learning.py:512] global step 8927: loss = 0.8273 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 8928: loss = 0.8496 (0.237 sec/step)\n",
            "I0802 20:38:39.290379 139820296341376 learning.py:512] global step 8928: loss = 0.8496 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8929: loss = 0.8753 (0.247 sec/step)\n",
            "I0802 20:38:39.538571 139820296341376 learning.py:512] global step 8929: loss = 0.8753 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8930: loss = 1.1604 (0.238 sec/step)\n",
            "I0802 20:38:39.777813 139820296341376 learning.py:512] global step 8930: loss = 1.1604 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8931: loss = 0.8993 (0.234 sec/step)\n",
            "I0802 20:38:40.012849 139820296341376 learning.py:512] global step 8931: loss = 0.8993 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8932: loss = 0.8154 (0.242 sec/step)\n",
            "I0802 20:38:40.256589 139820296341376 learning.py:512] global step 8932: loss = 0.8154 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8933: loss = 0.7673 (0.241 sec/step)\n",
            "I0802 20:38:40.504296 139820296341376 learning.py:512] global step 8933: loss = 0.7673 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8934: loss = 1.1397 (0.238 sec/step)\n",
            "I0802 20:38:40.743436 139820296341376 learning.py:512] global step 8934: loss = 1.1397 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8935: loss = 1.2268 (0.239 sec/step)\n",
            "I0802 20:38:40.983684 139820296341376 learning.py:512] global step 8935: loss = 1.2268 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8936: loss = 0.8568 (0.238 sec/step)\n",
            "I0802 20:38:41.222893 139820296341376 learning.py:512] global step 8936: loss = 0.8568 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8937: loss = 0.9896 (0.229 sec/step)\n",
            "I0802 20:38:41.453769 139820296341376 learning.py:512] global step 8937: loss = 0.9896 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 8938: loss = 0.8456 (0.235 sec/step)\n",
            "I0802 20:38:41.690165 139820296341376 learning.py:512] global step 8938: loss = 0.8456 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8939: loss = 0.6115 (0.232 sec/step)\n",
            "I0802 20:38:41.924009 139820296341376 learning.py:512] global step 8939: loss = 0.6115 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8940: loss = 0.8021 (0.238 sec/step)\n",
            "I0802 20:38:42.163146 139820296341376 learning.py:512] global step 8940: loss = 0.8021 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8941: loss = 1.1936 (0.225 sec/step)\n",
            "I0802 20:38:42.389600 139820296341376 learning.py:512] global step 8941: loss = 1.1936 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8942: loss = 1.0834 (0.244 sec/step)\n",
            "I0802 20:38:42.635553 139820296341376 learning.py:512] global step 8942: loss = 1.0834 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8943: loss = 0.7940 (0.237 sec/step)\n",
            "I0802 20:38:42.873650 139820296341376 learning.py:512] global step 8943: loss = 0.7940 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8944: loss = 1.1673 (0.226 sec/step)\n",
            "I0802 20:38:43.101234 139820296341376 learning.py:512] global step 8944: loss = 1.1673 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8945: loss = 1.0957 (0.231 sec/step)\n",
            "I0802 20:38:43.333457 139820296341376 learning.py:512] global step 8945: loss = 1.0957 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8946: loss = 1.1022 (0.243 sec/step)\n",
            "I0802 20:38:43.577909 139820296341376 learning.py:512] global step 8946: loss = 1.1022 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8947: loss = 1.0266 (0.241 sec/step)\n",
            "I0802 20:38:43.820891 139820296341376 learning.py:512] global step 8947: loss = 1.0266 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8948: loss = 0.7744 (0.226 sec/step)\n",
            "I0802 20:38:44.048784 139820296341376 learning.py:512] global step 8948: loss = 0.7744 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8949: loss = 1.0367 (0.247 sec/step)\n",
            "I0802 20:38:44.297132 139820296341376 learning.py:512] global step 8949: loss = 1.0367 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8950: loss = 0.7397 (0.238 sec/step)\n",
            "I0802 20:38:44.536388 139820296341376 learning.py:512] global step 8950: loss = 0.7397 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8951: loss = 0.8092 (0.244 sec/step)\n",
            "I0802 20:38:44.781548 139820296341376 learning.py:512] global step 8951: loss = 0.8092 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8952: loss = 0.7899 (0.244 sec/step)\n",
            "I0802 20:38:45.027640 139820296341376 learning.py:512] global step 8952: loss = 0.7899 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8953: loss = 0.7161 (0.223 sec/step)\n",
            "I0802 20:38:45.252235 139820296341376 learning.py:512] global step 8953: loss = 0.7161 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8954: loss = 0.8868 (0.238 sec/step)\n",
            "I0802 20:38:45.492018 139820296341376 learning.py:512] global step 8954: loss = 0.8868 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8955: loss = 0.7556 (0.238 sec/step)\n",
            "I0802 20:38:45.731163 139820296341376 learning.py:512] global step 8955: loss = 0.7556 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8956: loss = 0.8111 (0.232 sec/step)\n",
            "I0802 20:38:45.964342 139820296341376 learning.py:512] global step 8956: loss = 0.8111 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8957: loss = 0.8527 (0.236 sec/step)\n",
            "I0802 20:38:46.201406 139820296341376 learning.py:512] global step 8957: loss = 0.8527 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8958: loss = 0.8948 (0.234 sec/step)\n",
            "I0802 20:38:46.436498 139820296341376 learning.py:512] global step 8958: loss = 0.8948 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 8959: loss = 1.0394 (0.236 sec/step)\n",
            "I0802 20:38:46.674531 139820296341376 learning.py:512] global step 8959: loss = 1.0394 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8960: loss = 0.8456 (0.240 sec/step)\n",
            "I0802 20:38:46.915762 139820296341376 learning.py:512] global step 8960: loss = 0.8456 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8961: loss = 0.8430 (0.235 sec/step)\n",
            "I0802 20:38:47.152675 139820296341376 learning.py:512] global step 8961: loss = 0.8430 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8962: loss = 0.8805 (0.240 sec/step)\n",
            "I0802 20:38:47.393826 139820296341376 learning.py:512] global step 8962: loss = 0.8805 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 8963: loss = 0.7745 (0.231 sec/step)\n",
            "I0802 20:38:47.626622 139820296341376 learning.py:512] global step 8963: loss = 0.7745 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 8964: loss = 0.8770 (0.241 sec/step)\n",
            "I0802 20:38:47.868892 139820296341376 learning.py:512] global step 8964: loss = 0.8770 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8965: loss = 0.8649 (0.243 sec/step)\n",
            "I0802 20:38:48.113867 139820296341376 learning.py:512] global step 8965: loss = 0.8649 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8966: loss = 0.9558 (0.224 sec/step)\n",
            "I0802 20:38:48.339720 139820296341376 learning.py:512] global step 8966: loss = 0.9558 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8967: loss = 1.1325 (0.222 sec/step)\n",
            "I0802 20:38:48.562949 139820296341376 learning.py:512] global step 8967: loss = 1.1325 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8968: loss = 0.9212 (0.238 sec/step)\n",
            "I0802 20:38:48.802522 139820296341376 learning.py:512] global step 8968: loss = 0.9212 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8969: loss = 0.5262 (0.242 sec/step)\n",
            "I0802 20:38:49.045683 139820296341376 learning.py:512] global step 8969: loss = 0.5262 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8970: loss = 1.0629 (0.223 sec/step)\n",
            "I0802 20:38:49.269910 139820296341376 learning.py:512] global step 8970: loss = 1.0629 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8971: loss = 0.9765 (0.237 sec/step)\n",
            "I0802 20:38:49.508591 139820296341376 learning.py:512] global step 8971: loss = 0.9765 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8972: loss = 0.8322 (0.222 sec/step)\n",
            "I0802 20:38:49.731863 139820296341376 learning.py:512] global step 8972: loss = 0.8322 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 8973: loss = 1.0341 (0.241 sec/step)\n",
            "I0802 20:38:49.974502 139820296341376 learning.py:512] global step 8973: loss = 1.0341 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 8974: loss = 0.7708 (0.242 sec/step)\n",
            "I0802 20:38:50.218533 139820296341376 learning.py:512] global step 8974: loss = 0.7708 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 8975: loss = 0.7661 (0.223 sec/step)\n",
            "I0802 20:38:50.443337 139820296341376 learning.py:512] global step 8975: loss = 0.7661 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 8976: loss = 1.3367 (0.225 sec/step)\n",
            "I0802 20:38:50.669639 139820296341376 learning.py:512] global step 8976: loss = 1.3367 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8977: loss = 0.9762 (0.228 sec/step)\n",
            "I0802 20:38:50.898578 139820296341376 learning.py:512] global step 8977: loss = 0.9762 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 8978: loss = 0.7560 (0.226 sec/step)\n",
            "I0802 20:38:51.126045 139820296341376 learning.py:512] global step 8978: loss = 0.7560 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8979: loss = 0.7817 (0.253 sec/step)\n",
            "I0802 20:38:51.380177 139820296341376 learning.py:512] global step 8979: loss = 0.7817 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 8980: loss = 0.8465 (0.226 sec/step)\n",
            "I0802 20:38:51.607907 139820296341376 learning.py:512] global step 8980: loss = 0.8465 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 8981: loss = 1.4496 (0.225 sec/step)\n",
            "I0802 20:38:51.833981 139820296341376 learning.py:512] global step 8981: loss = 1.4496 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8982: loss = 1.0044 (0.244 sec/step)\n",
            "I0802 20:38:52.079485 139820296341376 learning.py:512] global step 8982: loss = 1.0044 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8983: loss = 1.1199 (0.238 sec/step)\n",
            "I0802 20:38:52.318958 139820296341376 learning.py:512] global step 8983: loss = 1.1199 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8984: loss = 0.9013 (0.247 sec/step)\n",
            "I0802 20:38:52.567677 139820296341376 learning.py:512] global step 8984: loss = 0.9013 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 8985: loss = 0.9981 (0.238 sec/step)\n",
            "I0802 20:38:52.807019 139820296341376 learning.py:512] global step 8985: loss = 0.9981 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8986: loss = 0.8084 (0.251 sec/step)\n",
            "I0802 20:38:53.059006 139820296341376 learning.py:512] global step 8986: loss = 0.8084 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 8987: loss = 0.8869 (0.237 sec/step)\n",
            "I0802 20:38:53.297471 139820296341376 learning.py:512] global step 8987: loss = 0.8869 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 8988: loss = 0.7738 (0.248 sec/step)\n",
            "I0802 20:38:53.548088 139820296341376 learning.py:512] global step 8988: loss = 0.7738 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 8989: loss = 0.8871 (0.224 sec/step)\n",
            "I0802 20:38:53.774124 139820296341376 learning.py:512] global step 8989: loss = 0.8871 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 8990: loss = 0.7799 (0.235 sec/step)\n",
            "I0802 20:38:54.010234 139820296341376 learning.py:512] global step 8990: loss = 0.7799 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 8991: loss = 1.0124 (0.243 sec/step)\n",
            "I0802 20:38:54.254636 139820296341376 learning.py:512] global step 8991: loss = 1.0124 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 8992: loss = 1.1404 (0.232 sec/step)\n",
            "I0802 20:38:54.488359 139820296341376 learning.py:512] global step 8992: loss = 1.1404 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 8993: loss = 0.8534 (0.225 sec/step)\n",
            "I0802 20:38:54.714991 139820296341376 learning.py:512] global step 8993: loss = 0.8534 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 8994: loss = 0.9298 (0.238 sec/step)\n",
            "I0802 20:38:54.954817 139820296341376 learning.py:512] global step 8994: loss = 0.9298 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 8995: loss = 0.7386 (0.239 sec/step)\n",
            "I0802 20:38:55.195060 139820296341376 learning.py:512] global step 8995: loss = 0.7386 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8996: loss = 0.9262 (0.239 sec/step)\n",
            "I0802 20:38:55.436044 139820296341376 learning.py:512] global step 8996: loss = 0.9262 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 8997: loss = 0.8785 (0.244 sec/step)\n",
            "I0802 20:38:55.681115 139820296341376 learning.py:512] global step 8997: loss = 0.8785 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 8998: loss = 0.9562 (0.236 sec/step)\n",
            "I0802 20:38:55.919099 139820296341376 learning.py:512] global step 8998: loss = 0.9562 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 8999: loss = 0.8376 (0.229 sec/step)\n",
            "I0802 20:38:56.149879 139820296341376 learning.py:512] global step 8999: loss = 0.8376 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9000: loss = 1.5179 (0.241 sec/step)\n",
            "I0802 20:38:56.392645 139820296341376 learning.py:512] global step 9000: loss = 1.5179 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9001: loss = 1.1005 (0.234 sec/step)\n",
            "I0802 20:38:56.628195 139820296341376 learning.py:512] global step 9001: loss = 1.1005 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9002: loss = 0.8844 (0.232 sec/step)\n",
            "I0802 20:38:56.862060 139820296341376 learning.py:512] global step 9002: loss = 0.8844 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9003: loss = 0.7153 (0.225 sec/step)\n",
            "I0802 20:38:57.088856 139820296341376 learning.py:512] global step 9003: loss = 0.7153 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9004: loss = 0.6896 (0.236 sec/step)\n",
            "I0802 20:38:57.326761 139820296341376 learning.py:512] global step 9004: loss = 0.6896 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9005: loss = 0.8889 (0.239 sec/step)\n",
            "I0802 20:38:57.567226 139820296341376 learning.py:512] global step 9005: loss = 0.8889 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9006: loss = 0.9963 (0.229 sec/step)\n",
            "I0802 20:38:57.797558 139820296341376 learning.py:512] global step 9006: loss = 0.9963 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9007: loss = 0.9919 (0.223 sec/step)\n",
            "I0802 20:38:58.022211 139820296341376 learning.py:512] global step 9007: loss = 0.9919 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9008: loss = 0.8369 (0.239 sec/step)\n",
            "I0802 20:38:58.262175 139820296341376 learning.py:512] global step 9008: loss = 0.8369 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9009: loss = 0.9233 (0.245 sec/step)\n",
            "I0802 20:38:58.508653 139820296341376 learning.py:512] global step 9009: loss = 0.9233 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9010: loss = 0.8018 (0.231 sec/step)\n",
            "I0802 20:38:58.741103 139820296341376 learning.py:512] global step 9010: loss = 0.8018 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9011: loss = 1.1115 (0.243 sec/step)\n",
            "I0802 20:38:58.985733 139820296341376 learning.py:512] global step 9011: loss = 1.1115 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9012: loss = 0.8678 (0.238 sec/step)\n",
            "I0802 20:38:59.225374 139820296341376 learning.py:512] global step 9012: loss = 0.8678 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9013: loss = 0.8935 (0.249 sec/step)\n",
            "I0802 20:38:59.476176 139820296341376 learning.py:512] global step 9013: loss = 0.8935 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9014: loss = 0.8947 (0.240 sec/step)\n",
            "I0802 20:38:59.718096 139820296341376 learning.py:512] global step 9014: loss = 0.8947 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9015: loss = 0.7724 (0.221 sec/step)\n",
            "I0802 20:38:59.940540 139820296341376 learning.py:512] global step 9015: loss = 0.7724 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 9016: loss = 0.6039 (0.241 sec/step)\n",
            "I0802 20:39:00.183458 139820296341376 learning.py:512] global step 9016: loss = 0.6039 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9017: loss = 0.8851 (0.232 sec/step)\n",
            "I0802 20:39:00.417436 139820296341376 learning.py:512] global step 9017: loss = 0.8851 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9018: loss = 1.0397 (0.225 sec/step)\n",
            "I0802 20:39:00.644281 139820296341376 learning.py:512] global step 9018: loss = 1.0397 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9019: loss = 1.0759 (0.249 sec/step)\n",
            "I0802 20:39:00.894637 139820296341376 learning.py:512] global step 9019: loss = 1.0759 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9020: loss = 1.0770 (0.236 sec/step)\n",
            "I0802 20:39:01.131880 139820296341376 learning.py:512] global step 9020: loss = 1.0770 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9021: loss = 0.7548 (0.220 sec/step)\n",
            "I0802 20:39:01.353837 139820296341376 learning.py:512] global step 9021: loss = 0.7548 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 9022: loss = 1.1609 (0.244 sec/step)\n",
            "I0802 20:39:01.599800 139820296341376 learning.py:512] global step 9022: loss = 1.1609 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9023: loss = 0.9868 (0.240 sec/step)\n",
            "I0802 20:39:01.841741 139820296341376 learning.py:512] global step 9023: loss = 0.9868 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9024: loss = 0.8066 (0.222 sec/step)\n",
            "I0802 20:39:02.065470 139820296341376 learning.py:512] global step 9024: loss = 0.8066 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9025: loss = 0.8531 (0.236 sec/step)\n",
            "I0802 20:39:02.303132 139820296341376 learning.py:512] global step 9025: loss = 0.8531 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9026: loss = 1.1643 (0.244 sec/step)\n",
            "I0802 20:39:02.548788 139820296341376 learning.py:512] global step 9026: loss = 1.1643 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9027: loss = 0.7570 (0.228 sec/step)\n",
            "I0802 20:39:02.778180 139820296341376 learning.py:512] global step 9027: loss = 0.7570 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9028: loss = 0.6826 (0.247 sec/step)\n",
            "I0802 20:39:03.027674 139820296341376 learning.py:512] global step 9028: loss = 0.6826 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9029: loss = 0.9433 (0.244 sec/step)\n",
            "I0802 20:39:03.274529 139820296341376 learning.py:512] global step 9029: loss = 0.9433 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9030: loss = 0.8130 (0.226 sec/step)\n",
            "I0802 20:39:03.502160 139820296341376 learning.py:512] global step 9030: loss = 0.8130 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9031: loss = 1.0549 (0.243 sec/step)\n",
            "I0802 20:39:03.746907 139820296341376 learning.py:512] global step 9031: loss = 1.0549 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9032: loss = 1.4322 (0.224 sec/step)\n",
            "I0802 20:39:03.972758 139820296341376 learning.py:512] global step 9032: loss = 1.4322 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9033: loss = 0.7259 (0.246 sec/step)\n",
            "I0802 20:39:04.219889 139820296341376 learning.py:512] global step 9033: loss = 0.7259 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9034: loss = 0.9657 (0.243 sec/step)\n",
            "I0802 20:39:04.463888 139820296341376 learning.py:512] global step 9034: loss = 0.9657 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9035: loss = 0.6725 (0.241 sec/step)\n",
            "I0802 20:39:04.707864 139820296341376 learning.py:512] global step 9035: loss = 0.6725 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9036: loss = 1.1441 (0.240 sec/step)\n",
            "I0802 20:39:04.949752 139820296341376 learning.py:512] global step 9036: loss = 1.1441 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9037: loss = 0.7918 (0.237 sec/step)\n",
            "I0802 20:39:05.188040 139820296341376 learning.py:512] global step 9037: loss = 0.7918 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9038: loss = 0.9578 (0.238 sec/step)\n",
            "I0802 20:39:05.427366 139820296341376 learning.py:512] global step 9038: loss = 0.9578 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9039: loss = 0.8377 (0.241 sec/step)\n",
            "I0802 20:39:05.669700 139820296341376 learning.py:512] global step 9039: loss = 0.8377 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9040: loss = 1.0215 (0.240 sec/step)\n",
            "I0802 20:39:05.911054 139820296341376 learning.py:512] global step 9040: loss = 1.0215 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9041: loss = 0.8336 (0.237 sec/step)\n",
            "I0802 20:39:06.149824 139820296341376 learning.py:512] global step 9041: loss = 0.8336 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9042: loss = 0.6421 (0.245 sec/step)\n",
            "I0802 20:39:06.395901 139820296341376 learning.py:512] global step 9042: loss = 0.6421 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9043: loss = 0.8527 (0.238 sec/step)\n",
            "I0802 20:39:06.635481 139820296341376 learning.py:512] global step 9043: loss = 0.8527 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9044: loss = 0.7723 (0.241 sec/step)\n",
            "I0802 20:39:06.878813 139820296341376 learning.py:512] global step 9044: loss = 0.7723 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9045: loss = 1.0883 (0.233 sec/step)\n",
            "I0802 20:39:07.113734 139820296341376 learning.py:512] global step 9045: loss = 1.0883 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9046: loss = 1.1868 (0.240 sec/step)\n",
            "I0802 20:39:07.355079 139820296341376 learning.py:512] global step 9046: loss = 1.1868 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9047: loss = 0.7738 (0.240 sec/step)\n",
            "I0802 20:39:07.596895 139820296341376 learning.py:512] global step 9047: loss = 0.7738 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9048: loss = 1.2336 (0.239 sec/step)\n",
            "I0802 20:39:07.837686 139820296341376 learning.py:512] global step 9048: loss = 1.2336 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9049: loss = 0.9522 (0.224 sec/step)\n",
            "I0802 20:39:08.063610 139820296341376 learning.py:512] global step 9049: loss = 0.9522 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9050: loss = 0.8515 (0.220 sec/step)\n",
            "I0802 20:39:08.284740 139820296341376 learning.py:512] global step 9050: loss = 0.8515 (0.220 sec/step)\n",
            "INFO:tensorflow:global step 9051: loss = 0.9459 (0.237 sec/step)\n",
            "I0802 20:39:08.523002 139820296341376 learning.py:512] global step 9051: loss = 0.9459 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9052: loss = 0.8081 (0.244 sec/step)\n",
            "I0802 20:39:08.770995 139820296341376 learning.py:512] global step 9052: loss = 0.8081 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9053: loss = 0.9559 (0.237 sec/step)\n",
            "I0802 20:39:09.010042 139820296341376 learning.py:512] global step 9053: loss = 0.9559 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9054: loss = 0.8743 (0.235 sec/step)\n",
            "I0802 20:39:09.246421 139820296341376 learning.py:512] global step 9054: loss = 0.8743 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9055: loss = 0.7255 (0.235 sec/step)\n",
            "I0802 20:39:09.482654 139820296341376 learning.py:512] global step 9055: loss = 0.7255 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9056: loss = 1.0106 (0.241 sec/step)\n",
            "I0802 20:39:09.725337 139820296341376 learning.py:512] global step 9056: loss = 1.0106 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9057: loss = 1.0166 (0.238 sec/step)\n",
            "I0802 20:39:09.964375 139820296341376 learning.py:512] global step 9057: loss = 1.0166 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9058: loss = 0.8204 (0.241 sec/step)\n",
            "I0802 20:39:10.206562 139820296341376 learning.py:512] global step 9058: loss = 0.8204 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9059: loss = 0.9573 (0.241 sec/step)\n",
            "I0802 20:39:10.449180 139820296341376 learning.py:512] global step 9059: loss = 0.9573 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9060: loss = 0.8063 (0.234 sec/step)\n",
            "I0802 20:39:10.684612 139820296341376 learning.py:512] global step 9060: loss = 0.8063 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9061: loss = 0.7388 (0.238 sec/step)\n",
            "I0802 20:39:10.923643 139820296341376 learning.py:512] global step 9061: loss = 0.7388 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9062: loss = 0.6560 (0.235 sec/step)\n",
            "I0802 20:39:11.159742 139820296341376 learning.py:512] global step 9062: loss = 0.6560 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9063: loss = 0.7922 (0.235 sec/step)\n",
            "I0802 20:39:11.396375 139820296341376 learning.py:512] global step 9063: loss = 0.7922 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9064: loss = 0.8558 (0.240 sec/step)\n",
            "I0802 20:39:11.638105 139820296341376 learning.py:512] global step 9064: loss = 0.8558 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9065: loss = 0.8886 (0.231 sec/step)\n",
            "I0802 20:39:11.870719 139820296341376 learning.py:512] global step 9065: loss = 0.8886 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9066: loss = 1.1792 (0.236 sec/step)\n",
            "I0802 20:39:12.108838 139820296341376 learning.py:512] global step 9066: loss = 1.1792 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9067: loss = 0.7184 (0.236 sec/step)\n",
            "I0802 20:39:12.346200 139820296341376 learning.py:512] global step 9067: loss = 0.7184 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9068: loss = 0.8863 (0.246 sec/step)\n",
            "I0802 20:39:12.594510 139820296341376 learning.py:512] global step 9068: loss = 0.8863 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9069: loss = 1.0684 (0.243 sec/step)\n",
            "I0802 20:39:12.839584 139820296341376 learning.py:512] global step 9069: loss = 1.0684 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9070: loss = 1.0982 (0.247 sec/step)\n",
            "I0802 20:39:13.087641 139820296341376 learning.py:512] global step 9070: loss = 1.0982 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9071: loss = 1.2751 (0.247 sec/step)\n",
            "I0802 20:39:13.335856 139820296341376 learning.py:512] global step 9071: loss = 1.2751 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9072: loss = 0.9152 (0.246 sec/step)\n",
            "I0802 20:39:13.583047 139820296341376 learning.py:512] global step 9072: loss = 0.9152 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9073: loss = 0.8076 (0.250 sec/step)\n",
            "I0802 20:39:13.834144 139820296341376 learning.py:512] global step 9073: loss = 0.8076 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9074: loss = 0.6987 (0.230 sec/step)\n",
            "I0802 20:39:14.065203 139820296341376 learning.py:512] global step 9074: loss = 0.6987 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9075: loss = 0.9969 (0.250 sec/step)\n",
            "I0802 20:39:14.316821 139820296341376 learning.py:512] global step 9075: loss = 0.9969 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9076: loss = 0.8489 (0.244 sec/step)\n",
            "I0802 20:39:14.562984 139820296341376 learning.py:512] global step 9076: loss = 0.8489 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9077: loss = 0.7242 (0.229 sec/step)\n",
            "I0802 20:39:14.793915 139820296341376 learning.py:512] global step 9077: loss = 0.7242 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9078: loss = 0.8932 (0.241 sec/step)\n",
            "I0802 20:39:15.036097 139820296341376 learning.py:512] global step 9078: loss = 0.8932 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9079: loss = 0.8319 (0.226 sec/step)\n",
            "I0802 20:39:15.263350 139820296341376 learning.py:512] global step 9079: loss = 0.8319 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9080: loss = 0.9510 (0.251 sec/step)\n",
            "I0802 20:39:15.516385 139820296341376 learning.py:512] global step 9080: loss = 0.9510 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9081: loss = 1.0792 (0.226 sec/step)\n",
            "I0802 20:39:15.743606 139820296341376 learning.py:512] global step 9081: loss = 1.0792 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9082: loss = 0.6897 (0.243 sec/step)\n",
            "I0802 20:39:15.987522 139820296341376 learning.py:512] global step 9082: loss = 0.6897 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9083: loss = 0.8297 (0.235 sec/step)\n",
            "I0802 20:39:16.223482 139820296341376 learning.py:512] global step 9083: loss = 0.8297 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9084: loss = 0.7426 (0.242 sec/step)\n",
            "I0802 20:39:16.466585 139820296341376 learning.py:512] global step 9084: loss = 0.7426 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9085: loss = 0.8505 (0.231 sec/step)\n",
            "I0802 20:39:16.698984 139820296341376 learning.py:512] global step 9085: loss = 0.8505 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9086: loss = 0.9610 (0.229 sec/step)\n",
            "I0802 20:39:16.929661 139820296341376 learning.py:512] global step 9086: loss = 0.9610 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9087: loss = 0.6954 (0.239 sec/step)\n",
            "I0802 20:39:17.170293 139820296341376 learning.py:512] global step 9087: loss = 0.6954 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9088: loss = 0.7284 (0.242 sec/step)\n",
            "I0802 20:39:17.413570 139820296341376 learning.py:512] global step 9088: loss = 0.7284 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9089: loss = 0.6705 (0.246 sec/step)\n",
            "I0802 20:39:17.661647 139820296341376 learning.py:512] global step 9089: loss = 0.6705 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9090: loss = 0.8397 (0.239 sec/step)\n",
            "I0802 20:39:17.902120 139820296341376 learning.py:512] global step 9090: loss = 0.8397 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9091: loss = 0.8359 (0.235 sec/step)\n",
            "I0802 20:39:18.138458 139820296341376 learning.py:512] global step 9091: loss = 0.8359 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9092: loss = 0.9254 (0.233 sec/step)\n",
            "I0802 20:39:18.372947 139820296341376 learning.py:512] global step 9092: loss = 0.9254 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9093: loss = 0.7834 (0.243 sec/step)\n",
            "I0802 20:39:18.617661 139820296341376 learning.py:512] global step 9093: loss = 0.7834 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9094: loss = 0.7577 (0.244 sec/step)\n",
            "I0802 20:39:18.863349 139820296341376 learning.py:512] global step 9094: loss = 0.7577 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9095: loss = 1.0111 (0.244 sec/step)\n",
            "I0802 20:39:19.109348 139820296341376 learning.py:512] global step 9095: loss = 1.0111 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9096: loss = 0.9607 (0.238 sec/step)\n",
            "I0802 20:39:19.348333 139820296341376 learning.py:512] global step 9096: loss = 0.9607 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9097: loss = 1.0299 (0.228 sec/step)\n",
            "I0802 20:39:19.577846 139820296341376 learning.py:512] global step 9097: loss = 1.0299 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9098: loss = 0.8386 (0.245 sec/step)\n",
            "I0802 20:39:19.824590 139820296341376 learning.py:512] global step 9098: loss = 0.8386 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9099: loss = 0.8072 (0.246 sec/step)\n",
            "I0802 20:39:20.071723 139820296341376 learning.py:512] global step 9099: loss = 0.8072 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9100: loss = 1.0878 (0.236 sec/step)\n",
            "I0802 20:39:20.309095 139820296341376 learning.py:512] global step 9100: loss = 1.0878 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9101: loss = 0.9333 (0.238 sec/step)\n",
            "I0802 20:39:20.548604 139820296341376 learning.py:512] global step 9101: loss = 0.9333 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9102: loss = 0.9790 (0.232 sec/step)\n",
            "I0802 20:39:20.782524 139820296341376 learning.py:512] global step 9102: loss = 0.9790 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9103: loss = 0.9126 (0.239 sec/step)\n",
            "I0802 20:39:21.023065 139820296341376 learning.py:512] global step 9103: loss = 0.9126 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9104: loss = 0.9286 (0.239 sec/step)\n",
            "I0802 20:39:21.263988 139820296341376 learning.py:512] global step 9104: loss = 0.9286 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9105: loss = 1.0213 (0.247 sec/step)\n",
            "I0802 20:39:21.512060 139820296341376 learning.py:512] global step 9105: loss = 1.0213 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9106: loss = 0.9206 (0.247 sec/step)\n",
            "I0802 20:39:21.760880 139820296341376 learning.py:512] global step 9106: loss = 0.9206 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9107: loss = 0.7667 (0.228 sec/step)\n",
            "I0802 20:39:21.990764 139820296341376 learning.py:512] global step 9107: loss = 0.7667 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9108: loss = 0.6310 (0.240 sec/step)\n",
            "I0802 20:39:22.231896 139820296341376 learning.py:512] global step 9108: loss = 0.6310 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9109: loss = 1.1759 (0.242 sec/step)\n",
            "I0802 20:39:22.474778 139820296341376 learning.py:512] global step 9109: loss = 1.1759 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9110: loss = 0.9134 (0.224 sec/step)\n",
            "I0802 20:39:22.700111 139820296341376 learning.py:512] global step 9110: loss = 0.9134 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9111: loss = 0.8443 (0.244 sec/step)\n",
            "I0802 20:39:22.949157 139820296341376 learning.py:512] global step 9111: loss = 0.8443 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9112: loss = 0.5894 (0.250 sec/step)\n",
            "I0802 20:39:23.201086 139820296341376 learning.py:512] global step 9112: loss = 0.5894 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9113: loss = 0.9364 (0.233 sec/step)\n",
            "I0802 20:39:23.435248 139820296341376 learning.py:512] global step 9113: loss = 0.9364 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9114: loss = 0.9286 (0.241 sec/step)\n",
            "I0802 20:39:23.677844 139820296341376 learning.py:512] global step 9114: loss = 0.9286 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9115: loss = 0.7799 (0.238 sec/step)\n",
            "I0802 20:39:23.917136 139820296341376 learning.py:512] global step 9115: loss = 0.7799 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9116: loss = 1.0822 (0.242 sec/step)\n",
            "I0802 20:39:24.160499 139820296341376 learning.py:512] global step 9116: loss = 1.0822 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9117: loss = 0.6902 (0.239 sec/step)\n",
            "I0802 20:39:24.402029 139820296341376 learning.py:512] global step 9117: loss = 0.6902 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9118: loss = 0.9145 (0.233 sec/step)\n",
            "I0802 20:39:24.636303 139820296341376 learning.py:512] global step 9118: loss = 0.9145 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9119: loss = 0.9304 (0.243 sec/step)\n",
            "I0802 20:39:24.881213 139820296341376 learning.py:512] global step 9119: loss = 0.9304 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9120: loss = 0.9390 (0.244 sec/step)\n",
            "I0802 20:39:25.128466 139820296341376 learning.py:512] global step 9120: loss = 0.9390 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9121: loss = 0.8848 (0.238 sec/step)\n",
            "I0802 20:39:25.368376 139820296341376 learning.py:512] global step 9121: loss = 0.8848 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9122: loss = 0.8191 (0.237 sec/step)\n",
            "I0802 20:39:25.607042 139820296341376 learning.py:512] global step 9122: loss = 0.8191 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9123: loss = 0.9793 (0.240 sec/step)\n",
            "I0802 20:39:25.848495 139820296341376 learning.py:512] global step 9123: loss = 0.9793 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9124: loss = 0.8483 (0.241 sec/step)\n",
            "I0802 20:39:26.090679 139820296341376 learning.py:512] global step 9124: loss = 0.8483 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9125: loss = 0.8058 (0.239 sec/step)\n",
            "I0802 20:39:26.330883 139820296341376 learning.py:512] global step 9125: loss = 0.8058 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9126: loss = 1.1362 (0.232 sec/step)\n",
            "I0802 20:39:26.564103 139820296341376 learning.py:512] global step 9126: loss = 1.1362 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9127: loss = 0.9050 (0.243 sec/step)\n",
            "I0802 20:39:26.808182 139820296341376 learning.py:512] global step 9127: loss = 0.9050 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9128: loss = 0.7997 (0.239 sec/step)\n",
            "I0802 20:39:27.048393 139820296341376 learning.py:512] global step 9128: loss = 0.7997 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9129: loss = 0.9630 (0.232 sec/step)\n",
            "I0802 20:39:27.282003 139820296341376 learning.py:512] global step 9129: loss = 0.9630 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9130: loss = 0.8177 (0.238 sec/step)\n",
            "I0802 20:39:27.521214 139820296341376 learning.py:512] global step 9130: loss = 0.8177 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9131: loss = 0.9146 (0.242 sec/step)\n",
            "I0802 20:39:27.764229 139820296341376 learning.py:512] global step 9131: loss = 0.9146 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9132: loss = 1.0523 (0.243 sec/step)\n",
            "I0802 20:39:28.008621 139820296341376 learning.py:512] global step 9132: loss = 1.0523 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9133: loss = 0.7043 (0.241 sec/step)\n",
            "I0802 20:39:28.251185 139820296341376 learning.py:512] global step 9133: loss = 0.7043 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9134: loss = 0.9688 (0.235 sec/step)\n",
            "I0802 20:39:28.487541 139820296341376 learning.py:512] global step 9134: loss = 0.9688 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9135: loss = 1.0643 (0.251 sec/step)\n",
            "I0802 20:39:28.740566 139820296341376 learning.py:512] global step 9135: loss = 1.0643 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9136: loss = 0.7346 (0.240 sec/step)\n",
            "I0802 20:39:28.981749 139820296341376 learning.py:512] global step 9136: loss = 0.7346 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9137: loss = 1.1869 (0.240 sec/step)\n",
            "I0802 20:39:29.223048 139820296341376 learning.py:512] global step 9137: loss = 1.1869 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9138: loss = 0.8608 (0.240 sec/step)\n",
            "I0802 20:39:29.464235 139820296341376 learning.py:512] global step 9138: loss = 0.8608 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9139: loss = 0.8733 (0.248 sec/step)\n",
            "I0802 20:39:29.714070 139820296341376 learning.py:512] global step 9139: loss = 0.8733 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9140: loss = 1.0740 (0.239 sec/step)\n",
            "I0802 20:39:29.954335 139820296341376 learning.py:512] global step 9140: loss = 1.0740 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9141: loss = 0.7871 (0.247 sec/step)\n",
            "I0802 20:39:30.202553 139820296341376 learning.py:512] global step 9141: loss = 0.7871 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9142: loss = 0.7453 (0.237 sec/step)\n",
            "I0802 20:39:30.441449 139820296341376 learning.py:512] global step 9142: loss = 0.7453 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9143: loss = 0.8736 (0.241 sec/step)\n",
            "I0802 20:39:30.684130 139820296341376 learning.py:512] global step 9143: loss = 0.8736 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9144: loss = 0.8863 (0.247 sec/step)\n",
            "I0802 20:39:30.932688 139820296341376 learning.py:512] global step 9144: loss = 0.8863 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9145: loss = 0.9256 (0.228 sec/step)\n",
            "I0802 20:39:31.161775 139820296341376 learning.py:512] global step 9145: loss = 0.9256 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9146: loss = 0.7986 (0.225 sec/step)\n",
            "I0802 20:39:31.388277 139820296341376 learning.py:512] global step 9146: loss = 0.7986 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9147: loss = 0.6576 (0.232 sec/step)\n",
            "I0802 20:39:31.622462 139820296341376 learning.py:512] global step 9147: loss = 0.6576 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9148: loss = 0.7271 (0.242 sec/step)\n",
            "I0802 20:39:31.866003 139820296341376 learning.py:512] global step 9148: loss = 0.7271 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9149: loss = 0.7577 (0.227 sec/step)\n",
            "I0802 20:39:32.094912 139820296341376 learning.py:512] global step 9149: loss = 0.7577 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9150: loss = 0.9957 (0.241 sec/step)\n",
            "I0802 20:39:32.337028 139820296341376 learning.py:512] global step 9150: loss = 0.9957 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9151: loss = 0.8744 (0.227 sec/step)\n",
            "I0802 20:39:32.565221 139820296341376 learning.py:512] global step 9151: loss = 0.8744 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9152: loss = 0.7814 (0.228 sec/step)\n",
            "I0802 20:39:32.794691 139820296341376 learning.py:512] global step 9152: loss = 0.7814 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9153: loss = 0.8448 (0.235 sec/step)\n",
            "I0802 20:39:33.031672 139820296341376 learning.py:512] global step 9153: loss = 0.8448 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9154: loss = 0.7859 (0.245 sec/step)\n",
            "I0802 20:39:33.279677 139820296341376 learning.py:512] global step 9154: loss = 0.7859 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9155: loss = 1.0397 (0.241 sec/step)\n",
            "I0802 20:39:33.522682 139820296341376 learning.py:512] global step 9155: loss = 1.0397 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9156: loss = 0.6300 (0.245 sec/step)\n",
            "I0802 20:39:33.769977 139820296341376 learning.py:512] global step 9156: loss = 0.6300 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9157: loss = 0.9444 (0.239 sec/step)\n",
            "I0802 20:39:34.011071 139820296341376 learning.py:512] global step 9157: loss = 0.9444 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9158: loss = 1.1555 (0.244 sec/step)\n",
            "I0802 20:39:34.256841 139820296341376 learning.py:512] global step 9158: loss = 1.1555 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9159: loss = 0.8727 (0.235 sec/step)\n",
            "I0802 20:39:34.493246 139820296341376 learning.py:512] global step 9159: loss = 0.8727 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9160: loss = 0.8093 (0.239 sec/step)\n",
            "I0802 20:39:34.734129 139820296341376 learning.py:512] global step 9160: loss = 0.8093 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9161: loss = 0.9975 (0.246 sec/step)\n",
            "I0802 20:39:34.981716 139820296341376 learning.py:512] global step 9161: loss = 0.9975 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9162: loss = 1.0355 (0.243 sec/step)\n",
            "I0802 20:39:35.225892 139820296341376 learning.py:512] global step 9162: loss = 1.0355 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9163: loss = 0.9827 (0.244 sec/step)\n",
            "I0802 20:39:35.471316 139820296341376 learning.py:512] global step 9163: loss = 0.9827 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9164: loss = 0.6370 (0.239 sec/step)\n",
            "I0802 20:39:35.712109 139820296341376 learning.py:512] global step 9164: loss = 0.6370 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9165: loss = 0.7358 (0.246 sec/step)\n",
            "I0802 20:39:35.959706 139820296341376 learning.py:512] global step 9165: loss = 0.7358 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9166: loss = 1.0977 (0.237 sec/step)\n",
            "I0802 20:39:36.197862 139820296341376 learning.py:512] global step 9166: loss = 1.0977 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9167: loss = 0.9443 (0.241 sec/step)\n",
            "I0802 20:39:36.439932 139820296341376 learning.py:512] global step 9167: loss = 0.9443 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9168: loss = 0.6611 (0.247 sec/step)\n",
            "I0802 20:39:36.688418 139820296341376 learning.py:512] global step 9168: loss = 0.6611 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9169: loss = 1.0136 (0.242 sec/step)\n",
            "I0802 20:39:36.931984 139820296341376 learning.py:512] global step 9169: loss = 1.0136 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9170: loss = 1.7489 (0.233 sec/step)\n",
            "I0802 20:39:37.166594 139820296341376 learning.py:512] global step 9170: loss = 1.7489 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9171: loss = 0.7925 (0.231 sec/step)\n",
            "I0802 20:39:37.399152 139820296341376 learning.py:512] global step 9171: loss = 0.7925 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9172: loss = 1.0455 (0.232 sec/step)\n",
            "I0802 20:39:37.632632 139820296341376 learning.py:512] global step 9172: loss = 1.0455 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9173: loss = 0.8838 (0.235 sec/step)\n",
            "I0802 20:39:37.869523 139820296341376 learning.py:512] global step 9173: loss = 0.8838 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9174: loss = 1.0275 (0.241 sec/step)\n",
            "I0802 20:39:38.112163 139820296341376 learning.py:512] global step 9174: loss = 1.0275 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9175: loss = 1.0166 (0.237 sec/step)\n",
            "I0802 20:39:38.350777 139820296341376 learning.py:512] global step 9175: loss = 1.0166 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9176: loss = 0.7059 (0.242 sec/step)\n",
            "I0802 20:39:38.594888 139820296341376 learning.py:512] global step 9176: loss = 0.7059 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9177: loss = 1.2952 (0.240 sec/step)\n",
            "I0802 20:39:38.835908 139820296341376 learning.py:512] global step 9177: loss = 1.2952 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9178: loss = 0.9075 (0.243 sec/step)\n",
            "I0802 20:39:39.080818 139820296341376 learning.py:512] global step 9178: loss = 0.9075 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9179: loss = 0.6533 (0.233 sec/step)\n",
            "I0802 20:39:39.314858 139820296341376 learning.py:512] global step 9179: loss = 0.6533 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9180: loss = 0.9694 (0.225 sec/step)\n",
            "I0802 20:39:39.541081 139820296341376 learning.py:512] global step 9180: loss = 0.9694 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9181: loss = 1.0378 (0.225 sec/step)\n",
            "I0802 20:39:39.767884 139820296341376 learning.py:512] global step 9181: loss = 1.0378 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9182: loss = 1.0306 (0.251 sec/step)\n",
            "I0802 20:39:40.021210 139820296341376 learning.py:512] global step 9182: loss = 1.0306 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9183: loss = 0.9667 (0.237 sec/step)\n",
            "I0802 20:39:40.259762 139820296341376 learning.py:512] global step 9183: loss = 0.9667 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9184: loss = 0.8690 (0.226 sec/step)\n",
            "I0802 20:39:40.487250 139820296341376 learning.py:512] global step 9184: loss = 0.8690 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9185: loss = 0.8901 (0.237 sec/step)\n",
            "I0802 20:39:40.725716 139820296341376 learning.py:512] global step 9185: loss = 0.8901 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9186: loss = 1.0162 (0.228 sec/step)\n",
            "I0802 20:39:40.955513 139820296341376 learning.py:512] global step 9186: loss = 1.0162 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9187: loss = 1.0683 (0.245 sec/step)\n",
            "I0802 20:39:41.202916 139820296341376 learning.py:512] global step 9187: loss = 1.0683 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9188: loss = 0.6671 (0.221 sec/step)\n",
            "I0802 20:39:41.426180 139820296341376 learning.py:512] global step 9188: loss = 0.6671 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 9189: loss = 0.9292 (0.237 sec/step)\n",
            "I0802 20:39:41.664353 139820296341376 learning.py:512] global step 9189: loss = 0.9292 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9190: loss = 0.7081 (0.242 sec/step)\n",
            "I0802 20:39:41.907372 139820296341376 learning.py:512] global step 9190: loss = 0.7081 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9191: loss = 0.8639 (0.237 sec/step)\n",
            "I0802 20:39:42.145879 139820296341376 learning.py:512] global step 9191: loss = 0.8639 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9192: loss = 0.8240 (0.242 sec/step)\n",
            "I0802 20:39:42.390762 139820296341376 learning.py:512] global step 9192: loss = 0.8240 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9193: loss = 0.8163 (0.229 sec/step)\n",
            "I0802 20:39:42.621783 139820296341376 learning.py:512] global step 9193: loss = 0.8163 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9194: loss = 0.9839 (0.229 sec/step)\n",
            "I0802 20:39:42.852669 139820296341376 learning.py:512] global step 9194: loss = 0.9839 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9195: loss = 0.8694 (0.237 sec/step)\n",
            "I0802 20:39:43.091058 139820296341376 learning.py:512] global step 9195: loss = 0.8694 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9196: loss = 0.7072 (0.224 sec/step)\n",
            "I0802 20:39:43.316608 139820296341376 learning.py:512] global step 9196: loss = 0.7072 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9197: loss = 0.7814 (0.237 sec/step)\n",
            "I0802 20:39:43.554664 139820296341376 learning.py:512] global step 9197: loss = 0.7814 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9198: loss = 0.9592 (0.230 sec/step)\n",
            "I0802 20:39:43.786569 139820296341376 learning.py:512] global step 9198: loss = 0.9592 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9199: loss = 0.8178 (0.242 sec/step)\n",
            "I0802 20:39:44.030064 139820296341376 learning.py:512] global step 9199: loss = 0.8178 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9200: loss = 0.7455 (0.234 sec/step)\n",
            "I0802 20:39:44.265687 139820296341376 learning.py:512] global step 9200: loss = 0.7455 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9201: loss = 0.8346 (0.238 sec/step)\n",
            "I0802 20:39:44.505946 139820296341376 learning.py:512] global step 9201: loss = 0.8346 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9202: loss = 0.7902 (0.228 sec/step)\n",
            "I0802 20:39:44.735532 139820296341376 learning.py:512] global step 9202: loss = 0.7902 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9203: loss = 0.9121 (0.223 sec/step)\n",
            "I0802 20:39:44.960189 139820296341376 learning.py:512] global step 9203: loss = 0.9121 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9204: loss = 1.0665 (0.241 sec/step)\n",
            "I0802 20:39:45.202606 139820296341376 learning.py:512] global step 9204: loss = 1.0665 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9205: loss = 0.6289 (0.243 sec/step)\n",
            "I0802 20:39:45.447510 139820296341376 learning.py:512] global step 9205: loss = 0.6289 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9206: loss = 0.7609 (0.235 sec/step)\n",
            "I0802 20:39:45.683799 139820296341376 learning.py:512] global step 9206: loss = 0.7609 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9207: loss = 0.9184 (0.247 sec/step)\n",
            "I0802 20:39:45.932514 139820296341376 learning.py:512] global step 9207: loss = 0.9184 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9208: loss = 0.7719 (0.221 sec/step)\n",
            "I0802 20:39:46.154805 139820296341376 learning.py:512] global step 9208: loss = 0.7719 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 9209: loss = 0.8368 (0.230 sec/step)\n",
            "I0802 20:39:46.386566 139820296341376 learning.py:512] global step 9209: loss = 0.8368 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9210: loss = 0.8199 (0.230 sec/step)\n",
            "I0802 20:39:46.617886 139820296341376 learning.py:512] global step 9210: loss = 0.8199 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9211: loss = 0.8653 (0.239 sec/step)\n",
            "I0802 20:39:46.858524 139820296341376 learning.py:512] global step 9211: loss = 0.8653 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9212: loss = 0.9523 (0.221 sec/step)\n",
            "I0802 20:39:47.080852 139820296341376 learning.py:512] global step 9212: loss = 0.9523 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 9213: loss = 0.6661 (0.235 sec/step)\n",
            "I0802 20:39:47.317368 139820296341376 learning.py:512] global step 9213: loss = 0.6661 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9214: loss = 0.8076 (0.230 sec/step)\n",
            "I0802 20:39:47.548346 139820296341376 learning.py:512] global step 9214: loss = 0.8076 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9215: loss = 0.7391 (0.236 sec/step)\n",
            "I0802 20:39:47.785589 139820296341376 learning.py:512] global step 9215: loss = 0.7391 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9216: loss = 0.8158 (0.232 sec/step)\n",
            "I0802 20:39:48.019349 139820296341376 learning.py:512] global step 9216: loss = 0.8158 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9217: loss = 0.8314 (0.223 sec/step)\n",
            "I0802 20:39:48.243600 139820296341376 learning.py:512] global step 9217: loss = 0.8314 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9218: loss = 0.9287 (0.245 sec/step)\n",
            "I0802 20:39:48.490175 139820296341376 learning.py:512] global step 9218: loss = 0.9287 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9219: loss = 0.6097 (0.228 sec/step)\n",
            "I0802 20:39:48.719444 139820296341376 learning.py:512] global step 9219: loss = 0.6097 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9220: loss = 1.0007 (0.238 sec/step)\n",
            "I0802 20:39:48.958817 139820296341376 learning.py:512] global step 9220: loss = 1.0007 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9221: loss = 0.8649 (0.243 sec/step)\n",
            "I0802 20:39:49.203389 139820296341376 learning.py:512] global step 9221: loss = 0.8649 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9222: loss = 0.7265 (0.240 sec/step)\n",
            "I0802 20:39:49.444968 139820296341376 learning.py:512] global step 9222: loss = 0.7265 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9223: loss = 0.8948 (0.236 sec/step)\n",
            "I0802 20:39:49.682039 139820296341376 learning.py:512] global step 9223: loss = 0.8948 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9224: loss = 0.8364 (0.236 sec/step)\n",
            "I0802 20:39:49.919774 139820296341376 learning.py:512] global step 9224: loss = 0.8364 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9225: loss = 0.5495 (0.231 sec/step)\n",
            "I0802 20:39:50.152812 139820296341376 learning.py:512] global step 9225: loss = 0.5495 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9226: loss = 0.9014 (0.228 sec/step)\n",
            "I0802 20:39:50.382308 139820296341376 learning.py:512] global step 9226: loss = 0.9014 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9227: loss = 1.0149 (0.239 sec/step)\n",
            "I0802 20:39:50.623165 139820296341376 learning.py:512] global step 9227: loss = 1.0149 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9228: loss = 0.5999 (0.245 sec/step)\n",
            "I0802 20:39:50.869465 139820296341376 learning.py:512] global step 9228: loss = 0.5999 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9229: loss = 0.7594 (0.240 sec/step)\n",
            "I0802 20:39:51.111040 139820296341376 learning.py:512] global step 9229: loss = 0.7594 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9230: loss = 0.9453 (0.232 sec/step)\n",
            "I0802 20:39:51.344190 139820296341376 learning.py:512] global step 9230: loss = 0.9453 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9231: loss = 0.9469 (0.225 sec/step)\n",
            "I0802 20:39:51.570184 139820296341376 learning.py:512] global step 9231: loss = 0.9469 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9232: loss = 1.1084 (0.224 sec/step)\n",
            "I0802 20:39:51.795530 139820296341376 learning.py:512] global step 9232: loss = 1.1084 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9233: loss = 0.8028 (0.244 sec/step)\n",
            "I0802 20:39:52.040553 139820296341376 learning.py:512] global step 9233: loss = 0.8028 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9234: loss = 0.9894 (0.238 sec/step)\n",
            "I0802 20:39:52.279605 139820296341376 learning.py:512] global step 9234: loss = 0.9894 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9235: loss = 0.7260 (0.221 sec/step)\n",
            "I0802 20:39:52.501614 139820296341376 learning.py:512] global step 9235: loss = 0.7260 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 9236: loss = 0.8880 (0.233 sec/step)\n",
            "I0802 20:39:52.735939 139820296341376 learning.py:512] global step 9236: loss = 0.8880 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9237: loss = 0.8601 (0.245 sec/step)\n",
            "I0802 20:39:52.982312 139820296341376 learning.py:512] global step 9237: loss = 0.8601 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9238: loss = 0.8942 (0.242 sec/step)\n",
            "I0802 20:39:53.227770 139820296341376 learning.py:512] global step 9238: loss = 0.8942 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9239: loss = 0.7089 (0.223 sec/step)\n",
            "I0802 20:39:53.451820 139820296341376 learning.py:512] global step 9239: loss = 0.7089 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9240: loss = 1.2943 (0.239 sec/step)\n",
            "I0802 20:39:53.692609 139820296341376 learning.py:512] global step 9240: loss = 1.2943 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9241: loss = 0.6865 (0.240 sec/step)\n",
            "I0802 20:39:53.933546 139820296341376 learning.py:512] global step 9241: loss = 0.6865 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9242: loss = 0.8049 (0.248 sec/step)\n",
            "I0802 20:39:54.182909 139820296341376 learning.py:512] global step 9242: loss = 0.8049 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9243: loss = 0.7486 (0.223 sec/step)\n",
            "I0802 20:39:54.408074 139820296341376 learning.py:512] global step 9243: loss = 0.7486 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9244: loss = 0.7381 (0.234 sec/step)\n",
            "I0802 20:39:54.643318 139820296341376 learning.py:512] global step 9244: loss = 0.7381 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9245: loss = 0.7249 (0.235 sec/step)\n",
            "I0802 20:39:54.879956 139820296341376 learning.py:512] global step 9245: loss = 0.7249 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9246: loss = 0.8158 (0.236 sec/step)\n",
            "I0802 20:39:55.117480 139820296341376 learning.py:512] global step 9246: loss = 0.8158 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9247: loss = 0.8685 (0.243 sec/step)\n",
            "I0802 20:39:55.361595 139820296341376 learning.py:512] global step 9247: loss = 0.8685 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9248: loss = 0.8436 (0.242 sec/step)\n",
            "I0802 20:39:55.604763 139820296341376 learning.py:512] global step 9248: loss = 0.8436 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9249: loss = 0.8276 (0.227 sec/step)\n",
            "I0802 20:39:55.833552 139820296341376 learning.py:512] global step 9249: loss = 0.8276 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9250: loss = 0.6967 (0.223 sec/step)\n",
            "I0802 20:39:56.057620 139820296341376 learning.py:512] global step 9250: loss = 0.6967 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9251: loss = 0.8310 (0.239 sec/step)\n",
            "I0802 20:39:56.298236 139820296341376 learning.py:512] global step 9251: loss = 0.8310 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9252: loss = 0.7828 (0.239 sec/step)\n",
            "I0802 20:39:56.538519 139820296341376 learning.py:512] global step 9252: loss = 0.7828 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9253: loss = 0.8265 (0.218 sec/step)\n",
            "I0802 20:39:56.757637 139820296341376 learning.py:512] global step 9253: loss = 0.8265 (0.218 sec/step)\n",
            "INFO:tensorflow:global step 9254: loss = 0.7779 (0.237 sec/step)\n",
            "I0802 20:39:56.996326 139820296341376 learning.py:512] global step 9254: loss = 0.7779 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9255: loss = 0.7708 (0.241 sec/step)\n",
            "I0802 20:39:57.239388 139820296341376 learning.py:512] global step 9255: loss = 0.7708 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9256: loss = 0.8368 (0.245 sec/step)\n",
            "I0802 20:39:57.486414 139820296341376 learning.py:512] global step 9256: loss = 0.8368 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9257: loss = 0.8793 (0.236 sec/step)\n",
            "I0802 20:39:57.724098 139820296341376 learning.py:512] global step 9257: loss = 0.8793 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9258: loss = 1.0951 (0.221 sec/step)\n",
            "I0802 20:39:57.946516 139820296341376 learning.py:512] global step 9258: loss = 1.0951 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 9259: loss = 0.7155 (0.241 sec/step)\n",
            "I0802 20:39:58.188981 139820296341376 learning.py:512] global step 9259: loss = 0.7155 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9260: loss = 0.7675 (0.242 sec/step)\n",
            "I0802 20:39:58.432182 139820296341376 learning.py:512] global step 9260: loss = 0.7675 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9261: loss = 1.2174 (0.235 sec/step)\n",
            "I0802 20:39:58.668297 139820296341376 learning.py:512] global step 9261: loss = 1.2174 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9262: loss = 0.9026 (0.237 sec/step)\n",
            "I0802 20:39:58.907246 139820296341376 learning.py:512] global step 9262: loss = 0.9026 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9263: loss = 0.8377 (0.244 sec/step)\n",
            "I0802 20:39:59.152578 139820296341376 learning.py:512] global step 9263: loss = 0.8377 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9264: loss = 0.9373 (0.235 sec/step)\n",
            "I0802 20:39:59.388897 139820296341376 learning.py:512] global step 9264: loss = 0.9373 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9265: loss = 0.7619 (0.247 sec/step)\n",
            "I0802 20:39:59.637248 139820296341376 learning.py:512] global step 9265: loss = 0.7619 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9266: loss = 0.6864 (0.237 sec/step)\n",
            "I0802 20:39:59.875733 139820296341376 learning.py:512] global step 9266: loss = 0.6864 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9267: loss = 1.0819 (0.233 sec/step)\n",
            "I0802 20:40:00.110544 139820296341376 learning.py:512] global step 9267: loss = 1.0819 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9268: loss = 0.7962 (0.238 sec/step)\n",
            "I0802 20:40:00.350229 139820296341376 learning.py:512] global step 9268: loss = 0.7962 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9269: loss = 0.6990 (0.239 sec/step)\n",
            "I0802 20:40:00.590791 139820296341376 learning.py:512] global step 9269: loss = 0.6990 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9270: loss = 0.8924 (0.237 sec/step)\n",
            "I0802 20:40:00.828959 139820296341376 learning.py:512] global step 9270: loss = 0.8924 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9271: loss = 1.0638 (0.224 sec/step)\n",
            "I0802 20:40:01.054368 139820296341376 learning.py:512] global step 9271: loss = 1.0638 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9272: loss = 0.9205 (0.241 sec/step)\n",
            "I0802 20:40:01.297250 139820296341376 learning.py:512] global step 9272: loss = 0.9205 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9273: loss = 0.9882 (0.222 sec/step)\n",
            "I0802 20:40:01.520654 139820296341376 learning.py:512] global step 9273: loss = 0.9882 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9274: loss = 0.8423 (0.241 sec/step)\n",
            "I0802 20:40:01.763237 139820296341376 learning.py:512] global step 9274: loss = 0.8423 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9275: loss = 1.2143 (0.228 sec/step)\n",
            "I0802 20:40:01.993118 139820296341376 learning.py:512] global step 9275: loss = 1.2143 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9276: loss = 0.8388 (0.246 sec/step)\n",
            "I0802 20:40:02.240403 139820296341376 learning.py:512] global step 9276: loss = 0.8388 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9277: loss = 0.8525 (0.237 sec/step)\n",
            "I0802 20:40:02.479117 139820296341376 learning.py:512] global step 9277: loss = 0.8525 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9278: loss = 0.7538 (0.224 sec/step)\n",
            "I0802 20:40:02.704807 139820296341376 learning.py:512] global step 9278: loss = 0.7538 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9279: loss = 0.8719 (0.243 sec/step)\n",
            "I0802 20:40:02.949449 139820296341376 learning.py:512] global step 9279: loss = 0.8719 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9280: loss = 0.7266 (0.239 sec/step)\n",
            "I0802 20:40:03.190434 139820296341376 learning.py:512] global step 9280: loss = 0.7266 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9281: loss = 0.8788 (0.237 sec/step)\n",
            "I0802 20:40:03.429172 139820296341376 learning.py:512] global step 9281: loss = 0.8788 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9282: loss = 0.8075 (0.234 sec/step)\n",
            "I0802 20:40:03.664572 139820296341376 learning.py:512] global step 9282: loss = 0.8075 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9283: loss = 0.8062 (0.237 sec/step)\n",
            "I0802 20:40:03.902601 139820296341376 learning.py:512] global step 9283: loss = 0.8062 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9284: loss = 0.8277 (0.222 sec/step)\n",
            "I0802 20:40:04.126341 139820296341376 learning.py:512] global step 9284: loss = 0.8277 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9285: loss = 0.9904 (0.237 sec/step)\n",
            "I0802 20:40:04.364208 139820296341376 learning.py:512] global step 9285: loss = 0.9904 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9286: loss = 0.7570 (0.242 sec/step)\n",
            "I0802 20:40:04.607982 139820296341376 learning.py:512] global step 9286: loss = 0.7570 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9287: loss = 1.2657 (0.238 sec/step)\n",
            "I0802 20:40:04.846994 139820296341376 learning.py:512] global step 9287: loss = 1.2657 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9288: loss = 1.0543 (0.227 sec/step)\n",
            "I0802 20:40:05.075189 139820296341376 learning.py:512] global step 9288: loss = 1.0543 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9289: loss = 0.7772 (0.235 sec/step)\n",
            "I0802 20:40:05.311298 139820296341376 learning.py:512] global step 9289: loss = 0.7772 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9290: loss = 0.7034 (0.236 sec/step)\n",
            "I0802 20:40:05.549228 139820296341376 learning.py:512] global step 9290: loss = 0.7034 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9291: loss = 1.0387 (0.232 sec/step)\n",
            "I0802 20:40:05.787283 139820296341376 learning.py:512] global step 9291: loss = 1.0387 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9292: loss = 0.9202 (0.234 sec/step)\n",
            "I0802 20:40:06.022325 139820296341376 learning.py:512] global step 9292: loss = 0.9202 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9293: loss = 0.7150 (0.239 sec/step)\n",
            "I0802 20:40:06.263234 139820296341376 learning.py:512] global step 9293: loss = 0.7150 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9294: loss = 0.8251 (0.237 sec/step)\n",
            "I0802 20:40:06.501719 139820296341376 learning.py:512] global step 9294: loss = 0.8251 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9295: loss = 0.9056 (0.227 sec/step)\n",
            "I0802 20:40:06.729982 139820296341376 learning.py:512] global step 9295: loss = 0.9056 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9296: loss = 1.1191 (0.235 sec/step)\n",
            "I0802 20:40:06.965852 139820296341376 learning.py:512] global step 9296: loss = 1.1191 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9297: loss = 0.8764 (0.236 sec/step)\n",
            "I0802 20:40:07.203305 139820296341376 learning.py:512] global step 9297: loss = 0.8764 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9298: loss = 0.8756 (0.249 sec/step)\n",
            "I0802 20:40:07.453519 139820296341376 learning.py:512] global step 9298: loss = 0.8756 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9299: loss = 0.9259 (0.240 sec/step)\n",
            "I0802 20:40:07.695099 139820296341376 learning.py:512] global step 9299: loss = 0.9259 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9300: loss = 0.7475 (0.232 sec/step)\n",
            "I0802 20:40:07.928779 139820296341376 learning.py:512] global step 9300: loss = 0.7475 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9301: loss = 0.8625 (0.229 sec/step)\n",
            "I0802 20:40:08.159143 139820296341376 learning.py:512] global step 9301: loss = 0.8625 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9302: loss = 1.0960 (0.229 sec/step)\n",
            "I0802 20:40:08.390323 139820296341376 learning.py:512] global step 9302: loss = 1.0960 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9303: loss = 0.8329 (0.239 sec/step)\n",
            "I0802 20:40:08.631236 139820296341376 learning.py:512] global step 9303: loss = 0.8329 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9304: loss = 0.7216 (0.231 sec/step)\n",
            "I0802 20:40:08.863382 139820296341376 learning.py:512] global step 9304: loss = 0.7216 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9305: loss = 0.6858 (0.237 sec/step)\n",
            "I0802 20:40:09.101706 139820296341376 learning.py:512] global step 9305: loss = 0.6858 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9306: loss = 0.8597 (0.240 sec/step)\n",
            "I0802 20:40:09.343552 139820296341376 learning.py:512] global step 9306: loss = 0.8597 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9307: loss = 0.8076 (0.241 sec/step)\n",
            "I0802 20:40:09.586103 139820296341376 learning.py:512] global step 9307: loss = 0.8076 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9308: loss = 0.7391 (0.232 sec/step)\n",
            "I0802 20:40:09.819393 139820296341376 learning.py:512] global step 9308: loss = 0.7391 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9309: loss = 0.8604 (0.235 sec/step)\n",
            "I0802 20:40:10.055666 139820296341376 learning.py:512] global step 9309: loss = 0.8604 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9310: loss = 0.8892 (0.239 sec/step)\n",
            "I0802 20:40:10.296458 139820296341376 learning.py:512] global step 9310: loss = 0.8892 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9311: loss = 0.7300 (0.239 sec/step)\n",
            "I0802 20:40:10.537151 139820296341376 learning.py:512] global step 9311: loss = 0.7300 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9312: loss = 0.9453 (0.234 sec/step)\n",
            "I0802 20:40:10.772545 139820296341376 learning.py:512] global step 9312: loss = 0.9453 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9313: loss = 1.0651 (0.232 sec/step)\n",
            "I0802 20:40:11.005413 139820296341376 learning.py:512] global step 9313: loss = 1.0651 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9314: loss = 0.8825 (0.233 sec/step)\n",
            "I0802 20:40:11.239821 139820296341376 learning.py:512] global step 9314: loss = 0.8825 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9315: loss = 0.9282 (0.230 sec/step)\n",
            "I0802 20:40:11.471077 139820296341376 learning.py:512] global step 9315: loss = 0.9282 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9316: loss = 0.8618 (0.239 sec/step)\n",
            "I0802 20:40:11.712105 139820296341376 learning.py:512] global step 9316: loss = 0.8618 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9317: loss = 1.1715 (0.226 sec/step)\n",
            "I0802 20:40:11.939020 139820296341376 learning.py:512] global step 9317: loss = 1.1715 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9318: loss = 1.0216 (0.237 sec/step)\n",
            "I0802 20:40:12.177625 139820296341376 learning.py:512] global step 9318: loss = 1.0216 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9319: loss = 1.0125 (0.241 sec/step)\n",
            "I0802 20:40:12.420430 139820296341376 learning.py:512] global step 9319: loss = 1.0125 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9320: loss = 0.9535 (0.233 sec/step)\n",
            "I0802 20:40:12.655322 139820296341376 learning.py:512] global step 9320: loss = 0.9535 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9321: loss = 0.8084 (0.237 sec/step)\n",
            "I0802 20:40:12.894096 139820296341376 learning.py:512] global step 9321: loss = 0.8084 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9322: loss = 1.0414 (0.222 sec/step)\n",
            "I0802 20:40:13.117040 139820296341376 learning.py:512] global step 9322: loss = 1.0414 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9323: loss = 0.8078 (0.237 sec/step)\n",
            "I0802 20:40:13.355022 139820296341376 learning.py:512] global step 9323: loss = 0.8078 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9324: loss = 0.8355 (0.229 sec/step)\n",
            "I0802 20:40:13.585285 139820296341376 learning.py:512] global step 9324: loss = 0.8355 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9325: loss = 0.6709 (0.235 sec/step)\n",
            "I0802 20:40:13.822286 139820296341376 learning.py:512] global step 9325: loss = 0.6709 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9326: loss = 0.9283 (0.237 sec/step)\n",
            "I0802 20:40:14.060275 139820296341376 learning.py:512] global step 9326: loss = 0.9283 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9327: loss = 0.5993 (0.241 sec/step)\n",
            "I0802 20:40:14.303102 139820296341376 learning.py:512] global step 9327: loss = 0.5993 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9328: loss = 0.8271 (0.224 sec/step)\n",
            "I0802 20:40:14.528504 139820296341376 learning.py:512] global step 9328: loss = 0.8271 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9329: loss = 0.7991 (0.234 sec/step)\n",
            "I0802 20:40:14.764112 139820296341376 learning.py:512] global step 9329: loss = 0.7991 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9330: loss = 0.9526 (0.237 sec/step)\n",
            "I0802 20:40:15.003597 139820296341376 learning.py:512] global step 9330: loss = 0.9526 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9331: loss = 0.8186 (0.235 sec/step)\n",
            "I0802 20:40:15.240007 139820296341376 learning.py:512] global step 9331: loss = 0.8186 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9332: loss = 0.8921 (0.239 sec/step)\n",
            "I0802 20:40:15.480730 139820296341376 learning.py:512] global step 9332: loss = 0.8921 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9333: loss = 0.8265 (0.244 sec/step)\n",
            "I0802 20:40:15.726188 139820296341376 learning.py:512] global step 9333: loss = 0.8265 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9334: loss = 0.6784 (0.219 sec/step)\n",
            "I0802 20:40:15.946634 139820296341376 learning.py:512] global step 9334: loss = 0.6784 (0.219 sec/step)\n",
            "INFO:tensorflow:global step 9335: loss = 1.0307 (0.236 sec/step)\n",
            "I0802 20:40:16.183877 139820296341376 learning.py:512] global step 9335: loss = 1.0307 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9336: loss = 0.8119 (0.224 sec/step)\n",
            "I0802 20:40:16.409164 139820296341376 learning.py:512] global step 9336: loss = 0.8119 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9337: loss = 0.9866 (0.240 sec/step)\n",
            "I0802 20:40:16.650558 139820296341376 learning.py:512] global step 9337: loss = 0.9866 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9338: loss = 0.9137 (0.228 sec/step)\n",
            "I0802 20:40:16.883498 139820296341376 learning.py:512] global step 9338: loss = 0.9137 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9339: loss = 0.9617 (0.234 sec/step)\n",
            "I0802 20:40:17.118571 139820296341376 learning.py:512] global step 9339: loss = 0.9617 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9340: loss = 0.9078 (0.231 sec/step)\n",
            "I0802 20:40:17.350685 139820296341376 learning.py:512] global step 9340: loss = 0.9078 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9341: loss = 0.8646 (0.236 sec/step)\n",
            "I0802 20:40:17.588620 139820296341376 learning.py:512] global step 9341: loss = 0.8646 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9342: loss = 0.9778 (0.237 sec/step)\n",
            "I0802 20:40:17.826875 139820296341376 learning.py:512] global step 9342: loss = 0.9778 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9343: loss = 0.8767 (0.232 sec/step)\n",
            "I0802 20:40:18.060481 139820296341376 learning.py:512] global step 9343: loss = 0.8767 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9344: loss = 0.6610 (0.226 sec/step)\n",
            "I0802 20:40:18.288191 139820296341376 learning.py:512] global step 9344: loss = 0.6610 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9345: loss = 0.8864 (0.236 sec/step)\n",
            "I0802 20:40:18.525345 139820296341376 learning.py:512] global step 9345: loss = 0.8864 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9346: loss = 0.8831 (0.262 sec/step)\n",
            "I0802 20:40:18.790281 139820296341376 learning.py:512] global step 9346: loss = 0.8831 (0.262 sec/step)\n",
            "INFO:tensorflow:global step 9347: loss = 0.9134 (0.279 sec/step)\n",
            "I0802 20:40:19.072416 139820296341376 learning.py:512] global step 9347: loss = 0.9134 (0.279 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 9347.\n",
            "I0802 20:40:19.159494 139815876826880 supervisor.py:1050] Recording summary at step 9347.\n",
            "INFO:tensorflow:global step 9348: loss = 0.7010 (0.254 sec/step)\n",
            "I0802 20:40:19.332072 139820296341376 learning.py:512] global step 9348: loss = 0.7010 (0.254 sec/step)\n",
            "INFO:tensorflow:global step 9349: loss = 0.8140 (0.246 sec/step)\n",
            "I0802 20:40:19.580341 139820296341376 learning.py:512] global step 9349: loss = 0.8140 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9350: loss = 0.8328 (0.245 sec/step)\n",
            "I0802 20:40:19.827355 139820296341376 learning.py:512] global step 9350: loss = 0.8328 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9351: loss = 0.7489 (0.229 sec/step)\n",
            "I0802 20:40:20.058155 139820296341376 learning.py:512] global step 9351: loss = 0.7489 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9352: loss = 1.1017 (0.240 sec/step)\n",
            "I0802 20:40:20.299193 139820296341376 learning.py:512] global step 9352: loss = 1.1017 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9353: loss = 0.8885 (0.240 sec/step)\n",
            "I0802 20:40:20.540490 139820296341376 learning.py:512] global step 9353: loss = 0.8885 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9354: loss = 0.9041 (0.230 sec/step)\n",
            "I0802 20:40:20.771725 139820296341376 learning.py:512] global step 9354: loss = 0.9041 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9355: loss = 0.7492 (0.245 sec/step)\n",
            "I0802 20:40:21.018143 139820296341376 learning.py:512] global step 9355: loss = 0.7492 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9356: loss = 0.6854 (0.241 sec/step)\n",
            "I0802 20:40:21.260166 139820296341376 learning.py:512] global step 9356: loss = 0.6854 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9357: loss = 1.1513 (0.245 sec/step)\n",
            "I0802 20:40:21.506561 139820296341376 learning.py:512] global step 9357: loss = 1.1513 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9358: loss = 0.7799 (0.241 sec/step)\n",
            "I0802 20:40:21.749314 139820296341376 learning.py:512] global step 9358: loss = 0.7799 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9359: loss = 0.8600 (0.237 sec/step)\n",
            "I0802 20:40:21.987737 139820296341376 learning.py:512] global step 9359: loss = 0.8600 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9360: loss = 0.8965 (0.228 sec/step)\n",
            "I0802 20:40:22.217019 139820296341376 learning.py:512] global step 9360: loss = 0.8965 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9361: loss = 0.6758 (0.227 sec/step)\n",
            "I0802 20:40:22.445509 139820296341376 learning.py:512] global step 9361: loss = 0.6758 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9362: loss = 1.7672 (0.242 sec/step)\n",
            "I0802 20:40:22.688697 139820296341376 learning.py:512] global step 9362: loss = 1.7672 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9363: loss = 0.7315 (0.238 sec/step)\n",
            "I0802 20:40:22.927749 139820296341376 learning.py:512] global step 9363: loss = 0.7315 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9364: loss = 0.8069 (0.227 sec/step)\n",
            "I0802 20:40:23.155958 139820296341376 learning.py:512] global step 9364: loss = 0.8069 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9365: loss = 0.9300 (0.238 sec/step)\n",
            "I0802 20:40:23.395213 139820296341376 learning.py:512] global step 9365: loss = 0.9300 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9366: loss = 0.6689 (0.236 sec/step)\n",
            "I0802 20:40:23.632324 139820296341376 learning.py:512] global step 9366: loss = 0.6689 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9367: loss = 0.7642 (0.241 sec/step)\n",
            "I0802 20:40:23.875183 139820296341376 learning.py:512] global step 9367: loss = 0.7642 (0.241 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 4.19932\n",
            "I0802 20:40:23.899033 139815885219584 supervisor.py:1099] global_step/sec: 4.19932\n",
            "INFO:tensorflow:global step 9368: loss = 1.0071 (0.237 sec/step)\n",
            "I0802 20:40:24.113149 139820296341376 learning.py:512] global step 9368: loss = 1.0071 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9369: loss = 0.6834 (0.235 sec/step)\n",
            "I0802 20:40:24.349239 139820296341376 learning.py:512] global step 9369: loss = 0.6834 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9370: loss = 0.9094 (0.228 sec/step)\n",
            "I0802 20:40:24.579275 139820296341376 learning.py:512] global step 9370: loss = 0.9094 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9371: loss = 0.7585 (0.240 sec/step)\n",
            "I0802 20:40:24.820751 139820296341376 learning.py:512] global step 9371: loss = 0.7585 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9372: loss = 0.8383 (0.237 sec/step)\n",
            "I0802 20:40:25.058778 139820296341376 learning.py:512] global step 9372: loss = 0.8383 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9373: loss = 0.6825 (0.242 sec/step)\n",
            "I0802 20:40:25.302782 139820296341376 learning.py:512] global step 9373: loss = 0.6825 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9374: loss = 0.6657 (0.240 sec/step)\n",
            "I0802 20:40:25.544160 139820296341376 learning.py:512] global step 9374: loss = 0.6657 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9375: loss = 0.8175 (0.243 sec/step)\n",
            "I0802 20:40:25.788641 139820296341376 learning.py:512] global step 9375: loss = 0.8175 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9376: loss = 0.6368 (0.233 sec/step)\n",
            "I0802 20:40:26.023587 139820296341376 learning.py:512] global step 9376: loss = 0.6368 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9377: loss = 0.9988 (0.241 sec/step)\n",
            "I0802 20:40:26.266005 139820296341376 learning.py:512] global step 9377: loss = 0.9988 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9378: loss = 1.0652 (0.234 sec/step)\n",
            "I0802 20:40:26.501343 139820296341376 learning.py:512] global step 9378: loss = 1.0652 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9379: loss = 0.7520 (0.235 sec/step)\n",
            "I0802 20:40:26.737946 139820296341376 learning.py:512] global step 9379: loss = 0.7520 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9380: loss = 1.1351 (0.245 sec/step)\n",
            "I0802 20:40:26.984076 139820296341376 learning.py:512] global step 9380: loss = 1.1351 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9381: loss = 1.0347 (0.234 sec/step)\n",
            "I0802 20:40:27.219738 139820296341376 learning.py:512] global step 9381: loss = 1.0347 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9382: loss = 0.8448 (0.229 sec/step)\n",
            "I0802 20:40:27.450265 139820296341376 learning.py:512] global step 9382: loss = 0.8448 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9383: loss = 0.9604 (0.245 sec/step)\n",
            "I0802 20:40:27.699327 139820296341376 learning.py:512] global step 9383: loss = 0.9604 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9384: loss = 0.7679 (0.240 sec/step)\n",
            "I0802 20:40:27.941383 139820296341376 learning.py:512] global step 9384: loss = 0.7679 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9385: loss = 1.1099 (0.237 sec/step)\n",
            "I0802 20:40:28.180085 139820296341376 learning.py:512] global step 9385: loss = 1.1099 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9386: loss = 0.6900 (0.241 sec/step)\n",
            "I0802 20:40:28.422080 139820296341376 learning.py:512] global step 9386: loss = 0.6900 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9387: loss = 0.9571 (0.232 sec/step)\n",
            "I0802 20:40:28.655042 139820296341376 learning.py:512] global step 9387: loss = 0.9571 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9388: loss = 0.9548 (0.240 sec/step)\n",
            "I0802 20:40:28.896269 139820296341376 learning.py:512] global step 9388: loss = 0.9548 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9389: loss = 0.8210 (0.241 sec/step)\n",
            "I0802 20:40:29.140564 139820296341376 learning.py:512] global step 9389: loss = 0.8210 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9390: loss = 0.8373 (0.235 sec/step)\n",
            "I0802 20:40:29.377282 139820296341376 learning.py:512] global step 9390: loss = 0.8373 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9391: loss = 0.8330 (0.242 sec/step)\n",
            "I0802 20:40:29.620485 139820296341376 learning.py:512] global step 9391: loss = 0.8330 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9392: loss = 0.6809 (0.239 sec/step)\n",
            "I0802 20:40:29.860627 139820296341376 learning.py:512] global step 9392: loss = 0.6809 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9393: loss = 1.0559 (0.228 sec/step)\n",
            "I0802 20:40:30.089798 139820296341376 learning.py:512] global step 9393: loss = 1.0559 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9394: loss = 0.8036 (0.239 sec/step)\n",
            "I0802 20:40:30.330284 139820296341376 learning.py:512] global step 9394: loss = 0.8036 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9395: loss = 0.7943 (0.224 sec/step)\n",
            "I0802 20:40:30.555700 139820296341376 learning.py:512] global step 9395: loss = 0.7943 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9396: loss = 0.9375 (0.233 sec/step)\n",
            "I0802 20:40:30.789793 139820296341376 learning.py:512] global step 9396: loss = 0.9375 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9397: loss = 0.9100 (0.245 sec/step)\n",
            "I0802 20:40:31.036989 139820296341376 learning.py:512] global step 9397: loss = 0.9100 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9398: loss = 0.8992 (0.235 sec/step)\n",
            "I0802 20:40:31.273565 139820296341376 learning.py:512] global step 9398: loss = 0.8992 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9399: loss = 0.9672 (0.238 sec/step)\n",
            "I0802 20:40:31.513035 139820296341376 learning.py:512] global step 9399: loss = 0.9672 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9400: loss = 0.7968 (0.243 sec/step)\n",
            "I0802 20:40:31.757246 139820296341376 learning.py:512] global step 9400: loss = 0.7968 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9401: loss = 0.7761 (0.240 sec/step)\n",
            "I0802 20:40:31.999336 139820296341376 learning.py:512] global step 9401: loss = 0.7761 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9402: loss = 0.8040 (0.243 sec/step)\n",
            "I0802 20:40:32.244398 139820296341376 learning.py:512] global step 9402: loss = 0.8040 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9403: loss = 0.9685 (0.233 sec/step)\n",
            "I0802 20:40:32.479147 139820296341376 learning.py:512] global step 9403: loss = 0.9685 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9404: loss = 0.7180 (0.229 sec/step)\n",
            "I0802 20:40:32.709324 139820296341376 learning.py:512] global step 9404: loss = 0.7180 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9405: loss = 1.0711 (0.241 sec/step)\n",
            "I0802 20:40:32.951590 139820296341376 learning.py:512] global step 9405: loss = 1.0711 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9406: loss = 0.7659 (0.243 sec/step)\n",
            "I0802 20:40:33.196128 139820296341376 learning.py:512] global step 9406: loss = 0.7659 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9407: loss = 0.6717 (0.222 sec/step)\n",
            "I0802 20:40:33.419517 139820296341376 learning.py:512] global step 9407: loss = 0.6717 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9408: loss = 0.7697 (0.237 sec/step)\n",
            "I0802 20:40:33.658503 139820296341376 learning.py:512] global step 9408: loss = 0.7697 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9409: loss = 0.8980 (0.243 sec/step)\n",
            "I0802 20:40:33.905085 139820296341376 learning.py:512] global step 9409: loss = 0.8980 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9410: loss = 0.7387 (0.233 sec/step)\n",
            "I0802 20:40:34.140895 139820296341376 learning.py:512] global step 9410: loss = 0.7387 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9411: loss = 0.8000 (0.241 sec/step)\n",
            "I0802 20:40:34.383289 139820296341376 learning.py:512] global step 9411: loss = 0.8000 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9412: loss = 0.7685 (0.235 sec/step)\n",
            "I0802 20:40:34.619770 139820296341376 learning.py:512] global step 9412: loss = 0.7685 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9413: loss = 0.9068 (0.242 sec/step)\n",
            "I0802 20:40:34.863903 139820296341376 learning.py:512] global step 9413: loss = 0.9068 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9414: loss = 0.9132 (0.250 sec/step)\n",
            "I0802 20:40:35.115072 139820296341376 learning.py:512] global step 9414: loss = 0.9132 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9415: loss = 0.7562 (0.246 sec/step)\n",
            "I0802 20:40:35.362566 139820296341376 learning.py:512] global step 9415: loss = 0.7562 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9416: loss = 1.3226 (0.234 sec/step)\n",
            "I0802 20:40:35.598115 139820296341376 learning.py:512] global step 9416: loss = 1.3226 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9417: loss = 0.8586 (0.238 sec/step)\n",
            "I0802 20:40:35.838048 139820296341376 learning.py:512] global step 9417: loss = 0.8586 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9418: loss = 0.7003 (0.255 sec/step)\n",
            "I0802 20:40:36.094288 139820296341376 learning.py:512] global step 9418: loss = 0.7003 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 9419: loss = 0.9412 (0.237 sec/step)\n",
            "I0802 20:40:36.332811 139820296341376 learning.py:512] global step 9419: loss = 0.9412 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9420: loss = 0.6797 (0.227 sec/step)\n",
            "I0802 20:40:36.561577 139820296341376 learning.py:512] global step 9420: loss = 0.6797 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9421: loss = 0.7440 (0.239 sec/step)\n",
            "I0802 20:40:36.802496 139820296341376 learning.py:512] global step 9421: loss = 0.7440 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9422: loss = 0.9150 (0.239 sec/step)\n",
            "I0802 20:40:37.042986 139820296341376 learning.py:512] global step 9422: loss = 0.9150 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9423: loss = 1.3521 (0.240 sec/step)\n",
            "I0802 20:40:37.284777 139820296341376 learning.py:512] global step 9423: loss = 1.3521 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9424: loss = 0.6350 (0.243 sec/step)\n",
            "I0802 20:40:37.529241 139820296341376 learning.py:512] global step 9424: loss = 0.6350 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9425: loss = 0.8826 (0.243 sec/step)\n",
            "I0802 20:40:37.773431 139820296341376 learning.py:512] global step 9425: loss = 0.8826 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9426: loss = 0.9720 (0.228 sec/step)\n",
            "I0802 20:40:38.003180 139820296341376 learning.py:512] global step 9426: loss = 0.9720 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9427: loss = 1.1562 (0.226 sec/step)\n",
            "I0802 20:40:38.230844 139820296341376 learning.py:512] global step 9427: loss = 1.1562 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9428: loss = 0.8100 (0.238 sec/step)\n",
            "I0802 20:40:38.470705 139820296341376 learning.py:512] global step 9428: loss = 0.8100 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9429: loss = 1.0154 (0.233 sec/step)\n",
            "I0802 20:40:38.705389 139820296341376 learning.py:512] global step 9429: loss = 1.0154 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9430: loss = 0.6503 (0.253 sec/step)\n",
            "I0802 20:40:38.960049 139820296341376 learning.py:512] global step 9430: loss = 0.6503 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9431: loss = 0.9835 (0.239 sec/step)\n",
            "I0802 20:40:39.200289 139820296341376 learning.py:512] global step 9431: loss = 0.9835 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9432: loss = 1.0385 (0.237 sec/step)\n",
            "I0802 20:40:39.438667 139820296341376 learning.py:512] global step 9432: loss = 1.0385 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9433: loss = 0.8274 (0.242 sec/step)\n",
            "I0802 20:40:39.681598 139820296341376 learning.py:512] global step 9433: loss = 0.8274 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9434: loss = 1.0945 (0.240 sec/step)\n",
            "I0802 20:40:39.923041 139820296341376 learning.py:512] global step 9434: loss = 1.0945 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9435: loss = 1.0744 (0.243 sec/step)\n",
            "I0802 20:40:40.167715 139820296341376 learning.py:512] global step 9435: loss = 1.0744 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9436: loss = 0.8703 (0.237 sec/step)\n",
            "I0802 20:40:40.406282 139820296341376 learning.py:512] global step 9436: loss = 0.8703 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9437: loss = 0.9095 (0.238 sec/step)\n",
            "I0802 20:40:40.645876 139820296341376 learning.py:512] global step 9437: loss = 0.9095 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9438: loss = 0.7404 (0.243 sec/step)\n",
            "I0802 20:40:40.889883 139820296341376 learning.py:512] global step 9438: loss = 0.7404 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9439: loss = 1.0264 (0.224 sec/step)\n",
            "I0802 20:40:41.115593 139820296341376 learning.py:512] global step 9439: loss = 1.0264 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9440: loss = 1.1720 (0.240 sec/step)\n",
            "I0802 20:40:41.357390 139820296341376 learning.py:512] global step 9440: loss = 1.1720 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9441: loss = 0.9729 (0.219 sec/step)\n",
            "I0802 20:40:41.577525 139820296341376 learning.py:512] global step 9441: loss = 0.9729 (0.219 sec/step)\n",
            "INFO:tensorflow:global step 9442: loss = 0.9370 (0.241 sec/step)\n",
            "I0802 20:40:41.820291 139820296341376 learning.py:512] global step 9442: loss = 0.9370 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9443: loss = 0.8808 (0.238 sec/step)\n",
            "I0802 20:40:42.059935 139820296341376 learning.py:512] global step 9443: loss = 0.8808 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9444: loss = 0.8394 (0.243 sec/step)\n",
            "I0802 20:40:42.304698 139820296341376 learning.py:512] global step 9444: loss = 0.8394 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9445: loss = 0.7986 (0.235 sec/step)\n",
            "I0802 20:40:42.540992 139820296341376 learning.py:512] global step 9445: loss = 0.7986 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9446: loss = 0.7930 (0.226 sec/step)\n",
            "I0802 20:40:42.768567 139820296341376 learning.py:512] global step 9446: loss = 0.7930 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9447: loss = 0.9120 (0.246 sec/step)\n",
            "I0802 20:40:43.016442 139820296341376 learning.py:512] global step 9447: loss = 0.9120 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9448: loss = 0.8351 (0.239 sec/step)\n",
            "I0802 20:40:43.256618 139820296341376 learning.py:512] global step 9448: loss = 0.8351 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9449: loss = 1.3165 (0.237 sec/step)\n",
            "I0802 20:40:43.496040 139820296341376 learning.py:512] global step 9449: loss = 1.3165 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9450: loss = 1.0393 (0.238 sec/step)\n",
            "I0802 20:40:43.735941 139820296341376 learning.py:512] global step 9450: loss = 1.0393 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9451: loss = 0.7745 (0.237 sec/step)\n",
            "I0802 20:40:43.974424 139820296341376 learning.py:512] global step 9451: loss = 0.7745 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9452: loss = 1.0325 (0.244 sec/step)\n",
            "I0802 20:40:44.220195 139820296341376 learning.py:512] global step 9452: loss = 1.0325 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9453: loss = 0.7994 (0.224 sec/step)\n",
            "I0802 20:40:44.446088 139820296341376 learning.py:512] global step 9453: loss = 0.7994 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9454: loss = 1.3032 (0.221 sec/step)\n",
            "I0802 20:40:44.668880 139820296341376 learning.py:512] global step 9454: loss = 1.3032 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 9455: loss = 0.7602 (0.223 sec/step)\n",
            "I0802 20:40:44.892878 139820296341376 learning.py:512] global step 9455: loss = 0.7602 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9456: loss = 0.9775 (0.241 sec/step)\n",
            "I0802 20:40:45.134969 139820296341376 learning.py:512] global step 9456: loss = 0.9775 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9457: loss = 0.8940 (0.243 sec/step)\n",
            "I0802 20:40:45.379209 139820296341376 learning.py:512] global step 9457: loss = 0.8940 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9458: loss = 0.8029 (0.248 sec/step)\n",
            "I0802 20:40:45.628885 139820296341376 learning.py:512] global step 9458: loss = 0.8029 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9459: loss = 1.1427 (0.224 sec/step)\n",
            "I0802 20:40:45.854574 139820296341376 learning.py:512] global step 9459: loss = 1.1427 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9460: loss = 0.6604 (0.226 sec/step)\n",
            "I0802 20:40:46.081952 139820296341376 learning.py:512] global step 9460: loss = 0.6604 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9461: loss = 0.7100 (0.230 sec/step)\n",
            "I0802 20:40:46.313789 139820296341376 learning.py:512] global step 9461: loss = 0.7100 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9462: loss = 0.6743 (0.241 sec/step)\n",
            "I0802 20:40:46.556021 139820296341376 learning.py:512] global step 9462: loss = 0.6743 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9463: loss = 1.0233 (0.219 sec/step)\n",
            "I0802 20:40:46.777044 139820296341376 learning.py:512] global step 9463: loss = 1.0233 (0.219 sec/step)\n",
            "INFO:tensorflow:global step 9464: loss = 0.8593 (0.224 sec/step)\n",
            "I0802 20:40:47.002526 139820296341376 learning.py:512] global step 9464: loss = 0.8593 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9465: loss = 0.7754 (0.228 sec/step)\n",
            "I0802 20:40:47.232403 139820296341376 learning.py:512] global step 9465: loss = 0.7754 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9466: loss = 0.6711 (0.242 sec/step)\n",
            "I0802 20:40:47.476277 139820296341376 learning.py:512] global step 9466: loss = 0.6711 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9467: loss = 1.1602 (0.238 sec/step)\n",
            "I0802 20:40:47.717382 139820296341376 learning.py:512] global step 9467: loss = 1.1602 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9468: loss = 0.7198 (0.225 sec/step)\n",
            "I0802 20:40:47.944377 139820296341376 learning.py:512] global step 9468: loss = 0.7198 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9469: loss = 1.2022 (0.238 sec/step)\n",
            "I0802 20:40:48.183429 139820296341376 learning.py:512] global step 9469: loss = 1.2022 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9470: loss = 0.7235 (0.239 sec/step)\n",
            "I0802 20:40:48.424020 139820296341376 learning.py:512] global step 9470: loss = 0.7235 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9471: loss = 0.7894 (0.244 sec/step)\n",
            "I0802 20:40:48.669454 139820296341376 learning.py:512] global step 9471: loss = 0.7894 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9472: loss = 0.6982 (0.244 sec/step)\n",
            "I0802 20:40:48.915364 139820296341376 learning.py:512] global step 9472: loss = 0.6982 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9473: loss = 0.8195 (0.235 sec/step)\n",
            "I0802 20:40:49.151900 139820296341376 learning.py:512] global step 9473: loss = 0.8195 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9474: loss = 0.7196 (0.233 sec/step)\n",
            "I0802 20:40:49.386060 139820296341376 learning.py:512] global step 9474: loss = 0.7196 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9475: loss = 1.0042 (0.241 sec/step)\n",
            "I0802 20:40:49.628390 139820296341376 learning.py:512] global step 9475: loss = 1.0042 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9476: loss = 0.8293 (0.233 sec/step)\n",
            "I0802 20:40:49.862579 139820296341376 learning.py:512] global step 9476: loss = 0.8293 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9477: loss = 0.7590 (0.235 sec/step)\n",
            "I0802 20:40:50.099078 139820296341376 learning.py:512] global step 9477: loss = 0.7590 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9478: loss = 0.8956 (0.227 sec/step)\n",
            "I0802 20:40:50.327830 139820296341376 learning.py:512] global step 9478: loss = 0.8956 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9479: loss = 0.7755 (0.238 sec/step)\n",
            "I0802 20:40:50.566867 139820296341376 learning.py:512] global step 9479: loss = 0.7755 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9480: loss = 0.8305 (0.241 sec/step)\n",
            "I0802 20:40:50.809575 139820296341376 learning.py:512] global step 9480: loss = 0.8305 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9481: loss = 0.9298 (0.238 sec/step)\n",
            "I0802 20:40:51.048771 139820296341376 learning.py:512] global step 9481: loss = 0.9298 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9482: loss = 0.9815 (0.244 sec/step)\n",
            "I0802 20:40:51.294192 139820296341376 learning.py:512] global step 9482: loss = 0.9815 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9483: loss = 0.5860 (0.230 sec/step)\n",
            "I0802 20:40:51.525482 139820296341376 learning.py:512] global step 9483: loss = 0.5860 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9484: loss = 0.9123 (0.233 sec/step)\n",
            "I0802 20:40:51.759993 139820296341376 learning.py:512] global step 9484: loss = 0.9123 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9485: loss = 0.7556 (0.238 sec/step)\n",
            "I0802 20:40:51.999344 139820296341376 learning.py:512] global step 9485: loss = 0.7556 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9486: loss = 1.1443 (0.239 sec/step)\n",
            "I0802 20:40:52.239642 139820296341376 learning.py:512] global step 9486: loss = 1.1443 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9487: loss = 0.7341 (0.232 sec/step)\n",
            "I0802 20:40:52.473314 139820296341376 learning.py:512] global step 9487: loss = 0.7341 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9488: loss = 0.7549 (0.242 sec/step)\n",
            "I0802 20:40:52.716436 139820296341376 learning.py:512] global step 9488: loss = 0.7549 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9489: loss = 0.7452 (0.242 sec/step)\n",
            "I0802 20:40:52.960355 139820296341376 learning.py:512] global step 9489: loss = 0.7452 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9490: loss = 1.1771 (0.224 sec/step)\n",
            "I0802 20:40:53.186002 139820296341376 learning.py:512] global step 9490: loss = 1.1771 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9491: loss = 0.9670 (0.225 sec/step)\n",
            "I0802 20:40:53.412545 139820296341376 learning.py:512] global step 9491: loss = 0.9670 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9492: loss = 0.9439 (0.229 sec/step)\n",
            "I0802 20:40:53.643422 139820296341376 learning.py:512] global step 9492: loss = 0.9439 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9493: loss = 0.8330 (0.244 sec/step)\n",
            "I0802 20:40:53.888518 139820296341376 learning.py:512] global step 9493: loss = 0.8330 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9494: loss = 0.8814 (0.236 sec/step)\n",
            "I0802 20:40:54.125846 139820296341376 learning.py:512] global step 9494: loss = 0.8814 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9495: loss = 0.8922 (0.227 sec/step)\n",
            "I0802 20:40:54.354420 139820296341376 learning.py:512] global step 9495: loss = 0.8922 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9496: loss = 0.8867 (0.228 sec/step)\n",
            "I0802 20:40:54.584411 139820296341376 learning.py:512] global step 9496: loss = 0.8867 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9497: loss = 0.9518 (0.247 sec/step)\n",
            "I0802 20:40:54.833180 139820296341376 learning.py:512] global step 9497: loss = 0.9518 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9498: loss = 0.7002 (0.242 sec/step)\n",
            "I0802 20:40:55.076711 139820296341376 learning.py:512] global step 9498: loss = 0.7002 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9499: loss = 0.8335 (0.244 sec/step)\n",
            "I0802 20:40:55.321794 139820296341376 learning.py:512] global step 9499: loss = 0.8335 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9500: loss = 0.6700 (0.244 sec/step)\n",
            "I0802 20:40:55.566962 139820296341376 learning.py:512] global step 9500: loss = 0.6700 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9501: loss = 1.1795 (0.240 sec/step)\n",
            "I0802 20:40:55.808234 139820296341376 learning.py:512] global step 9501: loss = 1.1795 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9502: loss = 0.6711 (0.235 sec/step)\n",
            "I0802 20:40:56.044702 139820296341376 learning.py:512] global step 9502: loss = 0.6711 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9503: loss = 0.7688 (0.229 sec/step)\n",
            "I0802 20:40:56.274744 139820296341376 learning.py:512] global step 9503: loss = 0.7688 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9504: loss = 0.9699 (0.235 sec/step)\n",
            "I0802 20:40:56.511167 139820296341376 learning.py:512] global step 9504: loss = 0.9699 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9505: loss = 1.0536 (0.240 sec/step)\n",
            "I0802 20:40:56.753256 139820296341376 learning.py:512] global step 9505: loss = 1.0536 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9506: loss = 0.7253 (0.238 sec/step)\n",
            "I0802 20:40:56.992542 139820296341376 learning.py:512] global step 9506: loss = 0.7253 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9507: loss = 1.0512 (0.238 sec/step)\n",
            "I0802 20:40:57.231858 139820296341376 learning.py:512] global step 9507: loss = 1.0512 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9508: loss = 0.9336 (0.240 sec/step)\n",
            "I0802 20:40:57.473172 139820296341376 learning.py:512] global step 9508: loss = 0.9336 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9509: loss = 0.8436 (0.243 sec/step)\n",
            "I0802 20:40:57.717363 139820296341376 learning.py:512] global step 9509: loss = 0.8436 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9510: loss = 0.5933 (0.235 sec/step)\n",
            "I0802 20:40:57.953786 139820296341376 learning.py:512] global step 9510: loss = 0.5933 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9511: loss = 0.8050 (0.240 sec/step)\n",
            "I0802 20:40:58.195554 139820296341376 learning.py:512] global step 9511: loss = 0.8050 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9512: loss = 0.8848 (0.255 sec/step)\n",
            "I0802 20:40:58.454267 139820296341376 learning.py:512] global step 9512: loss = 0.8848 (0.255 sec/step)\n",
            "INFO:tensorflow:global step 9513: loss = 0.6257 (0.232 sec/step)\n",
            "I0802 20:40:58.688061 139820296341376 learning.py:512] global step 9513: loss = 0.6257 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9514: loss = 0.8466 (0.237 sec/step)\n",
            "I0802 20:40:58.926184 139820296341376 learning.py:512] global step 9514: loss = 0.8466 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9515: loss = 1.1009 (0.231 sec/step)\n",
            "I0802 20:40:59.158831 139820296341376 learning.py:512] global step 9515: loss = 1.1009 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9516: loss = 0.8651 (0.238 sec/step)\n",
            "I0802 20:40:59.398777 139820296341376 learning.py:512] global step 9516: loss = 0.8651 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9517: loss = 0.9337 (0.244 sec/step)\n",
            "I0802 20:40:59.644846 139820296341376 learning.py:512] global step 9517: loss = 0.9337 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9518: loss = 1.0707 (0.249 sec/step)\n",
            "I0802 20:40:59.895408 139820296341376 learning.py:512] global step 9518: loss = 1.0707 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9519: loss = 0.7236 (0.236 sec/step)\n",
            "I0802 20:41:00.132333 139820296341376 learning.py:512] global step 9519: loss = 0.7236 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9520: loss = 0.9469 (0.241 sec/step)\n",
            "I0802 20:41:00.375202 139820296341376 learning.py:512] global step 9520: loss = 0.9469 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9521: loss = 0.8519 (0.245 sec/step)\n",
            "I0802 20:41:00.621649 139820296341376 learning.py:512] global step 9521: loss = 0.8519 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9522: loss = 0.7995 (0.244 sec/step)\n",
            "I0802 20:41:00.867185 139820296341376 learning.py:512] global step 9522: loss = 0.7995 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9523: loss = 1.1056 (0.224 sec/step)\n",
            "I0802 20:41:01.092513 139820296341376 learning.py:512] global step 9523: loss = 1.1056 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9524: loss = 0.9970 (0.233 sec/step)\n",
            "I0802 20:41:01.326607 139820296341376 learning.py:512] global step 9524: loss = 0.9970 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9525: loss = 0.8521 (0.224 sec/step)\n",
            "I0802 20:41:01.552632 139820296341376 learning.py:512] global step 9525: loss = 0.8521 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9526: loss = 0.8510 (0.247 sec/step)\n",
            "I0802 20:41:01.801498 139820296341376 learning.py:512] global step 9526: loss = 0.8510 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9527: loss = 0.6286 (0.231 sec/step)\n",
            "I0802 20:41:02.033540 139820296341376 learning.py:512] global step 9527: loss = 0.6286 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9528: loss = 0.6360 (0.223 sec/step)\n",
            "I0802 20:41:02.258262 139820296341376 learning.py:512] global step 9528: loss = 0.6360 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9529: loss = 0.6531 (0.245 sec/step)\n",
            "I0802 20:41:02.504818 139820296341376 learning.py:512] global step 9529: loss = 0.6531 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9530: loss = 0.7309 (0.244 sec/step)\n",
            "I0802 20:41:02.750523 139820296341376 learning.py:512] global step 9530: loss = 0.7309 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9531: loss = 1.0924 (0.231 sec/step)\n",
            "I0802 20:41:02.983800 139820296341376 learning.py:512] global step 9531: loss = 1.0924 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9532: loss = 0.7706 (0.246 sec/step)\n",
            "I0802 20:41:03.232017 139820296341376 learning.py:512] global step 9532: loss = 0.7706 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9533: loss = 0.6026 (0.249 sec/step)\n",
            "I0802 20:41:03.482230 139820296341376 learning.py:512] global step 9533: loss = 0.6026 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9534: loss = 1.1078 (0.239 sec/step)\n",
            "I0802 20:41:03.723237 139820296341376 learning.py:512] global step 9534: loss = 1.1078 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9535: loss = 0.7329 (0.243 sec/step)\n",
            "I0802 20:41:03.968060 139820296341376 learning.py:512] global step 9535: loss = 0.7329 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9536: loss = 0.7194 (0.224 sec/step)\n",
            "I0802 20:41:04.193674 139820296341376 learning.py:512] global step 9536: loss = 0.7194 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9537: loss = 0.8870 (0.249 sec/step)\n",
            "I0802 20:41:04.445043 139820296341376 learning.py:512] global step 9537: loss = 0.8870 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9538: loss = 0.7956 (0.243 sec/step)\n",
            "I0802 20:41:04.689888 139820296341376 learning.py:512] global step 9538: loss = 0.7956 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9539: loss = 0.6877 (0.249 sec/step)\n",
            "I0802 20:41:04.940436 139820296341376 learning.py:512] global step 9539: loss = 0.6877 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9540: loss = 0.7819 (0.243 sec/step)\n",
            "I0802 20:41:05.184881 139820296341376 learning.py:512] global step 9540: loss = 0.7819 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9541: loss = 0.8450 (0.239 sec/step)\n",
            "I0802 20:41:05.425823 139820296341376 learning.py:512] global step 9541: loss = 0.8450 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9542: loss = 0.8059 (0.259 sec/step)\n",
            "I0802 20:41:05.686654 139820296341376 learning.py:512] global step 9542: loss = 0.8059 (0.259 sec/step)\n",
            "INFO:tensorflow:global step 9543: loss = 0.8745 (0.238 sec/step)\n",
            "I0802 20:41:05.925929 139820296341376 learning.py:512] global step 9543: loss = 0.8745 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9544: loss = 1.2287 (0.244 sec/step)\n",
            "I0802 20:41:06.171552 139820296341376 learning.py:512] global step 9544: loss = 1.2287 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9545: loss = 0.8948 (0.241 sec/step)\n",
            "I0802 20:41:06.413697 139820296341376 learning.py:512] global step 9545: loss = 0.8948 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9546: loss = 0.8001 (0.227 sec/step)\n",
            "I0802 20:41:06.642393 139820296341376 learning.py:512] global step 9546: loss = 0.8001 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9547: loss = 0.7263 (0.225 sec/step)\n",
            "I0802 20:41:06.869326 139820296341376 learning.py:512] global step 9547: loss = 0.7263 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9548: loss = 0.8567 (0.237 sec/step)\n",
            "I0802 20:41:07.107750 139820296341376 learning.py:512] global step 9548: loss = 0.8567 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9549: loss = 0.9463 (0.227 sec/step)\n",
            "I0802 20:41:07.335947 139820296341376 learning.py:512] global step 9549: loss = 0.9463 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9550: loss = 0.7722 (0.247 sec/step)\n",
            "I0802 20:41:07.584355 139820296341376 learning.py:512] global step 9550: loss = 0.7722 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9551: loss = 0.6408 (0.242 sec/step)\n",
            "I0802 20:41:07.827547 139820296341376 learning.py:512] global step 9551: loss = 0.6408 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9552: loss = 0.8782 (0.228 sec/step)\n",
            "I0802 20:41:08.057041 139820296341376 learning.py:512] global step 9552: loss = 0.8782 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9553: loss = 0.7502 (0.239 sec/step)\n",
            "I0802 20:41:08.297088 139820296341376 learning.py:512] global step 9553: loss = 0.7502 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9554: loss = 0.6729 (0.237 sec/step)\n",
            "I0802 20:41:08.535129 139820296341376 learning.py:512] global step 9554: loss = 0.6729 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9555: loss = 1.0824 (0.228 sec/step)\n",
            "I0802 20:41:08.765307 139820296341376 learning.py:512] global step 9555: loss = 1.0824 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9556: loss = 0.8039 (0.242 sec/step)\n",
            "I0802 20:41:09.008778 139820296341376 learning.py:512] global step 9556: loss = 0.8039 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9557: loss = 0.9170 (0.239 sec/step)\n",
            "I0802 20:41:09.249023 139820296341376 learning.py:512] global step 9557: loss = 0.9170 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9558: loss = 0.8183 (0.230 sec/step)\n",
            "I0802 20:41:09.480950 139820296341376 learning.py:512] global step 9558: loss = 0.8183 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9559: loss = 0.8482 (0.243 sec/step)\n",
            "I0802 20:41:09.725470 139820296341376 learning.py:512] global step 9559: loss = 0.8482 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9560: loss = 0.9787 (0.229 sec/step)\n",
            "I0802 20:41:09.956716 139820296341376 learning.py:512] global step 9560: loss = 0.9787 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9561: loss = 0.8744 (0.240 sec/step)\n",
            "I0802 20:41:10.198530 139820296341376 learning.py:512] global step 9561: loss = 0.8744 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9562: loss = 1.3394 (0.237 sec/step)\n",
            "I0802 20:41:10.437188 139820296341376 learning.py:512] global step 9562: loss = 1.3394 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9563: loss = 0.7136 (0.250 sec/step)\n",
            "I0802 20:41:10.689294 139820296341376 learning.py:512] global step 9563: loss = 0.7136 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9564: loss = 0.7897 (0.241 sec/step)\n",
            "I0802 20:41:10.931476 139820296341376 learning.py:512] global step 9564: loss = 0.7897 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9565: loss = 0.7950 (0.225 sec/step)\n",
            "I0802 20:41:11.157503 139820296341376 learning.py:512] global step 9565: loss = 0.7950 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9566: loss = 0.7583 (0.244 sec/step)\n",
            "I0802 20:41:11.402899 139820296341376 learning.py:512] global step 9566: loss = 0.7583 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9567: loss = 0.6944 (0.246 sec/step)\n",
            "I0802 20:41:11.650299 139820296341376 learning.py:512] global step 9567: loss = 0.6944 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9568: loss = 1.0540 (0.244 sec/step)\n",
            "I0802 20:41:11.896091 139820296341376 learning.py:512] global step 9568: loss = 1.0540 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9569: loss = 0.8338 (0.245 sec/step)\n",
            "I0802 20:41:12.142581 139820296341376 learning.py:512] global step 9569: loss = 0.8338 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9570: loss = 0.5963 (0.227 sec/step)\n",
            "I0802 20:41:12.370866 139820296341376 learning.py:512] global step 9570: loss = 0.5963 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9571: loss = 0.8449 (0.245 sec/step)\n",
            "I0802 20:41:12.617253 139820296341376 learning.py:512] global step 9571: loss = 0.8449 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9572: loss = 1.0721 (0.245 sec/step)\n",
            "I0802 20:41:12.863937 139820296341376 learning.py:512] global step 9572: loss = 1.0721 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9573: loss = 0.8279 (0.225 sec/step)\n",
            "I0802 20:41:13.090126 139820296341376 learning.py:512] global step 9573: loss = 0.8279 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9574: loss = 0.7615 (0.240 sec/step)\n",
            "I0802 20:41:13.331949 139820296341376 learning.py:512] global step 9574: loss = 0.7615 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9575: loss = 1.1034 (0.250 sec/step)\n",
            "I0802 20:41:13.583811 139820296341376 learning.py:512] global step 9575: loss = 1.1034 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9576: loss = 0.7168 (0.234 sec/step)\n",
            "I0802 20:41:13.819075 139820296341376 learning.py:512] global step 9576: loss = 0.7168 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9577: loss = 0.9443 (0.241 sec/step)\n",
            "I0802 20:41:14.061793 139820296341376 learning.py:512] global step 9577: loss = 0.9443 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9578: loss = 0.6572 (0.234 sec/step)\n",
            "I0802 20:41:14.297892 139820296341376 learning.py:512] global step 9578: loss = 0.6572 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9579: loss = 0.8426 (0.237 sec/step)\n",
            "I0802 20:41:14.536182 139820296341376 learning.py:512] global step 9579: loss = 0.8426 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9580: loss = 1.1922 (0.237 sec/step)\n",
            "I0802 20:41:14.774725 139820296341376 learning.py:512] global step 9580: loss = 1.1922 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9581: loss = 0.8381 (0.225 sec/step)\n",
            "I0802 20:41:15.001332 139820296341376 learning.py:512] global step 9581: loss = 0.8381 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9582: loss = 0.9552 (0.240 sec/step)\n",
            "I0802 20:41:15.242811 139820296341376 learning.py:512] global step 9582: loss = 0.9552 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9583: loss = 0.7640 (0.235 sec/step)\n",
            "I0802 20:41:15.478955 139820296341376 learning.py:512] global step 9583: loss = 0.7640 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9584: loss = 0.7514 (0.229 sec/step)\n",
            "I0802 20:41:15.709502 139820296341376 learning.py:512] global step 9584: loss = 0.7514 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9585: loss = 0.7555 (0.236 sec/step)\n",
            "I0802 20:41:15.946870 139820296341376 learning.py:512] global step 9585: loss = 0.7555 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9586: loss = 0.7639 (0.239 sec/step)\n",
            "I0802 20:41:16.186761 139820296341376 learning.py:512] global step 9586: loss = 0.7639 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9587: loss = 0.8282 (0.235 sec/step)\n",
            "I0802 20:41:16.422825 139820296341376 learning.py:512] global step 9587: loss = 0.8282 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9588: loss = 0.9859 (0.245 sec/step)\n",
            "I0802 20:41:16.669581 139820296341376 learning.py:512] global step 9588: loss = 0.9859 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9589: loss = 0.8199 (0.241 sec/step)\n",
            "I0802 20:41:16.912149 139820296341376 learning.py:512] global step 9589: loss = 0.8199 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9590: loss = 1.0296 (0.238 sec/step)\n",
            "I0802 20:41:17.151366 139820296341376 learning.py:512] global step 9590: loss = 1.0296 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9591: loss = 0.7676 (0.241 sec/step)\n",
            "I0802 20:41:17.393385 139820296341376 learning.py:512] global step 9591: loss = 0.7676 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9592: loss = 0.9083 (0.232 sec/step)\n",
            "I0802 20:41:17.626832 139820296341376 learning.py:512] global step 9592: loss = 0.9083 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9593: loss = 1.0152 (0.235 sec/step)\n",
            "I0802 20:41:17.863779 139820296341376 learning.py:512] global step 9593: loss = 1.0152 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9594: loss = 0.6933 (0.228 sec/step)\n",
            "I0802 20:41:18.093719 139820296341376 learning.py:512] global step 9594: loss = 0.6933 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9595: loss = 0.8585 (0.236 sec/step)\n",
            "I0802 20:41:18.330894 139820296341376 learning.py:512] global step 9595: loss = 0.8585 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9596: loss = 0.7917 (0.240 sec/step)\n",
            "I0802 20:41:18.572298 139820296341376 learning.py:512] global step 9596: loss = 0.7917 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9597: loss = 0.7651 (0.237 sec/step)\n",
            "I0802 20:41:18.811258 139820296341376 learning.py:512] global step 9597: loss = 0.7651 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9598: loss = 0.8636 (0.234 sec/step)\n",
            "I0802 20:41:19.046868 139820296341376 learning.py:512] global step 9598: loss = 0.8636 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9599: loss = 0.7588 (0.225 sec/step)\n",
            "I0802 20:41:19.273730 139820296341376 learning.py:512] global step 9599: loss = 0.7588 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9600: loss = 0.9327 (0.241 sec/step)\n",
            "I0802 20:41:19.516643 139820296341376 learning.py:512] global step 9600: loss = 0.9327 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9601: loss = 0.8236 (0.240 sec/step)\n",
            "I0802 20:41:19.758198 139820296341376 learning.py:512] global step 9601: loss = 0.8236 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9602: loss = 1.0933 (0.224 sec/step)\n",
            "I0802 20:41:19.983940 139820296341376 learning.py:512] global step 9602: loss = 1.0933 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9603: loss = 0.8669 (0.240 sec/step)\n",
            "I0802 20:41:20.225666 139820296341376 learning.py:512] global step 9603: loss = 0.8669 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9604: loss = 0.9715 (0.232 sec/step)\n",
            "I0802 20:41:20.459253 139820296341376 learning.py:512] global step 9604: loss = 0.9715 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9605: loss = 0.7163 (0.227 sec/step)\n",
            "I0802 20:41:20.687897 139820296341376 learning.py:512] global step 9605: loss = 0.7163 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9606: loss = 0.9592 (0.234 sec/step)\n",
            "I0802 20:41:20.923568 139820296341376 learning.py:512] global step 9606: loss = 0.9592 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9607: loss = 0.8701 (0.237 sec/step)\n",
            "I0802 20:41:21.162485 139820296341376 learning.py:512] global step 9607: loss = 0.8701 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9608: loss = 1.0289 (0.225 sec/step)\n",
            "I0802 20:41:21.389462 139820296341376 learning.py:512] global step 9608: loss = 1.0289 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9609: loss = 0.9080 (0.238 sec/step)\n",
            "I0802 20:41:21.628829 139820296341376 learning.py:512] global step 9609: loss = 0.9080 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9610: loss = 0.9655 (0.233 sec/step)\n",
            "I0802 20:41:21.863439 139820296341376 learning.py:512] global step 9610: loss = 0.9655 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9611: loss = 1.0894 (0.242 sec/step)\n",
            "I0802 20:41:22.107791 139820296341376 learning.py:512] global step 9611: loss = 1.0894 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9612: loss = 1.1678 (0.246 sec/step)\n",
            "I0802 20:41:22.355422 139820296341376 learning.py:512] global step 9612: loss = 1.1678 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9613: loss = 1.0375 (0.232 sec/step)\n",
            "I0802 20:41:22.589082 139820296341376 learning.py:512] global step 9613: loss = 1.0375 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9614: loss = 0.7210 (0.224 sec/step)\n",
            "I0802 20:41:22.814601 139820296341376 learning.py:512] global step 9614: loss = 0.7210 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9615: loss = 1.0170 (0.241 sec/step)\n",
            "I0802 20:41:23.057421 139820296341376 learning.py:512] global step 9615: loss = 1.0170 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9616: loss = 0.5768 (0.226 sec/step)\n",
            "I0802 20:41:23.284935 139820296341376 learning.py:512] global step 9616: loss = 0.5768 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9617: loss = 0.8094 (0.231 sec/step)\n",
            "I0802 20:41:23.517445 139820296341376 learning.py:512] global step 9617: loss = 0.8094 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9618: loss = 0.7613 (0.223 sec/step)\n",
            "I0802 20:41:23.741906 139820296341376 learning.py:512] global step 9618: loss = 0.7613 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9619: loss = 0.9891 (0.234 sec/step)\n",
            "I0802 20:41:23.977382 139820296341376 learning.py:512] global step 9619: loss = 0.9891 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9620: loss = 0.8726 (0.224 sec/step)\n",
            "I0802 20:41:24.202392 139820296341376 learning.py:512] global step 9620: loss = 0.8726 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9621: loss = 1.2528 (0.242 sec/step)\n",
            "I0802 20:41:24.445766 139820296341376 learning.py:512] global step 9621: loss = 1.2528 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9622: loss = 0.6874 (0.240 sec/step)\n",
            "I0802 20:41:24.686889 139820296341376 learning.py:512] global step 9622: loss = 0.6874 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9623: loss = 1.1359 (0.238 sec/step)\n",
            "I0802 20:41:24.926202 139820296341376 learning.py:512] global step 9623: loss = 1.1359 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9624: loss = 1.1306 (0.234 sec/step)\n",
            "I0802 20:41:25.162101 139820296341376 learning.py:512] global step 9624: loss = 1.1306 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9625: loss = 1.1528 (0.236 sec/step)\n",
            "I0802 20:41:25.399946 139820296341376 learning.py:512] global step 9625: loss = 1.1528 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9626: loss = 0.9031 (0.234 sec/step)\n",
            "I0802 20:41:25.635664 139820296341376 learning.py:512] global step 9626: loss = 0.9031 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9627: loss = 1.0253 (0.223 sec/step)\n",
            "I0802 20:41:25.860301 139820296341376 learning.py:512] global step 9627: loss = 1.0253 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9628: loss = 0.6935 (0.223 sec/step)\n",
            "I0802 20:41:26.084289 139820296341376 learning.py:512] global step 9628: loss = 0.6935 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9629: loss = 0.9989 (0.236 sec/step)\n",
            "I0802 20:41:26.321689 139820296341376 learning.py:512] global step 9629: loss = 0.9989 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9630: loss = 0.9805 (0.251 sec/step)\n",
            "I0802 20:41:26.574627 139820296341376 learning.py:512] global step 9630: loss = 0.9805 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9631: loss = 1.0725 (0.238 sec/step)\n",
            "I0802 20:41:26.813907 139820296341376 learning.py:512] global step 9631: loss = 1.0725 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9632: loss = 1.3608 (0.227 sec/step)\n",
            "I0802 20:41:27.042788 139820296341376 learning.py:512] global step 9632: loss = 1.3608 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9633: loss = 0.7716 (0.225 sec/step)\n",
            "I0802 20:41:27.269536 139820296341376 learning.py:512] global step 9633: loss = 0.7716 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9634: loss = 1.1895 (0.239 sec/step)\n",
            "I0802 20:41:27.510053 139820296341376 learning.py:512] global step 9634: loss = 1.1895 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9635: loss = 0.7149 (0.247 sec/step)\n",
            "I0802 20:41:27.759150 139820296341376 learning.py:512] global step 9635: loss = 0.7149 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9636: loss = 0.8169 (0.237 sec/step)\n",
            "I0802 20:41:27.998174 139820296341376 learning.py:512] global step 9636: loss = 0.8169 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9637: loss = 0.6963 (0.236 sec/step)\n",
            "I0802 20:41:28.235140 139820296341376 learning.py:512] global step 9637: loss = 0.6963 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9638: loss = 0.7418 (0.239 sec/step)\n",
            "I0802 20:41:28.475825 139820296341376 learning.py:512] global step 9638: loss = 0.7418 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9639: loss = 0.6855 (0.241 sec/step)\n",
            "I0802 20:41:28.718146 139820296341376 learning.py:512] global step 9639: loss = 0.6855 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9640: loss = 0.7243 (0.239 sec/step)\n",
            "I0802 20:41:28.958671 139820296341376 learning.py:512] global step 9640: loss = 0.7243 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9641: loss = 1.0603 (0.234 sec/step)\n",
            "I0802 20:41:29.194715 139820296341376 learning.py:512] global step 9641: loss = 1.0603 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9642: loss = 0.7382 (0.235 sec/step)\n",
            "I0802 20:41:29.430721 139820296341376 learning.py:512] global step 9642: loss = 0.7382 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9643: loss = 0.8216 (0.242 sec/step)\n",
            "I0802 20:41:29.674456 139820296341376 learning.py:512] global step 9643: loss = 0.8216 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9644: loss = 0.7991 (0.239 sec/step)\n",
            "I0802 20:41:29.915490 139820296341376 learning.py:512] global step 9644: loss = 0.7991 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9645: loss = 0.8157 (0.243 sec/step)\n",
            "I0802 20:41:30.160238 139820296341376 learning.py:512] global step 9645: loss = 0.8157 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9646: loss = 0.8633 (0.237 sec/step)\n",
            "I0802 20:41:30.398809 139820296341376 learning.py:512] global step 9646: loss = 0.8633 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9647: loss = 0.7257 (0.236 sec/step)\n",
            "I0802 20:41:30.636818 139820296341376 learning.py:512] global step 9647: loss = 0.7257 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9648: loss = 0.8833 (0.227 sec/step)\n",
            "I0802 20:41:30.865232 139820296341376 learning.py:512] global step 9648: loss = 0.8833 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9649: loss = 0.9644 (0.240 sec/step)\n",
            "I0802 20:41:31.107227 139820296341376 learning.py:512] global step 9649: loss = 0.9644 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9650: loss = 0.6916 (0.223 sec/step)\n",
            "I0802 20:41:31.331813 139820296341376 learning.py:512] global step 9650: loss = 0.6916 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9651: loss = 0.7214 (0.237 sec/step)\n",
            "I0802 20:41:31.569945 139820296341376 learning.py:512] global step 9651: loss = 0.7214 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9652: loss = 0.8954 (0.249 sec/step)\n",
            "I0802 20:41:31.820615 139820296341376 learning.py:512] global step 9652: loss = 0.8954 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9653: loss = 0.9432 (0.238 sec/step)\n",
            "I0802 20:41:32.060411 139820296341376 learning.py:512] global step 9653: loss = 0.9432 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9654: loss = 0.8830 (0.238 sec/step)\n",
            "I0802 20:41:32.300082 139820296341376 learning.py:512] global step 9654: loss = 0.8830 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9655: loss = 0.9736 (0.239 sec/step)\n",
            "I0802 20:41:32.540506 139820296341376 learning.py:512] global step 9655: loss = 0.9736 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9656: loss = 0.6763 (0.248 sec/step)\n",
            "I0802 20:41:32.790492 139820296341376 learning.py:512] global step 9656: loss = 0.6763 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9657: loss = 0.8363 (0.241 sec/step)\n",
            "I0802 20:41:33.032833 139820296341376 learning.py:512] global step 9657: loss = 0.8363 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9658: loss = 0.6912 (0.240 sec/step)\n",
            "I0802 20:41:33.274646 139820296341376 learning.py:512] global step 9658: loss = 0.6912 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9659: loss = 0.6981 (0.229 sec/step)\n",
            "I0802 20:41:33.505196 139820296341376 learning.py:512] global step 9659: loss = 0.6981 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9660: loss = 1.0353 (0.236 sec/step)\n",
            "I0802 20:41:33.744047 139820296341376 learning.py:512] global step 9660: loss = 1.0353 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9661: loss = 0.7106 (0.245 sec/step)\n",
            "I0802 20:41:33.990687 139820296341376 learning.py:512] global step 9661: loss = 0.7106 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9662: loss = 0.7426 (0.242 sec/step)\n",
            "I0802 20:41:34.235152 139820296341376 learning.py:512] global step 9662: loss = 0.7426 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9663: loss = 0.8243 (0.230 sec/step)\n",
            "I0802 20:41:34.466468 139820296341376 learning.py:512] global step 9663: loss = 0.8243 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9664: loss = 0.6671 (0.252 sec/step)\n",
            "I0802 20:41:34.720294 139820296341376 learning.py:512] global step 9664: loss = 0.6671 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9665: loss = 0.7728 (0.244 sec/step)\n",
            "I0802 20:41:34.966141 139820296341376 learning.py:512] global step 9665: loss = 0.7728 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9666: loss = 0.8469 (0.248 sec/step)\n",
            "I0802 20:41:35.215559 139820296341376 learning.py:512] global step 9666: loss = 0.8469 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9667: loss = 0.6934 (0.243 sec/step)\n",
            "I0802 20:41:35.460002 139820296341376 learning.py:512] global step 9667: loss = 0.6934 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9668: loss = 1.0454 (0.242 sec/step)\n",
            "I0802 20:41:35.703968 139820296341376 learning.py:512] global step 9668: loss = 1.0454 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9669: loss = 0.7787 (0.247 sec/step)\n",
            "I0802 20:41:35.952846 139820296341376 learning.py:512] global step 9669: loss = 0.7787 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9670: loss = 0.6632 (0.242 sec/step)\n",
            "I0802 20:41:36.196747 139820296341376 learning.py:512] global step 9670: loss = 0.6632 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9671: loss = 0.5745 (0.232 sec/step)\n",
            "I0802 20:41:36.430359 139820296341376 learning.py:512] global step 9671: loss = 0.5745 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9672: loss = 0.9723 (0.242 sec/step)\n",
            "I0802 20:41:36.674048 139820296341376 learning.py:512] global step 9672: loss = 0.9723 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9673: loss = 0.8604 (0.247 sec/step)\n",
            "I0802 20:41:36.922642 139820296341376 learning.py:512] global step 9673: loss = 0.8604 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9674: loss = 0.8767 (0.239 sec/step)\n",
            "I0802 20:41:37.163339 139820296341376 learning.py:512] global step 9674: loss = 0.8767 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9675: loss = 0.7993 (0.239 sec/step)\n",
            "I0802 20:41:37.403399 139820296341376 learning.py:512] global step 9675: loss = 0.7993 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9676: loss = 0.7472 (0.240 sec/step)\n",
            "I0802 20:41:37.645367 139820296341376 learning.py:512] global step 9676: loss = 0.7472 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9677: loss = 0.8070 (0.247 sec/step)\n",
            "I0802 20:41:37.893900 139820296341376 learning.py:512] global step 9677: loss = 0.8070 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9678: loss = 1.1000 (0.235 sec/step)\n",
            "I0802 20:41:38.130486 139820296341376 learning.py:512] global step 9678: loss = 1.1000 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9679: loss = 1.0106 (0.245 sec/step)\n",
            "I0802 20:41:38.376943 139820296341376 learning.py:512] global step 9679: loss = 1.0106 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9680: loss = 1.0994 (0.256 sec/step)\n",
            "I0802 20:41:38.635046 139820296341376 learning.py:512] global step 9680: loss = 1.0994 (0.256 sec/step)\n",
            "INFO:tensorflow:global step 9681: loss = 1.0298 (0.240 sec/step)\n",
            "I0802 20:41:38.876658 139820296341376 learning.py:512] global step 9681: loss = 1.0298 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9682: loss = 0.9269 (0.245 sec/step)\n",
            "I0802 20:41:39.122639 139820296341376 learning.py:512] global step 9682: loss = 0.9269 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9683: loss = 0.6109 (0.226 sec/step)\n",
            "I0802 20:41:39.350189 139820296341376 learning.py:512] global step 9683: loss = 0.6109 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9684: loss = 0.7343 (0.240 sec/step)\n",
            "I0802 20:41:39.592029 139820296341376 learning.py:512] global step 9684: loss = 0.7343 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9685: loss = 0.7524 (0.243 sec/step)\n",
            "I0802 20:41:39.837013 139820296341376 learning.py:512] global step 9685: loss = 0.7524 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9686: loss = 0.9585 (0.228 sec/step)\n",
            "I0802 20:41:40.066744 139820296341376 learning.py:512] global step 9686: loss = 0.9585 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9687: loss = 0.8199 (0.230 sec/step)\n",
            "I0802 20:41:40.298382 139820296341376 learning.py:512] global step 9687: loss = 0.8199 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9688: loss = 1.4314 (0.248 sec/step)\n",
            "I0802 20:41:40.548095 139820296341376 learning.py:512] global step 9688: loss = 1.4314 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9689: loss = 0.8240 (0.241 sec/step)\n",
            "I0802 20:41:40.791275 139820296341376 learning.py:512] global step 9689: loss = 0.8240 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9690: loss = 0.6154 (0.249 sec/step)\n",
            "I0802 20:41:41.041997 139820296341376 learning.py:512] global step 9690: loss = 0.6154 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9691: loss = 0.6140 (0.231 sec/step)\n",
            "I0802 20:41:41.277384 139820296341376 learning.py:512] global step 9691: loss = 0.6140 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9692: loss = 0.8616 (0.241 sec/step)\n",
            "I0802 20:41:41.520232 139820296341376 learning.py:512] global step 9692: loss = 0.8616 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9693: loss = 0.7116 (0.241 sec/step)\n",
            "I0802 20:41:41.763125 139820296341376 learning.py:512] global step 9693: loss = 0.7116 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9694: loss = 0.9411 (0.246 sec/step)\n",
            "I0802 20:41:42.010776 139820296341376 learning.py:512] global step 9694: loss = 0.9411 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9695: loss = 0.6465 (0.225 sec/step)\n",
            "I0802 20:41:42.237698 139820296341376 learning.py:512] global step 9695: loss = 0.6465 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9696: loss = 0.7909 (0.246 sec/step)\n",
            "I0802 20:41:42.485533 139820296341376 learning.py:512] global step 9696: loss = 0.7909 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9697: loss = 1.0927 (0.239 sec/step)\n",
            "I0802 20:41:42.726050 139820296341376 learning.py:512] global step 9697: loss = 1.0927 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9698: loss = 0.8621 (0.239 sec/step)\n",
            "I0802 20:41:42.966145 139820296341376 learning.py:512] global step 9698: loss = 0.8621 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9699: loss = 1.0504 (0.232 sec/step)\n",
            "I0802 20:41:43.199687 139820296341376 learning.py:512] global step 9699: loss = 1.0504 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9700: loss = 0.9549 (0.242 sec/step)\n",
            "I0802 20:41:43.443351 139820296341376 learning.py:512] global step 9700: loss = 0.9549 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9701: loss = 0.6575 (0.243 sec/step)\n",
            "I0802 20:41:43.687973 139820296341376 learning.py:512] global step 9701: loss = 0.6575 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9702: loss = 0.7596 (0.241 sec/step)\n",
            "I0802 20:41:43.930555 139820296341376 learning.py:512] global step 9702: loss = 0.7596 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9703: loss = 0.8487 (0.249 sec/step)\n",
            "I0802 20:41:44.180578 139820296341376 learning.py:512] global step 9703: loss = 0.8487 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9704: loss = 0.6478 (0.239 sec/step)\n",
            "I0802 20:41:44.421158 139820296341376 learning.py:512] global step 9704: loss = 0.6478 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9705: loss = 1.0013 (0.227 sec/step)\n",
            "I0802 20:41:44.649697 139820296341376 learning.py:512] global step 9705: loss = 1.0013 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9706: loss = 0.8581 (0.244 sec/step)\n",
            "I0802 20:41:44.895526 139820296341376 learning.py:512] global step 9706: loss = 0.8581 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9707: loss = 0.8249 (0.240 sec/step)\n",
            "I0802 20:41:45.136688 139820296341376 learning.py:512] global step 9707: loss = 0.8249 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9708: loss = 0.8059 (0.245 sec/step)\n",
            "I0802 20:41:45.385205 139820296341376 learning.py:512] global step 9708: loss = 0.8059 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9709: loss = 0.6625 (0.247 sec/step)\n",
            "I0802 20:41:45.633319 139820296341376 learning.py:512] global step 9709: loss = 0.6625 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9710: loss = 0.8441 (0.229 sec/step)\n",
            "I0802 20:41:45.864885 139820296341376 learning.py:512] global step 9710: loss = 0.8441 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9711: loss = 1.0256 (0.231 sec/step)\n",
            "I0802 20:41:46.098850 139820296341376 learning.py:512] global step 9711: loss = 1.0256 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9712: loss = 0.9041 (0.235 sec/step)\n",
            "I0802 20:41:46.335689 139820296341376 learning.py:512] global step 9712: loss = 0.9041 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9713: loss = 1.0600 (0.240 sec/step)\n",
            "I0802 20:41:46.577163 139820296341376 learning.py:512] global step 9713: loss = 1.0600 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9714: loss = 1.0400 (0.237 sec/step)\n",
            "I0802 20:41:46.816160 139820296341376 learning.py:512] global step 9714: loss = 1.0400 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9715: loss = 1.1522 (0.233 sec/step)\n",
            "I0802 20:41:47.050793 139820296341376 learning.py:512] global step 9715: loss = 1.1522 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9716: loss = 1.1629 (0.246 sec/step)\n",
            "I0802 20:41:47.298573 139820296341376 learning.py:512] global step 9716: loss = 1.1629 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9717: loss = 0.7234 (0.233 sec/step)\n",
            "I0802 20:41:47.532836 139820296341376 learning.py:512] global step 9717: loss = 0.7234 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9718: loss = 1.0861 (0.231 sec/step)\n",
            "I0802 20:41:47.765240 139820296341376 learning.py:512] global step 9718: loss = 1.0861 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9719: loss = 0.7920 (0.241 sec/step)\n",
            "I0802 20:41:48.008598 139820296341376 learning.py:512] global step 9719: loss = 0.7920 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9720: loss = 0.9184 (0.240 sec/step)\n",
            "I0802 20:41:48.249985 139820296341376 learning.py:512] global step 9720: loss = 0.9184 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9721: loss = 0.7840 (0.227 sec/step)\n",
            "I0802 20:41:48.478240 139820296341376 learning.py:512] global step 9721: loss = 0.7840 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9722: loss = 0.7574 (0.229 sec/step)\n",
            "I0802 20:41:48.708907 139820296341376 learning.py:512] global step 9722: loss = 0.7574 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9723: loss = 0.8059 (0.246 sec/step)\n",
            "I0802 20:41:48.956460 139820296341376 learning.py:512] global step 9723: loss = 0.8059 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9724: loss = 1.0788 (0.222 sec/step)\n",
            "I0802 20:41:49.181026 139820296341376 learning.py:512] global step 9724: loss = 1.0788 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9725: loss = 1.0593 (0.239 sec/step)\n",
            "I0802 20:41:49.422224 139820296341376 learning.py:512] global step 9725: loss = 1.0593 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9726: loss = 0.7820 (0.238 sec/step)\n",
            "I0802 20:41:49.661817 139820296341376 learning.py:512] global step 9726: loss = 0.7820 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9727: loss = 1.1420 (0.240 sec/step)\n",
            "I0802 20:41:49.903086 139820296341376 learning.py:512] global step 9727: loss = 1.1420 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9728: loss = 0.8803 (0.233 sec/step)\n",
            "I0802 20:41:50.138097 139820296341376 learning.py:512] global step 9728: loss = 0.8803 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9729: loss = 0.6160 (0.233 sec/step)\n",
            "I0802 20:41:50.372763 139820296341376 learning.py:512] global step 9729: loss = 0.6160 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9730: loss = 1.0240 (0.225 sec/step)\n",
            "I0802 20:41:50.599598 139820296341376 learning.py:512] global step 9730: loss = 1.0240 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9731: loss = 1.0335 (0.239 sec/step)\n",
            "I0802 20:41:50.839489 139820296341376 learning.py:512] global step 9731: loss = 1.0335 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9732: loss = 0.7899 (0.238 sec/step)\n",
            "I0802 20:41:51.078694 139820296341376 learning.py:512] global step 9732: loss = 0.7899 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9733: loss = 0.8245 (0.231 sec/step)\n",
            "I0802 20:41:51.310893 139820296341376 learning.py:512] global step 9733: loss = 0.8245 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9734: loss = 0.8183 (0.239 sec/step)\n",
            "I0802 20:41:51.551365 139820296341376 learning.py:512] global step 9734: loss = 0.8183 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9735: loss = 0.7087 (0.224 sec/step)\n",
            "I0802 20:41:51.777019 139820296341376 learning.py:512] global step 9735: loss = 0.7087 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9736: loss = 0.8007 (0.246 sec/step)\n",
            "I0802 20:41:52.031668 139820296341376 learning.py:512] global step 9736: loss = 0.8007 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9737: loss = 0.6892 (0.234 sec/step)\n",
            "I0802 20:41:52.267353 139820296341376 learning.py:512] global step 9737: loss = 0.6892 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9738: loss = 1.0584 (0.243 sec/step)\n",
            "I0802 20:41:52.511869 139820296341376 learning.py:512] global step 9738: loss = 1.0584 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9739: loss = 0.7920 (0.231 sec/step)\n",
            "I0802 20:41:52.744038 139820296341376 learning.py:512] global step 9739: loss = 0.7920 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9740: loss = 1.0514 (0.242 sec/step)\n",
            "I0802 20:41:52.987766 139820296341376 learning.py:512] global step 9740: loss = 1.0514 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9741: loss = 0.9521 (0.233 sec/step)\n",
            "I0802 20:41:53.221842 139820296341376 learning.py:512] global step 9741: loss = 0.9521 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9742: loss = 0.6991 (0.235 sec/step)\n",
            "I0802 20:41:53.458116 139820296341376 learning.py:512] global step 9742: loss = 0.6991 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9743: loss = 0.6068 (0.224 sec/step)\n",
            "I0802 20:41:53.683667 139820296341376 learning.py:512] global step 9743: loss = 0.6068 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9744: loss = 0.7607 (0.246 sec/step)\n",
            "I0802 20:41:53.931352 139820296341376 learning.py:512] global step 9744: loss = 0.7607 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9745: loss = 0.7537 (0.242 sec/step)\n",
            "I0802 20:41:54.175811 139820296341376 learning.py:512] global step 9745: loss = 0.7537 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9746: loss = 0.8668 (0.223 sec/step)\n",
            "I0802 20:41:54.400151 139820296341376 learning.py:512] global step 9746: loss = 0.8668 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9747: loss = 0.8268 (0.238 sec/step)\n",
            "I0802 20:41:54.639654 139820296341376 learning.py:512] global step 9747: loss = 0.8268 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9748: loss = 0.5797 (0.240 sec/step)\n",
            "I0802 20:41:54.881525 139820296341376 learning.py:512] global step 9748: loss = 0.5797 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9749: loss = 0.8175 (0.239 sec/step)\n",
            "I0802 20:41:55.121778 139820296341376 learning.py:512] global step 9749: loss = 0.8175 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9750: loss = 0.8028 (0.236 sec/step)\n",
            "I0802 20:41:55.359287 139820296341376 learning.py:512] global step 9750: loss = 0.8028 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9751: loss = 0.8063 (0.234 sec/step)\n",
            "I0802 20:41:55.595148 139820296341376 learning.py:512] global step 9751: loss = 0.8063 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9752: loss = 0.8530 (0.241 sec/step)\n",
            "I0802 20:41:55.837455 139820296341376 learning.py:512] global step 9752: loss = 0.8530 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9753: loss = 1.0451 (0.241 sec/step)\n",
            "I0802 20:41:56.082088 139820296341376 learning.py:512] global step 9753: loss = 1.0451 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9754: loss = 1.0191 (0.225 sec/step)\n",
            "I0802 20:41:56.308230 139820296341376 learning.py:512] global step 9754: loss = 1.0191 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9755: loss = 0.9356 (0.233 sec/step)\n",
            "I0802 20:41:56.542501 139820296341376 learning.py:512] global step 9755: loss = 0.9356 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9756: loss = 0.6722 (0.240 sec/step)\n",
            "I0802 20:41:56.785021 139820296341376 learning.py:512] global step 9756: loss = 0.6722 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9757: loss = 0.8678 (0.246 sec/step)\n",
            "I0802 20:41:57.032416 139820296341376 learning.py:512] global step 9757: loss = 0.8678 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9758: loss = 1.0893 (0.247 sec/step)\n",
            "I0802 20:41:57.281105 139820296341376 learning.py:512] global step 9758: loss = 1.0893 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9759: loss = 0.6647 (0.243 sec/step)\n",
            "I0802 20:41:57.525873 139820296341376 learning.py:512] global step 9759: loss = 0.6647 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9760: loss = 0.9032 (0.239 sec/step)\n",
            "I0802 20:41:57.766666 139820296341376 learning.py:512] global step 9760: loss = 0.9032 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9761: loss = 0.6557 (0.242 sec/step)\n",
            "I0802 20:41:58.010197 139820296341376 learning.py:512] global step 9761: loss = 0.6557 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9762: loss = 0.8460 (0.246 sec/step)\n",
            "I0802 20:41:58.258210 139820296341376 learning.py:512] global step 9762: loss = 0.8460 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9763: loss = 1.0260 (0.226 sec/step)\n",
            "I0802 20:41:58.486555 139820296341376 learning.py:512] global step 9763: loss = 1.0260 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9764: loss = 0.8006 (0.237 sec/step)\n",
            "I0802 20:41:58.725513 139820296341376 learning.py:512] global step 9764: loss = 0.8006 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9765: loss = 0.9584 (0.248 sec/step)\n",
            "I0802 20:41:58.974974 139820296341376 learning.py:512] global step 9765: loss = 0.9584 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9766: loss = 0.9619 (0.242 sec/step)\n",
            "I0802 20:41:59.218502 139820296341376 learning.py:512] global step 9766: loss = 0.9619 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9767: loss = 0.7966 (0.238 sec/step)\n",
            "I0802 20:41:59.458343 139820296341376 learning.py:512] global step 9767: loss = 0.7966 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9768: loss = 1.1197 (0.247 sec/step)\n",
            "I0802 20:41:59.708662 139820296341376 learning.py:512] global step 9768: loss = 1.1197 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9769: loss = 1.4124 (0.236 sec/step)\n",
            "I0802 20:41:59.946685 139820296341376 learning.py:512] global step 9769: loss = 1.4124 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9770: loss = 0.8420 (0.238 sec/step)\n",
            "I0802 20:42:00.186284 139820296341376 learning.py:512] global step 9770: loss = 0.8420 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9771: loss = 0.9357 (0.249 sec/step)\n",
            "I0802 20:42:00.436533 139820296341376 learning.py:512] global step 9771: loss = 0.9357 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9772: loss = 0.7329 (0.242 sec/step)\n",
            "I0802 20:42:00.679764 139820296341376 learning.py:512] global step 9772: loss = 0.7329 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9773: loss = 0.8221 (0.240 sec/step)\n",
            "I0802 20:42:00.921686 139820296341376 learning.py:512] global step 9773: loss = 0.8221 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9774: loss = 0.7483 (0.238 sec/step)\n",
            "I0802 20:42:01.161504 139820296341376 learning.py:512] global step 9774: loss = 0.7483 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9775: loss = 0.7379 (0.241 sec/step)\n",
            "I0802 20:42:01.403983 139820296341376 learning.py:512] global step 9775: loss = 0.7379 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9776: loss = 0.5565 (0.241 sec/step)\n",
            "I0802 20:42:01.646212 139820296341376 learning.py:512] global step 9776: loss = 0.5565 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9777: loss = 0.6947 (0.244 sec/step)\n",
            "I0802 20:42:01.891831 139820296341376 learning.py:512] global step 9777: loss = 0.6947 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9778: loss = 0.9356 (0.240 sec/step)\n",
            "I0802 20:42:02.133809 139820296341376 learning.py:512] global step 9778: loss = 0.9356 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9779: loss = 0.7030 (0.239 sec/step)\n",
            "I0802 20:42:02.374872 139820296341376 learning.py:512] global step 9779: loss = 0.7030 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9780: loss = 0.7010 (0.244 sec/step)\n",
            "I0802 20:42:02.620739 139820296341376 learning.py:512] global step 9780: loss = 0.7010 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9781: loss = 0.7504 (0.230 sec/step)\n",
            "I0802 20:42:02.852501 139820296341376 learning.py:512] global step 9781: loss = 0.7504 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9782: loss = 0.9249 (0.243 sec/step)\n",
            "I0802 20:42:03.096784 139820296341376 learning.py:512] global step 9782: loss = 0.9249 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9783: loss = 0.8884 (0.232 sec/step)\n",
            "I0802 20:42:03.330612 139820296341376 learning.py:512] global step 9783: loss = 0.8884 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9784: loss = 0.9676 (0.231 sec/step)\n",
            "I0802 20:42:03.563477 139820296341376 learning.py:512] global step 9784: loss = 0.9676 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9785: loss = 0.8568 (0.244 sec/step)\n",
            "I0802 20:42:03.809688 139820296341376 learning.py:512] global step 9785: loss = 0.8568 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9786: loss = 1.1672 (0.246 sec/step)\n",
            "I0802 20:42:04.056971 139820296341376 learning.py:512] global step 9786: loss = 1.1672 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9787: loss = 0.9232 (0.240 sec/step)\n",
            "I0802 20:42:04.298525 139820296341376 learning.py:512] global step 9787: loss = 0.9232 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9788: loss = 0.7903 (0.240 sec/step)\n",
            "I0802 20:42:04.540495 139820296341376 learning.py:512] global step 9788: loss = 0.7903 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9789: loss = 0.8684 (0.243 sec/step)\n",
            "I0802 20:42:04.785005 139820296341376 learning.py:512] global step 9789: loss = 0.8684 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9790: loss = 1.2069 (0.250 sec/step)\n",
            "I0802 20:42:05.036451 139820296341376 learning.py:512] global step 9790: loss = 1.2069 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9791: loss = 0.7825 (0.249 sec/step)\n",
            "I0802 20:42:05.287121 139820296341376 learning.py:512] global step 9791: loss = 0.7825 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9792: loss = 0.8168 (0.248 sec/step)\n",
            "I0802 20:42:05.537158 139820296341376 learning.py:512] global step 9792: loss = 0.8168 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9793: loss = 0.8283 (0.239 sec/step)\n",
            "I0802 20:42:05.777981 139820296341376 learning.py:512] global step 9793: loss = 0.8283 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9794: loss = 0.9744 (0.238 sec/step)\n",
            "I0802 20:42:06.017038 139820296341376 learning.py:512] global step 9794: loss = 0.9744 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9795: loss = 0.7252 (0.228 sec/step)\n",
            "I0802 20:42:06.246604 139820296341376 learning.py:512] global step 9795: loss = 0.7252 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9796: loss = 0.8306 (0.243 sec/step)\n",
            "I0802 20:42:06.491493 139820296341376 learning.py:512] global step 9796: loss = 0.8306 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9797: loss = 1.0179 (0.248 sec/step)\n",
            "I0802 20:42:06.740765 139820296341376 learning.py:512] global step 9797: loss = 1.0179 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9798: loss = 0.9190 (0.219 sec/step)\n",
            "I0802 20:42:06.961351 139820296341376 learning.py:512] global step 9798: loss = 0.9190 (0.219 sec/step)\n",
            "INFO:tensorflow:global step 9799: loss = 0.9445 (0.235 sec/step)\n",
            "I0802 20:42:07.197765 139820296341376 learning.py:512] global step 9799: loss = 0.9445 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9800: loss = 0.6109 (0.249 sec/step)\n",
            "I0802 20:42:07.448359 139820296341376 learning.py:512] global step 9800: loss = 0.6109 (0.249 sec/step)\n",
            "INFO:tensorflow:global step 9801: loss = 0.7662 (0.236 sec/step)\n",
            "I0802 20:42:07.686326 139820296341376 learning.py:512] global step 9801: loss = 0.7662 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9802: loss = 1.0030 (0.238 sec/step)\n",
            "I0802 20:42:07.925538 139820296341376 learning.py:512] global step 9802: loss = 1.0030 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9803: loss = 0.6604 (0.248 sec/step)\n",
            "I0802 20:42:08.175468 139820296341376 learning.py:512] global step 9803: loss = 0.6604 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9804: loss = 0.7309 (0.243 sec/step)\n",
            "I0802 20:42:08.419956 139820296341376 learning.py:512] global step 9804: loss = 0.7309 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9805: loss = 0.9551 (0.244 sec/step)\n",
            "I0802 20:42:08.665597 139820296341376 learning.py:512] global step 9805: loss = 0.9551 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9806: loss = 0.8975 (0.224 sec/step)\n",
            "I0802 20:42:08.890755 139820296341376 learning.py:512] global step 9806: loss = 0.8975 (0.224 sec/step)\n",
            "INFO:tensorflow:global step 9807: loss = 0.9454 (0.244 sec/step)\n",
            "I0802 20:42:09.136708 139820296341376 learning.py:512] global step 9807: loss = 0.9454 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9808: loss = 0.7385 (0.246 sec/step)\n",
            "I0802 20:42:09.385490 139820296341376 learning.py:512] global step 9808: loss = 0.7385 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9809: loss = 0.9137 (0.237 sec/step)\n",
            "I0802 20:42:09.624152 139820296341376 learning.py:512] global step 9809: loss = 0.9137 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9810: loss = 0.7109 (0.259 sec/step)\n",
            "I0802 20:42:09.884695 139820296341376 learning.py:512] global step 9810: loss = 0.7109 (0.259 sec/step)\n",
            "INFO:tensorflow:global step 9811: loss = 0.7724 (0.240 sec/step)\n",
            "I0802 20:42:10.126431 139820296341376 learning.py:512] global step 9811: loss = 0.7724 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9812: loss = 0.8829 (0.244 sec/step)\n",
            "I0802 20:42:10.372097 139820296341376 learning.py:512] global step 9812: loss = 0.8829 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9813: loss = 1.1430 (0.242 sec/step)\n",
            "I0802 20:42:10.615443 139820296341376 learning.py:512] global step 9813: loss = 1.1430 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9814: loss = 1.2594 (0.238 sec/step)\n",
            "I0802 20:42:10.854903 139820296341376 learning.py:512] global step 9814: loss = 1.2594 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9815: loss = 0.8084 (0.236 sec/step)\n",
            "I0802 20:42:11.092350 139820296341376 learning.py:512] global step 9815: loss = 0.8084 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9816: loss = 0.8041 (0.241 sec/step)\n",
            "I0802 20:42:11.334544 139820296341376 learning.py:512] global step 9816: loss = 0.8041 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9817: loss = 0.7383 (0.246 sec/step)\n",
            "I0802 20:42:11.581815 139820296341376 learning.py:512] global step 9817: loss = 0.7383 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9818: loss = 0.7398 (0.234 sec/step)\n",
            "I0802 20:42:11.817353 139820296341376 learning.py:512] global step 9818: loss = 0.7398 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9819: loss = 0.9461 (0.244 sec/step)\n",
            "I0802 20:42:12.062809 139820296341376 learning.py:512] global step 9819: loss = 0.9461 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9820: loss = 1.2604 (0.244 sec/step)\n",
            "I0802 20:42:12.309452 139820296341376 learning.py:512] global step 9820: loss = 1.2604 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9821: loss = 1.1061 (0.242 sec/step)\n",
            "I0802 20:42:12.552745 139820296341376 learning.py:512] global step 9821: loss = 1.1061 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9822: loss = 0.8064 (0.231 sec/step)\n",
            "I0802 20:42:12.785117 139820296341376 learning.py:512] global step 9822: loss = 0.8064 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9823: loss = 0.9351 (0.236 sec/step)\n",
            "I0802 20:42:13.022898 139820296341376 learning.py:512] global step 9823: loss = 0.9351 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9824: loss = 0.8282 (0.251 sec/step)\n",
            "I0802 20:42:13.275824 139820296341376 learning.py:512] global step 9824: loss = 0.8282 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9825: loss = 0.9471 (0.242 sec/step)\n",
            "I0802 20:42:13.519160 139820296341376 learning.py:512] global step 9825: loss = 0.9471 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9826: loss = 0.7568 (0.234 sec/step)\n",
            "I0802 20:42:13.754557 139820296341376 learning.py:512] global step 9826: loss = 0.7568 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9827: loss = 0.9095 (0.237 sec/step)\n",
            "I0802 20:42:13.993130 139820296341376 learning.py:512] global step 9827: loss = 0.9095 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9828: loss = 0.9227 (0.228 sec/step)\n",
            "I0802 20:42:14.222700 139820296341376 learning.py:512] global step 9828: loss = 0.9227 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9829: loss = 0.8497 (0.246 sec/step)\n",
            "I0802 20:42:14.469821 139820296341376 learning.py:512] global step 9829: loss = 0.8497 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9830: loss = 0.7917 (0.228 sec/step)\n",
            "I0802 20:42:14.699244 139820296341376 learning.py:512] global step 9830: loss = 0.7917 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9831: loss = 1.2252 (0.235 sec/step)\n",
            "I0802 20:42:14.935445 139820296341376 learning.py:512] global step 9831: loss = 1.2252 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9832: loss = 0.9420 (0.226 sec/step)\n",
            "I0802 20:42:15.162392 139820296341376 learning.py:512] global step 9832: loss = 0.9420 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9833: loss = 0.8568 (0.235 sec/step)\n",
            "I0802 20:42:15.399157 139820296341376 learning.py:512] global step 9833: loss = 0.8568 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9834: loss = 1.0351 (0.242 sec/step)\n",
            "I0802 20:42:15.642915 139820296341376 learning.py:512] global step 9834: loss = 1.0351 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9835: loss = 0.8621 (0.236 sec/step)\n",
            "I0802 20:42:15.880439 139820296341376 learning.py:512] global step 9835: loss = 0.8621 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9836: loss = 0.9997 (0.223 sec/step)\n",
            "I0802 20:42:16.105088 139820296341376 learning.py:512] global step 9836: loss = 0.9997 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9837: loss = 0.8617 (0.223 sec/step)\n",
            "I0802 20:42:16.329299 139820296341376 learning.py:512] global step 9837: loss = 0.8617 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9838: loss = 0.5911 (0.235 sec/step)\n",
            "I0802 20:42:16.566266 139820296341376 learning.py:512] global step 9838: loss = 0.5911 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9839: loss = 0.7488 (0.244 sec/step)\n",
            "I0802 20:42:16.812283 139820296341376 learning.py:512] global step 9839: loss = 0.7488 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9840: loss = 0.7856 (0.238 sec/step)\n",
            "I0802 20:42:17.051545 139820296341376 learning.py:512] global step 9840: loss = 0.7856 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9841: loss = 0.6694 (0.252 sec/step)\n",
            "I0802 20:42:17.304833 139820296341376 learning.py:512] global step 9841: loss = 0.6694 (0.252 sec/step)\n",
            "INFO:tensorflow:global step 9842: loss = 0.7573 (0.241 sec/step)\n",
            "I0802 20:42:17.550703 139820296341376 learning.py:512] global step 9842: loss = 0.7573 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9843: loss = 0.6980 (0.233 sec/step)\n",
            "I0802 20:42:17.785043 139820296341376 learning.py:512] global step 9843: loss = 0.6980 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9844: loss = 0.7181 (0.244 sec/step)\n",
            "I0802 20:42:18.030298 139820296341376 learning.py:512] global step 9844: loss = 0.7181 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9845: loss = 0.8723 (0.240 sec/step)\n",
            "I0802 20:42:18.271677 139820296341376 learning.py:512] global step 9845: loss = 0.8723 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9846: loss = 0.8575 (0.247 sec/step)\n",
            "I0802 20:42:18.520001 139820296341376 learning.py:512] global step 9846: loss = 0.8575 (0.247 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path /root/models/trained_2/model.ckpt\n",
            "I0802 20:42:18.724216 139815893612288 supervisor.py:1117] Saving checkpoint to path /root/models/trained_2/model.ckpt\n",
            "INFO:tensorflow:global step 9847: loss = 0.8697 (0.282 sec/step)\n",
            "I0802 20:42:18.807484 139820296341376 learning.py:512] global step 9847: loss = 0.8697 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 9848: loss = 0.7268 (0.407 sec/step)\n",
            "I0802 20:42:19.221453 139820296341376 learning.py:512] global step 9848: loss = 0.7268 (0.407 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 9848.\n",
            "I0802 20:42:19.233628 139815876826880 supervisor.py:1050] Recording summary at step 9848.\n",
            "INFO:tensorflow:global step 9849: loss = 0.8056 (0.282 sec/step)\n",
            "I0802 20:42:19.516194 139820296341376 learning.py:512] global step 9849: loss = 0.8056 (0.282 sec/step)\n",
            "INFO:tensorflow:global step 9850: loss = 0.7010 (0.273 sec/step)\n",
            "I0802 20:42:19.807073 139820296341376 learning.py:512] global step 9850: loss = 0.7010 (0.273 sec/step)\n",
            "INFO:tensorflow:global step 9851: loss = 0.8997 (0.285 sec/step)\n",
            "I0802 20:42:20.105441 139820296341376 learning.py:512] global step 9851: loss = 0.8997 (0.285 sec/step)\n",
            "INFO:tensorflow:global step 9852: loss = 0.8120 (0.542 sec/step)\n",
            "I0802 20:42:20.659803 139820296341376 learning.py:512] global step 9852: loss = 0.8120 (0.542 sec/step)\n",
            "INFO:tensorflow:global step 9853: loss = 0.9825 (0.284 sec/step)\n",
            "I0802 20:42:20.947477 139820296341376 learning.py:512] global step 9853: loss = 0.9825 (0.284 sec/step)\n",
            "INFO:tensorflow:global step 9854: loss = 1.1742 (0.222 sec/step)\n",
            "I0802 20:42:21.171482 139820296341376 learning.py:512] global step 9854: loss = 1.1742 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9855: loss = 0.7404 (0.238 sec/step)\n",
            "I0802 20:42:21.410974 139820296341376 learning.py:512] global step 9855: loss = 0.7404 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9856: loss = 0.8853 (0.229 sec/step)\n",
            "I0802 20:42:21.641519 139820296341376 learning.py:512] global step 9856: loss = 0.8853 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9857: loss = 0.5894 (0.234 sec/step)\n",
            "I0802 20:42:21.877380 139820296341376 learning.py:512] global step 9857: loss = 0.5894 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9858: loss = 0.7551 (0.238 sec/step)\n",
            "I0802 20:42:22.116933 139820296341376 learning.py:512] global step 9858: loss = 0.7551 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9859: loss = 0.6962 (0.225 sec/step)\n",
            "I0802 20:42:22.343524 139820296341376 learning.py:512] global step 9859: loss = 0.6962 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9860: loss = 0.7297 (0.233 sec/step)\n",
            "I0802 20:42:22.577703 139820296341376 learning.py:512] global step 9860: loss = 0.7297 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9861: loss = 0.7481 (0.240 sec/step)\n",
            "I0802 20:42:22.819282 139820296341376 learning.py:512] global step 9861: loss = 0.7481 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9862: loss = 0.8411 (0.236 sec/step)\n",
            "I0802 20:42:23.057135 139820296341376 learning.py:512] global step 9862: loss = 0.8411 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9863: loss = 0.6843 (0.235 sec/step)\n",
            "I0802 20:42:23.293013 139820296341376 learning.py:512] global step 9863: loss = 0.6843 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9864: loss = 0.6278 (0.251 sec/step)\n",
            "I0802 20:42:23.545134 139820296341376 learning.py:512] global step 9864: loss = 0.6278 (0.251 sec/step)\n",
            "INFO:tensorflow:global step 9865: loss = 0.8831 (0.236 sec/step)\n",
            "I0802 20:42:23.783099 139820296341376 learning.py:512] global step 9865: loss = 0.8831 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9866: loss = 0.9929 (0.247 sec/step)\n",
            "I0802 20:42:24.031758 139820296341376 learning.py:512] global step 9866: loss = 0.9929 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9867: loss = 0.8752 (0.244 sec/step)\n",
            "I0802 20:42:24.277394 139820296341376 learning.py:512] global step 9867: loss = 0.8752 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9868: loss = 0.9069 (0.239 sec/step)\n",
            "I0802 20:42:24.518063 139820296341376 learning.py:512] global step 9868: loss = 0.9069 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9869: loss = 0.9923 (0.236 sec/step)\n",
            "I0802 20:42:24.755174 139820296341376 learning.py:512] global step 9869: loss = 0.9923 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9870: loss = 0.7295 (0.240 sec/step)\n",
            "I0802 20:42:24.996494 139820296341376 learning.py:512] global step 9870: loss = 0.7295 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9871: loss = 1.6631 (0.242 sec/step)\n",
            "I0802 20:42:25.239806 139820296341376 learning.py:512] global step 9871: loss = 1.6631 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9872: loss = 0.7513 (0.240 sec/step)\n",
            "I0802 20:42:25.481263 139820296341376 learning.py:512] global step 9872: loss = 0.7513 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9873: loss = 0.8954 (0.231 sec/step)\n",
            "I0802 20:42:25.714400 139820296341376 learning.py:512] global step 9873: loss = 0.8954 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9874: loss = 0.8683 (0.239 sec/step)\n",
            "I0802 20:42:25.954685 139820296341376 learning.py:512] global step 9874: loss = 0.8683 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9875: loss = 0.8644 (0.229 sec/step)\n",
            "I0802 20:42:26.185058 139820296341376 learning.py:512] global step 9875: loss = 0.8644 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9876: loss = 0.8385 (0.231 sec/step)\n",
            "I0802 20:42:26.417963 139820296341376 learning.py:512] global step 9876: loss = 0.8385 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9877: loss = 0.8736 (0.242 sec/step)\n",
            "I0802 20:42:26.661972 139820296341376 learning.py:512] global step 9877: loss = 0.8736 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9878: loss = 0.8155 (0.241 sec/step)\n",
            "I0802 20:42:26.904281 139820296341376 learning.py:512] global step 9878: loss = 0.8155 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9879: loss = 0.8948 (0.238 sec/step)\n",
            "I0802 20:42:27.143466 139820296341376 learning.py:512] global step 9879: loss = 0.8948 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9880: loss = 0.7410 (0.235 sec/step)\n",
            "I0802 20:42:27.380194 139820296341376 learning.py:512] global step 9880: loss = 0.7410 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9881: loss = 0.7734 (0.238 sec/step)\n",
            "I0802 20:42:27.619388 139820296341376 learning.py:512] global step 9881: loss = 0.7734 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9882: loss = 0.8060 (0.248 sec/step)\n",
            "I0802 20:42:27.872207 139820296341376 learning.py:512] global step 9882: loss = 0.8060 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9883: loss = 0.8557 (0.235 sec/step)\n",
            "I0802 20:42:28.108680 139820296341376 learning.py:512] global step 9883: loss = 0.8557 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9884: loss = 0.9859 (0.236 sec/step)\n",
            "I0802 20:42:28.345776 139820296341376 learning.py:512] global step 9884: loss = 0.9859 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9885: loss = 0.8626 (0.245 sec/step)\n",
            "I0802 20:42:28.591909 139820296341376 learning.py:512] global step 9885: loss = 0.8626 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9886: loss = 0.8895 (0.237 sec/step)\n",
            "I0802 20:42:28.830670 139820296341376 learning.py:512] global step 9886: loss = 0.8895 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9887: loss = 0.7678 (0.239 sec/step)\n",
            "I0802 20:42:29.071297 139820296341376 learning.py:512] global step 9887: loss = 0.7678 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9888: loss = 1.1006 (0.229 sec/step)\n",
            "I0802 20:42:29.301715 139820296341376 learning.py:512] global step 9888: loss = 1.1006 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9889: loss = 0.8692 (0.221 sec/step)\n",
            "I0802 20:42:29.523704 139820296341376 learning.py:512] global step 9889: loss = 0.8692 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 9890: loss = 1.0350 (0.243 sec/step)\n",
            "I0802 20:42:29.767831 139820296341376 learning.py:512] global step 9890: loss = 1.0350 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9891: loss = 0.6781 (0.233 sec/step)\n",
            "I0802 20:42:30.002549 139820296341376 learning.py:512] global step 9891: loss = 0.6781 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9892: loss = 0.6874 (0.233 sec/step)\n",
            "I0802 20:42:30.237347 139820296341376 learning.py:512] global step 9892: loss = 0.6874 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9893: loss = 0.9305 (0.237 sec/step)\n",
            "I0802 20:42:30.475635 139820296341376 learning.py:512] global step 9893: loss = 0.9305 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9894: loss = 1.3023 (0.236 sec/step)\n",
            "I0802 20:42:30.713509 139820296341376 learning.py:512] global step 9894: loss = 1.3023 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9895: loss = 0.7692 (0.234 sec/step)\n",
            "I0802 20:42:30.949058 139820296341376 learning.py:512] global step 9895: loss = 0.7692 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9896: loss = 0.8606 (0.234 sec/step)\n",
            "I0802 20:42:31.184529 139820296341376 learning.py:512] global step 9896: loss = 0.8606 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9897: loss = 0.7762 (0.237 sec/step)\n",
            "I0802 20:42:31.423108 139820296341376 learning.py:512] global step 9897: loss = 0.7762 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9898: loss = 0.7967 (0.221 sec/step)\n",
            "I0802 20:42:31.646106 139820296341376 learning.py:512] global step 9898: loss = 0.7967 (0.221 sec/step)\n",
            "INFO:tensorflow:global step 9899: loss = 0.7961 (0.223 sec/step)\n",
            "I0802 20:42:31.870132 139820296341376 learning.py:512] global step 9899: loss = 0.7961 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9900: loss = 0.7919 (0.223 sec/step)\n",
            "I0802 20:42:32.094422 139820296341376 learning.py:512] global step 9900: loss = 0.7919 (0.223 sec/step)\n",
            "INFO:tensorflow:global step 9901: loss = 0.7881 (0.222 sec/step)\n",
            "I0802 20:42:32.317625 139820296341376 learning.py:512] global step 9901: loss = 0.7881 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9902: loss = 0.6121 (0.245 sec/step)\n",
            "I0802 20:42:32.563770 139820296341376 learning.py:512] global step 9902: loss = 0.6121 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9903: loss = 0.9141 (0.241 sec/step)\n",
            "I0802 20:42:32.806710 139820296341376 learning.py:512] global step 9903: loss = 0.9141 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9904: loss = 0.9955 (0.236 sec/step)\n",
            "I0802 20:42:33.044804 139820296341376 learning.py:512] global step 9904: loss = 0.9955 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9905: loss = 1.1202 (0.234 sec/step)\n",
            "I0802 20:42:33.280376 139820296341376 learning.py:512] global step 9905: loss = 1.1202 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9906: loss = 0.8069 (0.234 sec/step)\n",
            "I0802 20:42:33.518858 139820296341376 learning.py:512] global step 9906: loss = 0.8069 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9907: loss = 0.9417 (0.236 sec/step)\n",
            "I0802 20:42:33.755996 139820296341376 learning.py:512] global step 9907: loss = 0.9417 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9908: loss = 0.6639 (0.237 sec/step)\n",
            "I0802 20:42:33.994614 139820296341376 learning.py:512] global step 9908: loss = 0.6639 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9909: loss = 0.9577 (0.237 sec/step)\n",
            "I0802 20:42:34.233423 139820296341376 learning.py:512] global step 9909: loss = 0.9577 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9910: loss = 0.6708 (0.234 sec/step)\n",
            "I0802 20:42:34.469017 139820296341376 learning.py:512] global step 9910: loss = 0.6708 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9911: loss = 1.0610 (0.238 sec/step)\n",
            "I0802 20:42:34.708828 139820296341376 learning.py:512] global step 9911: loss = 1.0610 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9912: loss = 0.7883 (0.236 sec/step)\n",
            "I0802 20:42:34.946016 139820296341376 learning.py:512] global step 9912: loss = 0.7883 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9913: loss = 0.9067 (0.235 sec/step)\n",
            "I0802 20:42:35.182582 139820296341376 learning.py:512] global step 9913: loss = 0.9067 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9914: loss = 1.1762 (0.236 sec/step)\n",
            "I0802 20:42:35.419823 139820296341376 learning.py:512] global step 9914: loss = 1.1762 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9915: loss = 0.9375 (0.233 sec/step)\n",
            "I0802 20:42:35.654970 139820296341376 learning.py:512] global step 9915: loss = 0.9375 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9916: loss = 0.5965 (0.238 sec/step)\n",
            "I0802 20:42:35.894083 139820296341376 learning.py:512] global step 9916: loss = 0.5965 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9917: loss = 0.7774 (0.229 sec/step)\n",
            "I0802 20:42:36.123996 139820296341376 learning.py:512] global step 9917: loss = 0.7774 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9918: loss = 0.7298 (0.233 sec/step)\n",
            "I0802 20:42:36.358174 139820296341376 learning.py:512] global step 9918: loss = 0.7298 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9919: loss = 0.8041 (0.234 sec/step)\n",
            "I0802 20:42:36.593130 139820296341376 learning.py:512] global step 9919: loss = 0.8041 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9920: loss = 0.7244 (0.236 sec/step)\n",
            "I0802 20:42:36.830227 139820296341376 learning.py:512] global step 9920: loss = 0.7244 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9921: loss = 0.7076 (0.231 sec/step)\n",
            "I0802 20:42:37.063024 139820296341376 learning.py:512] global step 9921: loss = 0.7076 (0.231 sec/step)\n",
            "INFO:tensorflow:global step 9922: loss = 0.9545 (0.233 sec/step)\n",
            "I0802 20:42:37.297357 139820296341376 learning.py:512] global step 9922: loss = 0.9545 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9923: loss = 0.9351 (0.227 sec/step)\n",
            "I0802 20:42:37.525603 139820296341376 learning.py:512] global step 9923: loss = 0.9351 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9924: loss = 0.7659 (0.232 sec/step)\n",
            "I0802 20:42:37.758966 139820296341376 learning.py:512] global step 9924: loss = 0.7659 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9925: loss = 0.8542 (0.233 sec/step)\n",
            "I0802 20:42:37.993606 139820296341376 learning.py:512] global step 9925: loss = 0.8542 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9926: loss = 0.7566 (0.237 sec/step)\n",
            "I0802 20:42:38.231666 139820296341376 learning.py:512] global step 9926: loss = 0.7566 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9927: loss = 0.7662 (0.244 sec/step)\n",
            "I0802 20:42:38.477975 139820296341376 learning.py:512] global step 9927: loss = 0.7662 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9928: loss = 1.1179 (0.236 sec/step)\n",
            "I0802 20:42:38.715319 139820296341376 learning.py:512] global step 9928: loss = 1.1179 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9929: loss = 1.0049 (0.246 sec/step)\n",
            "I0802 20:42:38.962670 139820296341376 learning.py:512] global step 9929: loss = 1.0049 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9930: loss = 0.8716 (0.230 sec/step)\n",
            "I0802 20:42:39.194521 139820296341376 learning.py:512] global step 9930: loss = 0.8716 (0.230 sec/step)\n",
            "INFO:tensorflow:global step 9931: loss = 0.8630 (0.242 sec/step)\n",
            "I0802 20:42:39.438488 139820296341376 learning.py:512] global step 9931: loss = 0.8630 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9932: loss = 0.7989 (0.243 sec/step)\n",
            "I0802 20:42:39.682672 139820296341376 learning.py:512] global step 9932: loss = 0.7989 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9933: loss = 0.6805 (0.233 sec/step)\n",
            "I0802 20:42:39.916985 139820296341376 learning.py:512] global step 9933: loss = 0.6805 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9934: loss = 0.7142 (0.232 sec/step)\n",
            "I0802 20:42:40.150866 139820296341376 learning.py:512] global step 9934: loss = 0.7142 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9935: loss = 0.8981 (0.226 sec/step)\n",
            "I0802 20:42:40.378577 139820296341376 learning.py:512] global step 9935: loss = 0.8981 (0.226 sec/step)\n",
            "INFO:tensorflow:global step 9936: loss = 0.8981 (0.242 sec/step)\n",
            "I0802 20:42:40.622507 139820296341376 learning.py:512] global step 9936: loss = 0.8981 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9937: loss = 0.8098 (0.241 sec/step)\n",
            "I0802 20:42:40.864663 139820296341376 learning.py:512] global step 9937: loss = 0.8098 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9938: loss = 0.8348 (0.219 sec/step)\n",
            "I0802 20:42:41.085002 139820296341376 learning.py:512] global step 9938: loss = 0.8348 (0.219 sec/step)\n",
            "INFO:tensorflow:global step 9939: loss = 1.1642 (0.240 sec/step)\n",
            "I0802 20:42:41.326540 139820296341376 learning.py:512] global step 9939: loss = 1.1642 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9940: loss = 0.7656 (0.248 sec/step)\n",
            "I0802 20:42:41.576279 139820296341376 learning.py:512] global step 9940: loss = 0.7656 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9941: loss = 0.9086 (0.237 sec/step)\n",
            "I0802 20:42:41.814631 139820296341376 learning.py:512] global step 9941: loss = 0.9086 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9942: loss = 0.7049 (0.229 sec/step)\n",
            "I0802 20:42:42.044734 139820296341376 learning.py:512] global step 9942: loss = 0.7049 (0.229 sec/step)\n",
            "INFO:tensorflow:global step 9943: loss = 0.7794 (0.225 sec/step)\n",
            "I0802 20:42:42.271886 139820296341376 learning.py:512] global step 9943: loss = 0.7794 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9944: loss = 1.3549 (0.240 sec/step)\n",
            "I0802 20:42:42.513893 139820296341376 learning.py:512] global step 9944: loss = 1.3549 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9945: loss = 0.7874 (0.248 sec/step)\n",
            "I0802 20:42:42.763574 139820296341376 learning.py:512] global step 9945: loss = 0.7874 (0.248 sec/step)\n",
            "INFO:tensorflow:global step 9946: loss = 0.9190 (0.240 sec/step)\n",
            "I0802 20:42:43.004624 139820296341376 learning.py:512] global step 9946: loss = 0.9190 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9947: loss = 0.8220 (0.235 sec/step)\n",
            "I0802 20:42:43.241499 139820296341376 learning.py:512] global step 9947: loss = 0.8220 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9948: loss = 0.8442 (0.245 sec/step)\n",
            "I0802 20:42:43.488244 139820296341376 learning.py:512] global step 9948: loss = 0.8442 (0.245 sec/step)\n",
            "INFO:tensorflow:global step 9949: loss = 0.9632 (0.237 sec/step)\n",
            "I0802 20:42:43.726565 139820296341376 learning.py:512] global step 9949: loss = 0.9632 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9950: loss = 0.8278 (0.237 sec/step)\n",
            "I0802 20:42:43.965198 139820296341376 learning.py:512] global step 9950: loss = 0.8278 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9951: loss = 0.9203 (0.241 sec/step)\n",
            "I0802 20:42:44.207534 139820296341376 learning.py:512] global step 9951: loss = 0.9203 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9952: loss = 0.8048 (0.239 sec/step)\n",
            "I0802 20:42:44.448137 139820296341376 learning.py:512] global step 9952: loss = 0.8048 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9953: loss = 0.7865 (0.237 sec/step)\n",
            "I0802 20:42:44.686783 139820296341376 learning.py:512] global step 9953: loss = 0.7865 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9954: loss = 0.9397 (0.237 sec/step)\n",
            "I0802 20:42:44.925256 139820296341376 learning.py:512] global step 9954: loss = 0.9397 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9955: loss = 0.8440 (0.234 sec/step)\n",
            "I0802 20:42:45.161133 139820296341376 learning.py:512] global step 9955: loss = 0.8440 (0.234 sec/step)\n",
            "INFO:tensorflow:global step 9956: loss = 0.9440 (0.237 sec/step)\n",
            "I0802 20:42:45.400309 139820296341376 learning.py:512] global step 9956: loss = 0.9440 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9957: loss = 1.0084 (0.233 sec/step)\n",
            "I0802 20:42:45.635232 139820296341376 learning.py:512] global step 9957: loss = 1.0084 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9958: loss = 0.9764 (0.225 sec/step)\n",
            "I0802 20:42:45.861468 139820296341376 learning.py:512] global step 9958: loss = 0.9764 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9959: loss = 0.8150 (0.227 sec/step)\n",
            "I0802 20:42:46.090215 139820296341376 learning.py:512] global step 9959: loss = 0.8150 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9960: loss = 0.9665 (0.241 sec/step)\n",
            "I0802 20:42:46.332581 139820296341376 learning.py:512] global step 9960: loss = 0.9665 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9961: loss = 0.8742 (0.243 sec/step)\n",
            "I0802 20:42:46.576852 139820296341376 learning.py:512] global step 9961: loss = 0.8742 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9962: loss = 0.9578 (0.240 sec/step)\n",
            "I0802 20:42:46.821161 139820296341376 learning.py:512] global step 9962: loss = 0.9578 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9963: loss = 0.9145 (0.243 sec/step)\n",
            "I0802 20:42:47.066127 139820296341376 learning.py:512] global step 9963: loss = 0.9145 (0.243 sec/step)\n",
            "INFO:tensorflow:global step 9964: loss = 0.8438 (0.240 sec/step)\n",
            "I0802 20:42:47.307648 139820296341376 learning.py:512] global step 9964: loss = 0.8438 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9965: loss = 0.8693 (0.244 sec/step)\n",
            "I0802 20:42:47.553308 139820296341376 learning.py:512] global step 9965: loss = 0.8693 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9966: loss = 1.2346 (0.239 sec/step)\n",
            "I0802 20:42:47.794353 139820296341376 learning.py:512] global step 9966: loss = 1.2346 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9967: loss = 1.0665 (0.246 sec/step)\n",
            "I0802 20:42:48.041198 139820296341376 learning.py:512] global step 9967: loss = 1.0665 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9968: loss = 0.8316 (0.235 sec/step)\n",
            "I0802 20:42:48.278116 139820296341376 learning.py:512] global step 9968: loss = 0.8316 (0.235 sec/step)\n",
            "INFO:tensorflow:global step 9969: loss = 0.8424 (0.239 sec/step)\n",
            "I0802 20:42:48.518654 139820296341376 learning.py:512] global step 9969: loss = 0.8424 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9970: loss = 1.4784 (0.240 sec/step)\n",
            "I0802 20:42:48.760468 139820296341376 learning.py:512] global step 9970: loss = 1.4784 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9971: loss = 0.8045 (0.232 sec/step)\n",
            "I0802 20:42:48.994180 139820296341376 learning.py:512] global step 9971: loss = 0.8045 (0.232 sec/step)\n",
            "INFO:tensorflow:global step 9972: loss = 0.6844 (0.239 sec/step)\n",
            "I0802 20:42:49.234976 139820296341376 learning.py:512] global step 9972: loss = 0.6844 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9973: loss = 1.2317 (0.242 sec/step)\n",
            "I0802 20:42:49.478942 139820296341376 learning.py:512] global step 9973: loss = 1.2317 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9974: loss = 0.9905 (0.227 sec/step)\n",
            "I0802 20:42:49.707530 139820296341376 learning.py:512] global step 9974: loss = 0.9905 (0.227 sec/step)\n",
            "INFO:tensorflow:global step 9975: loss = 1.2044 (0.233 sec/step)\n",
            "I0802 20:42:49.942423 139820296341376 learning.py:512] global step 9975: loss = 1.2044 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9976: loss = 0.9155 (0.236 sec/step)\n",
            "I0802 20:42:50.180024 139820296341376 learning.py:512] global step 9976: loss = 0.9155 (0.236 sec/step)\n",
            "INFO:tensorflow:global step 9977: loss = 1.0381 (0.240 sec/step)\n",
            "I0802 20:42:50.421101 139820296341376 learning.py:512] global step 9977: loss = 1.0381 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9978: loss = 1.0078 (0.246 sec/step)\n",
            "I0802 20:42:50.668790 139820296341376 learning.py:512] global step 9978: loss = 1.0078 (0.246 sec/step)\n",
            "INFO:tensorflow:global step 9979: loss = 0.8282 (0.241 sec/step)\n",
            "I0802 20:42:50.911624 139820296341376 learning.py:512] global step 9979: loss = 0.8282 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9980: loss = 0.9166 (0.244 sec/step)\n",
            "I0802 20:42:51.156685 139820296341376 learning.py:512] global step 9980: loss = 0.9166 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9981: loss = 0.9331 (0.244 sec/step)\n",
            "I0802 20:42:51.401725 139820296341376 learning.py:512] global step 9981: loss = 0.9331 (0.244 sec/step)\n",
            "INFO:tensorflow:global step 9982: loss = 0.9030 (0.253 sec/step)\n",
            "I0802 20:42:51.656183 139820296341376 learning.py:512] global step 9982: loss = 0.9030 (0.253 sec/step)\n",
            "INFO:tensorflow:global step 9983: loss = 0.8370 (0.233 sec/step)\n",
            "I0802 20:42:51.890753 139820296341376 learning.py:512] global step 9983: loss = 0.8370 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9984: loss = 1.1915 (0.241 sec/step)\n",
            "I0802 20:42:52.133646 139820296341376 learning.py:512] global step 9984: loss = 1.1915 (0.241 sec/step)\n",
            "INFO:tensorflow:global step 9985: loss = 0.8515 (0.247 sec/step)\n",
            "I0802 20:42:52.382054 139820296341376 learning.py:512] global step 9985: loss = 0.8515 (0.247 sec/step)\n",
            "INFO:tensorflow:global step 9986: loss = 0.7767 (0.228 sec/step)\n",
            "I0802 20:42:52.611514 139820296341376 learning.py:512] global step 9986: loss = 0.7767 (0.228 sec/step)\n",
            "INFO:tensorflow:global step 9987: loss = 0.8538 (0.238 sec/step)\n",
            "I0802 20:42:52.850632 139820296341376 learning.py:512] global step 9987: loss = 0.8538 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9988: loss = 0.7223 (0.233 sec/step)\n",
            "I0802 20:42:53.085119 139820296341376 learning.py:512] global step 9988: loss = 0.7223 (0.233 sec/step)\n",
            "INFO:tensorflow:global step 9989: loss = 1.1542 (0.238 sec/step)\n",
            "I0802 20:42:53.324526 139820296341376 learning.py:512] global step 9989: loss = 1.1542 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 9990: loss = 0.9317 (0.242 sec/step)\n",
            "I0802 20:42:53.567692 139820296341376 learning.py:512] global step 9990: loss = 0.9317 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9991: loss = 0.9415 (0.222 sec/step)\n",
            "I0802 20:42:53.791837 139820296341376 learning.py:512] global step 9991: loss = 0.9415 (0.222 sec/step)\n",
            "INFO:tensorflow:global step 9992: loss = 0.7559 (0.239 sec/step)\n",
            "I0802 20:42:54.033006 139820296341376 learning.py:512] global step 9992: loss = 0.7559 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9993: loss = 0.7972 (0.239 sec/step)\n",
            "I0802 20:42:54.273433 139820296341376 learning.py:512] global step 9993: loss = 0.7972 (0.239 sec/step)\n",
            "INFO:tensorflow:global step 9994: loss = 0.8648 (0.225 sec/step)\n",
            "I0802 20:42:54.499771 139820296341376 learning.py:512] global step 9994: loss = 0.8648 (0.225 sec/step)\n",
            "INFO:tensorflow:global step 9995: loss = 0.8411 (0.250 sec/step)\n",
            "I0802 20:42:54.751435 139820296341376 learning.py:512] global step 9995: loss = 0.8411 (0.250 sec/step)\n",
            "INFO:tensorflow:global step 9996: loss = 0.9959 (0.242 sec/step)\n",
            "I0802 20:42:54.995039 139820296341376 learning.py:512] global step 9996: loss = 0.9959 (0.242 sec/step)\n",
            "INFO:tensorflow:global step 9997: loss = 0.9178 (0.237 sec/step)\n",
            "I0802 20:42:55.233224 139820296341376 learning.py:512] global step 9997: loss = 0.9178 (0.237 sec/step)\n",
            "INFO:tensorflow:global step 9998: loss = 0.7399 (0.240 sec/step)\n",
            "I0802 20:42:55.474623 139820296341376 learning.py:512] global step 9998: loss = 0.7399 (0.240 sec/step)\n",
            "INFO:tensorflow:global step 9999: loss = 1.1347 (0.238 sec/step)\n",
            "I0802 20:42:55.714073 139820296341376 learning.py:512] global step 9999: loss = 1.1347 (0.238 sec/step)\n",
            "INFO:tensorflow:global step 10000: loss = 0.9315 (0.222 sec/step)\n",
            "I0802 20:42:55.937371 139820296341376 learning.py:512] global step 10000: loss = 0.9315 (0.222 sec/step)\n",
            "INFO:tensorflow:Stopping Training.\n",
            "I0802 20:42:55.938100 139820296341376 learning.py:769] Stopping Training.\n",
            "INFO:tensorflow:Finished training! Saving model to disk.\n",
            "I0802 20:42:55.938313 139820296341376 learning.py:777] Finished training! Saving model to disk.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0802 20:42:56.963012 139820296341376 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.\n",
            "  warnings.warn(\"Attempting to use a closed FileWriter. \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwpjep1BBUoZ",
        "outputId": "501b604a-e573-4922-81b7-b431384eea8e"
      },
      "source": [
        "#Export trained model \n",
        "%cd /root/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'\n",
        "!python /root/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path=/root/models/ssd_mobilenet_v2_coco.config \\\n",
        "    --output_directory=/root/models/fine_tuned_model_2 \\\n",
        "    --trained_checkpoint_prefix=/root/models/trained_2/model.ckpt-10000"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0802 20:44:00.084608 140231621138304 deprecation.py:323] From /usr/local/lib/python3.7/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 20:44:02.212506 140231621138304 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 20:44:02.253446 140231621138304 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 20:44:02.289835 140231621138304 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 20:44:02.325292 140231621138304 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 20:44:02.362952 140231621138304 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0802 20:44:02.403283 140231621138304 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/core/post_processing.py:601: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0802 20:44:02.661824 140231621138304 deprecation.py:323] From /root/models/research/object_detection/core/post_processing.py:601: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0802 20:44:03.347497 140231621138304 deprecation.py:323] From /root/models/research/object_detection/exporter.py:474: get_or_create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0802 20:44:03.351778 140231621138304 deprecation.py:323] From /root/models/research/object_detection/exporter.py:653: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0802 20:44:03.352410 140231621138304 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "153 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/4.74m params)\n",
            "  BoxPredictor_0 (--/27.70k params)\n",
            "    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n",
            "      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n",
            "    BoxPredictor_0/ClassPredictor (--/20.77k params)\n",
            "      BoxPredictor_0/ClassPredictor/biases (36, 36/36 params)\n",
            "      BoxPredictor_0/ClassPredictor/weights (1x1x576x36, 20.74k/20.74k params)\n",
            "  BoxPredictor_1 (--/122.98k params)\n",
            "    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n",
            "    BoxPredictor_1/ClassPredictor (--/92.23k params)\n",
            "      BoxPredictor_1/ClassPredictor/biases (72, 72/72 params)\n",
            "      BoxPredictor_1/ClassPredictor/weights (1x1x1280x72, 92.16k/92.16k params)\n",
            "  BoxPredictor_2 (--/49.25k params)\n",
            "    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "    BoxPredictor_2/ClassPredictor (--/36.94k params)\n",
            "      BoxPredictor_2/ClassPredictor/biases (72, 72/72 params)\n",
            "      BoxPredictor_2/ClassPredictor/weights (1x1x512x72, 36.86k/36.86k params)\n",
            "  BoxPredictor_3 (--/24.67k params)\n",
            "    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_3/ClassPredictor (--/18.50k params)\n",
            "      BoxPredictor_3/ClassPredictor/biases (72, 72/72 params)\n",
            "      BoxPredictor_3/ClassPredictor/weights (1x1x256x72, 18.43k/18.43k params)\n",
            "  BoxPredictor_4 (--/24.67k params)\n",
            "    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n",
            "    BoxPredictor_4/ClassPredictor (--/18.50k params)\n",
            "      BoxPredictor_4/ClassPredictor/biases (72, 72/72 params)\n",
            "      BoxPredictor_4/ClassPredictor/weights (1x1x256x72, 18.43k/18.43k params)\n",
            "  BoxPredictor_5 (--/12.38k params)\n",
            "    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n",
            "      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n",
            "    BoxPredictor_5/ClassPredictor (--/9.29k params)\n",
            "      BoxPredictor_5/ClassPredictor/biases (72, 72/72 params)\n",
            "      BoxPredictor_5/ClassPredictor/weights (1x1x128x72, 9.22k/9.22k params)\n",
            "  FeatureExtractor (--/4.48m params)\n",
            "    FeatureExtractor/MobilenetV2 (--/4.48m params)\n",
            "      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n",
            "      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n",
            "        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/1.18m params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (3x3x256x512, 1.18m/1.18m params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/294.91k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (3x3x128x256, 294.91k/294.91k params)\n",
            "      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/73.73k params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (3x3x64x128, 73.73k/73.73k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "153 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/13.74k flops)\n",
            "  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n",
            "  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n",
            "  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n",
            "  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n",
            "  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n",
            "  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n",
            "  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n",
            "  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n",
            "  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n",
            "  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n",
            "  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n",
            "  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n",
            "  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n",
            "  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n",
            "  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n",
            "  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n",
            "  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n",
            "  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_10 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_21 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_20 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/mul (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_10 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n",
            "  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "2021-08-02 20:44:05.378393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2021-08-02 20:44:05.386452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:05.387046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-02 20:44:05.387310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-02 20:44:05.388825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-02 20:44:05.390819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-02 20:44:05.391168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-02 20:44:05.392731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-02 20:44:05.394761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-02 20:44:05.398200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-02 20:44:05.398338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:05.398989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:05.399554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-02 20:44:05.399869: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2021-08-02 20:44:05.404557: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000150000 Hz\n",
            "2021-08-02 20:44:05.404804: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d5972f6840 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-08-02 20:44:05.404832: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-08-02 20:44:05.487234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:05.488179: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d5972f7480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2021-08-02 20:44:05.488223: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0\n",
            "2021-08-02 20:44:05.488462: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:05.489088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-02 20:44:05.489168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-02 20:44:05.489191: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-02 20:44:05.489207: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-02 20:44:05.489225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-02 20:44:05.489247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-02 20:44:05.489273: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-02 20:44:05.489288: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-02 20:44:05.489378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:05.489934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:05.490463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-02 20:44:05.490543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-02 20:44:05.491697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-02 20:44:05.491727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-02 20:44:05.491736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-02 20:44:05.491881: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:05.492451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:05.492973: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-08-02 20:44:05.493019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12672 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "INFO:tensorflow:Restoring parameters from /root/models/trained_2/model.ckpt-10000\n",
            "I0802 20:44:05.494915 140231621138304 saver.py:1284] Restoring parameters from /root/models/trained_2/model.ckpt-10000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0802 20:44:07.154593 140231621138304 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2021-08-02 20:44:07.718292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:07.718965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-02 20:44:07.719065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-02 20:44:07.719089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-02 20:44:07.719108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-02 20:44:07.719139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-02 20:44:07.719155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-02 20:44:07.719172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-02 20:44:07.719190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-02 20:44:07.719275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:07.719842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:07.720347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-02 20:44:07.720384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-02 20:44:07.720409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-02 20:44:07.720416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-02 20:44:07.720504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:07.721051: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:07.721573: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12672 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "INFO:tensorflow:Restoring parameters from /root/models/trained_2/model.ckpt-10000\n",
            "I0802 20:44:07.722888 140231621138304 saver.py:1284] Restoring parameters from /root/models/trained_2/model.ckpt-10000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0802 20:44:08.412795 140231621138304 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0802 20:44:08.413047 140231621138304 deprecation.py:323] From /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 324 variables.\n",
            "I0802 20:44:08.804788 140231621138304 graph_util_impl.py:334] Froze 324 variables.\n",
            "INFO:tensorflow:Converted 324 variables to const ops.\n",
            "I0802 20:44:08.882591 140231621138304 graph_util_impl.py:394] Converted 324 variables to const ops.\n",
            "2021-08-02 20:44:09.021121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:09.021776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\n",
            "pciBusID: 0000:00:04.0\n",
            "2021-08-02 20:44:09.021850: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2021-08-02 20:44:09.021872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2021-08-02 20:44:09.021887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-02 20:44:09.021904: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-02 20:44:09.021935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-08-02 20:44:09.021958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2021-08-02 20:44:09.021979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2021-08-02 20:44:09.022057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:09.022614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:09.023086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2021-08-02 20:44:09.023121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-02 20:44:09.023132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2021-08-02 20:44:09.023139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2021-08-02 20:44:09.023219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:09.023744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-02 20:44:09.024311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12672 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0)\n",
            "WARNING:tensorflow:From /root/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0802 20:44:09.636746 140231621138304 deprecation.py:323] From /root/models/research/object_detection/exporter.py:384: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0802 20:44:09.637464 140231621138304 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0802 20:44:09.637596 140231621138304 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /root/models/fine_tuned_model_2/saved_model/saved_model.pb\n",
            "I0802 20:44:09.944620 140231621138304 builder_impl.py:425] SavedModel written to: /root/models/fine_tuned_model_2/saved_model/saved_model.pb\n",
            "INFO:tensorflow:Writing pipeline config file to /root/models/fine_tuned_model_2/pipeline.config\n",
            "I0802 20:44:09.968983 140231621138304 config_util.py:254] Writing pipeline config file to /root/models/fine_tuned_model_2/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXt13_XIGrlE"
      },
      "source": [
        "test = pd.read_csv('/root/models/odometer/data/test_labels.csv')"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE3G4RC-G59P"
      },
      "source": [
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = '/root/models/character/data/object-detection.pbtxt'\n",
        "\n",
        "NUM_CLASSES = 11"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8NHTow3G94a"
      },
      "source": [
        "## PATH to recently trained model\n",
        "PATH_TO_CKPT = '/root/models/fine_tuned_model_2' + '/frozen_inference_graph.pb'\n",
        "## Path to fully trained model (Will give better results)\n",
        "PATH_TO_CKPT = '/root/models/character/fine_tuned' + '/frozen_inference_graph_v2_180.pb'\n",
        "detection_graph_v2  =tf.Graph()\n",
        "with detection_graph_v2.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRHDS6jyHJF2"
      },
      "source": [
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw7hmxLeHL6s"
      },
      "source": [
        "path = '/root/models/test_cropped'\n",
        "os.mkdir(path)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQKp9GgMHUp_"
      },
      "source": [
        "#make cropped test images\n",
        "import pandas as pd\n",
        "test_cropped = pd.read_csv('/root/models/research/odometer_small.csv')"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "jPP3zPofHgUw",
        "outputId": "8185eb52-f71c-4394-fea2-8bd1c733363d"
      },
      "source": [
        "!cd /root/models/Odometer_project/small_data/small_odometer_dataset_bicubic_result_sharpen\n",
        "for i in range(len(test_cropped)):\n",
        "  name = '/root/models/Odometer_project/small_data/small_odometer_dataset_bicubic_result_sharpen/result_' +  test_cropped['filename'][i][30:]\n",
        "  test_cropped['filename'][i] = test_cropped['filename'][i][30:]\n",
        "  im = Image.open(name)\n",
        "  w, h = im.size\n",
        "  top = round((test_cropped['box1_xmin'][i]-1)   *( h /100 )) \n",
        "  if top < 0:\n",
        "    top = 0\n",
        "  left = round((test_cropped['box1_ymin'][i] -1)   * (w / 100))\n",
        "  if left< 0 :\n",
        "    left = 0\n",
        "  bottom = round((test_cropped['box1_ymax'][i]+1)  *( h /100 )) \n",
        "  if bottom > h:\n",
        "    bottom = h \n",
        "  right = round((test_cropped['box1_xmax'][i]+1)   *( w /100 ))\n",
        "  if right > w:\n",
        "    right = w\n",
        "\n",
        "  print(left,right, top, bottom)\n",
        "  im1 = im.crop((left, top, right, bottom))\n",
        "  url_result = test_cropped['filename'][i]\n",
        "  im1.save(\"/root/models/test_cropped/\" + url_result, 'JPEG')\n",
        "  plt.imshow(im1)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "248 425 242 304\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoECukrtQJk8",
        "outputId": "872e9af7-7903-4bbc-e0b9-bcbcf866debe"
      },
      "source": [
        "# To test the code with your image add the path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = '/root/models/test_cropped'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, file_names[i]) for i in range(len(test)) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n",
        "print(TEST_IMAGE_PATHS)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/root/models/test_cropped/odo_3.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fk7RbruRyMR"
      },
      "source": [
        "true= pd.read_csv('/root/models/Odometer_project/small_data/True_mileage_small.csv')"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "H4ipYAqqQVPk",
        "outputId": "b92d2b69-994f-46db-8400-5e8064ad68d0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import networkx as nx\n",
        "import statistics\n",
        "columns = ['filename','mileage']\n",
        "N = range(len(file_names))\n",
        "df_ = pd.DataFrame(index=N,  columns=columns)\n",
        "df_ = df_.fillna(0) # with 0s rather than NaNs\n",
        "file_name = df_['filename']\n",
        "mileage = df_['mileage']\n",
        "count_v2 = 0;\n",
        "count_v2_1000 = 0;\n",
        "def listToString(s): \n",
        "    \n",
        "    # initialize an empty string\n",
        "    str1 = \"\" \n",
        "    \n",
        "    # traverse in the string  \n",
        "    for ele in s: \n",
        "        str1 += str(ele)  \n",
        "    \n",
        "    # return string  \n",
        "    return str1 \n",
        "thresh = [  .2]\n",
        "for l in range(len(thresh)):\n",
        "  count = 0;\n",
        "  for image_path in TEST_IMAGE_PATHS:\n",
        "    im_ind = int(image_path[30:-4]) -1\n",
        "    if(true['mileage'][im_ind] != ''):\n",
        "      Mileage = math.floor(float((true['mileage'][im_ind])))\n",
        "    else:\n",
        "      Mileage = 0\n",
        "    file_name[count] = image_path[26:]\n",
        "    image = Image.open(image_path)\n",
        "    # the array based representation of the image will be used later in order to prepare the\n",
        "    # result image with boxes and labels on it.\n",
        "    image_np = load_image_into_numpy_array(image)\n",
        "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    # Actual detection.\n",
        "    #output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "    #boxs = output_dict['detection_boxes']\n",
        "    #score = output_dict['detection_scores']\n",
        "    #classification = output_dict['detection_classes']\n",
        "    #print(classification)\n",
        "    # Detection V2 \n",
        "    output_dict_v2 = run_inference_for_single_image(image_np, detection_graph_v2)\n",
        "    boxs_v2 = output_dict_v2['detection_boxes']\n",
        "    score_v2 = output_dict_v2['detection_scores']\n",
        "    classification_v2 = output_dict_v2['detection_classes']\n",
        "    #vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    #    image_np,\n",
        "    #    boxs_v2,\n",
        "    #    classification_v2,\n",
        "    #    score_v2,\n",
        "    #    category_index,\n",
        "    #    instance_masks=output_dict_v2.get('detection_masks'),\n",
        "    #    use_normalized_coordinates=True,\n",
        "    #    line_thickness=4, mask_alpha = .1, min_score_thresh = .05, max_boxes_to_draw = 25)\n",
        "    #plt.figure(figsize=IMAGE_SIZE)\n",
        "    #plt.imshow(image_np)\n",
        "    #remove characters V1 \n",
        "    #ind = []\n",
        "    #for i in range(output_dict['num_detections']):\n",
        "    #  if classification[i] == 11:\n",
        "    #    ind.append(i)\n",
        "    #classification = np.delete(classification, ind, axis=0)\n",
        "    #score = np.delete(score, ind, axis=0)\n",
        "    #boxs = np.delete(boxs,ind,axis=0)\n",
        "    #remove characters V2\n",
        "    ind = []\n",
        "    for i in range(output_dict_v2['num_detections']):\n",
        "      if classification_v2[i] == 11:\n",
        "        ind.append(i)\n",
        "    classification_v2 = np.delete(classification_v2, ind, axis=0)\n",
        "    score_v2 = np.delete(score_v2, ind, axis=0)\n",
        "    boxs_v2 = np.delete(boxs_v2,ind,axis=0)\n",
        "    # remove digits under a certain threshold V1\n",
        "    #threshold = .01;\n",
        "   # ind = []\n",
        "   # for i in range(len(classification)):\n",
        "    #  if(score[i] < threshold):\n",
        "    #    ind.append(i)\n",
        "    #classification = np.delete(classification, ind, axis=0)\n",
        "    #score = np.delete(score, ind, axis=0)\n",
        "    #boxs = np.delete(boxs,ind,axis=0)\n",
        "\n",
        "    # remove digits under a certain threshold V2\n",
        "    threshold = thresh[l];\n",
        "    ind = []\n",
        "    for i in range(len(classification_v2)):\n",
        "      if(score_v2[i]) < threshold:\n",
        "        ind.append(i)\n",
        "    classification_v2 = np.delete(classification_v2, ind, axis=0)\n",
        "    score_v2 = np.delete(score_v2, ind, axis=0)\n",
        "    boxs_v2 = np.delete(boxs_v2,ind,axis=0)\n",
        "\n",
        "    # V2 remove boxes in the same area \n",
        "    ind = []\n",
        "    for i in range(len(boxs_v2)):\n",
        "      for j in range(len(boxs_v2)):\n",
        "        if (boxs_v2[i][1]> boxs_v2[j][1] and  boxs_v2[i][3] < boxs_v2[j][3]) or abs((boxs_v2[i][1] - boxs_v2[j][1])) < .01 :\n",
        "          if i != j:\n",
        "            if (i>j):\n",
        "              ind.append(i)\n",
        "            else:\n",
        "              ind.append(j)\n",
        "    classification_v2 = np.delete(classification_v2, ind, axis=0)\n",
        "    score_v2 = np.delete(score_v2, ind, axis=0)\n",
        "    boxs_v2 = np.delete(boxs_v2,ind,axis=0)\n",
        "  ## V1 remove boxes in the same area \n",
        "    #ind = []\n",
        "    #for i in range(len(boxs)):\n",
        "     # for j in range(len(boxs)):\n",
        "     #   if (boxs[i][1]> boxs[j][1] and  boxs[i][3] < boxs[j][3]) or abs((boxs[i][1] - boxs[j][1])) < .01 :\n",
        "     #     if i != j:\n",
        "     #       if (i>j):\n",
        "     #         ind.append(i)\n",
        "     #       else:\n",
        "     #         ind.append(j)\n",
        "    #classification = np.delete(classification, ind, axis=0)\n",
        "    #score = np.delete(score, ind, axis=0)\n",
        "    #boxs = np.delete(boxs,ind,axis=0)\n",
        "\n",
        "\n",
        "    #Extend V2\n",
        "    for i in range(len(boxs_v2)):\n",
        "      width = boxs_v2[i][3] - boxs_v2[i][1]\n",
        "      height = boxs_v2[i][3] - boxs_v2[i][1]\n",
        "      if(classification_v2[i] == 2):\n",
        "        width_add = width\n",
        "      else:\n",
        "        width_add = width / 3\n",
        "      boxs_v2[i][3] =boxs_v2[i][3] +width_add\n",
        "      boxs_v2[i][1] =boxs_v2[i][1]  - width_add\n",
        "\n",
        "    #Extend V1\n",
        "    #for i in range(len(boxs)):\n",
        "     # width = boxs[i][3] - boxs[i][1]\n",
        "     # height = boxs[i][3] - boxs[i][1]\n",
        "      #if(classification[i] == 2):\n",
        "      #  width_add = height / 2.5\n",
        "     # else:\n",
        "     #   width_add = width / 2.5\n",
        "     # boxs[i][3] =boxs[i][3] +width_add\n",
        "     # boxs[i][1] =boxs[i][1]  - width_add\n",
        "\n",
        "\n",
        "    # remove tall / long  boxes V2 \n",
        "    med_width = []\n",
        "    med_height = []\n",
        "    for i in range(len(boxs_v2)):\n",
        "      med_width.append(abs(boxs_v2[i][3]-boxs_v2[i][1]))\n",
        "      med_height.append(abs(boxs_v2[i][2]-boxs_v2[i][0]))\n",
        "    if(len(boxs_v2) > 0):\n",
        "      med_width = statistics.median(med_width)\n",
        "      med_height = statistics.median(med_height)\n",
        "    ind = [] \n",
        "    for i in range(len(boxs_v2)):\n",
        "      if(abs(abs(boxs_v2[i][3]-boxs_v2[i][1]) - med_width) > .15):\n",
        "        ind.append(i)\n",
        "      elif (abs(abs(boxs_v2[i][2]-boxs_v2[i][0]) - med_height) > .15):\n",
        "        ind.append(i)\n",
        "    classification_v2 = np.delete(classification_v2, ind, axis=0)\n",
        "    score_v2 = np.delete(score_v2, ind, axis=0)\n",
        "    boxs_v2 = np.delete(boxs_v2,ind,axis=0)\n",
        "\n",
        "\n",
        "    # remove tall / long  boxes V1\n",
        "    #med_width = []\n",
        "    #med_height = []\n",
        "    #for i in range(len(boxs)):\n",
        "    #  med_width.append(abs(boxs[i][3]-boxs[i][1]))\n",
        "    #  med_height.append(abs(boxs[i][2]-boxs[i][0]))\n",
        "    #if(len(boxs) > 0):\n",
        "    #  med_width = statistics.median(med_width)\n",
        "    #  med_height = statistics.median(med_height)\n",
        "    #ind = [] \n",
        "   # for i in range(len(boxs)):\n",
        "   #   if(abs(abs(boxs[i][3]-boxs[i][1]) - med_width) > .15):\n",
        "    #    ind.append(i)\n",
        "    #  elif (abs(abs(boxs[i][2]-boxs[i][0]) - med_height) > .15):\n",
        "    #    ind.append(i)\n",
        "    #classification = np.delete(classification, ind, axis=0)\n",
        "    #score = np.delete(score, ind, axis=0)\n",
        "    #boxs = np.delete(boxs,ind,axis=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    dic = {}\n",
        "    #############################################################################################\n",
        "    # check to see if they are close in width and height  ( NEEDS TO BE CHANGED BASED ON MODEL) #\n",
        "    ############################################################################################# \n",
        "    for i in range(len(boxs_v2)):\n",
        "      width = boxs_v2[i][3] - boxs_v2[i][1]\n",
        "      for j in range(len(boxs_v2)):\n",
        "        dif_width = boxs_v2[i][3] - boxs_v2[j][1]\n",
        "        dif_height = boxs_v2[i][0] - boxs_v2[j][0]\n",
        "        if (i !=j) and dif_width > 0 and dif_height < .1 and abs(dif_width) < .15 :\n",
        "          if not(j in dic and dic[j] == i):\n",
        "            dic[i] = j\n",
        "    G = nx.DiGraph()\n",
        "    G.add_edges_from(dic.items())\n",
        "    try:\n",
        "      path = nx.dag_longest_path(G)\n",
        "    except nx.exception.NetworkXUnfeasible: # There's a loop!\n",
        "      print(\"The graph has a cycle\")\n",
        "      path = []\n",
        "    final = []\n",
        "    for i in range(len(path)):\n",
        "      final.append(classification_v2[path[i]] -1)\n",
        "    if len(final) == 0:\n",
        "      final_int = 0\n",
        "      print('empty')\n",
        "    else:\n",
        "      final_string = listToString(final)\n",
        "      final_int = int(final_string)\n",
        "      if(len(final_string) >6 or final_int > 3000000 ):\n",
        "        final_int = int(str(final_int)[:-1])\n",
        "     # print(final_int)\n",
        "    print('Number from model :', + final_int)\n",
        "    mileage[count] = final_int;\n",
        "    if Mileage == final_int:\n",
        "      count_v2 = count_v2 + 1 \n",
        "    if(abs(Mileage - final_int) < 1000):\n",
        "      count_v2_1000 = count_v2_1000 + 1\n",
        "    # Visualization of the results of a detection.\n",
        "    count = count + 1;\n",
        "    #vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    #    image_np,\n",
        "    #    output_dict['detection_boxes'],\n",
        "    #   output_dict['detection_classes'],\n",
        "    #   output_dict['detection_scores'],\n",
        "    #   category_index,\n",
        "    #   instance_masks=output_dict.get('detection_masks'),\n",
        "    #    use_normalized_coordinates=True,\n",
        "    #    line_thickness=1, mask_alpha = .1, min_score_thresh = .05, max_boxes_to_draw = 25)\n",
        "    #plt.figure(figsize=IMAGE_SIZE)\n",
        "    # Visualization of the results of v2 detection\n",
        "    #plt.imshow(image_np)\n",
        "\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        boxs_v2,\n",
        "        classification_v2,\n",
        "        score_v2,\n",
        "        category_index,\n",
        "        instance_masks=output_dict_v2.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=1, mask_alpha = .1, min_score_thresh = .01, max_boxes_to_draw = 25)\n",
        "    plt.figure(figsize=IMAGE_SIZE)\n",
        "    plt.imshow(image_np)\n",
        "print('Accuracy:', + count_v2/len(TEST_IMAGE_PATHS))\n",
        "print('Accuracy with 1k:' , + count_v2_1000 / len(TEST_IMAGE_PATHS))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number from model : 203415\n",
            "Accuracy: 1.0\n",
            "Accuracy with 1k: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:225: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}