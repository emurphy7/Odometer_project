{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Test Digit_Detection_Using_V1",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DirnTh9B4NEP"
      },
      "source": [
        "Installing tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iJiy4kJBJMe",
        "outputId": "2b1d34b0-bb15-44f4-e7d6-5b7e2ed54a54"
      },
      "source": [
        "%tensorflow_version 1.x # Select module of the tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.x # Select module of the tensorflow`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bp3LZ7CMDo6B",
        "outputId": "92261217-f7a2-47f4-e778-e00a655eb373"
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-29 19:56:40--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 35.175.167.123, 54.82.179.106, 3.231.73.243, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|35.175.167.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13832437 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.19M  6.46MB/s    in 2.0s    \n",
            "\n",
            "2021-07-29 19:56:43 (6.46 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13832437/13832437]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g83aRU0cDp3b",
        "outputId": "434d830a-8b8f-4332-fbf7-fc96f9155d2a"
      },
      "source": [
        "#the logs that are created while training \n",
        "LOG_DIR = \"/root/models/trained\"\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "#The link to tensorboard.\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "IndexError: list index out of range\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvVBzPmLxiou",
        "outputId": "0b423095-8c40-4e5e-ea86-c8df51dc1ad2"
      },
      "source": [
        "!python -c 'import matplotlib as tf; print(tf.__version__)' # Check the version of the tensorflow\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Uv5oo05_w_f",
        "outputId": "2aaafb1e-7bb6-4a0f-c55a-0296d6016a49"
      },
      "source": [
        "%cd "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5HQjw8n4bA6"
      },
      "source": [
        "Cloning Object Detection Models from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUGwDKR62WpS",
        "outputId": "7738e11e-a518-4459-bf9d-6455d58283df"
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git # Import required files from the website\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 59469, done.\u001b[K\n",
            "remote: Counting objects: 100% (948/948), done.\u001b[K\n",
            "remote: Compressing objects: 100% (351/351), done.\u001b[K\n",
            "remote: Total 59469 (delta 634), reused 868 (delta 579), pack-reused 58521\u001b[K\n",
            "Receiving objects: 100% (59469/59469), 573.70 MiB | 25.35 MiB/s, done.\n",
            "Resolving deltas: 100% (41261/41261), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DiK5vm_4o1b"
      },
      "source": [
        "Testing a File in Cloned Object Detection File "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6i7fbZ8XzuoC",
        "outputId": "bb493381-d850-4fb6-9e47-7497535b8eb3"
      },
      "source": [
        "%cd /root/models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "!python setup.py build"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n",
            "python3: can't open file 'setup.py': [Errno 2] No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJtmMRYr8iPr"
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/root/models/research/:/root/models/research/slim/:/root/models/research/object_detection/utils/:/root/models/research/object_detection'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thMo1S6qAp1d",
        "outputId": "83e57df2-b253-4881-bce2-4c6732a5d52a"
      },
      "source": [
        "!pip install tf_slim"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 39.9 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 352 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNNJ917V_hoe"
      },
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5YwT9Lf3mly",
        "outputId": "f2a1bdcd-f5b0-4412-eab7-988a607a873c"
      },
      "source": [
        "#!python3 --version\n",
        "\n",
        "!python -c 'import tensorflow as tf; print(tf.__version__)'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJKl7DzPyiSG",
        "outputId": "1e0b52ce-6bcc-46d2-e6b5-2329bd775ecc"
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.15.2\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /tensorflow-1.15.2/python3.7\n",
            "Requires: opt-einsum, astor, protobuf, wheel, keras-preprocessing, tensorboard, absl-py, google-pasta, termcolor, wrapt, gast, grpcio, numpy, tensorflow-estimator, six, keras-applications\n",
            "Required-by: stable-baselines, magenta, kapre\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVUIxcOP5R9o"
      },
      "source": [
        "Import from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KI_9ceNWVYro",
        "outputId": "6d650548-5262-442d-c1af-7821d3f222b3"
      },
      "source": [
        "%cd /root/models/\n",
        "!git clone https://github.com/emurphy7/Odometer_project "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models\n",
            "Cloning into 'Odometer_project'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 45 (delta 14), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (45/45), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ePj_eojrMTo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "21f80c61-04b8-4ba7-e842-3104a142e18d"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import urllib\n",
        "import tarfile\n",
        "from requests import get\n",
        "source = '/root/models/Odometer_project/character'\n",
        "destination = '/root/models/'\n",
        "shutil.move('/root/models/Odometer_project/character',  '/root/models/') \n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/models/character'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "r_iGctBBtMF2",
        "outputId": "d7c72953-1272-4d0c-f3aa-0e04d86a70f9"
      },
      "source": [
        "shutil.move('/root/models/character/fine_tuned',  '/root/models/') "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/models/fine_tuned'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxdLTEzBr575"
      },
      "source": [
        "Add csv files      \n",
        "Data Folder : test_labels.csv       \n",
        "Data Folder : odometer_long.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82ZMxxofDtax"
      },
      "source": [
        "Change name of folder and add files from Desktop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuZwmzDaO1yR",
        "outputId": "f9391021-ad62-4b77-9653-1005eb676abc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brpJ5fii5aMj"
      },
      "source": [
        "Converting XML Files to CSV Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qpYUFw1cYoUP",
        "outputId": "99c58ba0-5843-4284-b6ab-652723788a43"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/models'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2V4ANIWHCy4"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "test = pd.read_csv('/root/models/character/data/test_labels.csv')\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFXjiGuX57R-"
      },
      "source": [
        "Downloading Pre-trained Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0D6p_3cg_Ex",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d294f16d-9ddc-41be-d017-1ff82475c72e"
      },
      "source": [
        "%cd ~/models\n",
        "\n",
        "\n",
        "\n",
        "MODEL = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "DEST_DIR = 'pretrained_model'\n",
        "\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "  with open(MODEL_FILE, \"wb\") as file:\n",
        "    # get request\n",
        "    response = get(DOWNLOAD_BASE + MODEL_FILE)\n",
        "    # write to file\n",
        "    file.write(response.content)\n",
        "\n",
        "\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(DEST_DIR)):\n",
        "  shutil.rmtree(DEST_DIR)\n",
        "os.rename(MODEL, DEST_DIR)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZA8XMKc8pCv"
      },
      "source": [
        "Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQknj0c3TtJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0caa758-3e41-451b-9256-ede9282ecae9"
      },
      "source": [
        "%cd /root/models/research/\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "# This is needed to display the images.\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L_sQ3JZdKen"
      },
      "source": [
        "# What model to download.\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = '/root/models/fine_tuned' + '/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = '/root/models/character/data/object-detection.pbtxt'\n",
        "\n",
        "NUM_CLASSES = 11\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cJ8FuN8U4r4"
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBK7-x8W2XlY"
      },
      "source": [
        "# \n",
        "PATH_TO_CKPT = '/root/models/fine_tuned' + '/frozen_inference_graph_v2_300.pb'\n",
        "detection_graph_v2  =tf.Graph()\n",
        "with detection_graph_v2.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqEm90PKVe9t"
      },
      "source": [
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWE6RVQ1WamB"
      },
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yijap_io46b_"
      },
      "source": [
        "Commented out section to be run when cropping based off of a new odometer model output \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oh1Kt8hQvT06"
      },
      "source": [
        "path = '/root/models/character/images'\n",
        "os.mkdir(path)\n",
        "path = '/root/models/character/images/test'\n",
        "os.mkdir(path)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXf8NU6O58oo"
      },
      "source": [
        "path = '/root/models/test_cropped'\n",
        "os.mkdir(path)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "421nx0WCNS2L"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/ODOMETER_FILTERED_bicubic_result_sharpen/ /root/models/character/images/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB31LA0EQVh9"
      },
      "source": [
        "#make cropped test images\n",
        "import pandas as pd\n",
        "test_cropped = pd.read_csv('/root/models/character/data/odometer_long_v2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPAdY8LGQdUp"
      },
      "source": [
        "!cd /content/models/character/images/test/ODOMETER_FILTERED_bicubic_result_sharpen\n",
        "for i in range(len(test_cropped)):\n",
        "  name = '/root/models/character/images/test/ODOMETER_FILTERED_bicubic_result_sharpen/result_' +  test_cropped['filename'][i]\n",
        "  im = Image.open(name)\n",
        "  w, h = im.size\n",
        "  top = round((test_cropped['box1_xmin'][i]-2)   *( h /100 )) \n",
        "  if top < 0:\n",
        "    top = 0\n",
        "  left = round((test_cropped['box1_ymin'][i] -2)   * (w / 100))\n",
        "  if left< 0 :\n",
        "    left = 0\n",
        "  bottom = round((test_cropped['box1_ymax'][i]+2)  *( h /100 )) \n",
        "  if bottom > h:\n",
        "    bottom = h \n",
        "  right = round((test_cropped['box1_xmax'][i]+2)   *( w /100 ))\n",
        "  if right > w:\n",
        "    right = w\n",
        "\n",
        " # print(left,right, top, bottom)\n",
        "  im1 = im.crop((left, top, right, bottom))\n",
        "  url_result = test_cropped['filename'][i]\n",
        "  im1.save(\"/root/models/test_cropped/\" + url_result, 'JPEG')\n",
        "  plt.imshow(im1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKUp0PBhKR7e"
      },
      "source": [
        "!cp -r  /root/models/test_cropped /content/drive/MyDrive/crop_test_final_sharp_v2"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElGbOGOQHaTI"
      },
      "source": [
        "#!cp -r /content/drive/MyDrive/crop_test_final_sharp /root/models/test_cropped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftJ9g8FOOtZY"
      },
      "source": [
        "cd /root/models/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_flVTmbIkRTZ"
      },
      "source": [
        "#!cp -r /root/models/test_cropped /content/drive/MyDrive/crop_test_final_sharp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sswn4gUEWcux"
      },
      "source": [
        "file_names = test_cropped['filename']\n",
        "# To test the code with your image add the path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = '/root/models/test_cropped'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, file_names[i]) for i in range(len(test_cropped)) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (12, 8)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28qSav2rWmsG"
      },
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.1), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.uint8)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzhjfGwtWqY0"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import networkx as nx\n",
        "import statistics\n",
        "columns = ['filename','mileage']\n",
        "N = range(len(file_names))\n",
        "df_ = pd.DataFrame(index=N,  columns=columns)\n",
        "df_ = df_.fillna(0) # with 0s rather than NaNs\n",
        "file_name = df_['filename']\n",
        "mileage = df_['mileage']\n",
        "\n",
        "\n",
        "def listToString(s): \n",
        "    \n",
        "    # initialize an empty string\n",
        "    str1 = \"\" \n",
        "    \n",
        "    # traverse in the string  \n",
        "    for ele in s: \n",
        "        str1 += str(ele)  \n",
        "    \n",
        "    # return string  \n",
        "    return str1 \n",
        "count = 0;\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  file_name[count] = image_path[26:]\n",
        "  image = Image.open(image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
        "  boxs = output_dict['detection_boxes']\n",
        "  score = output_dict['detection_scores']\n",
        "  classification = output_dict['detection_classes']\n",
        "  #print(classification)\n",
        "  # Detection V2 \n",
        "  output_dict_v2 = run_inference_for_single_image(image_np, detection_graph_v2)\n",
        "  boxs_v2 = output_dict_v2['detection_boxes']\n",
        "  score_v2 = output_dict_v2['detection_scores']\n",
        "  classification_v2 = output_dict_v2['detection_classes']\n",
        "  #vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "  #    image_np,\n",
        "  #    boxs_v2,\n",
        "  #    classification_v2,\n",
        "  #    score_v2,\n",
        "  #    category_index,\n",
        "  #    instance_masks=output_dict_v2.get('detection_masks'),\n",
        "  #    use_normalized_coordinates=True,\n",
        "  #    line_thickness=4, mask_alpha = .1, min_score_thresh = .05, max_boxes_to_draw = 25)\n",
        "  #plt.figure(figsize=IMAGE_SIZE)\n",
        "  #plt.imshow(image_np)\n",
        "  #remove characters V1 \n",
        "  ind = []\n",
        "  for i in range(output_dict['num_detections']):\n",
        "    if classification[i] == 11:\n",
        "      ind.append(i)\n",
        "  classification = np.delete(classification, ind, axis=0)\n",
        "  score = np.delete(score, ind, axis=0)\n",
        "  boxs = np.delete(boxs,ind,axis=0)\n",
        "  #remove characters V2\n",
        "  ind = []\n",
        "  for i in range(output_dict_v2['num_detections']):\n",
        "    if classification_v2[i] == 11:\n",
        "      ind.append(i)\n",
        "  classification_v2 = np.delete(classification_v2, ind, axis=0)\n",
        "  score_v2 = np.delete(score_v2, ind, axis=0)\n",
        "  boxs_v2 = np.delete(boxs_v2,ind,axis=0)\n",
        "  # remove digits under a certain threshold V1\n",
        "  threshold = .01;\n",
        "  ind = []\n",
        "  for i in range(len(classification)):\n",
        "   if(score[i]) < threshold:\n",
        "      ind.append(i)\n",
        "  classification = np.delete(classification, ind, axis=0)\n",
        "  score = np.delete(score, ind, axis=0)\n",
        "  boxs = np.delete(boxs,ind,axis=0)\n",
        "\n",
        "  # remove digits under a certain threshold V2\n",
        "  threshold = .1;\n",
        "  ind = []\n",
        "  for i in range(len(classification_v2)):\n",
        "   if(score_v2[i]) < threshold:\n",
        "      ind.append(i)\n",
        "  classification_v2 = np.delete(classification_v2, ind, axis=0)\n",
        "  score_v2 = np.delete(score_v2, ind, axis=0)\n",
        "  boxs_v2 = np.delete(boxs_v2,ind,axis=0)\n",
        "\n",
        "  # V2 remove boxes in the same area \n",
        "  ind = []\n",
        "  for i in range(len(boxs_v2)):\n",
        "    for j in range(len(boxs_v2)):\n",
        "      if (boxs_v2[i][1]> boxs_v2[j][1] and  boxs_v2[i][3] < boxs_v2[j][3]) or abs((boxs_v2[i][1] - boxs_v2[j][1])) < .01 :\n",
        "        if i != j:\n",
        "          if (i>j):\n",
        "            ind.append(i)\n",
        "          else:\n",
        "            ind.append(j)\n",
        "  classification_v2 = np.delete(classification_v2, ind, axis=0)\n",
        "  score_v2 = np.delete(score_v2, ind, axis=0)\n",
        "  boxs_v2 = np.delete(boxs_v2,ind,axis=0)\n",
        " ## V1 remove boxes in the same area \n",
        "  ind = []\n",
        "  for i in range(len(boxs)):\n",
        "    for j in range(len(boxs)):\n",
        "      if (boxs[i][1]> boxs[j][1] and  boxs[i][3] < boxs[j][3]) or abs((boxs[i][1] - boxs[j][1])) < .01 :\n",
        "        if i != j:\n",
        "          if (i>j):\n",
        "            ind.append(i)\n",
        "          else:\n",
        "            ind.append(j)\n",
        "  classification = np.delete(classification, ind, axis=0)\n",
        "  score = np.delete(score, ind, axis=0)\n",
        "  boxs = np.delete(boxs,ind,axis=0)\n",
        "\n",
        "\n",
        "  #Extend V2\n",
        "  for i in range(len(boxs_v2)):\n",
        "    width = boxs_v2[i][3] - boxs_v2[i][1]\n",
        "    if(classification_v2[i] == 2):\n",
        "      width_add = width\n",
        "    else:\n",
        "      width_add = width / 2.5\n",
        "    boxs_v2[i][3] =boxs_v2[i][3] +width_add\n",
        "    boxs_v2[i][1] =boxs_v2[i][1]  - width_add\n",
        "\n",
        "  #Extend V1\n",
        "  for i in range(len(boxs)):\n",
        "    width = boxs[i][3] - boxs[i][1]\n",
        "    height = boxs[i][3] - boxs[i][1]\n",
        "    if(classification[i] == 2):\n",
        "      width_add = height / 2.5\n",
        "    else:\n",
        "      width_add = width / 2.5\n",
        "    boxs[i][3] =boxs[i][3] +width_add\n",
        "    boxs[i][1] =boxs[i][1]  - width_add\n",
        "\n",
        "\n",
        "  # remove tall / long  boxes V2 \n",
        "  med_width = []\n",
        "  med_height = []\n",
        "  for i in range(len(boxs_v2)):\n",
        "    med_width.append(abs(boxs_v2[i][3]-boxs_v2[i][1]))\n",
        "    med_height.append(abs(boxs_v2[i][2]-boxs_v2[i][0]))\n",
        "  if(len(boxs_v2) > 0):\n",
        "    med_width = statistics.median(med_width)\n",
        "    med_height = statistics.median(med_height)\n",
        "  ind = [] \n",
        "  for i in range(len(boxs_v2)):\n",
        "    if(abs(abs(boxs_v2[i][3]-boxs_v2[i][1]) - med_width) > .15):\n",
        "      ind.append(i)\n",
        "    elif (abs(abs(boxs_v2[i][2]-boxs_v2[i][0]) - med_height) > .15):\n",
        "      ind.append(i)\n",
        "  classification_v2 = np.delete(classification_v2, ind, axis=0)\n",
        "  score_v2 = np.delete(score_v2, ind, axis=0)\n",
        "  boxs_v2 = np.delete(boxs_v2,ind,axis=0)\n",
        "\n",
        "\n",
        "  # remove tall / long  boxes V1\n",
        "  med_width = []\n",
        "  med_height = []\n",
        "  for i in range(len(boxs)):\n",
        "    med_width.append(abs(boxs[i][3]-boxs[i][1]))\n",
        "    med_height.append(abs(boxs[i][2]-boxs[i][0]))\n",
        "  if(len(boxs) > 0):\n",
        "    med_width = statistics.median(med_width)\n",
        "    med_height = statistics.median(med_height)\n",
        "  ind = [] \n",
        "  for i in range(len(boxs)):\n",
        "    if(abs(abs(boxs[i][3]-boxs[i][1]) - med_width) > .15):\n",
        "      ind.append(i)\n",
        "    elif (abs(abs(boxs[i][2]-boxs[i][0]) - med_height) > .15):\n",
        "      ind.append(i)\n",
        "  classification = np.delete(classification, ind, axis=0)\n",
        "  score = np.delete(score, ind, axis=0)\n",
        "  boxs = np.delete(boxs,ind,axis=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  dic = {}\n",
        "  #############################################################################################\n",
        "  # check to see if they are close in width and height  ( NEEDS TO BE CHANGED BASED ON MODEL) #\n",
        "  ############################################################################################# \n",
        "  for i in range(len(boxs_v2)):\n",
        "    width = boxs_v2[i][3] - boxs_v2[i][1]\n",
        "    for j in range(len(boxs_v2)):\n",
        "      dif_width = boxs_v2[i][3] - boxs_v2[j][1]\n",
        "      dif_height = boxs_v2[i][0] - boxs_v2[j][0]\n",
        "      if (i !=j) and dif_width > 0 and dif_height < .1 and abs(dif_width) < .1 :\n",
        "        if not(j in dic and dic[j] == i):\n",
        "          dic[i] = j\n",
        "  G = nx.DiGraph()\n",
        "  G.add_edges_from(dic.items())\n",
        "  try:\n",
        "    path = nx.dag_longest_path(G)\n",
        "  except nx.exception.NetworkXUnfeasible: # There's a loop!\n",
        "    print(\"The graph has a cycle\")\n",
        "    path = []\n",
        "  final = []\n",
        "  for i in range(len(path)):\n",
        "    final.append(classification_v2[path[i]] -1)\n",
        "  if len(final) == 0:\n",
        "    final_int = 0\n",
        "    print('empty')\n",
        "  else:\n",
        "    final_string = listToString(final)\n",
        "    final_int = int(final_string)\n",
        "    if(len(final_string) >6 or final_int > 300000 ):\n",
        "      final_int = int(str(final_int)[:-1])\n",
        "    print(final_int)\n",
        "  mileage[count] = final_int;\n",
        "  # Visualization of the results of a detection.\n",
        "  count = count + 1;\n",
        "  #vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "  #    image_np,\n",
        "  #    output_dict['detection_boxes'],\n",
        "   #   output_dict['detection_classes'],\n",
        "   #   output_dict['detection_scores'],\n",
        "   #   category_index,\n",
        "   #   instance_masks=output_dict.get('detection_masks'),\n",
        "  #    use_normalized_coordinates=True,\n",
        "  #    line_thickness=1, mask_alpha = .1, min_score_thresh = .05, max_boxes_to_draw = 25)\n",
        "  #plt.figure(figsize=IMAGE_SIZE)\n",
        "  # Visualization of the results of v2 detection\n",
        "  #plt.imshow(image_np)\n",
        "\n",
        "  #vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "  #    image_np,\n",
        "  #    boxs_v2,\n",
        "  #    classification_v2,\n",
        "  #    score_v2,\n",
        "  #    category_index,\n",
        "  #    instance_masks=output_dict_v2.get('detection_masks'),\n",
        "  #    use_normalized_coordinates=True,\n",
        "  #    line_thickness=4, mask_alpha = .1, min_score_thresh = .01, max_boxes_to_draw = 25)\n",
        "  #plt.figure(figsize=IMAGE_SIZE)\n",
        "  #plt.imshow(image_np)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUmat5NW0kOX",
        "outputId": "6f5d1080-e0f3-4ce7-b0ef-3b0277e3b87d"
      },
      "source": [
        "#count = 0 \n",
        "#for image_path in TEST_IMAGE_PATHS:\n",
        "#  file_name[count] = image_path[26:]\n",
        "#  count = count +1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk6OFmZ0e9gN"
      },
      "source": [
        "!cp /root/models/test_cropped /content/drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1I3OItKMByK8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "e1a707a4-6ab7-43d0-a81f-c4d7023c84ae"
      },
      "source": [
        "compression_opts = dict(method='zip',\n",
        "                        archive_name='digit_result_v2_extend1_longer_train_2.csv') \n",
        "df_.to_csv('digit_result_v2_extend1_longer_train_2.zip', index=False,\n",
        "          compression=compression_opts) "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-00bacc3a0bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m compression_opts = dict(method='zip',\n\u001b[1;32m      2\u001b[0m                         archive_name='digit_result_v2_extend1_longer_train_2.csv') \n\u001b[0;32m----> 3\u001b[0;31m df_.to_csv('digit_result_v2_extend1_longer_train_2.zip', index=False,\n\u001b[0m\u001b[1;32m      4\u001b[0m           compression=compression_opts) \n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cer0xMgUbEgJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1613820a-6d51-4ee5-869d-1884501f2326"
      },
      "source": [
        "!cp -r /root/models/digit_result_v2_extend1_longer_train_2.zip /content/drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/root/models/digit_result_v1_extend1.zip': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
